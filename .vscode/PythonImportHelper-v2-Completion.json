[
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "zip_longest",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DateOffset",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "makedirs",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "environ",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generic",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generic",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "SupportsFloat",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TextIO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "SupportsFloat",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Protocol",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "SupportsFloat",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Final",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "dateutil.parser",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "HTTPError",
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "isExtraImport": true,
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "perf_counter",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "perf_counter",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "perf_counter",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "alpaca_trade_api",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "isExtraImport": true,
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "aiohttp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiohttp",
        "description": "aiohttp",
        "detail": "aiohttp",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "CancelledError",
        "importPath": "asyncio",
        "description": "asyncio",
        "isExtraImport": true,
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "CancelledError",
        "importPath": "asyncio",
        "description": "asyncio",
        "isExtraImport": true,
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "CancelledError",
        "importPath": "asyncio",
        "description": "asyncio",
        "isExtraImport": true,
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "BarsV2",
        "importPath": "alpaca_trade_api.entity_v2",
        "description": "alpaca_trade_api.entity_v2",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "QuotesV2",
        "importPath": "alpaca_trade_api.entity_v2",
        "description": "alpaca_trade_api.entity_v2",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "TradesV2",
        "importPath": "alpaca_trade_api.entity_v2",
        "description": "alpaca_trade_api.entity_v2",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "alpaca_trade_api.entity_v2",
        "description": "alpaca_trade_api.entity_v2",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "URL",
        "importPath": "alpaca_trade_api.common",
        "description": "alpaca_trade_api.common",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_credentials",
        "importPath": "alpaca_trade_api.common",
        "description": "alpaca_trade_api.common",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_data_url",
        "importPath": "alpaca_trade_api.common",
        "description": "alpaca_trade_api.common",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "UserDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "UserDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "UserDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "msgpack",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "msgpack",
        "description": "msgpack",
        "detail": "msgpack",
        "documentation": {}
    },
    {
        "label": "websockets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "websockets",
        "description": "websockets",
        "detail": "websockets",
        "documentation": {}
    },
    {
        "label": "queue",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "queue",
        "description": "queue",
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Empty",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Empty",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Empty",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "APIError",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca_trade_api.rest",
        "description": "alpaca_trade_api.rest",
        "isExtraImport": true,
        "detail": "alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "requests_mock",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests_mock",
        "description": "requests_mock",
        "detail": "requests_mock",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "stable_baselines3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "PaperTradingAlpaca",
        "importPath": "finrl.meta.paper_trading.alpaca",
        "description": "finrl.meta.paper_trading.alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "test",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "BDay",
        "importPath": "pandas.tseries.offsets",
        "description": "pandas.tseries.offsets",
        "isExtraImport": true,
        "detail": "pandas.tseries.offsets",
        "documentation": {}
    },
    {
        "label": "BDay",
        "importPath": "pandas.tseries.offsets",
        "description": "pandas.tseries.offsets",
        "isExtraImport": true,
        "detail": "pandas.tseries.offsets",
        "documentation": {}
    },
    {
        "label": "finrl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "finrl",
        "description": "finrl",
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "stock_trading",
        "importPath": "finrl.applications.stock_trading.stock_trading",
        "description": "finrl.applications.stock_trading.stock_trading",
        "isExtraImport": true,
        "detail": "finrl.applications.stock_trading.stock_trading",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "float_info",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "exit",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "exit",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "exit",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "flash",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "url_for",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "gym",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gym",
        "description": "gym",
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "numpy.random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.random",
        "description": "numpy.random",
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Lock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "currentThread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Lock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "currentThread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Lock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "currentThread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "exchange_calendars",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "exchange_calendars",
        "description": "exchange_calendars",
        "detail": "exchange_calendars",
        "documentation": {}
    },
    {
        "label": "pytz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytz",
        "description": "pytz",
        "detail": "pytz",
        "documentation": {}
    },
    {
        "label": "yfinance",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yfinance",
        "description": "yfinance",
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "Ticker",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "Ticker",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "Ticker",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "Ticker",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "Ticker",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "yfinance",
        "description": "yfinance",
        "isExtraImport": true,
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "matplotlib.ticker",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "matplotlib.dates",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.dates",
        "description": "matplotlib.dates",
        "detail": "matplotlib.dates",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "importPath": "alpaca.trading.enums",
        "description": "alpaca.trading.enums",
        "isExtraImport": true,
        "detail": "alpaca.trading.enums",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "importPath": "alpaca.trading.enums",
        "description": "alpaca.trading.enums",
        "isExtraImport": true,
        "detail": "alpaca.trading.enums",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "importPath": "alpaca.trading.enums",
        "description": "alpaca.trading.enums",
        "isExtraImport": true,
        "detail": "alpaca.trading.enums",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "importPath": "alpaca.trading.enums",
        "description": "alpaca.trading.enums",
        "isExtraImport": true,
        "detail": "alpaca.trading.enums",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "importPath": "alpaca.trading.enums",
        "description": "alpaca.trading.enums",
        "isExtraImport": true,
        "detail": "alpaca.trading.enums",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "importPath": "alpaca.trading.enums",
        "description": "alpaca.trading.enums",
        "isExtraImport": true,
        "detail": "alpaca.trading.enums",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "ta",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ta",
        "description": "ta",
        "detail": "ta",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "AutoTS",
        "importPath": "autots",
        "description": "autots",
        "isExtraImport": true,
        "detail": "autots",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "ThetaDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "ThetaDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "ThetaDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "AlpacaBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lumibot.backtesting",
        "description": "lumibot.backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Broker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers",
        "description": "lumibot.brokers",
        "isExtraImport": true,
        "detail": "lumibot.brokers",
        "documentation": {}
    },
    {
        "label": "lumibot.entities",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Position",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Bars",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Order",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities",
        "description": "lumibot.entities",
        "isExtraImport": true,
        "detail": "lumibot.entities",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Asset",
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "isExtraImport": true,
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "isExtraImport": true,
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders",
        "description": "lumibot.traders",
        "isExtraImport": true,
        "detail": "lumibot.traders",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "importPath": "credentials",
        "description": "credentials",
        "isExtraImport": true,
        "detail": "credentials",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "jprint",
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "isExtraImport": true,
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "lib.rl.agents.elegantrl",
        "description": "lib.rl.agents.elegantrl",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "lib.rl.agents.elegantrl",
        "description": "lib.rl.agents.elegantrl",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "lib.rl.agents.elegantrl",
        "description": "lib.rl.agents.elegantrl",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "lib.rl.agents.elegantrl.models ",
        "description": "lib.rl.agents.elegantrl.models ",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl.models ",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "lib.rl.agents.elegantrl.models ",
        "description": "lib.rl.agents.elegantrl.models ",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl.models ",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "lib.rl.agents.elegantrl.models ",
        "description": "lib.rl.agents.elegantrl.models ",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl.models ",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Batch",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Batch",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Batch",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "RGCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "RGCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "RGCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "to_dense_batch",
        "importPath": "torch_geometric.utils",
        "description": "torch_geometric.utils",
        "isExtraImport": true,
        "detail": "torch_geometric.utils",
        "documentation": {}
    },
    {
        "label": "to_dense_batch",
        "importPath": "torch_geometric.utils",
        "description": "torch_geometric.utils",
        "isExtraImport": true,
        "detail": "torch_geometric.utils",
        "documentation": {}
    },
    {
        "label": "to_dense_batch",
        "importPath": "torch_geometric.utils",
        "description": "torch_geometric.utils",
        "isExtraImport": true,
        "detail": "torch_geometric.utils",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "torch.utils.data.dataset",
        "description": "torch.utils.data.dataset",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataset",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "torch.utils.data.dataset",
        "description": "torch.utils.data.dataset",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataset",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "torch.utils.data.dataset",
        "description": "torch.utils.data.dataset",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataset",
        "documentation": {}
    },
    {
        "label": "ray",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ray",
        "description": "ray",
        "detail": "ray",
        "documentation": {}
    },
    {
        "label": "tune",
        "importPath": "ray",
        "description": "ray",
        "isExtraImport": true,
        "detail": "ray",
        "documentation": {}
    },
    {
        "label": "tune",
        "importPath": "ray",
        "description": "ray",
        "isExtraImport": true,
        "detail": "ray",
        "documentation": {}
    },
    {
        "label": "tune",
        "importPath": "ray",
        "description": "ray",
        "isExtraImport": true,
        "detail": "ray",
        "documentation": {}
    },
    {
        "label": "ConcurrencyLimiter",
        "importPath": "ray.tune.search",
        "description": "ray.tune.search",
        "isExtraImport": true,
        "detail": "ray.tune.search",
        "documentation": {}
    },
    {
        "label": "ConcurrencyLimiter",
        "importPath": "ray.tune.search",
        "description": "ray.tune.search",
        "isExtraImport": true,
        "detail": "ray.tune.search",
        "documentation": {}
    },
    {
        "label": "ConcurrencyLimiter",
        "importPath": "ray.tune.search",
        "description": "ray.tune.search",
        "isExtraImport": true,
        "detail": "ray.tune.search",
        "documentation": {}
    },
    {
        "label": "Algorithm",
        "importPath": "ray.rllib.algorithms",
        "description": "ray.rllib.algorithms",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms",
        "documentation": {}
    },
    {
        "label": "Algorithm",
        "importPath": "ray.rllib.algorithms",
        "description": "ray.rllib.algorithms",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms",
        "documentation": {}
    },
    {
        "label": "Algorithm",
        "importPath": "ray.rllib.algorithms",
        "description": "ray.rllib.algorithms",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms",
        "documentation": {}
    },
    {
        "label": "register_env",
        "importPath": "ray.tune",
        "description": "ray.tune",
        "isExtraImport": true,
        "detail": "ray.tune",
        "documentation": {}
    },
    {
        "label": "register_env",
        "importPath": "ray.tune",
        "description": "ray.tune",
        "isExtraImport": true,
        "detail": "ray.tune",
        "documentation": {}
    },
    {
        "label": "register_env",
        "importPath": "ray.tune",
        "description": "ray.tune",
        "isExtraImport": true,
        "detail": "ray.tune",
        "documentation": {}
    },
    {
        "label": "RunConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "FailureConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "ScalingConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "RunConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "FailureConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "ScalingConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "RunConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "FailureConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "ScalingConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "TuneConfig",
        "importPath": "ray.tune.tune_config",
        "description": "ray.tune.tune_config",
        "isExtraImport": true,
        "detail": "ray.tune.tune_config",
        "documentation": {}
    },
    {
        "label": "TuneConfig",
        "importPath": "ray.tune.tune_config",
        "description": "ray.tune.tune_config",
        "isExtraImport": true,
        "detail": "ray.tune.tune_config",
        "documentation": {}
    },
    {
        "label": "TuneConfig",
        "importPath": "ray.tune.tune_config",
        "description": "ray.tune.tune_config",
        "isExtraImport": true,
        "detail": "ray.tune.tune_config",
        "documentation": {}
    },
    {
        "label": "CheckpointConfig",
        "importPath": "ray.air.config",
        "description": "ray.air.config",
        "isExtraImport": true,
        "detail": "ray.air.config",
        "documentation": {}
    },
    {
        "label": "CheckpointConfig",
        "importPath": "ray.air.config",
        "description": "ray.air.config",
        "isExtraImport": true,
        "detail": "ray.air.config",
        "documentation": {}
    },
    {
        "label": "CheckpointConfig",
        "importPath": "ray.air.config",
        "description": "ray.air.config",
        "isExtraImport": true,
        "detail": "ray.air.config",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "a2c",
        "importPath": "ray.rllib.algorithms.a2c",
        "description": "ray.rllib.algorithms.a2c",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.a2c",
        "documentation": {}
    },
    {
        "label": "a2c",
        "importPath": "ray.rllib.algorithms.a2c",
        "description": "ray.rllib.algorithms.a2c",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.a2c",
        "documentation": {}
    },
    {
        "label": "a2c",
        "importPath": "ray.rllib.algorithms.a2c",
        "description": "ray.rllib.algorithms.a2c",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.a2c",
        "documentation": {}
    },
    {
        "label": "ddpg",
        "importPath": "ray.rllib.algorithms.ddpg",
        "description": "ray.rllib.algorithms.ddpg",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ddpg",
        "documentation": {}
    },
    {
        "label": "ddpg",
        "importPath": "ray.rllib.algorithms.ddpg",
        "description": "ray.rllib.algorithms.ddpg",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ddpg",
        "documentation": {}
    },
    {
        "label": "ddpg",
        "importPath": "ray.rllib.algorithms.ddpg",
        "description": "ray.rllib.algorithms.ddpg",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ddpg",
        "documentation": {}
    },
    {
        "label": "ppo",
        "importPath": "ray.rllib.algorithms.ppo",
        "description": "ray.rllib.algorithms.ppo",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ppo",
        "documentation": {}
    },
    {
        "label": "ppo",
        "importPath": "ray.rllib.algorithms.ppo",
        "description": "ray.rllib.algorithms.ppo",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ppo",
        "documentation": {}
    },
    {
        "label": "ppo",
        "importPath": "ray.rllib.algorithms.ppo",
        "description": "ray.rllib.algorithms.ppo",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ppo",
        "documentation": {}
    },
    {
        "label": "sac",
        "importPath": "ray.rllib.algorithms.sac",
        "description": "ray.rllib.algorithms.sac",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.sac",
        "documentation": {}
    },
    {
        "label": "sac",
        "importPath": "ray.rllib.algorithms.sac",
        "description": "ray.rllib.algorithms.sac",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.sac",
        "documentation": {}
    },
    {
        "label": "sac",
        "importPath": "ray.rllib.algorithms.sac",
        "description": "ray.rllib.algorithms.sac",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.sac",
        "documentation": {}
    },
    {
        "label": "td3",
        "importPath": "ray.rllib.algorithms.td3",
        "description": "ray.rllib.algorithms.td3",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.td3",
        "documentation": {}
    },
    {
        "label": "td3",
        "importPath": "ray.rllib.algorithms.td3",
        "description": "ray.rllib.algorithms.td3",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.td3",
        "documentation": {}
    },
    {
        "label": "td3",
        "importPath": "ray.rllib.algorithms.td3",
        "description": "ray.rllib.algorithms.td3",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.td3",
        "documentation": {}
    },
    {
        "label": "gymnasium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gymnasium",
        "description": "gymnasium",
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "Env",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "RolloutBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "DictReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "DictRolloutBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "RolloutBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "DictReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "RolloutBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "importPath": "stable_baselines3.common.buffers",
        "description": "stable_baselines3.common.buffers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "OnPolicyAlgorithm",
        "importPath": "stable_baselines3.common.on_policy_algorithm",
        "description": "stable_baselines3.common.on_policy_algorithm",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.on_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "OnPolicyAlgorithm",
        "importPath": "stable_baselines3.common.on_policy_algorithm",
        "description": "stable_baselines3.common.on_policy_algorithm",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.on_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "ActorCriticCnnPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticCnnPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticCnnPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticCnnPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputActorCriticPolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ContinuousCritic",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ContinuousCritic",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ContinuousCritic",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ContinuousCritic",
        "importPath": "stable_baselines3.common.policies",
        "description": "stable_baselines3.common.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymStepReturn",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymStepReturn",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymStepReturn",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "AtariResetReturn",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "AtariStepReturn",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "DictReplayBufferSamples",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "DictRolloutBufferSamples",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "ReplayBufferSamples",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "RolloutBufferSamples",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "RolloutReturn",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TrainFreq",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TrainFrequencyUnit",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "PyTorchObs",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TrainFreq",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TrainFrequencyUnit",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "PyTorchObs",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "DictReplayBufferSamples",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "PyTorchObs",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "PyTorchObs",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "importPath": "stable_baselines3.common.type_aliases",
        "description": "stable_baselines3.common.type_aliases",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "explained_variance",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "check_for_correct_spaces",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_schedule_fn",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_system_info",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "update_learning_rate",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "safe_mean",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "should_collect_more_steps",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "obs_as_tensor",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "safe_mean",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_observation",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "obs_as_tensor",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_system_info",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_linear_fn",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_parameters_by_name",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "polyak_update",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "explained_variance",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_schedule_fn",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_parameters_by_name",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "polyak_update",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_parameters_by_name",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "polyak_update",
        "importPath": "stable_baselines3.common.utils",
        "description": "stable_baselines3.common.utils",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "EnvSpec",
        "importPath": "gymnasium.envs.registration",
        "description": "gymnasium.envs.registration",
        "isExtraImport": true,
        "detail": "gymnasium.envs.registration",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "signature",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "cloudpickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cloudpickle",
        "description": "cloudpickle",
        "detail": "cloudpickle",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvIndices",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "CloudpickleWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvIndices",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "importPath": "stable_baselines3.common.vec_env.base_vec_env",
        "description": "stable_baselines3.common.vec_env.base_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "_patch_env",
        "importPath": "stable_baselines3.common.vec_env.patch_gym",
        "description": "stable_baselines3.common.vec_env.patch_gym",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.patch_gym",
        "documentation": {}
    },
    {
        "label": "_patch_env",
        "importPath": "stable_baselines3.common.vec_env.patch_gym",
        "description": "stable_baselines3.common.vec_env.patch_gym",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.patch_gym",
        "documentation": {}
    },
    {
        "label": "_convert_space",
        "importPath": "stable_baselines3.common.vec_env.patch_gym",
        "description": "stable_baselines3.common.vec_env.patch_gym",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.patch_gym",
        "documentation": {}
    },
    {
        "label": "_patch_env",
        "importPath": "stable_baselines3.common.vec_env.patch_gym",
        "description": "stable_baselines3.common.vec_env.patch_gym",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.patch_gym",
        "documentation": {}
    },
    {
        "label": "_patch_env",
        "importPath": "stable_baselines3.common.vec_env.patch_gym",
        "description": "stable_baselines3.common.vec_env.patch_gym",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.patch_gym",
        "documentation": {}
    },
    {
        "label": "copy_obs_dict",
        "importPath": "stable_baselines3.common.vec_env.util",
        "description": "stable_baselines3.common.vec_env.util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.util",
        "documentation": {}
    },
    {
        "label": "dict_to_obs",
        "importPath": "stable_baselines3.common.vec_env.util",
        "description": "stable_baselines3.common.vec_env.util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.util",
        "documentation": {}
    },
    {
        "label": "obs_space_info",
        "importPath": "stable_baselines3.common.vec_env.util",
        "description": "stable_baselines3.common.vec_env.util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.util",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space_channels_first",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "check_for_nested_spaces",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space_channels_first",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "check_for_nested_spaces",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space_channels_first",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_action_dim",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_obs_shape",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_action_dim",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "check_for_nested_spaces",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space_channels_first",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_action_dim",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "maybe_transpose",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "preprocess_obs",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_flattened_obs_dim",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_action_dim",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_action_dim",
        "importPath": "stable_baselines3.common.preprocessing",
        "description": "stable_baselines3.common.preprocessing",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "StackedObservations",
        "importPath": "stable_baselines3.common.vec_env.stacked_observations",
        "description": "stable_baselines3.common.vec_env.stacked_observations",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.stacked_observations",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "utils",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "utils",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "type_aliases",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "RunningMeanStd",
        "importPath": "stable_baselines3.common.running_mean_std",
        "description": "stable_baselines3.common.running_mean_std",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.running_mean_std",
        "documentation": {}
    },
    {
        "label": "video_recorder",
        "importPath": "gymnasium.wrappers.monitoring",
        "description": "gymnasium.wrappers.monitoring",
        "isExtraImport": true,
        "detail": "gymnasium.wrappers.monitoring",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env.dummy_vec_env",
        "description": "stable_baselines3.common.vec_env.dummy_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.dummy_vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env.subproc_vec_env",
        "description": "stable_baselines3.common.vec_env.subproc_vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env.subproc_vec_env",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "TextIOBase",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "CallbackList",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "ConvertCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "ProgressBarCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "is_wrapped",
        "importPath": "stable_baselines3.common.env_util",
        "description": "stable_baselines3.common.env_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.env_util",
        "documentation": {}
    },
    {
        "label": "Monitor",
        "importPath": "stable_baselines3.common.monitor",
        "description": "stable_baselines3.common.monitor",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "Monitor",
        "importPath": "stable_baselines3.common.monitor",
        "description": "stable_baselines3.common.monitor",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "load_results",
        "importPath": "stable_baselines3.common.monitor",
        "description": "stable_baselines3.common.monitor",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "ActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "ActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "VectorizedActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "ActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "ActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "ActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "load_from_zip_file",
        "importPath": "stable_baselines3.common.save_util",
        "description": "stable_baselines3.common.save_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "recursive_getattr",
        "importPath": "stable_baselines3.common.save_util",
        "description": "stable_baselines3.common.save_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "recursive_setattr",
        "importPath": "stable_baselines3.common.save_util",
        "description": "stable_baselines3.common.save_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "save_to_zip_file",
        "importPath": "stable_baselines3.common.save_util",
        "description": "stable_baselines3.common.save_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "load_from_pkl",
        "importPath": "stable_baselines3.common.save_util",
        "description": "stable_baselines3.common.save_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "save_to_pkl",
        "importPath": "stable_baselines3.common.save_util",
        "description": "stable_baselines3.common.save_util",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecNormalize",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecTransposeImage",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "is_vecenv_wrapped",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "unwrap_vec_normalize",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecNormalize",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "sync_envs_normalization",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecCheckNan",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecMonitor",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "is_vecenv_wrapped",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "VecNormalize",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "evaluate_policy",
        "importPath": "stable_baselines3.common.evaluation",
        "description": "stable_baselines3.common.evaluation",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.evaluation",
        "documentation": {}
    },
    {
        "label": "Bernoulli",
        "importPath": "torch.distributions",
        "description": "torch.distributions",
        "isExtraImport": true,
        "detail": "torch.distributions",
        "documentation": {}
    },
    {
        "label": "Categorical",
        "importPath": "torch.distributions",
        "description": "torch.distributions",
        "isExtraImport": true,
        "detail": "torch.distributions",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions",
        "description": "torch.distributions",
        "isExtraImport": true,
        "detail": "torch.distributions",
        "documentation": {}
    },
    {
        "label": "AtariWrapper",
        "importPath": "stable_baselines3.common.atari_wrappers",
        "description": "stable_baselines3.common.atari_wrappers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "matplotlib.figure",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.figure",
        "description": "matplotlib.figure",
        "detail": "matplotlib.figure",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "ActType",
        "importPath": "gymnasium.core",
        "description": "gymnasium.core",
        "isExtraImport": true,
        "detail": "gymnasium.core",
        "documentation": {}
    },
    {
        "label": "ObsType",
        "importPath": "gymnasium.core",
        "description": "gymnasium.core",
        "isExtraImport": true,
        "detail": "gymnasium.core",
        "documentation": {}
    },
    {
        "label": "numpy.typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "DTypeLike",
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "isExtraImport": true,
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "BaseAlgorithm",
        "importPath": "stable_baselines3.common.base_class",
        "description": "stable_baselines3.common.base_class",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.base_class",
        "documentation": {}
    },
    {
        "label": "BaseAlgorithm",
        "importPath": "stable_baselines3.common.base_class",
        "description": "stable_baselines3.common.base_class",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.base_class",
        "documentation": {}
    },
    {
        "label": "HerReplayBuffer",
        "importPath": "stable_baselines3.her.her_replay_buffer",
        "description": "stable_baselines3.her.her_replay_buffer",
        "isExtraImport": true,
        "detail": "stable_baselines3.her.her_replay_buffer",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "BernoulliDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "CategoricalDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "DiagGaussianDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "Distribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "MultiCategoricalDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "StateDependentNoiseDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "make_proba_distribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SquashedDiagGaussianDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "StateDependentNoiseDistribution",
        "importPath": "stable_baselines3.common.distributions",
        "description": "stable_baselines3.common.distributions",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "BaseFeaturesExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "CombinedExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "FlattenExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "MlpExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "NatureCNN",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "create_mlp",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "BaseFeaturesExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "CombinedExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "FlattenExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "NatureCNN",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "create_mlp",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "BaseFeaturesExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "CombinedExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "FlattenExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "NatureCNN",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "create_mlp",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "get_actor_critic_arch",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "BaseFeaturesExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "CombinedExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "FlattenExtractor",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "NatureCNN",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "create_mlp",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "get_actor_critic_arch",
        "importPath": "stable_baselines3.common.torch_layers",
        "description": "stable_baselines3.common.torch_layers",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "TD3Policy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "Actor",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "TD3Policy",
        "importPath": "stable_baselines3.td3.policies",
        "description": "stable_baselines3.td3.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3.td3.td3",
        "description": "stable_baselines3.td3.td3",
        "isExtraImport": true,
        "detail": "stable_baselines3.td3.td3",
        "documentation": {}
    },
    {
        "label": "OffPolicyAlgorithm",
        "importPath": "stable_baselines3.common.off_policy_algorithm",
        "description": "stable_baselines3.common.off_policy_algorithm",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.off_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "OffPolicyAlgorithm",
        "importPath": "stable_baselines3.common.off_policy_algorithm",
        "description": "stable_baselines3.common.off_policy_algorithm",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.off_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "OffPolicyAlgorithm",
        "importPath": "stable_baselines3.common.off_policy_algorithm",
        "description": "stable_baselines3.common.off_policy_algorithm",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.off_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "importPath": "stable_baselines3.dqn.policies",
        "description": "stable_baselines3.dqn.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "DQNPolicy",
        "importPath": "stable_baselines3.dqn.policies",
        "description": "stable_baselines3.dqn.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "importPath": "stable_baselines3.dqn.policies",
        "description": "stable_baselines3.dqn.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "importPath": "stable_baselines3.dqn.policies",
        "description": "stable_baselines3.dqn.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "QNetwork",
        "importPath": "stable_baselines3.dqn.policies",
        "description": "stable_baselines3.dqn.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "KEY_TO_GOAL_STRATEGY",
        "importPath": "stable_baselines3.her.goal_selection_strategy",
        "description": "stable_baselines3.her.goal_selection_strategy",
        "isExtraImport": true,
        "detail": "stable_baselines3.her.goal_selection_strategy",
        "documentation": {}
    },
    {
        "label": "GoalSelectionStrategy",
        "importPath": "stable_baselines3.her.goal_selection_strategy",
        "description": "stable_baselines3.her.goal_selection_strategy",
        "isExtraImport": true,
        "detail": "stable_baselines3.her.goal_selection_strategy",
        "documentation": {}
    },
    {
        "label": "Actor",
        "importPath": "stable_baselines3.sac.policies",
        "description": "stable_baselines3.sac.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "importPath": "stable_baselines3.sac.policies",
        "description": "stable_baselines3.sac.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "importPath": "stable_baselines3.sac.policies",
        "description": "stable_baselines3.sac.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "importPath": "stable_baselines3.sac.policies",
        "description": "stable_baselines3.sac.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "SACPolicy",
        "importPath": "stable_baselines3.sac.policies",
        "description": "stable_baselines3.sac.policies",
        "isExtraImport": true,
        "detail": "stable_baselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "optuna",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "optuna",
        "description": "optuna",
        "detail": "optuna",
        "documentation": {}
    },
    {
        "label": "linear_schedule",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "linear_schedule",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "linear_schedule",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_FRAME_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_FRAME_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_FRAME_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_FRAME_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "isExtraImport": true,
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "lib.rl",
        "description": "lib.rl",
        "isExtraImport": true,
        "detail": "lib.rl",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "finrl.agents.stablebaselines3.hyperparams_opt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "finrl.agents.stablebaselines3.hyperparams_opt",
        "description": "finrl.agents.stablebaselines3.hyperparams_opt",
        "detail": "finrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "concurrent.futures",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "calendar",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "calendar",
        "description": "calendar",
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "ccxt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ccxt",
        "description": "ccxt",
        "detail": "ccxt",
        "documentation": {}
    },
    {
        "label": "jqdatasdk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jqdatasdk",
        "description": "jqdatasdk",
        "detail": "jqdatasdk",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "wrds",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wrds",
        "description": "wrds",
        "detail": "wrds",
        "documentation": {}
    },
    {
        "label": "Timestamp",
        "importPath": "sqlite3",
        "description": "sqlite3",
        "isExtraImport": true,
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "Timestamp",
        "importPath": "sqlite3",
        "description": "sqlite3",
        "isExtraImport": true,
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "Timestamp",
        "importPath": "sqlite3",
        "description": "sqlite3",
        "isExtraImport": true,
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pow",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "gcd",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "e",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "gcd",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "e",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "gcd",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "e",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gym.utils",
        "description": "gym.utils",
        "isExtraImport": true,
        "detail": "gym.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gym.utils",
        "description": "gym.utils",
        "isExtraImport": true,
        "detail": "gym.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gym.utils",
        "description": "gym.utils",
        "isExtraImport": true,
        "detail": "gym.utils",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "sector_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "usa_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "sector_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "usa_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "sector_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "usa_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "isExtraImport": true,
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result ;",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result ;",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result ;",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "isExtraImport": true,
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "Value",
        "importPath": "multiprocessing.sharedctypes",
        "description": "multiprocessing.sharedctypes",
        "isExtraImport": true,
        "detail": "multiprocessing.sharedctypes",
        "documentation": {}
    },
    {
        "label": "Value",
        "importPath": "multiprocessing.sharedctypes",
        "description": "multiprocessing.sharedctypes",
        "isExtraImport": true,
        "detail": "multiprocessing.sharedctypes",
        "documentation": {}
    },
    {
        "label": "Value",
        "importPath": "multiprocessing.sharedctypes",
        "description": "multiprocessing.sharedctypes",
        "isExtraImport": true,
        "detail": "multiprocessing.sharedctypes",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "MaxAbsScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MaxAbsScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MaxAbsScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "tushare",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tushare",
        "description": "tushare",
        "detail": "tushare",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_wrds",
        "description": "lib.rl.meta.data_processors.processor_wrds",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_wrds",
        "description": "lib.rl.meta.data_processors.processor_wrds",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_wrds",
        "description": "lib.rl.meta.data_processors.processor_wrds",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_yahoofinance",
        "description": "lib.rl.meta.data_processors.processor_yahoofinance",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_yahoofinance",
        "description": "lib.rl.meta.data_processors.processor_yahoofinance",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "importPath": "lib.rl.meta.data_processors.processor_yahoofinance",
        "description": "lib.rl.meta.data_processors.processor_yahoofinance",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pyfolio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyfolio",
        "description": "pyfolio",
        "detail": "pyfolio",
        "documentation": {}
    },
    {
        "label": "timeseries",
        "importPath": "pyfolio",
        "description": "pyfolio",
        "isExtraImport": true,
        "detail": "pyfolio",
        "documentation": {}
    },
    {
        "label": "timeseries",
        "importPath": "pyfolio",
        "description": "pyfolio",
        "isExtraImport": true,
        "detail": "pyfolio",
        "documentation": {}
    },
    {
        "label": "timeseries",
        "importPath": "pyfolio",
        "description": "pyfolio",
        "isExtraImport": true,
        "detail": "pyfolio",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "test",
        "importPath": "lib.rl.test",
        "description": "lib.rl.test",
        "isExtraImport": true,
        "detail": "lib.rl.test",
        "documentation": {}
    },
    {
        "label": "test",
        "importPath": "lib.rl.test",
        "description": "lib.rl.test",
        "isExtraImport": true,
        "detail": "lib.rl.test",
        "documentation": {}
    },
    {
        "label": "test",
        "importPath": "lib.rl.test",
        "description": "lib.rl.test",
        "isExtraImport": true,
        "detail": "lib.rl.test",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "nltk.sentiment.vader",
        "description": "nltk.sentiment.vader",
        "isExtraImport": true,
        "detail": "nltk.sentiment.vader",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "nltk.sentiment.vader",
        "description": "nltk.sentiment.vader",
        "isExtraImport": true,
        "detail": "nltk.sentiment.vader",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "nltk.sentiment.vader",
        "description": "nltk.sentiment.vader",
        "isExtraImport": true,
        "detail": "nltk.sentiment.vader",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "nltk.sentiment.vader",
        "description": "nltk.sentiment.vader",
        "isExtraImport": true,
        "detail": "nltk.sentiment.vader",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "nltk.sentiment.vader",
        "description": "nltk.sentiment.vader",
        "isExtraImport": true,
        "detail": "nltk.sentiment.vader",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urlopen",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "isExtraImport": true,
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "isExtraImport": true,
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "isExtraImport": true,
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "isExtraImport": true,
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "isExtraImport": true,
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "lib.MLTradingBot.finbert_utils",
        "description": "lib.MLTradingBot.finbert_utils",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "lib.MLTradingBot.finbert_utils",
        "description": "lib.MLTradingBot.finbert_utils",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "lib.MLTradingBot.finbert_utils",
        "description": "lib.MLTradingBot.finbert_utils",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting  ",
        "description": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting  ",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting  ",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lib.MLTradingBot.lumibot.traders",
        "description": "lib.MLTradingBot.lumibot.traders",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lib.MLTradingBot.lumibot.traders",
        "description": "lib.MLTradingBot.lumibot.traders",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.traders",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lib.MLTradingBot.lumibot.brokers.alpaca",
        "description": "lib.MLTradingBot.lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lib.MLTradingBot.lumibot.brokers.alpaca",
        "description": "lib.MLTradingBot.lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "isExtraImport": true,
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "lumibot.strategies",
        "description": "lumibot.strategies",
        "isExtraImport": true,
        "detail": "lumibot.strategies",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "importPath": "lumibot.example_strategies.crypto_important_functions",
        "description": "lumibot.example_strategies.crypto_important_functions",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "importPath": "lumibot.example_strategies.crypto_important_functions",
        "description": "lumibot.example_strategies.crypto_important_functions",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "importPath": "lumibot.example_strategies.crypto_important_functions",
        "description": "lumibot.example_strategies.crypto_important_functions",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "importPath": "lumibot.example_strategies.crypto_important_functions",
        "description": "lumibot.example_strategies.crypto_important_functions",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "IS_BACKTESTING",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "IS_BACKTESTING",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_API_KEY",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "IS_BACKTESTING",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_API_KEY",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "IS_BACKTESTING",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_API_KEY",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "isExtraImport": true,
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "getcontext",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "getcontext",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "getcontext",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "getcontext",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "getcontext",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "getcontext",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "ROUND_DOWN",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "sphinx_rtd_theme",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sphinx_rtd_theme",
        "description": "sphinx_rtd_theme",
        "detail": "sphinx_rtd_theme",
        "documentation": {}
    },
    {
        "label": "get_full_path",
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "isExtraImport": true,
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "GetTickerList",
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "isExtraImport": true,
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_yahoo_data_frame",
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "isExtraImport": true,
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "predict_with_models",
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "isExtraImport": true,
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "data",
        "importPath": "Sentiment-Analysis-Using-Vader",
        "description": "Sentiment-Analysis-Using-Vader",
        "isExtraImport": true,
        "detail": "Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "data.columns",
        "importPath": "lib.MLTradingBot.lumibot.example_strategies.alphavantage.1-alphavantage_demo",
        "description": "lib.MLTradingBot.lumibot.example_strategies.alphavantage.1-alphavantage_demo",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.example_strategies.alphavantage.1-alphavantage_demo",
        "documentation": {}
    },
    {
        "label": "empyrical",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "empyrical",
        "description": "empyrical",
        "detail": "empyrical",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "SkipTest",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "perf_attrib",
        "importPath": "empyrical.perf_attrib",
        "description": "empyrical.perf_attrib",
        "isExtraImport": true,
        "detail": "empyrical.perf_attrib",
        "documentation": {}
    },
    {
        "label": "attrgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "parameterized",
        "description": "parameterized",
        "isExtraImport": true,
        "detail": "parameterized",
        "documentation": {}
    },
    {
        "label": "assert_almost_equal",
        "importPath": "numpy.testing",
        "description": "numpy.testing",
        "isExtraImport": true,
        "detail": "numpy.testing",
        "documentation": {}
    },
    {
        "label": "assert_allclose",
        "importPath": "numpy.testing",
        "description": "numpy.testing",
        "isExtraImport": true,
        "detail": "numpy.testing",
        "documentation": {}
    },
    {
        "label": "NDFrame",
        "importPath": "pandas.core.generic",
        "description": "pandas.core.generic",
        "isExtraImport": true,
        "detail": "pandas.core.generic",
        "documentation": {}
    },
    {
        "label": "stats",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "stats",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "optimize",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "iteritems",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "iteritems",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "empyrical.utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "empyrical.utils",
        "description": "empyrical.utils",
        "detail": "empyrical.utils",
        "documentation": {}
    },
    {
        "label": "errno",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "errno",
        "description": "errno",
        "detail": "errno",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "expanduser",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "getmtime",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "isdir",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "as_strided",
        "importPath": "numpy.lib.stride_tricks",
        "description": "numpy.lib.stride_tricks",
        "isExtraImport": true,
        "detail": "numpy.lib.stride_tricks",
        "documentation": {}
    },
    {
        "label": "versioneer",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "versioneer",
        "description": "versioneer",
        "detail": "versioneer",
        "documentation": {}
    },
    {
        "label": "the",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "the",
        "description": "the",
        "detail": "the",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "importPath": "alpaca.data.timeframe",
        "description": "alpaca.data.timeframe",
        "isExtraImport": true,
        "detail": "alpaca.data.timeframe",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "CryptoHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "CryptoHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "CryptoHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "CryptoHistoricalDataClient",
        "importPath": "alpaca.data.historical",
        "description": "alpaca.data.historical",
        "isExtraImport": true,
        "detail": "alpaca.data.historical",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoLatestQuoteRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoLatestTradeRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockLatestTradeRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoLatestQuoteRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoLatestTradeRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockLatestTradeRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoLatestQuoteRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "CryptoLatestTradeRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockLatestTradeRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "StockBarsRequest",
        "importPath": "alpaca.data.requests",
        "description": "alpaca.data.requests",
        "isExtraImport": true,
        "detail": "alpaca.data.requests",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "BarSet",
        "importPath": "alpaca.data.models.bars",
        "description": "alpaca.data.models.bars",
        "isExtraImport": true,
        "detail": "alpaca.data.models.bars",
        "documentation": {}
    },
    {
        "label": "get_baseline2",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_baseline2",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_ticker_start_end_date",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_real_time_price",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_news_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "display_sentiment_summary",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "plot_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_ticker_start_end_date",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_real_time_price",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_news_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "display_sentiment_summary",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "plot_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "generate_trade_signals",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_barSet_to_DataFrame",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "collapsible_detailed_description",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "load_and_plot_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_real_time_price",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_news_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "display_sentiment_summary",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "plot_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "generate_trade_signals",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_barSet_to_DataFrame",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_twitter_sentiment",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_reddit_sentiment",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_google_trends",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "collapsible_detailed_description",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_stock_data",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_barSet_to_DataFrame",
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "isExtraImport": true,
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "plotly.express",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "plotly.express",
        "description": "plotly.express",
        "detail": "plotly.express",
        "documentation": {}
    },
    {
        "label": "relativedelta",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "relativedelta",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "YahooData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "CcxtData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "ExampleBrokerData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersRESTData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "YahooData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "CcxtData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "ExampleBrokerData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersRESTData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "YahooData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "CcxtData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "ExampleBrokerData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersRESTData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "importPath": "lumibot.data_sources",
        "description": "lumibot.data_sources",
        "isExtraImport": true,
        "detail": "lumibot.data_sources",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "CustomStream",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "SafeList",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "PollingStream",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "CustomStream",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "SafeList",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "PollingStream",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "CustomStream",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "SafeList",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "PollingStream",
        "importPath": "lumibot.trading_builtins",
        "description": "lumibot.trading_builtins",
        "isExtraImport": true,
        "detail": "lumibot.trading_builtins",
        "documentation": {}
    },
    {
        "label": "BadResponse",
        "importPath": "polygon.exceptions",
        "description": "polygon.exceptions",
        "isExtraImport": true,
        "detail": "polygon.exceptions",
        "documentation": {}
    },
    {
        "label": "BadResponse",
        "importPath": "polygon.exceptions",
        "description": "polygon.exceptions",
        "isExtraImport": true,
        "detail": "polygon.exceptions",
        "documentation": {}
    },
    {
        "label": "BadResponse",
        "importPath": "polygon.exceptions",
        "description": "polygon.exceptions",
        "isExtraImport": true,
        "detail": "polygon.exceptions",
        "documentation": {}
    },
    {
        "label": "termcolor",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "termcolor",
        "description": "termcolor",
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "polygon_helper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "thetadata_helper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "CcxtCacheDB",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "black_scholes",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "print_progress_bar",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "YahooHelper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "parse_symbol",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "ComparaisonMixin",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "create_tearsheet",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "day_deduplicate",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "plot_indicators",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "plot_returns",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "stats_summary",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_risk_free_rate",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "append_locals",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "staticdecorator",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "polygon_helper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "thetadata_helper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "CcxtCacheDB",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "black_scholes",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "print_progress_bar",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "YahooHelper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "parse_symbol",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "ComparaisonMixin",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "create_tearsheet",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "day_deduplicate",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "plot_indicators",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "plot_returns",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "stats_summary",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_risk_free_rate",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "append_locals",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "staticdecorator",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "polygon_helper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "thetadata_helper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "CcxtCacheDB",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "black_scholes",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "print_progress_bar",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "YahooHelper",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "parse_symbol",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "ComparaisonMixin",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "create_tearsheet",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "day_deduplicate",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "plot_indicators",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "plot_returns",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "stats_summary",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_risk_free_rate",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "append_locals",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "staticdecorator",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools",
        "description": "lumibot.tools",
        "isExtraImport": true,
        "detail": "lumibot.tools",
        "documentation": {}
    },
    {
        "label": "PolygonClient",
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "PolygonClient",
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "PolygonClient",
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "isExtraImport": true,
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "pandas_market_calendars",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas_market_calendars",
        "description": "pandas_market_calendars",
        "detail": "pandas_market_calendars",
        "documentation": {}
    },
    {
        "label": "TradingClient",
        "importPath": "alpaca.trading.client",
        "description": "alpaca.trading.client",
        "isExtraImport": true,
        "detail": "alpaca.trading.client",
        "documentation": {}
    },
    {
        "label": "TradingClient",
        "importPath": "alpaca.trading.client",
        "description": "alpaca.trading.client",
        "isExtraImport": true,
        "detail": "alpaca.trading.client",
        "documentation": {}
    },
    {
        "label": "TradingClient",
        "importPath": "alpaca.trading.client",
        "description": "alpaca.trading.client",
        "isExtraImport": true,
        "detail": "alpaca.trading.client",
        "documentation": {}
    },
    {
        "label": "TradingStream",
        "importPath": "alpaca.trading.stream",
        "description": "alpaca.trading.stream",
        "isExtraImport": true,
        "detail": "alpaca.trading.stream",
        "documentation": {}
    },
    {
        "label": "TradingStream",
        "importPath": "alpaca.trading.stream",
        "description": "alpaca.trading.stream",
        "isExtraImport": true,
        "detail": "alpaca.trading.stream",
        "documentation": {}
    },
    {
        "label": "TradingStream",
        "importPath": "alpaca.trading.stream",
        "description": "alpaca.trading.stream",
        "isExtraImport": true,
        "detail": "alpaca.trading.stream",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "asyncio.log",
        "description": "asyncio.log",
        "isExtraImport": true,
        "detail": "asyncio.log",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.client",
        "description": "ibapi.client",
        "isExtraImport": true,
        "detail": "ibapi.client",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.client",
        "description": "ibapi.client",
        "isExtraImport": true,
        "detail": "ibapi.client",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.client",
        "description": "ibapi.client",
        "isExtraImport": true,
        "detail": "ibapi.client",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.contract",
        "description": "ibapi.contract",
        "isExtraImport": true,
        "detail": "ibapi.contract",
        "documentation": {}
    },
    {
        "label": "Contract",
        "importPath": "ibapi.contract",
        "description": "ibapi.contract",
        "isExtraImport": true,
        "detail": "ibapi.contract",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.contract",
        "description": "ibapi.contract",
        "isExtraImport": true,
        "detail": "ibapi.contract",
        "documentation": {}
    },
    {
        "label": "Contract",
        "importPath": "ibapi.contract",
        "description": "ibapi.contract",
        "isExtraImport": true,
        "detail": "ibapi.contract",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.contract",
        "description": "ibapi.contract",
        "isExtraImport": true,
        "detail": "ibapi.contract",
        "documentation": {}
    },
    {
        "label": "Contract",
        "importPath": "ibapi.contract",
        "description": "ibapi.contract",
        "isExtraImport": true,
        "detail": "ibapi.contract",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.order",
        "description": "ibapi.order",
        "isExtraImport": true,
        "detail": "ibapi.order",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.order",
        "description": "ibapi.order",
        "isExtraImport": true,
        "detail": "ibapi.order",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.order",
        "description": "ibapi.order",
        "isExtraImport": true,
        "detail": "ibapi.order",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.wrapper",
        "description": "ibapi.wrapper",
        "isExtraImport": true,
        "detail": "ibapi.wrapper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.wrapper",
        "description": "ibapi.wrapper",
        "isExtraImport": true,
        "detail": "ibapi.wrapper",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ibapi.wrapper",
        "description": "ibapi.wrapper",
        "isExtraImport": true,
        "detail": "ibapi.wrapper",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumiwealth_tradier",
        "description": "lumiwealth_tradier",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumiwealth_tradier",
        "description": "lumiwealth_tradier",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumiwealth_tradier",
        "description": "lumiwealth_tradier",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumiwealth_tradier",
        "description": "lumiwealth_tradier",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumiwealth_tradier",
        "description": "lumiwealth_tradier",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "importPath": "lumiwealth_tradier",
        "description": "lumiwealth_tradier",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier",
        "documentation": {}
    },
    {
        "label": "TradierApiError",
        "importPath": "lumiwealth_tradier.base",
        "description": "lumiwealth_tradier.base",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier.base",
        "documentation": {}
    },
    {
        "label": "TradierApiError",
        "importPath": "lumiwealth_tradier.base",
        "description": "lumiwealth_tradier.base",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier.base",
        "documentation": {}
    },
    {
        "label": "TradierApiError",
        "importPath": "lumiwealth_tradier.base",
        "description": "lumiwealth_tradier.base",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier.base",
        "documentation": {}
    },
    {
        "label": "OrderLeg",
        "importPath": "lumiwealth_tradier.orders",
        "description": "lumiwealth_tradier.orders",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier.orders",
        "documentation": {}
    },
    {
        "label": "OrderLeg",
        "importPath": "lumiwealth_tradier.orders",
        "description": "lumiwealth_tradier.orders",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier.orders",
        "documentation": {}
    },
    {
        "label": "OrderLeg",
        "importPath": "lumiwealth_tradier.orders",
        "description": "lumiwealth_tradier.orders",
        "isExtraImport": true,
        "detail": "lumiwealth_tradier.orders",
        "documentation": {}
    },
    {
        "label": "TradierData",
        "importPath": "lumibot.data_sources.tradier_data",
        "description": "lumibot.data_sources.tradier_data",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "TradierData",
        "importPath": "lumibot.data_sources.tradier_data",
        "description": "lumibot.data_sources.tradier_data",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "TradierData",
        "importPath": "lumibot.data_sources.tradier_data",
        "description": "lumibot.data_sources.tradier_data",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "isExtraImport": true,
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources.data_source",
        "description": "lumibot.data_sources.data_source",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.data_source",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources.data_source",
        "description": "lumibot.data_sources.data_source",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.data_source",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "importPath": "lumibot.data_sources.data_source",
        "description": "lumibot.data_sources.data_source",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.data_source",
        "documentation": {}
    },
    {
        "label": "TimeSeries",
        "importPath": "alpha_vantage.timeseries",
        "description": "alpha_vantage.timeseries",
        "isExtraImport": true,
        "detail": "alpha_vantage.timeseries",
        "documentation": {}
    },
    {
        "label": "TimeSeries",
        "importPath": "alpha_vantage.timeseries",
        "description": "alpha_vantage.timeseries",
        "isExtraImport": true,
        "detail": "alpha_vantage.timeseries",
        "documentation": {}
    },
    {
        "label": "TimeSeries",
        "importPath": "alpha_vantage.timeseries",
        "description": "alpha_vantage.timeseries",
        "isExtraImport": true,
        "detail": "alpha_vantage.timeseries",
        "documentation": {}
    },
    {
        "label": "TimeSeries",
        "importPath": "alpha_vantage.timeseries",
        "description": "alpha_vantage.timeseries",
        "isExtraImport": true,
        "detail": "alpha_vantage.timeseries",
        "documentation": {}
    },
    {
        "label": "TimeSeries",
        "importPath": "alpha_vantage.timeseries",
        "description": "alpha_vantage.timeseries",
        "isExtraImport": true,
        "detail": "alpha_vantage.timeseries",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_CACHE_FOLDER",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_PYTZ",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "LUMIBOT_DEFAULT_TIMEZONE",
        "importPath": "lumibot",
        "description": "lumibot",
        "isExtraImport": true,
        "detail": "lumibot",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "importPath": "lumibot.data_sources.exceptions",
        "description": "lumibot.data_sources.exceptions",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "importPath": "lumibot.data_sources.exceptions",
        "description": "lumibot.data_sources.exceptions",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "importPath": "lumibot.data_sources.exceptions",
        "description": "lumibot.data_sources.exceptions",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "importPath": "lumibot.data_sources.exceptions",
        "description": "lumibot.data_sources.exceptions",
        "isExtraImport": true,
        "detail": "lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "urllib3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib3",
        "description": "urllib3",
        "detail": "urllib3",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "check_positive",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_price",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_quantity",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_positive",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_price",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_quantity",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_positive",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_price",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_quantity",
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "isExtraImport": true,
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "pandas_datareader",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas_datareader",
        "description": "pandas_datareader",
        "detail": "pandas_datareader",
        "documentation": {}
    },
    {
        "label": "strategy",
        "importPath": "lib.MLTradingBot.t1",
        "description": "lib.MLTradingBot.t1",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.t1",
        "documentation": {}
    },
    {
        "label": "strategy",
        "importPath": "lib.MLTradingBot.t1",
        "description": "lib.MLTradingBot.t1",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.t1",
        "documentation": {}
    },
    {
        "label": "strategy",
        "importPath": "lib.MLTradingBot.t1",
        "description": "lib.MLTradingBot.t1",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.t1",
        "documentation": {}
    },
    {
        "label": "strategy.name",
        "importPath": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "description": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "documentation": {}
    },
    {
        "label": "strategy.name",
        "importPath": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "description": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "documentation": {}
    },
    {
        "label": "strategy.name",
        "importPath": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "description": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.example_strategies.fasttrading_2",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "description": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "description": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "importPath": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "description": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "isExtraImport": true,
        "detail": "lib.MLTradingBot.lumibot.backtesting.yahoo_backtesting",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "isExtraImport": true,
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "isExtraImport": true,
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "isExtraImport": true,
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "isExtraImport": true,
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "isExtraImport": true,
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "isExtraImport": true,
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "isExtraImport": true,
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "text",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "bindparam",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "text",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "bindparam",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "text",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "bindparam",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "OperationalError",
        "importPath": "sqlalchemy.exc",
        "description": "sqlalchemy.exc",
        "isExtraImport": true,
        "detail": "sqlalchemy.exc",
        "documentation": {}
    },
    {
        "label": "OperationalError",
        "importPath": "sqlalchemy.exc",
        "description": "sqlalchemy.exc",
        "isExtraImport": true,
        "detail": "sqlalchemy.exc",
        "documentation": {}
    },
    {
        "label": "OperationalError",
        "importPath": "sqlalchemy.exc",
        "description": "sqlalchemy.exc",
        "isExtraImport": true,
        "detail": "sqlalchemy.exc",
        "documentation": {}
    },
    {
        "label": "jsonpickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jsonpickle",
        "description": "jsonpickle",
        "detail": "jsonpickle",
        "documentation": {}
    },
    {
        "label": "MemoryJobStore",
        "importPath": "apscheduler.jobstores.memory",
        "description": "apscheduler.jobstores.memory",
        "isExtraImport": true,
        "detail": "apscheduler.jobstores.memory",
        "documentation": {}
    },
    {
        "label": "MemoryJobStore",
        "importPath": "apscheduler.jobstores.memory",
        "description": "apscheduler.jobstores.memory",
        "isExtraImport": true,
        "detail": "apscheduler.jobstores.memory",
        "documentation": {}
    },
    {
        "label": "MemoryJobStore",
        "importPath": "apscheduler.jobstores.memory",
        "description": "apscheduler.jobstores.memory",
        "isExtraImport": true,
        "detail": "apscheduler.jobstores.memory",
        "documentation": {}
    },
    {
        "label": "BackgroundScheduler",
        "importPath": "apscheduler.schedulers.background",
        "description": "apscheduler.schedulers.background",
        "isExtraImport": true,
        "detail": "apscheduler.schedulers.background",
        "documentation": {}
    },
    {
        "label": "BackgroundScheduler",
        "importPath": "apscheduler.schedulers.background",
        "description": "apscheduler.schedulers.background",
        "isExtraImport": true,
        "detail": "apscheduler.schedulers.background",
        "documentation": {}
    },
    {
        "label": "BackgroundScheduler",
        "importPath": "apscheduler.schedulers.background",
        "description": "apscheduler.schedulers.background",
        "isExtraImport": true,
        "detail": "apscheduler.schedulers.background",
        "documentation": {}
    },
    {
        "label": "CronTrigger",
        "importPath": "apscheduler.triggers.cron",
        "description": "apscheduler.triggers.cron",
        "isExtraImport": true,
        "detail": "apscheduler.triggers.cron",
        "documentation": {}
    },
    {
        "label": "CronTrigger",
        "importPath": "apscheduler.triggers.cron",
        "description": "apscheduler.triggers.cron",
        "isExtraImport": true,
        "detail": "apscheduler.triggers.cron",
        "documentation": {}
    },
    {
        "label": "CronTrigger",
        "importPath": "apscheduler.triggers.cron",
        "description": "apscheduler.triggers.cron",
        "isExtraImport": true,
        "detail": "apscheduler.triggers.cron",
        "documentation": {}
    },
    {
        "label": "duckdb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "duckdb",
        "description": "duckdb",
        "detail": "duckdb",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "webbrowser",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "webbrowser",
        "description": "webbrowser",
        "detail": "webbrowser",
        "documentation": {}
    },
    {
        "label": "plotly.graph_objects",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "plotly.graph_objects",
        "description": "plotly.graph_objects",
        "detail": "plotly.graph_objects",
        "documentation": {}
    },
    {
        "label": "quantstats_lumi",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "quantstats_lumi",
        "description": "quantstats_lumi",
        "detail": "quantstats_lumi",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "MaxRetryError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "MaxRetryError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "MaxRetryError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "RESTClient",
        "importPath": "polygon",
        "description": "polygon",
        "isExtraImport": true,
        "detail": "polygon",
        "documentation": {}
    },
    {
        "label": "RESTClient",
        "importPath": "polygon",
        "description": "polygon",
        "isExtraImport": true,
        "detail": "polygon",
        "documentation": {}
    },
    {
        "label": "RESTClient",
        "importPath": "polygon",
        "description": "polygon",
        "isExtraImport": true,
        "detail": "polygon",
        "documentation": {}
    },
    {
        "label": "ThetaClient",
        "importPath": "thetadata",
        "description": "thetadata",
        "isExtraImport": true,
        "detail": "thetadata",
        "documentation": {}
    },
    {
        "label": "ThetaClient",
        "importPath": "thetadata",
        "description": "thetadata",
        "isExtraImport": true,
        "detail": "thetadata",
        "documentation": {}
    },
    {
        "label": "ThetaClient",
        "importPath": "thetadata",
        "description": "thetadata",
        "isExtraImport": true,
        "detail": "thetadata",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "_thread",
        "description": "_thread",
        "isExtraImport": true,
        "detail": "_thread",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "_thread",
        "description": "_thread",
        "isExtraImport": true,
        "detail": "_thread",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "_thread",
        "description": "_thread",
        "isExtraImport": true,
        "detail": "_thread",
        "documentation": {}
    },
    {
        "label": "dotenv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dotenv",
        "description": "dotenv",
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "pipeline",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "pipeline",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WorkingAlpacaBacktesting",
        "importPath": "alpaca_backtesting",
        "description": "alpaca_backtesting",
        "isExtraImport": true,
        "detail": "alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "finbert_utils",
        "description": "finbert_utils",
        "isExtraImport": true,
        "detail": "finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "finbert_utils",
        "description": "finbert_utils",
        "isExtraImport": true,
        "detail": "finbert_utils",
        "documentation": {}
    },
    {
        "label": "AlpacaDataBacktesting",
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "WorkingAlpacaBacktesting",
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "WorkingAlpacaBacktesting",
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "AlpacaDataBacktesting",
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "AlpacaBacktesting",
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "AlpacaBacktesting",
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "isExtraImport": true,
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "quantstats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "quantstats",
        "description": "quantstats",
        "detail": "quantstats",
        "documentation": {}
    },
    {
        "label": "EmbeddingModel",
        "importPath": "BCEmbedding",
        "description": "BCEmbedding",
        "isExtraImport": true,
        "detail": "BCEmbedding",
        "documentation": {}
    },
    {
        "label": "RerankerModel",
        "importPath": "BCEmbedding",
        "description": "BCEmbedding",
        "isExtraImport": true,
        "detail": "BCEmbedding",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "CACHE_DIR",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "COLLECTION_NAME",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "EMBEDDING_MODEL",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "MILVUS_URI",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "RAG_PROMPT",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "RERANK_MODEL",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "STORAGE_TYPE",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "STORAGE_TYPE",
        "importPath": "conf.config",
        "description": "conf.config",
        "isExtraImport": true,
        "detail": "conf.config",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "fitz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fitz",
        "description": "fitz",
        "detail": "fitz",
        "documentation": {}
    },
    {
        "label": "UnstructuredFileLoader",
        "importPath": "langchain.document_loaders.unstructured",
        "description": "langchain.document_loaders.unstructured",
        "isExtraImport": true,
        "detail": "langchain.document_loaders.unstructured",
        "documentation": {}
    },
    {
        "label": "PaddleOCR",
        "importPath": "paddleocr",
        "description": "paddleocr",
        "isExtraImport": true,
        "detail": "paddleocr",
        "documentation": {}
    },
    {
        "label": "partition_text",
        "importPath": "unstructured.partition.text",
        "description": "unstructured.partition.text",
        "isExtraImport": true,
        "detail": "unstructured.partition.text",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "CharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "TextLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredFileLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredWordDocumentLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "ChineseTextSplitter",
        "importPath": "app.core.splitter",
        "description": "app.core.splitter",
        "isExtraImport": true,
        "detail": "app.core.splitter",
        "documentation": {}
    },
    {
        "label": "zh_title_enhance",
        "importPath": "app.core.splitter",
        "description": "app.core.splitter",
        "isExtraImport": true,
        "detail": "app.core.splitter",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "conf",
        "description": "conf",
        "isExtraImport": true,
        "detail": "conf",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "conf",
        "description": "conf",
        "isExtraImport": true,
        "detail": "conf",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.docstore.document",
        "description": "langchain.docstore.document",
        "isExtraImport": true,
        "detail": "langchain.docstore.document",
        "documentation": {}
    },
    {
        "label": "Collection",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "CollectionSchema",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "DataType",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "FieldSchema",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "MilvusClient",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "connections",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "utility",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "Collection",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "CollectionSchema",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "DataType",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "FieldSchema",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "connections",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "connections",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "utility",
        "importPath": "pymilvus",
        "description": "pymilvus",
        "isExtraImport": true,
        "detail": "pymilvus",
        "documentation": {}
    },
    {
        "label": "EmbeddingClient",
        "importPath": "app.core.bce.embedding_client",
        "description": "app.core.bce.embedding_client",
        "isExtraImport": true,
        "detail": "app.core.bce.embedding_client",
        "documentation": {}
    },
    {
        "label": "EmbeddingClient",
        "importPath": "app.core.bce.embedding_client",
        "description": "app.core.bce.embedding_client",
        "isExtraImport": true,
        "detail": "app.core.bce.embedding_client",
        "documentation": {}
    },
    {
        "label": "EmbeddingClient",
        "importPath": "app.core.bce.embedding_client",
        "description": "app.core.bce.embedding_client",
        "isExtraImport": true,
        "detail": "app.core.bce.embedding_client",
        "documentation": {}
    },
    {
        "label": "RerankClient",
        "importPath": "app.core.bce.rerank_client",
        "description": "app.core.bce.rerank_client",
        "isExtraImport": true,
        "detail": "app.core.bce.rerank_client",
        "documentation": {}
    },
    {
        "label": "OpenChat",
        "importPath": "app.core.chat.open_chat",
        "description": "app.core.chat.open_chat",
        "isExtraImport": true,
        "detail": "app.core.chat.open_chat",
        "documentation": {}
    },
    {
        "label": "OpenChat",
        "importPath": "app.core.chat.open_chat",
        "description": "app.core.chat.open_chat",
        "isExtraImport": true,
        "detail": "app.core.chat.open_chat",
        "documentation": {}
    },
    {
        "label": "FileProcesser",
        "importPath": "app.core.preprocessor.file_processor",
        "description": "app.core.preprocessor.file_processor",
        "isExtraImport": true,
        "detail": "app.core.preprocessor.file_processor",
        "documentation": {}
    },
    {
        "label": "FileProcesser",
        "importPath": "app.core.preprocessor.file_processor",
        "description": "app.core.preprocessor.file_processor",
        "isExtraImport": true,
        "detail": "app.core.preprocessor.file_processor",
        "documentation": {}
    },
    {
        "label": "Downloader",
        "importPath": "app.oss.download_file",
        "description": "app.oss.download_file",
        "isExtraImport": true,
        "detail": "app.oss.download_file",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "oss2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "oss2",
        "description": "oss2",
        "detail": "oss2",
        "documentation": {}
    },
    {
        "label": "EnvironmentVariableCredentialsProvider",
        "importPath": "oss2.credentials",
        "description": "oss2.credentials",
        "isExtraImport": true,
        "detail": "oss2.credentials",
        "documentation": {}
    },
    {
        "label": "httpx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httpx",
        "description": "httpx",
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "uvicorn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uvicorn",
        "description": "uvicorn",
        "detail": "uvicorn",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BackgroundTasks",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "status",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "status",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Form",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "CustomerMilvusClient",
        "importPath": "app.core.vectorstore.customer_milvus_client",
        "description": "app.core.vectorstore.customer_milvus_client",
        "isExtraImport": true,
        "detail": "app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "CustomerMilvusClient",
        "importPath": "app.core.vectorstore.customer_milvus_client",
        "description": "app.core.vectorstore.customer_milvus_client",
        "isExtraImport": true,
        "detail": "app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "ErrorMsg",
        "importPath": "app.models.status",
        "description": "app.models.status",
        "isExtraImport": true,
        "detail": "app.models.status",
        "documentation": {}
    },
    {
        "label": "SuccessMsg",
        "importPath": "app.models.status",
        "description": "app.models.status",
        "isExtraImport": true,
        "detail": "app.models.status",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "jojostock1.pages.FinRAG.app.finrag_server",
        "description": "jojostock1.pages.FinRAG.app.finrag_server",
        "isExtraImport": true,
        "detail": "jojostock1.pages.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "loguru",
        "description": "loguru",
        "isExtraImport": true,
        "detail": "loguru",
        "documentation": {}
    },
    {
        "label": "RedditUtils",
        "importPath": "finrobot.data_source",
        "description": "finrobot.data_source",
        "isExtraImport": true,
        "detail": "finrobot.data_source",
        "documentation": {}
    },
    {
        "label": "FinnHubUtils",
        "importPath": "finrobot.data_source",
        "description": "finrobot.data_source",
        "isExtraImport": true,
        "detail": "finrobot.data_source",
        "documentation": {}
    },
    {
        "label": "FMPUtils",
        "importPath": "finrobot.data_source",
        "description": "finrobot.data_source",
        "isExtraImport": true,
        "detail": "finrobot.data_source",
        "documentation": {}
    },
    {
        "label": "YFinanceUtils",
        "importPath": "finrobot.data_source",
        "description": "finrobot.data_source",
        "isExtraImport": true,
        "detail": "finrobot.data_source",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "finrobot.data_source",
        "description": "finrobot.data_source",
        "isExtraImport": true,
        "detail": "finrobot.data_source",
        "documentation": {}
    },
    {
        "label": "autogen",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "autogen",
        "description": "autogen",
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "register_function",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "ConversableAgent",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "AssistantAgent",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "UserProxyAgent",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "GroupChat",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "GroupChatManager",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "register_function",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "register_function",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "ConversableAgent",
        "importPath": "autogen",
        "description": "autogen",
        "isExtraImport": true,
        "detail": "autogen",
        "documentation": {}
    },
    {
        "label": "Cache",
        "importPath": "autogen.cache",
        "description": "autogen.cache",
        "isExtraImport": true,
        "detail": "autogen.cache",
        "documentation": {}
    },
    {
        "label": "Cache",
        "importPath": "autogen.cache",
        "description": "autogen.cache",
        "isExtraImport": true,
        "detail": "autogen.cache",
        "documentation": {}
    },
    {
        "label": "MultiAssistant",
        "importPath": "finrobot.agents.workflow",
        "description": "finrobot.agents.workflow",
        "isExtraImport": true,
        "detail": "finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "MultiAssistantWithLeader",
        "importPath": "finrobot.agents.workflow",
        "description": "finrobot.agents.workflow",
        "isExtraImport": true,
        "detail": "finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "get_rag_function",
        "importPath": "finrobot.functional",
        "description": "finrobot.functional",
        "isExtraImport": true,
        "detail": "finrobot.functional",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "finrobot.functional",
        "description": "finrobot.functional",
        "isExtraImport": true,
        "detail": "finrobot.functional",
        "documentation": {}
    },
    {
        "label": "register_keys_from_json",
        "importPath": "finrobot.utils",
        "description": "finrobot.utils",
        "isExtraImport": true,
        "detail": "finrobot.utils",
        "documentation": {}
    },
    {
        "label": "get_current_date",
        "importPath": "finrobot.utils",
        "description": "finrobot.utils",
        "isExtraImport": true,
        "detail": "finrobot.utils",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "group_config",
        "importPath": "investment_group",
        "description": "investment_group",
        "isExtraImport": true,
        "detail": "investment_group",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "RetryError",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "get_earnings_transcript",
        "importPath": "finrobot.data_source.earnings_calls_src.earningsData",
        "description": "finrobot.data_source.earnings_calls_src.earningsData",
        "isExtraImport": true,
        "detail": "finrobot.data_source.earnings_calls_src.earningsData",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "gzip",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gzip",
        "description": "gzip",
        "detail": "gzip",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "PlainTextResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "Headers",
        "importPath": "starlette.datastructures",
        "description": "starlette.datastructures",
        "isExtraImport": true,
        "detail": "starlette.datastructures",
        "documentation": {}
    },
    {
        "label": "Send",
        "importPath": "starlette.types",
        "description": "starlette.types",
        "isExtraImport": true,
        "detail": "starlette.types",
        "documentation": {}
    },
    {
        "label": "secrets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "secrets",
        "description": "secrets",
        "detail": "secrets",
        "documentation": {}
    },
    {
        "label": "section_string_to_enum",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "validate_section_names",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECSection",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "ALL_SECTIONS",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10K",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10Q",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_S1",
        "importPath": "prepline_sec_filings.sections",
        "description": "prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECDocument",
        "importPath": "prepline_sec_filings.sec_document",
        "description": "prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "REPORT_TYPES",
        "importPath": "prepline_sec_filings.sec_document",
        "description": "prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "VALID_FILING_TYPES",
        "importPath": "prepline_sec_filings.sec_document",
        "description": "prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "convert_to_isd",
        "importPath": "unstructured.staging.base",
        "description": "unstructured.staging.base",
        "isExtraImport": true,
        "detail": "unstructured.staging.base",
        "documentation": {}
    },
    {
        "label": "convert_to_isd",
        "importPath": "unstructured.staging.base",
        "description": "unstructured.staging.base",
        "isExtraImport": true,
        "detail": "unstructured.staging.base",
        "documentation": {}
    },
    {
        "label": "Text",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "NarrativeText",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "Title",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "ListItem",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "Text",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "ListItem",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "NarrativeText",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "Title",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "Element",
        "importPath": "unstructured.documents.elements",
        "description": "unstructured.documents.elements",
        "isExtraImport": true,
        "detail": "unstructured.documents.elements",
        "documentation": {}
    },
    {
        "label": "stage_for_label_studio",
        "importPath": "unstructured.staging.label_studio",
        "description": "unstructured.staging.label_studio",
        "isExtraImport": true,
        "detail": "unstructured.staging.label_studio",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "VALID_FILING_TYPES",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "SECDocument",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "REPORT_TYPES",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "VALID_FILING_TYPES",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "clean",
        "importPath": "unstructured.cleaners.core",
        "description": "unstructured.cleaners.core",
        "isExtraImport": true,
        "detail": "unstructured.cleaners.core",
        "documentation": {}
    },
    {
        "label": "HTMLDocument",
        "importPath": "unstructured.documents.html",
        "description": "unstructured.documents.html",
        "isExtraImport": true,
        "detail": "unstructured.documents.html",
        "documentation": {}
    },
    {
        "label": "is_possible_title",
        "importPath": "unstructured.nlp.partition",
        "description": "unstructured.nlp.partition",
        "isExtraImport": true,
        "detail": "unstructured.nlp.partition",
        "documentation": {}
    },
    {
        "label": "SECSection",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "section_string_to_enum",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "validate_section_names",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECSection",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "ALL_SECTIONS",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10K",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10Q",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_S1",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECExtractor",
        "importPath": "finrobot.data_source.filings_src.sec_filings",
        "description": "finrobot.data_source.filings_src.sec_filings",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "get_cik_by_ticker",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_filing",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_form_by_ticker",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "open_form_by_ticker",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_filing",
        "importPath": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "convert_single_pdf",
        "importPath": "marker.convert",
        "description": "marker.convert",
        "isExtraImport": true,
        "detail": "marker.convert",
        "documentation": {}
    },
    {
        "label": "convert_single_pdf",
        "importPath": "marker.convert",
        "description": "marker.convert",
        "isExtraImport": true,
        "detail": "marker.convert",
        "documentation": {}
    },
    {
        "label": "load_all_models",
        "importPath": "marker.models",
        "description": "marker.models",
        "isExtraImport": true,
        "detail": "marker.models",
        "documentation": {}
    },
    {
        "label": "load_all_models",
        "importPath": "marker.models",
        "description": "marker.models",
        "isExtraImport": true,
        "detail": "marker.models",
        "documentation": {}
    },
    {
        "label": "save_markdown",
        "importPath": "marker.output",
        "description": "marker.output",
        "isExtraImport": true,
        "detail": "marker.output",
        "documentation": {}
    },
    {
        "label": "markdown_exists",
        "importPath": "marker.output",
        "description": "marker.output",
        "isExtraImport": true,
        "detail": "marker.output",
        "documentation": {}
    },
    {
        "label": "save_markdown",
        "importPath": "marker.output",
        "description": "marker.output",
        "isExtraImport": true,
        "detail": "marker.output",
        "documentation": {}
    },
    {
        "label": "pypdfium2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pypdfium2",
        "description": "pypdfium2",
        "detail": "pypdfium2",
        "documentation": {}
    },
    {
        "label": "torch.multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.multiprocessing",
        "description": "torch.multiprocessing",
        "detail": "torch.multiprocessing",
        "documentation": {}
    },
    {
        "label": "find_filetype",
        "importPath": "marker.pdf.utils",
        "description": "marker.pdf.utils",
        "isExtraImport": true,
        "detail": "marker.pdf.utils",
        "documentation": {}
    },
    {
        "label": "get_length_of_text",
        "importPath": "marker.pdf.extract_text",
        "description": "marker.pdf.extract_text",
        "isExtraImport": true,
        "detail": "marker.pdf.extract_text",
        "documentation": {}
    },
    {
        "label": "settings",
        "importPath": "marker.settings",
        "description": "marker.settings",
        "isExtraImport": true,
        "detail": "marker.settings",
        "documentation": {}
    },
    {
        "label": "configure_logging",
        "importPath": "marker.logger",
        "description": "marker.logger",
        "isExtraImport": true,
        "detail": "marker.logger",
        "documentation": {}
    },
    {
        "label": "pdfkit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pdfkit",
        "description": "pdfkit",
        "detail": "pdfkit",
        "documentation": {}
    },
    {
        "label": "get_earnings_all_docs",
        "importPath": "finrobot.data_source.earnings_calls_src",
        "description": "finrobot.data_source.earnings_calls_src",
        "isExtraImport": true,
        "detail": "finrobot.data_source.earnings_calls_src",
        "documentation": {}
    },
    {
        "label": "get_earnings_all_docs",
        "importPath": "finrobot.data_source.earnings_calls_src",
        "description": "finrobot.data_source.earnings_calls_src",
        "isExtraImport": true,
        "detail": "finrobot.data_source.earnings_calls_src",
        "documentation": {}
    },
    {
        "label": "sec_main",
        "importPath": "finrobot.data_source.filings_src",
        "description": "finrobot.data_source.filings_src",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src",
        "documentation": {}
    },
    {
        "label": "sec_main",
        "importPath": "finrobot.data_source.filings_src",
        "description": "finrobot.data_source.filings_src",
        "isExtraImport": true,
        "detail": "finrobot.data_source.filings_src",
        "documentation": {}
    },
    {
        "label": "sec_save_pdfs",
        "importPath": "finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "description": "finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "isExtraImport": true,
        "detail": "finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "documentation": {}
    },
    {
        "label": "sec_save_pdfs",
        "importPath": "finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "description": "finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "isExtraImport": true,
        "detail": "finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "documentation": {}
    },
    {
        "label": "run_marker",
        "importPath": "finrobot.data_source.marker_sec_src.pdf_to_md",
        "description": "finrobot.data_source.marker_sec_src.pdf_to_md",
        "isExtraImport": true,
        "detail": "finrobot.data_source.marker_sec_src.pdf_to_md",
        "documentation": {}
    },
    {
        "label": "run_marker",
        "importPath": "finrobot.data_source.marker_sec_src.pdf_to_md",
        "description": "finrobot.data_source.marker_sec_src.pdf_to_md",
        "isExtraImport": true,
        "detail": "finrobot.data_source.marker_sec_src.pdf_to_md",
        "documentation": {}
    },
    {
        "label": "run_marker_mp",
        "importPath": "finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "isExtraImport": true,
        "detail": "finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "run_marker_mp",
        "importPath": "finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "isExtraImport": true,
        "detail": "finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "finnhub",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "finnhub",
        "description": "finnhub",
        "detail": "finnhub",
        "documentation": {}
    },
    {
        "label": "CNBC_Streaming",
        "importPath": "finnlp.data_sources.news.cnbc_streaming",
        "description": "finnlp.data_sources.news.cnbc_streaming",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.news.cnbc_streaming",
        "documentation": {}
    },
    {
        "label": "Yicai_Streaming",
        "importPath": "finnlp.data_sources.news.yicai_streaming",
        "description": "finnlp.data_sources.news.yicai_streaming",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.news.yicai_streaming",
        "documentation": {}
    },
    {
        "label": "InvestorPlace_Streaming",
        "importPath": "finnlp.data_sources.news.investorplace_streaming",
        "description": "finnlp.data_sources.news.investorplace_streaming",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.news.investorplace_streaming",
        "documentation": {}
    },
    {
        "label": "Xueqiu_Streaming",
        "importPath": "finnlp.data_sources.social_media.xueqiu_streaming",
        "description": "finnlp.data_sources.social_media.xueqiu_streaming",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.social_media.xueqiu_streaming",
        "documentation": {}
    },
    {
        "label": "Stocktwits_Streaming",
        "importPath": "finnlp.data_sources.social_media.stocktwits_streaming",
        "description": "finnlp.data_sources.social_media.stocktwits_streaming",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.social_media.stocktwits_streaming",
        "documentation": {}
    },
    {
        "label": "Sina_Finance_Date_Range",
        "importPath": "finnlp.data_sources.news.sina_finance_date_range",
        "description": "finnlp.data_sources.news.sina_finance_date_range",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.news.sina_finance_date_range",
        "documentation": {}
    },
    {
        "label": "Finnhub_Date_Range",
        "importPath": "finnlp.data_sources.news.finnhub_date_range",
        "description": "finnlp.data_sources.news.finnhub_date_range",
        "isExtraImport": true,
        "detail": "finnlp.data_sources.news.finnhub_date_range",
        "documentation": {}
    },
    {
        "label": "praw",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "praw",
        "description": "praw",
        "detail": "praw",
        "documentation": {}
    },
    {
        "label": "ExtractorApi",
        "importPath": "sec_api",
        "description": "sec_api",
        "isExtraImport": true,
        "detail": "sec_api",
        "documentation": {}
    },
    {
        "label": "QueryApi",
        "importPath": "sec_api",
        "description": "sec_api",
        "isExtraImport": true,
        "detail": "sec_api",
        "documentation": {}
    },
    {
        "label": "RenderApi",
        "importPath": "sec_api",
        "description": "sec_api",
        "isExtraImport": true,
        "detail": "sec_api",
        "documentation": {}
    },
    {
        "label": "mplfinance",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mplfinance",
        "description": "mplfinance",
        "detail": "mplfinance",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "get_ipython",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "get_ipython",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "backtrader",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "backtrader",
        "description": "backtrader",
        "detail": "backtrader",
        "documentation": {}
    },
    {
        "label": "SMA_CrossOver",
        "importPath": "backtrader.strategies",
        "description": "backtrader.strategies",
        "isExtraImport": true,
        "detail": "backtrader.strategies",
        "documentation": {}
    },
    {
        "label": "RetrieveUserProxyAgent",
        "importPath": "autogen.agentchat.contrib.retrieve_user_proxy_agent",
        "description": "autogen.agentchat.contrib.retrieve_user_proxy_agent",
        "isExtraImport": true,
        "detail": "autogen.agentchat.contrib.retrieve_user_proxy_agent",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "SentenceTransformerEmbeddings",
        "importPath": "langchain_community.embeddings.sentence_transformer",
        "description": "langchain_community.embeddings.sentence_transformer",
        "isExtraImport": true,
        "detail": "langchain_community.embeddings.sentence_transformer",
        "documentation": {}
    },
    {
        "label": "MarkdownHeaderTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "MarkdownHeaderTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "MarkdownHeaderTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "get_data",
        "importPath": "finrobot.data_source.finance_data",
        "description": "finrobot.data_source.finance_data",
        "isExtraImport": true,
        "detail": "finrobot.data_source.finance_data",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "reportlab.lib",
        "description": "reportlab.lib",
        "isExtraImport": true,
        "detail": "reportlab.lib",
        "documentation": {}
    },
    {
        "label": "pagesizes",
        "importPath": "reportlab.lib",
        "description": "reportlab.lib",
        "isExtraImport": true,
        "detail": "reportlab.lib",
        "documentation": {}
    },
    {
        "label": "SimpleDocTemplate",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "Frame",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "Paragraph",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "PageTemplate",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "FrameBreak",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "Spacer",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "Table",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "TableStyle",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "NextPageTemplate",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "PageBreak",
        "importPath": "reportlab.platypus",
        "description": "reportlab.platypus",
        "isExtraImport": true,
        "detail": "reportlab.platypus",
        "documentation": {}
    },
    {
        "label": "inch",
        "importPath": "reportlab.lib.units",
        "description": "reportlab.lib.units",
        "isExtraImport": true,
        "detail": "reportlab.lib.units",
        "documentation": {}
    },
    {
        "label": "getSampleStyleSheet",
        "importPath": "reportlab.lib.styles",
        "description": "reportlab.lib.styles",
        "isExtraImport": true,
        "detail": "reportlab.lib.styles",
        "documentation": {}
    },
    {
        "label": "ParagraphStyle",
        "importPath": "reportlab.lib.styles",
        "description": "reportlab.lib.styles",
        "isExtraImport": true,
        "detail": "reportlab.lib.styles",
        "documentation": {}
    },
    {
        "label": "TA_CENTER",
        "importPath": "reportlab.lib.enums",
        "description": "reportlab.lib.enums",
        "isExtraImport": true,
        "detail": "reportlab.lib.enums",
        "documentation": {}
    },
    {
        "label": "TA_JUSTIFY",
        "importPath": "reportlab.lib.enums",
        "description": "reportlab.lib.enums",
        "isExtraImport": true,
        "detail": "reportlab.lib.enums",
        "documentation": {}
    },
    {
        "label": "TA_LEFT",
        "importPath": "reportlab.lib.enums",
        "description": "reportlab.lib.enums",
        "isExtraImport": true,
        "detail": "reportlab.lib.enums",
        "documentation": {}
    },
    {
        "label": "AgentBuilder",
        "importPath": "autogen.agentchat.contrib.agent_builder",
        "description": "autogen.agentchat.contrib.agent_builder",
        "isExtraImport": true,
        "detail": "autogen.agentchat.contrib.agent_builder",
        "documentation": {}
    },
    {
        "label": "ARIMA",
        "importPath": "statsmodels.tsa.arima.model",
        "description": "statsmodels.tsa.arima.model",
        "isExtraImport": true,
        "detail": "statsmodels.tsa.arima.model",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "math,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math.",
        "description": "math.",
        "detail": "math.",
        "documentation": {}
    },
    {
        "label": "tweepy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tweepy",
        "description": "tweepy",
        "detail": "tweepy",
        "documentation": {}
    },
    {
        "label": "preprocessor",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "preprocessor",
        "description": "preprocessor",
        "detail": "preprocessor",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "TextBlob",
        "importPath": "textblob",
        "description": "textblob",
        "isExtraImport": true,
        "detail": "textblob",
        "documentation": {}
    },
    {
        "label": "constants",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "constants",
        "description": "constants",
        "detail": "constants",
        "documentation": {}
    },
    {
        "label": "Tweet",
        "importPath": "Tweet",
        "description": "Tweet",
        "isExtraImport": true,
        "detail": "Tweet",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "sys,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys.",
        "description": "sys.",
        "detail": "sys.",
        "documentation": {}
    },
    {
        "label": "StockModel",
        "importPath": "lstm",
        "description": "lstm",
        "isExtraImport": true,
        "detail": "lstm",
        "documentation": {}
    },
    {
        "label": "StockModel",
        "importPath": "lstm",
        "description": "lstm",
        "isExtraImport": true,
        "detail": "lstm",
        "documentation": {}
    },
    {
        "label": "StockModel",
        "importPath": "lstm",
        "description": "lstm",
        "isExtraImport": true,
        "detail": "lstm",
        "documentation": {}
    },
    {
        "label": "StockModel",
        "importPath": "lstm",
        "description": "lstm",
        "isExtraImport": true,
        "detail": "lstm",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "helpers",
        "description": "helpers",
        "isExtraImport": true,
        "detail": "helpers",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "helpers",
        "description": "helpers",
        "isExtraImport": true,
        "detail": "helpers",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "helpers",
        "description": "helpers",
        "isExtraImport": true,
        "detail": "helpers",
        "documentation": {}
    },
    {
        "label": "matplotlib.patches",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "keras.layers.core",
        "description": "keras.layers.core",
        "isExtraImport": true,
        "detail": "keras.layers.core",
        "documentation": {}
    },
    {
        "label": "Activation",
        "importPath": "keras.layers.core",
        "description": "keras.layers.core",
        "isExtraImport": true,
        "detail": "keras.layers.core",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "keras.layers.core",
        "description": "keras.layers.core",
        "isExtraImport": true,
        "detail": "keras.layers.core",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "importPath": "keras.layers.recurrent",
        "description": "keras.layers.recurrent",
        "isExtraImport": true,
        "detail": "keras.layers.recurrent",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "OllamaEmbeddings",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "OllamaEmbeddings",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "SystemMessagePromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "HumanMessagePromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "AIMessagePromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "SystemMessagePromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "HumanMessagePromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "AIMessagePromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "DocumentConverter",
        "importPath": "docling.document_converter",
        "description": "docling.document_converter",
        "isExtraImport": true,
        "detail": "docling.document_converter",
        "documentation": {}
    },
    {
        "label": "DocumentConverter",
        "importPath": "docling.document_converter",
        "description": "docling.document_converter",
        "isExtraImport": true,
        "detail": "docling.document_converter",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "FAISS",
        "importPath": "langchain_community.vectorstores",
        "description": "langchain_community.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_community.vectorstores",
        "documentation": {}
    },
    {
        "label": "FAISS",
        "importPath": "langchain_community.vectorstores",
        "description": "langchain_community.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_community.vectorstores",
        "documentation": {}
    },
    {
        "label": "FAISS",
        "importPath": "langchain_community.vectorstores",
        "description": "langchain_community.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_community.vectorstores",
        "documentation": {}
    },
    {
        "label": "InMemoryDocstore",
        "importPath": "langchain_community.docstore.in_memory",
        "description": "langchain_community.docstore.in_memory",
        "isExtraImport": true,
        "detail": "langchain_community.docstore.in_memory",
        "documentation": {}
    },
    {
        "label": "InMemoryDocstore",
        "importPath": "langchain_community.docstore.in_memory",
        "description": "langchain_community.docstore.in_memory",
        "isExtraImport": true,
        "detail": "langchain_community.docstore.in_memory",
        "documentation": {}
    },
    {
        "label": "hub",
        "importPath": "langchain",
        "description": "langchain",
        "isExtraImport": true,
        "detail": "langchain",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "load_and_convert_document",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "get_markdown_splits",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "create_or_load_vector_store",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "build_rag_chain",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "convert_from_path",
        "importPath": "pdf2image",
        "description": "pdf2image",
        "isExtraImport": true,
        "detail": "pdf2image",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "pdf2image",
        "description": "pdf2image",
        "isExtraImport": true,
        "detail": "pdf2image",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "isExtraImport": true,
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "configparser",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "configparser",
        "description": "configparser",
        "detail": "configparser",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "vaderSentiment.vaderSentiment",
        "description": "vaderSentiment.vaderSentiment",
        "isExtraImport": true,
        "detail": "vaderSentiment.vaderSentiment",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "vaderSentiment.vaderSentiment",
        "description": "vaderSentiment.vaderSentiment",
        "isExtraImport": true,
        "detail": "vaderSentiment.vaderSentiment",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "vaderSentiment.vaderSentiment",
        "description": "vaderSentiment.vaderSentiment",
        "isExtraImport": true,
        "detail": "vaderSentiment.vaderSentiment",
        "documentation": {}
    },
    {
        "label": "SentimentIntensityAnalyzer",
        "importPath": "vaderSentiment.vaderSentiment",
        "description": "vaderSentiment.vaderSentiment",
        "isExtraImport": true,
        "detail": "vaderSentiment.vaderSentiment",
        "documentation": {}
    },
    {
        "label": "getpass",
        "importPath": "getpass",
        "description": "getpass",
        "isExtraImport": true,
        "detail": "getpass",
        "documentation": {}
    },
    {
        "label": "OptionParser",
        "importPath": "optparse",
        "description": "optparse",
        "isExtraImport": true,
        "detail": "optparse",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "print_",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "CockroachDatabase",
        "importPath": "playhouse.cockroachdb",
        "description": "playhouse.cockroachdb",
        "isExtraImport": true,
        "detail": "playhouse.cockroachdb",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "playhouse.reflection",
        "description": "playhouse.reflection",
        "isExtraImport": true,
        "detail": "playhouse.reflection",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage",
        "importPath": "lumibot.example_strategies.stock_diversified_leverage",
        "description": "lumibot.example_strategies.stock_diversified_leverage",
        "isExtraImport": true,
        "detail": "lumibot.example_strategies.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "streamlit.runtime.scriptrunner_utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit.runtime.scriptrunner_utils",
        "description": "streamlit.runtime.scriptrunner_utils",
        "detail": "streamlit.runtime.scriptrunner_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "importPath": "pages.TraderBot.finbert_utils",
        "description": "pages.TraderBot.finbert_utils",
        "isExtraImport": true,
        "detail": "pages.TraderBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "stock_trading_rolling_window",
        "kind": 2,
        "importPath": "docs.examples.FINRL.3",
        "description": "docs.examples.FINRL.3",
        "peekOfCode": "def stock_trading_rolling_window(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    rolling_window_length: int,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,",
        "detail": "docs.examples.FINRL.3",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "class URL(str):\n    def __new__(cls, *value):\n        \"\"\"\n        note: we use *value and v0 to allow an empty URL string\n        \"\"\"\n        if value:\n            v0 = value[0]\n            if not (isinstance(v0, str) or isinstance(v0, URL)):\n                raise TypeError(f'Unexpected type for URL: \"{type(v0)}\"')\n            if not (v0.startswith('http://') or v0.startswith('https://') or",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "DATE",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "class DATE(str):\n    \"\"\"\n    date string in the format YYYY-MM-DD\n    \"\"\"\n    def __new__(cls, value):\n        if not value:\n            raise ValueError('Unexpected empty string')\n        if not isinstance(value, str):\n            raise TypeError(f'Unexpected type for DATE: \"{type(value)}\"')\n        if value.count(\"-\") != 2:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "FLOAT",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "class FLOAT(str):\n    \"\"\"\n    api allows passing floats or float as strings.\n    let's make sure that param passed is one of the two, so we don't pass\n    invalid strings all the way to the servers.\n    \"\"\"\n    def __new__(cls, value):\n        if isinstance(value, float) or isinstance(value, int):\n            return value\n        if isinstance(value, str):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_base_url",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "def get_base_url() -> URL:\n    return URL(os.environ.get(\n        'APCA_API_BASE_URL', 'https://api.alpaca.markets').rstrip('/'))\ndef get_data_url() -> URL:\n    return URL(os.environ.get(\n        'APCA_API_DATA_URL', 'https://data.alpaca.markets').rstrip('/'))\ndef get_data_stream_url() -> URL:\n    return URL(os.environ.get(\n        'APCA_API_STREAM_URL',\n        'https://stream.data.alpaca.markets').rstrip('/')",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_data_url",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "def get_data_url() -> URL:\n    return URL(os.environ.get(\n        'APCA_API_DATA_URL', 'https://data.alpaca.markets').rstrip('/'))\ndef get_data_stream_url() -> URL:\n    return URL(os.environ.get(\n        'APCA_API_STREAM_URL',\n        'https://stream.data.alpaca.markets').rstrip('/')\n               )\ndef get_credentials(key_id: str = None,\n                    secret_key: str = None,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_data_stream_url",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "def get_data_stream_url() -> URL:\n    return URL(os.environ.get(\n        'APCA_API_STREAM_URL',\n        'https://stream.data.alpaca.markets').rstrip('/')\n               )\ndef get_credentials(key_id: str = None,\n                    secret_key: str = None,\n                    oauth: str = None) -> Credentials:\n    oauth = oauth or os.environ.get('APCA_API_OAUTH_TOKEN')\n    key_id = key_id or os.environ.get('APCA_API_KEY_ID')",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_credentials",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "def get_credentials(key_id: str = None,\n                    secret_key: str = None,\n                    oauth: str = None) -> Credentials:\n    oauth = oauth or os.environ.get('APCA_API_OAUTH_TOKEN')\n    key_id = key_id or os.environ.get('APCA_API_KEY_ID')\n    if key_id is None and oauth is None:\n        raise ValueError('Key ID must be given to access Alpaca trade API',\n                         ' (env: APCA_API_KEY_ID)')\n    secret_key = secret_key or os.environ.get('APCA_API_SECRET_KEY')\n    if secret_key is None and oauth is None:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "get_api_version",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "def get_api_version(api_version: str) -> str:\n    api_version = api_version or os.environ.get('APCA_API_VERSION')\n    if api_version is None:\n        api_version = 'v2'\n    return api_version",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "Credentials",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.common",
        "description": "docs.examples.PY.lib.alpaca_trade_api.common",
        "peekOfCode": "Credentials = Tuple[str, str, str]\nclass URL(str):\n    def __new__(cls, *value):\n        \"\"\"\n        note: we use *value and v0 to allow an empty URL string\n        \"\"\"\n        if value:\n            v0 = value[0]\n            if not (isinstance(v0, str) or isinstance(v0, URL)):\n                raise TypeError(f'Unexpected type for URL: \"{type(v0)}\"')",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.common",
        "documentation": {}
    },
    {
        "label": "Entity",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Entity(object):\n    '''This helper class provides property access (the \"dot notation\")\n    to the json object, backed by the original object stored in the _raw\n    field.\n    '''\n    def __init__(self, raw):\n        self._raw = raw\n    def __getattr__(self, key):\n        if key in self._raw:\n            val = self._raw[key]",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Account",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Account(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/account/\n    \"\"\"\n    pass\nclass AccountConfigurations(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/account-configuration/",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "AccountConfigurations",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class AccountConfigurations(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/account-configuration/\n    \"\"\"\n    pass\nclass Asset(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/assets/#asset-entity",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Asset",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Asset(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/assets/#asset-entity\n    \"\"\"\n    pass\nclass Order(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/orders/#order-entity",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Order",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Order(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/orders/#order-entity\n    \"\"\"\n    def __init__(self, raw):\n        super().__init__(raw)\n        try:\n            self.legs = [Order(o) for o in self.legs]\n        except Exception:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Position",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Position(Entity):\n    \"\"\"\n    Entity properties:\nhttps://alpaca.markets/docs/api-documentation/api-v2/positions/#position-entity\n    \"\"\"\n    pass\nclass AccountActivity(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/account-activities/",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "AccountActivity",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class AccountActivity(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/account-activities/\n    \"\"\"\n    pass\nclass Bar(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/market-data/bars/",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Bar",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Bar(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/market-data/bars/\n    #bars-entity\n    \"\"\"\n    def __getattr__(self, key):\n        if key == 't':\n            val = self._raw[key[0]]\n            return pd.Timestamp(val, unit='s', tz=NY)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Bars",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Bars(list):\n    def __init__(self, raw):\n        super().__init__([Bar(o) for o in raw])\n        self._raw = raw\n    @property\n    def df(self):\n        if not hasattr(self, '_df'):\n            df = pd.DataFrame(\n                self._raw, columns=('t', 'o', 'h', 'l', 'c', 'v'),\n            )",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "_Timestamped",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class _Timestamped(object):\n    _tskeys = ('timestamp',)\n    def __getattr__(self, key):\n        if key in self._raw:\n            val = self._raw[key]\n            if key in self._tskeys:\n                return pd.Timestamp(val, tz=NY, unit=self._unit)\n            return val\n        return getattr(super(), key)\nclass _NanoTimestamped(_Timestamped):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "_NanoTimestamped",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class _NanoTimestamped(_Timestamped):\n    _unit = 'ns'\nclass Trade(_NanoTimestamped, Entity):\n    pass\nclass Quote(_NanoTimestamped, Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/market-data/last-quote\n    /#last-quote-entity\n    \"\"\"",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Trade",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Trade(_NanoTimestamped, Entity):\n    pass\nclass Quote(_NanoTimestamped, Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/market-data/last-quote\n    /#last-quote-entity\n    \"\"\"\n    pass\nclass Clock(Entity):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Quote",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Quote(_NanoTimestamped, Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/market-data/last-quote\n    /#last-quote-entity\n    \"\"\"\n    pass\nclass Clock(Entity):\n    \"\"\"\n    Entity properties:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Clock",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Clock(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/clock/#clock-entity\n    \"\"\"\n    def __getattr__(self, key):\n        if key in self._raw:\n            val = self._raw[key]\n            if key in ('timestamp', 'next_open', 'next_close'):\n                return pd.Timestamp(val)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Calendar",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Calendar(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/calendar/\n    #calendar-entity\n    \"\"\"\n    def __getattr__(self, key):\n        if key in self._raw:\n            val = self._raw[key]\n            if key in ('date',):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "Watchlist",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class Watchlist(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/watchlist/\n    #watchlist-entity\n    \"\"\"\n    pass\nclass PortfolioHistory(Entity):\n    \"\"\"\n    Entity properties:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "PortfolioHistory",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "class PortfolioHistory(Entity):\n    \"\"\"\n    Entity properties:\n    https://alpaca.markets/docs/api-documentation/api-v2/portfolio-history/\n    #portfoliohistory-entity\n    \"\"\"\n    def __init__(self, raw):\n        self._raw = raw\n    @property\n    def df(self):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "ISO8601YMD",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "ISO8601YMD = re.compile(r'\\d{4}-\\d{2}-\\d{2}T')\nNY = 'America/New_York'\nclass Entity(object):\n    '''This helper class provides property access (the \"dot notation\")\n    to the json object, backed by the original object stored in the _raw\n    field.\n    '''\n    def __init__(self, raw):\n        self._raw = raw\n    def __getattr__(self, key):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "NY",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "NY = 'America/New_York'\nclass Entity(object):\n    '''This helper class provides property access (the \"dot notation\")\n    to the json object, backed by the original object stored in the _raw\n    field.\n    '''\n    def __init__(self, raw):\n        self._raw = raw\n    def __getattr__(self, key):\n        if key in self._raw:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "trade_mapping",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "trade_mapping = {\n    \"T\": \"symbol\",\n    \"c\": \"conditions\",\n    \"x\": \"exchange\",\n    \"p\": \"price\",\n    \"s\": \"size\",\n    \"t\": \"timestamp\"\n}\nquote_mapping = {\n    \"T\": \"symbol\",",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "quote_mapping",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "quote_mapping = {\n    \"T\": \"symbol\",\n    \"X\": \"askexchange\",\n    \"P\": \"askprice\",\n    \"S\": \"asksize\",\n    \"x\": \"bidexchange\",\n    \"p\": \"bidprice\",\n    \"s\": \"bidsize\",\n    \"c\": \"conditions\",\n    \"t\": \"timestamp\"",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "agg_mapping",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "peekOfCode": "agg_mapping = {\n    \"T\": \"symbol\",\n    \"o\": \"open\",\n    \"c\": \"close\",\n    \"h\": \"high\",\n    \"l\": \"low\",\n    \"a\": \"average\",\n    \"x\": \"exchange\",\n    \"v\": \"volume\",\n    \"s\": \"start\",",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity",
        "documentation": {}
    },
    {
        "label": "EntityListType",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class EntityListType(Enum):\n    Trade = Trade, trade_mapping_v2\n    Quote = Quote, quote_mapping_v2\n    Bar = Bar, bar_mapping_v2\nclass EntityList(list):\n    def __init__(self, entity_type: EntityListType, raw):\n        entity = entity_type.value[0]\n        super().__init__([entity(o) for o in raw])\n        self._raw = raw\n        self.mapping = entity_type.value[1]",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "EntityList",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class EntityList(list):\n    def __init__(self, entity_type: EntityListType, raw):\n        entity = entity_type.value[0]\n        super().__init__([entity(o) for o in raw])\n        self._raw = raw\n        self.mapping = entity_type.value[1]\n    @property\n    def df(self):\n        if not hasattr(self, '_df'):\n            df = pd.DataFrame(",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "Remapped",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class Remapped:\n    def __init__(self, mapping: Dict[str, str], *args, **kwargs):\n        self._reversed_mapping = {\n            value: key for (key, value) in mapping.items()}\n        super().__init__(*args, **kwargs)\n    def __getattr__(self, key):\n        if key in self._reversed_mapping:\n            return super().__getattr__(self._reversed_mapping[key])\n        return super().__getattr__(key)\nclass BarsV2(EntityList):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "BarsV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class BarsV2(EntityList):\n    def __init__(self, raw):\n        super().__init__(EntityListType.Bar, raw)\nclass TradesV2(EntityList):\n    def __init__(self, raw):\n        super().__init__(EntityListType.Trade, raw)\nclass QuotesV2(EntityList):\n    def __init__(self, raw):\n        super().__init__(EntityListType.Quote, raw)\nclass TradeV2(Remapped, _NanoTimestamped, Entity):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "TradesV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class TradesV2(EntityList):\n    def __init__(self, raw):\n        super().__init__(EntityListType.Trade, raw)\nclass QuotesV2(EntityList):\n    def __init__(self, raw):\n        super().__init__(EntityListType.Quote, raw)\nclass TradeV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(trade_mapping_v2, raw)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "QuotesV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class QuotesV2(EntityList):\n    def __init__(self, raw):\n        super().__init__(EntityListType.Quote, raw)\nclass TradeV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(trade_mapping_v2, raw)\nclass QuoteV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "TradeV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class TradeV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(trade_mapping_v2, raw)\nclass QuoteV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(quote_mapping_v2, raw)\nclass BarV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "QuoteV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class QuoteV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(quote_mapping_v2, raw)\nclass BarV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(bar_mapping_v2, raw)\nclass StatusV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "BarV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class BarV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(bar_mapping_v2, raw)\nclass StatusV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(status_mapping_v2, raw)\nclass LULDV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "StatusV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class StatusV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(status_mapping_v2, raw)\nclass LULDV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(luld_mapping_v2, raw)\nclass CancelErrorV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "LULDV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class LULDV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(luld_mapping_v2, raw)\nclass CancelErrorV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(cancel_error_mapping_v2, raw)\nclass CorrectionV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "CancelErrorV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class CancelErrorV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(cancel_error_mapping_v2, raw)\nclass CorrectionV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(correction_mapping_v2, raw)\nclass SnapshotV2:\n    def __init__(self, raw):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "CorrectionV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class CorrectionV2(Remapped, _NanoTimestamped, Entity):\n    _tskeys = ('t',)\n    def __init__(self, raw):\n        super().__init__(correction_mapping_v2, raw)\nclass SnapshotV2:\n    def __init__(self, raw):\n        self.latest_trade = _convert_or_none(TradeV2, raw.get('latestTrade'))\n        self.latest_quote = _convert_or_none(QuoteV2, raw.get('latestQuote'))\n        self.minute_bar = _convert_or_none(BarV2, raw.get('minuteBar'))\n        self.daily_bar = _convert_or_none(BarV2, raw.get('dailyBar'))",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "SnapshotV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class SnapshotV2:\n    def __init__(self, raw):\n        self.latest_trade = _convert_or_none(TradeV2, raw.get('latestTrade'))\n        self.latest_quote = _convert_or_none(QuoteV2, raw.get('latestQuote'))\n        self.minute_bar = _convert_or_none(BarV2, raw.get('minuteBar'))\n        self.daily_bar = _convert_or_none(BarV2, raw.get('dailyBar'))\n        self.prev_daily_bar = _convert_or_none(BarV2, raw.get('prevDailyBar'))\nclass SnapshotsV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "SnapshotsV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class SnapshotsV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(SnapshotV2, v)\nclass LatestBarsV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(BarV2, v)\nclass LatestTradesV2(dict):\n    def __init__(self, raw):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "LatestBarsV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class LatestBarsV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(BarV2, v)\nclass LatestTradesV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(TradeV2, v)\nclass LatestQuotesV2(dict):\n    def __init__(self, raw):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "LatestTradesV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class LatestTradesV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(TradeV2, v)\nclass LatestQuotesV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(QuoteV2, v)\nclass BidOrAsk(Entity):\n    def __init__(self, raw):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "LatestQuotesV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class LatestQuotesV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            self[k] = _convert_or_none(QuoteV2, v)\nclass BidOrAsk(Entity):\n    def __init__(self, raw):\n        super().__init__(raw)\nclass OrderbookV2(Entity):\n    def __init__(self, raw):\n        super().__init__(raw)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "BidOrAsk",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class BidOrAsk(Entity):\n    def __init__(self, raw):\n        super().__init__(raw)\nclass OrderbookV2(Entity):\n    def __init__(self, raw):\n        super().__init__(raw)\n        if self.bids:\n            for i in range(len(self.bids)):\n                self.bids[i] = BidOrAsk(self.bids[i])\n        if self.asks:",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "OrderbookV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class OrderbookV2(Entity):\n    def __init__(self, raw):\n        super().__init__(raw)\n        if self.bids:\n            for i in range(len(self.bids)):\n                self.bids[i] = BidOrAsk(self.bids[i])\n        if self.asks:\n            for i in range(len(self.asks)):\n                self.asks[i] = BidOrAsk(self.asks[i])\nclass OrderbooksV2(dict):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "OrderbooksV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class OrderbooksV2(dict):\n    def __init__(self, raw):\n        for k, v in raw.items():\n            for side in orderbook_mapping_v2.keys():\n                if side not in v:\n                    continue\n                readable_side = orderbook_mapping_v2[side]\n                v[readable_side] = v[side]\n                v.pop(side)\n            self[k] = _convert_or_none(OrderbookV2, v)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "NewsV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class NewsV2(Entity):\n    def __init__(self, raw):\n        super().__init__(raw)\nclass NewsListV2(list):\n    def __init__(self, raw):\n        super().__init__([NewsV2(o) for o in raw])\ndef _convert_or_none(entityType, value):\n    if value:\n        return entityType(value)\n    return None",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "NewsListV2",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "class NewsListV2(list):\n    def __init__(self, raw):\n        super().__init__([NewsV2(o) for o in raw])\ndef _convert_or_none(entityType, value):\n    if value:\n        return entityType(value)\n    return None",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "trade_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "trade_mapping_v2 = {\n    \"i\": \"id\",\n    \"S\": \"symbol\",\n    \"c\": \"conditions\",\n    \"x\": \"exchange\",\n    \"p\": \"price\",\n    \"s\": \"size\",\n    \"t\": \"timestamp\",\n    \"z\": \"tape\",  # stocks only\n    \"tks\": \"takerside\"  # crypto only",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "quote_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "quote_mapping_v2 = {\n    \"S\":  \"symbol\",\n    \"x\": \"exchange\",  # crypto only\n    \"ax\": \"ask_exchange\",\n    \"ap\": \"ask_price\",\n    \"as\": \"ask_size\",\n    \"bx\": \"bid_exchange\",\n    \"bp\": \"bid_price\",\n    \"bs\": \"bid_size\",\n    \"c\":  \"conditions\",  # stocks only",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "bar_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "bar_mapping_v2 = {\n    \"S\":  \"symbol\",\n    \"x\": \"exchange\",  # crypto only\n    \"o\":  \"open\",\n    \"h\":  \"high\",\n    \"l\":  \"low\",\n    \"c\":  \"close\",\n    \"v\":  \"volume\",\n    \"t\":  \"timestamp\",\n    \"n\":  \"trade_count\",",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "status_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "status_mapping_v2 = {\n    \"S\":  \"symbol\",\n    \"sc\": \"status_code\",\n    \"sm\": \"status_message\",\n    \"rc\": \"reason_code\",\n    \"rm\": \"reason_message\",\n    \"t\":  \"timestamp\",\n    \"z\":  \"tape\"\n}\nluld_mapping_v2 = {",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "luld_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "luld_mapping_v2 = {\n    \"S\": \"symbol\",\n    \"u\": \"limit_up_price\",\n    \"d\": \"limit_down_price\",\n    \"i\": \"indicator\",\n    \"t\": \"timestamp\",\n    \"z\": \"tape\"\n}\ncancel_error_mapping_v2 = {\n    \"S\": \"symbol\",",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "cancel_error_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "cancel_error_mapping_v2 = {\n    \"S\": \"symbol\",\n    \"i\": \"id\",\n    \"x\": \"exchange\",\n    \"p\": \"price\",\n    \"s\": \"size\",\n    \"a\": \"cancel_error_action\",\n    \"z\": \"tape\",\n    \"t\": \"timestamp\",\n}",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "correction_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "correction_mapping_v2 = {\n    \"S\": \"symbol\",\n    \"x\": \"exchange\",\n    \"oi\": \"original_id\",\n    \"op\": \"original_price\",\n    \"os\": \"original_size\",\n    \"oc\": \"original_conditions\",\n    \"ci\": \"corrected_id\",\n    \"cp\": \"corrected_price\",\n    \"cs\": \"corrected_size\",",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "orderbook_mapping_v2",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "description": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "peekOfCode": "orderbook_mapping_v2 = {\n    \"S\": \"symbol\",\n    \"x\": \"exchange\",\n    \"t\": \"timestamp\",\n    \"b\": \"bids\",\n    \"a\": \"asks\",\n}\nclass EntityListType(Enum):\n    Trade = Trade, trade_mapping_v2\n    Quote = Quote, quote_mapping_v2",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.entity_v2",
        "documentation": {}
    },
    {
        "label": "RetryException",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "class RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"\n    Represent API related error.\n    error.status_code will have http status code.\n    \"\"\"\n    def __init__(self, error, http_error=None):\n        super().__init__(error['message'])\n        self._error = error",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "APIError",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "class APIError(Exception):\n    \"\"\"\n    Represent API related error.\n    error.status_code will have http status code.\n    \"\"\"\n    def __init__(self, error, http_error=None):\n        super().__init__(error['message'])\n        self._error = error\n        self._http_error = http_error\n    @property",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrameUnit",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "class TimeFrameUnit(Enum):\n    Minute = \"Min\"\n    Hour = \"Hour\"\n    Day = \"Day\"\n    Week = \"Week\"\n    Month = \"Month\"\nclass TimeFrame:\n    def __init__(self, amount: int, unit: TimeFrameUnit):\n        self.validate(amount, unit)\n        self.__amount = amount",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "class TimeFrame:\n    def __init__(self, amount: int, unit: TimeFrameUnit):\n        self.validate(amount, unit)\n        self.__amount = amount\n        self.__unit = unit\n    @property\n    def amount(self):\n        return self.__amount\n    @amount.setter\n    def amount(self, value: int):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "Sort",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "class Sort(Enum):\n    Asc = \"asc\"\n    Desc = \"desc\"\n    def __str__(self):\n        return self.value\nclass REST(object):\n    def __init__(self,\n                 key_id: str = None,\n                 secret_key: str = None,\n                 base_url: URL = None,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "REST",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "class REST(object):\n    def __init__(self,\n                 key_id: str = None,\n                 secret_key: str = None,\n                 base_url: URL = None,\n                 api_version: str = None,\n                 oauth=None,\n                 raw_data: bool = False\n                 ):\n        \"\"\"",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "raise_api_error",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "def raise_api_error(resp: requests.Response, http_error: requests.HTTPError):\n    try:\n        error = resp.json()\n    except:\n        raise http_error from None\n    if 'message' in error:\n        raise APIError(error, http_error) from None\n    raise http_error from None\nclass TimeFrameUnit(Enum):\n    Minute = \"Min\"",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "logger = logging.getLogger(__name__)\nPositions = List[Position]\nOrders = List[Order]\nAssets = List[Asset]\nAccountActivities = List[AccountActivity]\nCalendars = List[Calendar]\nWatchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "Positions",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "Positions = List[Position]\nOrders = List[Order]\nAssets = List[Asset]\nAccountActivities = List[AccountActivity]\nCalendars = List[Calendar]\nWatchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "Orders",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "Orders = List[Order]\nAssets = List[Asset]\nAccountActivities = List[AccountActivity]\nCalendars = List[Calendar]\nWatchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "Assets",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "Assets = List[Asset]\nAccountActivities = List[AccountActivity]\nCalendars = List[Calendar]\nWatchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "AccountActivities",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "AccountActivities = List[AccountActivity]\nCalendars = List[Calendar]\nWatchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "Calendars",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "Calendars = List[Calendar]\nWatchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "Watchlists",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "Watchlists = List[Watchlist]\nTradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TradeIterator",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "TradeIterator = Iterator[Union[Trade, dict]]\nQuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "QuoteIterator",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "QuoteIterator = Iterator[Union[Quote, dict]]\nBarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"\n    Represent API related error.",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "BarIterator",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "BarIterator = Iterator[Union[Bar, dict]]\nNewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"\n    Represent API related error.\n    error.status_code will have http status code.",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "NewsIterator",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "NewsIterator = Iterator[Union[NewsV2, dict]]\nDATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"\n    Represent API related error.\n    error.status_code will have http status code.\n    \"\"\"",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "DATA_V2_MAX_LIMIT",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "DATA_V2_MAX_LIMIT = 10000  # max items per api call\nNEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"\n    Represent API related error.\n    error.status_code will have http status code.\n    \"\"\"\n    def __init__(self, error, http_error=None):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "NEWS_MAX_LIMIT",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "NEWS_MAX_LIMIT = 50  # max items per api call\nclass RetryException(Exception):\n    pass\nclass APIError(Exception):\n    \"\"\"\n    Represent API related error.\n    error.status_code will have http status code.\n    \"\"\"\n    def __init__(self, error, http_error=None):\n        super().__init__(error['message'])",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame.Minute",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "TimeFrame.Minute = TimeFrame(1, TimeFrameUnit.Minute)\nTimeFrame.Hour = TimeFrame(1, TimeFrameUnit.Hour)\nTimeFrame.Day = TimeFrame(1, TimeFrameUnit.Day)\nTimeFrame.Week = TimeFrame(1, TimeFrameUnit.Week)\nTimeFrame.Month = TimeFrame(1, TimeFrameUnit.Month)\nclass Sort(Enum):\n    Asc = \"asc\"\n    Desc = \"desc\"\n    def __str__(self):\n        return self.value",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame.Hour",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "TimeFrame.Hour = TimeFrame(1, TimeFrameUnit.Hour)\nTimeFrame.Day = TimeFrame(1, TimeFrameUnit.Day)\nTimeFrame.Week = TimeFrame(1, TimeFrameUnit.Week)\nTimeFrame.Month = TimeFrame(1, TimeFrameUnit.Month)\nclass Sort(Enum):\n    Asc = \"asc\"\n    Desc = \"desc\"\n    def __str__(self):\n        return self.value\nclass REST(object):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame.Day",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "TimeFrame.Day = TimeFrame(1, TimeFrameUnit.Day)\nTimeFrame.Week = TimeFrame(1, TimeFrameUnit.Week)\nTimeFrame.Month = TimeFrame(1, TimeFrameUnit.Month)\nclass Sort(Enum):\n    Asc = \"asc\"\n    Desc = \"desc\"\n    def __str__(self):\n        return self.value\nclass REST(object):\n    def __init__(self,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame.Week",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "TimeFrame.Week = TimeFrame(1, TimeFrameUnit.Week)\nTimeFrame.Month = TimeFrame(1, TimeFrameUnit.Month)\nclass Sort(Enum):\n    Asc = \"asc\"\n    Desc = \"desc\"\n    def __str__(self):\n        return self.value\nclass REST(object):\n    def __init__(self,\n                 key_id: str = None,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "TimeFrame.Month",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "peekOfCode": "TimeFrame.Month = TimeFrame(1, TimeFrameUnit.Month)\nclass Sort(Enum):\n    Asc = \"asc\"\n    Desc = \"desc\"\n    def __str__(self):\n        return self.value\nclass REST(object):\n    def __init__(self,\n                 key_id: str = None,\n                 secret_key: str = None,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest",
        "documentation": {}
    },
    {
        "label": "AsyncRest",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.rest_async",
        "description": "docs.examples.PY.lib.alpaca_trade_api.rest_async",
        "peekOfCode": "class AsyncRest:\n    def __init__(self,\n                 key_id: str = None,\n                 secret_key: str = None,\n                 data_url: URL = None,\n                 api_version: str = None,\n                 raw_data: bool = False\n                 ):\n        \"\"\"\n        :param raw_data: should we return api response raw or wrap it with",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.rest_async",
        "documentation": {}
    },
    {
        "label": "_DataStream",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "class _DataStream:\n    def __init__(self,\n                 endpoint: str,\n                 key_id: str,\n                 secret_key: str,\n                 raw_data: bool = False,\n                 websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "DataStream",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "class DataStream(_DataStream):\n    def __init__(self,\n                 key_id: str,\n                 secret_key: str,\n                 base_url: URL,\n                 raw_data: bool,\n                 feed: str = 'iex',\n                 websocket_params: Optional[Dict] = None):\n        base_url = re.sub(r'^http', 'ws', base_url)\n        super().__init__(endpoint=base_url + '/v2/' + feed,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "CryptoDataStream",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "class CryptoDataStream(_DataStream):\n    def __init__(self,\n                 key_id: str,\n                 secret_key: str,\n                 base_url: URL,\n                 raw_data: bool,\n                 exchanges: Optional[List[str]] = None,\n                 websocket_params: Optional[Dict] = None):\n        self._key_id = key_id\n        self._secret_key = secret_key",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "NewsDataStream",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "class NewsDataStream(_DataStream):\n    def __init__(self,\n                 key_id: str,\n                 secret_key: str,\n                 base_url: URL,\n                 raw_data: bool,\n                 websocket_params: Optional[Dict] = None):\n        self._key_id = key_id\n        self._secret_key = secret_key\n        base_url = re.sub(r'^http', 'ws', base_url)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "TradingStream",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "class TradingStream:\n    def __init__(self,\n                 key_id: str,\n                 secret_key: str,\n                 base_url: URL,\n                 raw_data: bool = False,\n                 websocket_params: Optional[Dict] = None):\n        self._key_id = key_id\n        self._secret_key = secret_key\n        base_url = re.sub(r'^http', 'ws', base_url)",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "Stream",
        "kind": 6,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "class Stream:\n    def __init__(self,\n                 key_id: str = None,\n                 secret_key: str = None,\n                 base_url: URL = None,\n                 data_stream_url: URL = None,\n                 data_feed: str = 'iex',\n                 raw_data: bool = False,\n                 crypto_exchanges: Optional[List[str]] = None,\n                 websocket_params: Optional[Dict] = None):",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "log = logging.getLogger(__name__)\n# Default Params we pass to the websocket constructors\nWEBSOCKET_DEFAULTS = {\n    \"ping_interval\": 10,\n    \"ping_timeout\": 180,\n    \"max_queue\": 1024,\n}\ndef _ensure_coroutine(handler):\n    if not asyncio.iscoroutinefunction(handler):\n        raise ValueError('handler must be a coroutine function')",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "WEBSOCKET_DEFAULTS",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "description": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "peekOfCode": "WEBSOCKET_DEFAULTS = {\n    \"ping_interval\": 10,\n    \"ping_timeout\": 180,\n    \"max_queue\": 1024,\n}\ndef _ensure_coroutine(handler):\n    if not asyncio.iscoroutinefunction(handler):\n        raise ValueError('handler must be a coroutine function')\nclass _DataStream:\n    def __init__(self,",
        "detail": "docs.examples.PY.lib.alpaca_trade_api.stream",
        "documentation": {}
    },
    {
        "label": "delete_base_url_envs",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def delete_base_url_envs():\n    if 'APCA_API_BASE_URL' in os.environ:\n        del os.environ['APCA_API_BASE_URL']\n    if 'APCA_API_DATA_URL' in os.environ:\n        del os.environ['APCA_API_DATA_URL']\n@pytest.fixture\ndef reqmock():\n    with requests_mock.Mocker() as m:\n        yield m\ndef test_api(reqmock):",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "reqmock",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def reqmock():\n    with requests_mock.Mocker() as m:\n        yield m\ndef test_api(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # Get a list of accounts\n    reqmock.get('https://api.alpaca.markets/v1/account', text='''\n    {",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_api",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_api(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # Get a list of accounts\n    reqmock.get('https://api.alpaca.markets/v1/account', text='''\n    {\n      \"id\": \"904837e3-3b76-47ec-b432-046db621571b\",\n      \"status\": \"ACTIVE\",\n      \"currency\": \"USD\",",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_orders",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_orders(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # Get a list of orders\n    reqmock.get(\n        'https://api.alpaca.markets/v1/orders',\n        text='''[\n  {\n    \"id\": \"904837e3-3b76-47ec-b432-046db621571b\",",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_positions",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_positions(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # Get a list of positions\n    reqmock.get(\n        'https://api.alpaca.markets/v1/positions',\n        text='''[\n  {\n    \"account_id\": \"904837e3-3b76-47ec-b432-046db621571b\",",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_chronos",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_chronos(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # clock\n    reqmock.get(\n        'https://api.alpaca.markets/v1/clock',\n        text='''{\n  \"timestamp\": \"2018-04-01T12:00:00.000Z\",\n  \"is_open\": true,",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_data",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_data(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # Latest trade\n    reqmock.get(\n        'https://data.alpaca.markets/v2/stocks/AAPL/trades/latest',\n        text='''\n        {\n            \"symbol\": \"AAPL\",",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_timeframe",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_timeframe(reqmock):\n    # Custom timeframe: Minutes\n    reqmock.get('https://data.alpaca.markets/v2/stocks/AAPL/bars?'\n                'timeframe=45Min&adjustment=raw&'\n                'start=2021-06-08&end=2021-06-08', text='{}')\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    timeframe = tradeapi.TimeFrame(45, tradeapi.TimeFrameUnit.Minute)\n    api.get_bars('AAPL', timeframe, '2021-06-08', '2021-06-08')\n    assert reqmock.called\n    # Custom timeframe: Hours",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_watchlists",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_watchlists(reqmock):\n    api = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_raw = tradeapi.REST('key-id', 'secret-key', api_version='v1',\n                            raw_data=True)\n    # get watchlists\n    reqmock.get(\n        'https://api.alpaca.markets/v1/watchlists',\n        text='''[\n    {\n        \"id\": \"900e20b1-46eb-492b-a505-2ea67386b5fd\",",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_errors",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_errors(reqmock):\n    api_v1 = tradeapi.REST('key-id', 'secret-key', api_version='v1')\n    api_v1._retry = 1\n    api_v1._retry_wait = 0\n    api_v1._do_error = True\n    def callback_429(request, context):\n        if api_v1._do_error:\n            api_v1._do_error = False\n            context.status_code = 429\n            return 'Too Many Requests'",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "test_no_resource_warning_with_context_manager",
        "kind": 2,
        "importPath": "docs.examples.PY.lib.tests.test_rest",
        "description": "docs.examples.PY.lib.tests.test_rest",
        "peekOfCode": "def test_no_resource_warning_with_context_manager():\n    with warnings.catch_warnings():  # ensure no warnings are raised\n        warnings.simplefilter(\"error\")\n        with tradeapi.REST(\"key-id\", \"secret-key\", api_version=\"v1\") as api:\n            assert api",
        "detail": "docs.examples.PY.lib.tests.test_rest",
        "documentation": {}
    },
    {
        "label": "_version_re",
        "kind": 5,
        "importPath": "docs.examples.PY.lib.setup",
        "description": "docs.examples.PY.lib.setup",
        "peekOfCode": "_version_re = re.compile(r'__version__\\s+=\\s+(.*)')\nwith open('alpaca_trade_api/__init__.py', 'rb') as f:\n    version = str(ast.literal_eval(_version_re.search(\n        f.read().decode('utf-8')).group(1)))\nwith open('README.md') as readme_file:\n    README = readme_file.read()\nwith open(os.path.join(\"requirements\", \"requirements.txt\")) as reqs:\n    REQUIREMENTS = reqs.readlines()\nwith open(os.path.join(\"requirements\", \"requirements_test.txt\")) as reqs:\n    REQUIREMENTS_TEST = reqs.readlines()",
        "detail": "docs.examples.PY.lib.setup",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "docs.examples.PY.AlpacPaperTrading",
        "description": "docs.examples.PY.AlpacPaperTrading",
        "peekOfCode": "class AlpacaPaperTrading:\n    def __init__(self, ticker_list, time_interval, drl_lib, agent, cwd, net_dim, \n                 state_dim, action_dim, ALPACA_API_KEY, ALPACA_API_SECRET , \n                 ALPACA_API_BASE_URL, tech_indicator_list, turbulence_thresh=30, \n                 max_stock=1e2, latency=None):\n        self.ticker_list = ticker_list\n        self.time_interval = time_interval\n        self.drl_lib = drl_lib\n        self.agent = agent\n        self.cwd = cwd",
        "detail": "docs.examples.PY.AlpacPaperTrading",
        "documentation": {}
    },
    {
        "label": "DATA_API_KEY",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "DATA_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\" #args.data_key\nDATA_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.data_secret\nDATA_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.data_url\nTRADING_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\" #args.trading_key\nTRADING_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.trading_secret\nTRADING_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "DATA_API_SECRET",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "DATA_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.data_secret\nDATA_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.data_url\nTRADING_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\" #args.trading_key\nTRADING_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.trading_secret\nTRADING_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "DATA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "DATA_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.data_url\nTRADING_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\" #args.trading_key\nTRADING_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.trading_secret\nTRADING_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRADING_API_KEY",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRADING_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\" #args.trading_key\nTRADING_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.trading_secret\nTRADING_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)\nimport alpaca_trade_api",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRADING_API_SECRET",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRADING_API_SECRET = \"BxT64PIQtDBb*tnW\"  #args.trading_secret\nTRADING_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)\nimport alpaca_trade_api\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRADING_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRADING_API_BASE_URL = 'https://paper-api.alpaca.markets' #args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)\nimport alpaca_trade_api\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.paper_trading.alpaca import PaperTradingAlpaca",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "ticker_list = DOW_30_TICKER\nenv = StockTradingEnv\n# if you want to use larger datasets (change to longer period), and it raises error, please try to increase \"target_step\". It should be larger than the episode steps.\nERL_PARAMS = {\n    \"learning_rate\": 3e-6,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": [128, 64],\n    \"target_step\": 5000,",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "env = StockTradingEnv\n# if you want to use larger datasets (change to longer period), and it raises error, please try to increase \"target_step\". It should be larger than the episode steps.\nERL_PARAMS = {\n    \"learning_rate\": 3e-6,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": [128, 64],\n    \"target_step\": 5000,\n    \"eval_gap\": 30,",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "ERL_PARAMS = {\n    \"learning_rate\": 3e-6,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": [128, 64],\n    \"target_step\": 5000,\n    \"eval_gap\": 30,\n    \"eval_times\": 1,\n}",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "today",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "today = datetime.datetime.today()\nTEST_END_DATE = (today - BDay(1)).to_pydatetime().date()\nTEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_END_DATE = (today - BDay(1)).to_pydatetime().date()\nTEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)\ntrain(",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)\ntrain(\n    start_date=TRAIN_START_DATE,",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)\ntrain(\n    start_date=TRAIN_START_DATE,\n    end_date=TRAIN_END_DATE,",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "account_value_erl",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "account_value_erl = test(\n    start_date=TEST_START_DATE,\n    end_date=TEST_END_DATE,\n    ticker_list=ticker_list,\n    data_source=\"alpaca\",\n    time_interval=\"1Min\",\n    technical_indicator_list=INDICATORS,\n    drl_lib=\"elegantrl\",\n    env=env,\n    model_name=\"ppo\",",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "action_dim",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "action_dim = len(DOW_30_TICKER)\nstate_dim = (\n    1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\n)  # Calculate the DRL state dimension manually for paper trading. amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\npaper_trading_erl = PaperTradingAlpaca(\n    ticker_list=DOW_30_TICKER,\n    time_interval=\"1Min\",\n    drl_lib=\"elegantrl\",\n    agent=\"ppo\",\n    cwd=\"./papertrading_erl_retrain\",",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "state_dim",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "state_dim = (\n    1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\n)  # Calculate the DRL state dimension manually for paper trading. amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\npaper_trading_erl = PaperTradingAlpaca(\n    ticker_list=DOW_30_TICKER,\n    time_interval=\"1Min\",\n    drl_lib=\"elegantrl\",\n    agent=\"ppo\",\n    cwd=\"./papertrading_erl_retrain\",\n    net_dim=ERL_PARAMS[\"net_dimension\"],",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "paper_trading_erl",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "paper_trading_erl = PaperTradingAlpaca(\n    ticker_list=DOW_30_TICKER,\n    time_interval=\"1Min\",\n    drl_lib=\"elegantrl\",\n    agent=\"ppo\",\n    cwd=\"./papertrading_erl_retrain\",\n    net_dim=ERL_PARAMS[\"net_dimension\"],\n    state_dim=state_dim,\n    action_dim=action_dim,\n    ALPACA_API_KEY=TRADING_API_KEY,",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "returns_erl",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "returns_erl = cumu_erl - 1\nreturns_dia = cumu_djia - 1\nreturns_dia = returns_dia[: returns_erl.shape[0]]\n# plot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which=\"minor\", axis=\"y\")\nplt.title(\"Stock Trading (Paper trading)\", fontsize=20)\nplt.plot(returns_erl, label=\"ElegantRL Agent\", color=\"red\")",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "returns_dia = cumu_djia - 1\nreturns_dia = returns_dia[: returns_erl.shape[0]]\n# plot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which=\"minor\", axis=\"y\")\nplt.title(\"Stock Trading (Paper trading)\", fontsize=20)\nplt.plot(returns_erl, label=\"ElegantRL Agent\", color=\"red\")\n# plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "returns_dia = returns_dia[: returns_erl.shape[0]]\n# plot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which=\"minor\", axis=\"y\")\nplt.title(\"Stock Trading (Paper trading)\", fontsize=20)\nplt.plot(returns_erl, label=\"ElegantRL Agent\", color=\"red\")\n# plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )\n# plt.plot(returns_rllib, label = 'RLlib Agent', color = 'green')",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "ax",
        "kind": 5,
        "importPath": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "description": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "ax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(\n    ticker.FixedFormatter([\"\", \"10-19\", \"\", \"10-20\", \"\", \"10-21\", \"\", \"10-22\"])\n)\nplt.legend(fontsize=10.5)\nplt.savefig(\"papertrading_stock.png\")",
        "detail": "docs.examples.PY.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "stock_trading",
        "kind": 2,
        "importPath": "docs.examples.PY.Stablebaselines3 + Dow Jones",
        "description": "docs.examples.PY.Stablebaselines3 + Dow Jones",
        "peekOfCode": "def stock_trading(\n        train_start_date: str,\n        train_end_date: str,\n        trade_start_date: str,\n        trade_end_date: str,\n        if_store_actions: bool = True,\n        if_store_result: bool = True,\n        if_using_a2c: bool = True,\n        if_using_ddpg: bool = True,\n        if_using_ppo: bool = True,",
        "detail": "docs.examples.PY.Stablebaselines3 + Dow Jones",
        "documentation": {}
    },
    {
        "label": "stock_trading",
        "kind": 2,
        "importPath": "docs.examples.PY.df_account_value_a2c",
        "description": "docs.examples.PY.df_account_value_a2c",
        "peekOfCode": "def stock_trading(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,\n    if_using_ppo: bool = True,",
        "detail": "docs.examples.PY.df_account_value_a2c",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.examples.PY.ensemble_stock_trading copy",
        "description": "docs.examples.PY.ensemble_stock_trading copy",
        "peekOfCode": "def main():\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    import sys",
        "detail": "docs.examples.PY.ensemble_stock_trading copy",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "kind": 6,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "class YahooDownloader:\n    Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from config.py)\n        end_date : str\n            end date of the data (modified from config.py)\n        ticker_list : list",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "os = sys.path.append(\"/content/drive/packages\")\nprint(os)\nimport itertools\n# %matplotlib inline\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.head()\ndf.tail()\ndf.shape",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.head()\ndf.tail()\ndf.shape\ndf.sort_values(['date','tic']).head()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "TEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.head()\ndf.tail()\ndf.shape\ndf.sort_values(['date','tic']).head()\nlen(df.tic.unique())",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "TEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.head()\ndf.tail()\ndf.shape\ndf.sort_values(['date','tic']).head()\nlen(df.tic.unique())\ndf.tic.value_counts()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.head()\ndf.tail()\ndf.shape\ndf.sort_values(['date','tic']).head()\nlen(df.tic.unique())\ndf.tic.value_counts()\n\"\"\"# Part 4: Preprocess Data",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprocessed.sample(5)\n\"\"\"<a id='4'></a>",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprocessed.sample(5)\n\"\"\"<a id='4'></a>\n# Part 5. Design Environment\nConsidering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\nOur trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\nThe action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprocessed.sample(5)\n\"\"\"<a id='4'></a>\n# Part 5. Design Environment\nConsidering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\nOur trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\nThe action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.\n\"\"\"",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprocessed.sample(5)\n\"\"\"<a id='4'></a>\n# Part 5. Design Environment\nConsidering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\nOur trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\nThe action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.\n\"\"\"\nstock_dimension = len(processed.tic.unique())",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nprocessed.sample(5)\n\"\"\"<a id='4'></a>\n# Part 5. Design Environment\nConsidering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\nOur trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\nThe action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.\n\"\"\"\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension,\n    \"reward_scaling\": 1e-4,",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2048,\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2048,\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 10_000,\n                      \"learning_rate\": 0.0005,",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 10_000,\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\ntimesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,\n                 'ddpg' : 10_000\n                 }",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "timesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,\n                 'ddpg' : 10_000\n                 }\ndf_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,\n                                                 timesteps_dict)\ndf_summary\n\"\"\"<a id='6'></a>",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,\n                                                 timesteps_dict)\ndf_summary\n\"\"\"<a id='6'></a>\n# Part 7: Backtest OurStrategy\nBacktesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy.\n\"\"\"\nunique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value.append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value.append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\n# Commented out IPython magic to ensure Python compatibility.",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_dji_",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "stats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n\"\"\"<a id='6.2'></a>",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_dji['date']",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n\"\"\"<a id='6.2'></a>\n## 7.2 BackTestPlot",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_dji['dji']",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n\"\"\"<a id='6.2'></a>\n## 7.2 BackTestPlot\n\"\"\"",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n\"\"\"<a id='6.2'></a>\n## 7.2 BackTestPlot\n\"\"\"\n# Commented out IPython magic to ensure Python compatibility.\n# print(\"==============Compare to DJIA===========\")\n# %matplotlib inline",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_result_ensemble",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\ndf_result_ensemble = df_result_ensemble.set_index('date')\nprint(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\nprint(\"df_trade_date: \", df_trade_date)\n# df_result_ensemble['date'] = df_trade_date['datadate']\n# df_result_ensemble['account_value'] = df_account_value['account_value']\ndf_result_ensemble.to_csv(\"df_result_ensemble.csv\")\nprint(\"df_result_ensemble: \", df_result_ensemble)\nprint(\"==============Compare to DJIA===========\")",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "df_result_ensemble",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "df_result_ensemble = df_result_ensemble.set_index('date')\nprint(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\nprint(\"df_trade_date: \", df_trade_date)\n# df_result_ensemble['date'] = df_trade_date['datadate']\n# df_result_ensemble['account_value'] = df_account_value['account_value']\ndf_result_ensemble.to_csv(\"df_result_ensemble.csv\")\nprint(\"df_result_ensemble: \", df_result_ensemble)\nprint(\"==============Compare to DJIA===========\")\nresult = pd.DataFrame()",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "result = pd.DataFrame()\n# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n# result = pd.merge(result, df_dji, left_index=True, right_index=True)\nresult = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\nresult.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\nresult.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "result.columns",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "result.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "plt.rcParams[\"figure.figsize\"]",
        "kind": 5,
        "importPath": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "description": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "peekOfCode": "plt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "docs.examples.PY.finrl_ensemble_stocktrading_icaif_2020",
        "documentation": {}
    },
    {
        "label": "run_script",
        "kind": 2,
        "importPath": "docs.examples.PY.flusk",
        "description": "docs.examples.PY.flusk",
        "peekOfCode": "def run_script():\n    data = request.json.get('data')\n    # Simulate running a Python script (replace this with your actual logic)\n    time.sleep(2)  # Simulating a delay\n    result = f'Processed data: {data}'  # Example response\n    return jsonify({'message': result})\nif __name__ == '__main__':\n    app.run(debug=True)",
        "detail": "docs.examples.PY.flusk",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "docs.examples.PY.flusk",
        "description": "docs.examples.PY.flusk",
        "peekOfCode": "app = Flask(__name__)\n@app.route('/run-script', methods=['POST'])\ndef run_script():\n    data = request.json.get('data')\n    # Simulate running a Python script (replace this with your actual logic)\n    time.sleep(2)  # Simulating a delay\n    result = f'Processed data: {data}'  # Example response\n    return jsonify({'message': result})\nif __name__ == '__main__':\n    app.run(debug=True)",
        "detail": "docs.examples.PY.flusk",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.examples.PY.greet",
        "description": "docs.examples.PY.greet",
        "peekOfCode": "def main():\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    lib_path = os.path.join(script_dir, 'lib', 'alpaca_trade_api')\n    print(lib_path)\n    sys.path.append(lib_path)\n    import lib.alpaca_trade_api as tradeapi\n    now = datetime.now()\n    formatted_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n    print(f\"Time from greet.py at {formatted_time}\")\n    api = tradeapi.rest.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')",
        "detail": "docs.examples.PY.greet",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "docs.examples.PY.greet",
        "description": "docs.examples.PY.greet",
        "peekOfCode": "ALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"\nALPACA_API_SECRET  = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\n# Description: This is a simple python script that prints a greeting message along with the current date and time.\nfrom datetime import datetime\nimport sys\nimport os\n# import alpaca_trade_api as tradeapi\ndef main():\n    script_dir = os.path.dirname(os.path.abspath(__file__))",
        "detail": "docs.examples.PY.greet",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.greet",
        "description": "docs.examples.PY.greet",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\n# Description: This is a simple python script that prints a greeting message along with the current date and time.\nfrom datetime import datetime\nimport sys\nimport os\n# import alpaca_trade_api as tradeapi\ndef main():\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    lib_path = os.path.join(script_dir, 'lib', 'alpaca_trade_api')\n    print(lib_path)",
        "detail": "docs.examples.PY.greet",
        "documentation": {}
    },
    {
        "label": "place_order",
        "kind": 2,
        "importPath": "docs.examples.PY.ord",
        "description": "docs.examples.PY.ord",
        "peekOfCode": "def place_order(action):\n    if action == \"buy\":\n        api.submit_order(symbol='AAPL', qty=1, side='buy', type='market', time_in_force='gtc')\n    elif action == \"sell\":\n        api.submit_order(symbol='AAPL', qty=1, side='sell', type='market', time_in_force='gtc')\n    elif action == \"hold\":\n        print(\"Hold action. No trade executed.\")\ndef calculate_action():\n    # Simplified hedge ratio logic\n    hedge_ratio = 0.5  # Placeholder logic",
        "detail": "docs.examples.PY.ord",
        "documentation": {}
    },
    {
        "label": "calculate_action",
        "kind": 2,
        "importPath": "docs.examples.PY.ord",
        "description": "docs.examples.PY.ord",
        "peekOfCode": "def calculate_action():\n    # Simplified hedge ratio logic\n    hedge_ratio = 0.5  # Placeholder logic\n    if hedge_ratio > 0.6:\n        return \"buy\"\n    elif hedge_ratio < 0.4:\n        return \"sell\"\n    else:\n        return \"hold\"\naction = calculate_action()",
        "detail": "docs.examples.PY.ord",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "docs.examples.PY.ord",
        "description": "docs.examples.PY.ord",
        "peekOfCode": "api = tradeapi.REST('APCA-API-KEY-ID', 'APCA-API-SECRET-KEY', base_url='https://paper-api.alpaca.markets')\ndef place_order(action):\n    if action == \"buy\":\n        api.submit_order(symbol='AAPL', qty=1, side='buy', type='market', time_in_force='gtc')\n    elif action == \"sell\":\n        api.submit_order(symbol='AAPL', qty=1, side='sell', type='market', time_in_force='gtc')\n    elif action == \"hold\":\n        print(\"Hold action. No trade executed.\")\ndef calculate_action():\n    # Simplified hedge ratio logic",
        "detail": "docs.examples.PY.ord",
        "documentation": {}
    },
    {
        "label": "action",
        "kind": 5,
        "importPath": "docs.examples.PY.ord",
        "description": "docs.examples.PY.ord",
        "peekOfCode": "action = calculate_action()\nplace_order(action)",
        "detail": "docs.examples.PY.ord",
        "documentation": {}
    },
    {
        "label": "stock_trading",
        "kind": 2,
        "importPath": "docs.examples.PY.stock_trading",
        "description": "docs.examples.PY.stock_trading",
        "peekOfCode": "def stock_trading(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,\n    if_using_ppo: bool = True,",
        "detail": "docs.examples.PY.stock_trading",
        "documentation": {}
    },
    {
        "label": "stock_trading_rolling_window",
        "kind": 2,
        "importPath": "docs.examples.PY.stock_trading_rolling_window",
        "description": "docs.examples.PY.stock_trading_rolling_window",
        "peekOfCode": "def stock_trading_rolling_window(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    rolling_window_length: int,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,",
        "detail": "docs.examples.PY.stock_trading_rolling_window",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n        action_avg = self.net(state)\n        action_std = self.action_std_log.exp()",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {'env_name': None, 'state_dim': None, 'action_dim': None, 'if_discrete': None}\n        self.env_name = env_args['env_name']  # the name of environment. Be used to set 'cwd'.\n        self.state_dim = env_args['state_dim']  # vector dimension (feature number) of state\n        self.action_dim = env_args['action_dim']  # vector dimension (feature number) of action\n        self.if_discrete = env_args['if_discrete']  # discrete or continuous action space",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class AgentBase:\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.gamma = args.gamma\n        self.batch_size = args.batch_size\n        self.repeat_times = args.repeat_times\n        self.reward_scale = args.reward_scale\n        self.soft_update_tau = args.soft_update_tau\n        self.states = None  # assert self.states == (1, state_dim)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n        self.if_off_policy = False\n        self.act_class = getattr(self, \"act_class\", ActorPPO)\n        self.cri_class = getattr(self, \"cri_class\", CriticPPO)\n        AgentBase.__init__(self, net_dims, state_dim, action_dim, gpu_id, args)\n        self.ratio_clip = getattr(args, \"ratio_clip\", 0.25)  # `ratio.clamp(1 - clip, 1 + clip)`\n        self.lambda_gae_adv = getattr(args, \"lambda_gae_adv\", 0.95)  # could be 0.80~0.99\n        self.lambda_entropy = getattr(args, \"lambda_entropy\", 0.01)  # could be 0.00~0.10\n        self.lambda_entropy = torch.tensor(self.lambda_entropy, dtype=torch.float32, device=self.device)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < '0.18.0' else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        '''the necessary env information when you design a custom env'''\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class Evaluator:\n    def __init__(self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = '.'):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = eval_times  # number of times that get episodic cumulative return\n        self.eval_per_step = eval_per_step  # evaluate the agent per training steps\n        self.recorder = []",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class AlpacaPaperTrading():\n    def __init__(self,ticker_list, time_interval, drl_lib, agent, cwd, net_dim, \n                 state_dim, action_dim, ALPACA_API_KEY, ALPACA_API_SECRET , \n                 ALPACA_API_BASE_URL, tech_indicator_list, turbulence_thresh=30, \n                 max_stock=1e2, latency = None):\n        #load agent\n        self.drl_lib = drl_lib\n        if agent =='ppo':\n            if drl_lib == 'elegantrl':              \n                agent_class = AgentPPO",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    #Empty Env used for loading rllib agent\n    def __init__(self,config):\n      state_dim = config['state_dim']\n      action_dim = config['action_dim']\n      self.env_num = 1\n      self.max_step = 10000\n      self.env_name = 'StockEnvEmpty'\n      self.state_dim = state_dim  \n      self.action_dim = action_dim",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {'unwrapped', 'observation_space', 'action_space', 'spec'}.issubset(dir(env)):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = state_shape[0] if len(state_shape) == 1 else state_shape  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)\n        if if_discrete:  # make sure it is discrete action space\n            action_dim = env.action_space.n\n        elif isinstance(env.action_space, gym.spaces.Box):  # make sure it is continuous action space\n            action_dim = env.action_space.shape[0]",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == 'gym.envs.registration':  # special rule\n        env = env_class(id=env_args['env_name'])\n    else:",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == 'gym.envs.registration':  # special rule\n        env = env_class(id=env_args['env_name'])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in ('env_name', 'state_dim', 'action_dim', 'if_discrete'):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args)\n    new_env, _ = env.reset()\n    agent.states = new_env[np.newaxis, :]\n    evaluator = Evaluator(eval_env=build_env(args.env_class, args.env_args),\n                          eval_per_step=args.eval_per_step,\n                          eval_times=args.eval_times,\n                          cwd=args.cwd)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def render_agent(env_class, env_args: dict, net_dims: [int], agent_class, actor_path: str, render_times: int = 8):\n    env = build_env(env_class, env_args)\n    state_dim = env_args['state_dim']\n    action_dim = env_args['action_dim']\n    agent = agent_class(net_dims, state_dim, action_dim, gpu_id=-1)\n    actor = agent.act\n    print(f\"| render and load actor from: {actor_path}\")\n    actor.load_state_dict(torch.load(actor_path, map_location=lambda storage, loc: storage))\n    for i in range(render_times):\n        cumulative_reward, episode_step = get_rewards_and_steps(env, actor, if_render=True)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def get_rewards_and_steps(env, actor, if_render: bool = False) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state, _ = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        tensor_action = actor(tensor_state)\n        action = tensor_action.detach().cpu().numpy()[0]  # not need detach(), because using torch.no_grad() outside\n        state, reward, done, _, _ = env.step(action)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def get_trading_days(start, end):\n    nyse = tc.get_calendar('NYSE')\n    df = nyse.sessions_in_range(pd.Timestamp(start),\n                                pd.Timestamp(end))\n    trading_days = []\n    for day in df:\n        trading_days.append(str(day)[:10])\n    return trading_days\ndef alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, 'v2')",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, 'v2')\n    trading_days = get_trading_days(start, end)\n    df = pd.DataFrame()\n    for day in trading_days:\n        df = pd.concat([df, api.get_portfolio_history(date_start = day,timeframe='5Min').df.iloc[:78]])\n    equities = df.equity.values\n    cumu_returns = equities/equities[0]\n    cumu_returns = cumu_returns[~np.isnan(cumu_returns)]\n    return df, cumu_returns",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "kind": 2,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "def DIA_history(start):\n    data_df = yf.download(['^DJI'],start=start, interval=\"5m\")\n    data_df = data_df.iloc[:]\n    baseline_returns = data_df['Adj Close'].values/data_df['Adj Close'].values[0]\n    return data_df, baseline_returns\n# Get cumulative return\nALPACA_API_KEY = \"\"\nALPACA_API_SECRET  = \"\"\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nimport numpy as np\nimport pandas as pd\n# PPO",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ticker_list = DOW_30_TICKER\naction_dim = len(DOW_30_TICKER)\nprint(ticker_list)\nprint(INDICATORS)\n# Calculate the DRL state dimension manually for paper trading\n# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\nstate_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nstate_dim\n# Get the API Keys Ready\n# ALPACA_API_KEY = \"\"",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "action_dim",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "action_dim = len(DOW_30_TICKER)\nprint(ticker_list)\nprint(INDICATORS)\n# Calculate the DRL state dimension manually for paper trading\n# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\nstate_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nstate_dim\n# Get the API Keys Ready\n# ALPACA_API_KEY = \"\"\n# ALPACA_API_SECRET  = \"\"",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "state_dim",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nstate_dim\n# Get the API Keys Ready\n# ALPACA_API_KEY = \"\"\n# ALPACA_API_SECRET  = \"\"\nALPACA_API_KEY      = \"PKEJH4W0URAU56SHKQW3\"\nALPACA_API_SECRET    = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\nenv = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  ALPACA_API_KEY = ALPACA_API_KEY, \n#                  ALPACA_API_SECRET  = ALPACA_API_SECRET , \n#                  ALPACA_API_BASE_URL = ALPACA_API_BASE_URL",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\nenv = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  ALPACA_API_KEY = ALPACA_API_KEY, \n#                  ALPACA_API_SECRET  = ALPACA_API_SECRET , \n#                  ALPACA_API_BASE_URL = ALPACA_API_BASE_URL\n#                  )",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "data_url = 'wss://data.alpaca.markets'\nenv = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  ALPACA_API_KEY = ALPACA_API_KEY, \n#                  ALPACA_API_SECRET  = ALPACA_API_SECRET , \n#                  ALPACA_API_BASE_URL = ALPACA_API_BASE_URL\n#                  )\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "env = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  ALPACA_API_KEY = ALPACA_API_KEY, \n#                  ALPACA_API_SECRET  = ALPACA_API_SECRET , \n#                  ALPACA_API_BASE_URL = ALPACA_API_BASE_URL\n#                  )\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n#data = DP.download_data(start_date = '2021-10-04', ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "#DP",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "#DP = DataProcessor(data_source = 'alpaca',\n#                  ALPACA_API_KEY = ALPACA_API_KEY, \n#                  ALPACA_API_SECRET  = ALPACA_API_SECRET , \n#                  ALPACA_API_BASE_URL = ALPACA_API_BASE_URL\n#                  )\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n#data = DP.download_data(start_date = '2021-10-04', \n#                        end_date = '2021-10-08',\n#                        ticker_list = ticker_list, \n#                        time_interval= '1Min')",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "#data = DP.download_data(start_date = '2021-10-04', \n#                        end_date = '2021-10-08',\n#                        ticker_list = ticker_list, \n#                        time_interval= '1Min')\n#data['timestamp'].nunique()\n# Step 3. Data Cleaning & Feature Engineering\n#data = DP.clean_data(data)\n#data = DP.add_technical_indicator(data, INDICATORS)\n#data = DP.add_vix(data)\n#data.shape",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "#data = DP.clean_data(data)\n#data = DP.add_technical_indicator(data, INDICATORS)\n#data = DP.add_vix(data)\n#data.shape\n# Step 4. Transform to numpy array\n#price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\n# price_array\n# Part 2: Train the agent\n# Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "#data = DP.add_technical_indicator(data, INDICATORS)\n#data = DP.add_vix(data)\n#data.shape\n# Step 4. Transform to numpy array\n#price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\n# price_array\n# Part 2: Train the agent\n# Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "#data = DP.add_vix(data)\n#data.shape\n# Step 4. Transform to numpy array\n#price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\n# price_array\n# Part 2: Train the agent\n# Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n        \"eval_times\":1} ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n        \"eval_times\":1} \nenv = StockTradingEnv\n#if you want to use larger datasets (change to longer period), and it raises error, \n#please try to increase \"target_step\". It should be larger than the episode steps. \ntrain(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "env = StockTradingEnv\n#if you want to use larger datasets (change to longer period), and it raises error, \n#please try to increase \"target_step\". It should be larger than the episode steps. \ntrain(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "train(start_date",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "train(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', \n      env=env,\n      model_name='ppo',\n      if_vix=True, ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "account_value_erl=test(start_date",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "account_value_erl=test(start_date = '2022-09-01', \n                      end_date = '2022-09-02',\n                      ticker_list = ticker_list, \n                      data_source = 'alpaca',\n                      time_interval= '1Min', \n                      technical_indicator_list= INDICATORS,\n                      drl_lib='elegantrl', \n                      env=env, \n                      model_name='ppo',\n                      if_vix=True, ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "train(start_date",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "train(start_date = '2022-08-25', \n      end_date = '2022-09-02',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', \n      env=env, \n      model_name='ppo',\n      if_vix=True, ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "paper_trading_erl",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "paper_trading_erl = AlpacaPaperTrading(ticker_list = DOW_30_TICKER, \n                                       time_interval = '1Min', \n                                       drl_lib = 'elegantrl', \n                                       agent = 'ppo', \n                                       cwd = './papertrading_erl_retrain', \n                                       net_dim = ERL_PARAMS['net_dimension'], \n                                       state_dim = state_dim, \n                                       action_dim= action_dim, \n                                       ALPACA_API_KEY = ALPACA_API_KEY, \n                                       ALPACA_API_SECRET  = ALPACA_API_SECRET , ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ALPACA_API_KEY = \"\"\nALPACA_API_SECRET  = \"\"\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=ALPACA_API_KEY, \n                                  secret=ALPACA_API_SECRET , \n                                  url=ALPACA_API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=ALPACA_API_KEY, \n                                  secret=ALPACA_API_SECRET , \n                                  url=ALPACA_API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')\ndf_erl.tail()\nreturns_erl = cumu_erl -1 ",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "data_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=ALPACA_API_KEY, \n                                  secret=ALPACA_API_SECRET , \n                                  url=ALPACA_API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')\ndf_erl.tail()\nreturns_erl = cumu_erl -1 \nreturns_dia = cumu_djia - 1",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "returns_erl",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "returns_erl = cumu_erl -1 \nreturns_dia = cumu_djia - 1\nreturns_dia = returns_dia[:returns_erl.shape[0]]\nprint('len of erl return: ', returns_erl.shape[0])\nprint('len of dia return: ', returns_dia.shape[0])\nreturns_erl\nplot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "returns_dia = cumu_djia - 1\nreturns_dia = returns_dia[:returns_erl.shape[0]]\nprint('len of erl return: ', returns_erl.shape[0])\nprint('len of dia return: ', returns_dia.shape[0])\nreturns_erl\nplot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which='minor', axis='y')",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "returns_dia = returns_dia[:returns_erl.shape[0]]\nprint('len of erl return: ', returns_erl.shape[0])\nprint('len of dia return: ', returns_dia.shape[0])\nreturns_erl\nplot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which='minor', axis='y')\nplt.title('Stock Trading (Paper trading)', fontsize=20)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "plt.xticks(size",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "plt.xticks(size = 14)\nplt.yticks(size = 14)\nax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n                                                    '','10-21','','10-22']))\nplt.legend(fontsize=10.5)",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "plt.yticks(size",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "plt.yticks(size = 14)\nax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n                                                    '','10-21','','10-22']))\nplt.legend(fontsize=10.5)\nplt.savefig('papertrading_stock.png')",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "ax",
        "kind": 5,
        "importPath": "docs.examples.PY.submit_order",
        "description": "docs.examples.PY.submit_order",
        "peekOfCode": "ax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n                                                    '','10-21','','10-22']))\nplt.legend(fontsize=10.5)\nplt.savefig('papertrading_stock.png')",
        "detail": "docs.examples.PY.submit_order",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.examples.PY.t6",
        "description": "docs.examples.PY.t6",
        "peekOfCode": "def main():\n  ALPACA_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\"\n  ALPACA_API_SECRET  = \"BxT64PIQtDBb*tnW\"\n  ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\n  import warnings\n  warnings.filterwarnings(\"ignore\")\n  import os\n  import time\n  import gym\n  import torch",
        "detail": "docs.examples.PY.t6",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "TRAIN_START_DATE = '2009-04-01'\nTRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "TRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "TEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "TEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())\nprint(df.shape)",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())\nprint(df.shape)\nINDICATORS = ['macd',",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, ",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, ",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, ",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, ",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, ",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension, \n    \"reward_scaling\": 1e-4,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "SAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}\nTD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "TD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "timesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,\n    'td3' : 1\n}\ndf_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,\n    DDPG_model_kwargs,\n    SAC_model_kwargs,\n    TD3_model_kwargs,\n    timesteps_dict\n)\nprint(df_summary)\nunique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\ndf_account_value.account_value.plot()",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\n# %matplotlib inline",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "baseline_df",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "baseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "stats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX\nbacktest_plot(df_account_value, \n              baseline_ticker = '^DJI', \n              baseline_start = df_account_value.loc[0,'date'],\n              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "docs.examples.PY.t7",
        "description": "docs.examples.PY.t7",
        "peekOfCode": "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')\ntry:\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    symbol = 'CAT'\n    qty = 1  # Quantity to buy\n    if (sharpe > - 94):\n        buy_order = api.submit_order(\n            symbol=symbol,\n            qty=qty,",
        "detail": "docs.examples.PY.t7",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "ALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"\nALPACA_API_SECRET  = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nfrom pprint import pprint",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nfrom pprint import pprint\nimport sys\nsys.path.append(\"../FinRL-Library\")",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "TRAIN_START_DATE = '2009-04-01'\nTRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "TRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "TEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "TEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())\nprint(df.shape)",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())\nprint(df.shape)\nINDICATORS = ['macd',",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, ",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, ",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, ",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, ",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, ",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension, \n    \"reward_scaling\": 1e-4,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "SAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}\nTD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "TD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "timesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,\n    'td3' : 1\n}\ndf_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,\n    DDPG_model_kwargs,\n    SAC_model_kwargs,\n    TD3_model_kwargs,\n    timesteps_dict\n)\nprint(df_summary)\nunique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\ndf_account_value.account_value.plot()",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\n# %matplotlib inline",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "baseline_df",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "baseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "stats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX\nbacktest_plot(df_account_value, \n              baseline_ticker = '^DJI', \n              baseline_start = df_account_value.loc[0,'date'],\n              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "docs.examples.PY.trade_bot",
        "description": "docs.examples.PY.trade_bot",
        "peekOfCode": "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')\ntry:\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    symbol = 'CAT'\n    qty = 1  # Quantity to buy\n    if (sharpe > - 94):\n        buy_order = api.submit_order(\n            symbol=symbol,\n            qty=qty,",
        "detail": "docs.examples.PY.trade_bot",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "kind": 6,
        "importPath": "docs.lib.LumibotML.credentials",
        "description": "docs.lib.LumibotML.credentials",
        "peekOfCode": "class AlpacaConfig:\n    # Put your own Alpaca api key here:\n    # API_KEY = \"PK674RO5M858JZ217SPM\"\n    API_KEY = \"PKEJH4W0URAU56SHKQW3\"\n    # Put your own Alpaca secret here:\n    API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\n    # API_SECRET = \"uWm6opmroTTWuZ9Yr81XRTMsOMLNv8nvBmmLO4Dt\"\n    # If you want to go live, you must change this\n    ENDPOINT = \"https://paper-api.alpaca.markets\"\n    def __init__(self, load_from_secret_manager=True):",
        "detail": "docs.lib.LumibotML.credentials",
        "documentation": {}
    },
    {
        "label": "symbols",
        "kind": 5,
        "importPath": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "symbols = [\"VIX\", \"VXX\", \"XIV\", \"PBP\", \"SPXL\"]\ninterval = \"1min\"\napi_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):",
        "detail": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "interval",
        "kind": 5,
        "importPath": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "interval = \"1min\"\napi_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):",
        "detail": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "api_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"",
        "detail": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "years",
        "kind": 5,
        "importPath": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "years = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"\n                url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval={interval}&slice={slice}&apikey={api_key}\"\n                df = pd.read_csv(url)",
        "detail": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "months",
        "kind": 5,
        "importPath": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "months = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"\n                url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval={interval}&slice={slice}&apikey={api_key}\"\n                df = pd.read_csv(url)\n                dfs.append(df)",
        "detail": "docs.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "MachineLearningCrypto",
        "kind": 6,
        "importPath": "docs.lib.LumibotML.ml_strategy_crypto",
        "description": "docs.lib.LumibotML.ml_strategy_crypto",
        "peekOfCode": "class MachineLearningCrypto(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "docs.lib.LumibotML.ml_strategy_crypto",
        "documentation": {}
    },
    {
        "label": "MachineLearningStocks",
        "kind": 6,
        "importPath": "docs.lib.LumibotML.ml_strategy_stocks",
        "description": "docs.lib.LumibotML.ml_strategy_stocks",
        "peekOfCode": "class MachineLearningStocks(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "docs.lib.LumibotML.ml_strategy_stocks",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.elegantrl.models",
        "description": "docs.lib.rl.agents.elegantrl.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "docs.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.elegantrl.models",
        "description": "docs.lib.rl.agents.elegantrl.models",
        "peekOfCode": "MODELS = {\n    \"ddpg\": AgentDDPG,\n    \"td3\": AgentTD3,\n    \"sac\": AgentSAC,\n    \"ppo\": AgentPPO,\n    \"a2c\": AgentA2C,\n}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}",
        "detail": "docs.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.elegantrl.models",
        "description": "docs.lib.rl.agents.elegantrl.models",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "docs.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.elegantrl.models",
        "description": "docs.lib.rl.agents.elegantrl.models",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "docs.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "PolicyGradient",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.algorithms",
        "description": "docs.lib.rl.agents.portfolio_optimization.algorithms",
        "peekOfCode": "class PolicyGradient:\n    \"\"\"Class implementing policy gradient algorithm to train portfolio\n    optimization agents.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        train_env: Environment used to train the agent\n        train_policy: Policy used in training.",
        "detail": "docs.lib.rl.agents.portfolio_optimization.algorithms",
        "documentation": {}
    },
    {
        "label": "EIIE",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "description": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EIIE(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_size=3,\n        conv_mid_features=2,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",\n    ):",
        "detail": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "EI3",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "description": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EI3(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",",
        "detail": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "GPM",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "description": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class GPM(nn.Module):\n    def __init__(\n        self,\n        edge_index,\n        edge_type,\n        nodes_to_select,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,",
        "detail": "docs.lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.models",
        "description": "docs.lib.rl.agents.portfolio_optimization.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"\n    def __init__(self, env):",
        "detail": "docs.lib.rl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.models",
        "description": "docs.lib.rl.agents.portfolio_optimization.models",
        "peekOfCode": "MODELS = {\"pg\": PolicyGradient}\nclass DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"",
        "detail": "docs.lib.rl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "PVM",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.utils",
        "description": "docs.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class PVM:\n    def __init__(self, capacity, portfolio_size):\n        \"\"\"Initializes portfolio vector memory.\n        Args:\n          capacity: Max capacity of memory.\n          portfolio_size: Portfolio size.\n        \"\"\"\n        # initially, memory will have the same actions\n        self.capacity = capacity\n        self.portfolio_size = portfolio_size",
        "detail": "docs.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.utils",
        "description": "docs.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class ReplayBuffer:\n    def __init__(self, capacity):\n        \"\"\"Initializes replay buffer.\n        Args:\n          capacity: Max capacity of buffer.\n        \"\"\"\n        self.buffer = deque(maxlen=capacity)\n    def __len__(self):\n        \"\"\"Represents the size of the buffer\n        Returns:",
        "detail": "docs.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "RLDataset",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.utils",
        "description": "docs.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class RLDataset(IterableDataset):\n    def __init__(self, buffer):\n        \"\"\"Initializes reinforcement learning dataset.\n        Args:\n            buffer: replay buffer to become iterable dataset.\n        Note:\n            It's a subclass of pytorch's IterableDataset,\n            check https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n        \"\"\"\n        self.buffer = buffer",
        "detail": "docs.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "apply_portfolio_noise",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.portfolio_optimization.utils",
        "description": "docs.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "def apply_portfolio_noise(portfolio, epsilon=0.0):\n    \"\"\"Apply noise to portfolio distribution considering its constrains.\n    Arg:\n        portfolio: initial portfolio distribution.\n        epsilon: maximum rebalancing.\n    Returns:\n        New portolio distribution with noise applied.\n    \"\"\"\n    portfolio_size = portfolio.shape[0]\n    new_portfolio = portfolio.copy()",
        "detail": "docs.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "DRLlibv2",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.rllib.drllibv2",
        "description": "docs.lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "class DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:\n        Training environment instance\n    train_env_name: str",
        "detail": "docs.lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "psutil_memory_in_bytes",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.rllib.drllibv2",
        "description": "docs.lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "psutil_memory_in_bytes = psutil.virtual_memory().total\nray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter",
        "detail": "docs.lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "ray._private.utils.get_system_memory",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.rllib.drllibv2",
        "description": "docs.lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "ray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:",
        "detail": "docs.lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.rllib.models",
        "description": "docs.lib.rl.agents.rllib.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data\n        tech_array: numpy array\n            techical data",
        "detail": "docs.lib.rl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.rllib.models",
        "description": "docs.lib.rl.agents.rllib.models",
        "peekOfCode": "MODELS = {\"a2c\": a2c, \"ddpg\": ddpg, \"td3\": td3, \"sac\": sac, \"ppo\": ppo}\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nclass DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data",
        "detail": "docs.lib.rl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "A2C",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.a2c.a2c",
        "description": "docs.lib.rl.agents.stablebaselines3.a2c.a2c",
        "peekOfCode": "class A2C(OnPolicyAlgorithm):\n    \"\"\"\n    Advantage Actor Critic (A2C)\n    Paper: https://arxiv.org/abs/1602.01783\n    Code: This implementation borrows code from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n    and Stable Baselines (https://github.com/hill-a/stable-baselines)\n    Introduction to A2C: https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: The learning rate, it can be a function",
        "detail": "docs.lib.rl.agents.stablebaselines3.a2c.a2c",
        "documentation": {}
    },
    {
        "label": "SelfA2C",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.a2c.a2c",
        "description": "docs.lib.rl.agents.stablebaselines3.a2c.a2c",
        "peekOfCode": "SelfA2C = TypeVar(\"SelfA2C\", bound=\"A2C\")\nclass A2C(OnPolicyAlgorithm):\n    \"\"\"\n    Advantage Actor Critic (A2C)\n    Paper: https://arxiv.org/abs/1602.01783\n    Code: This implementation borrows code from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n    and Stable Baselines (https://github.com/hill-a/stable-baselines)\n    Introduction to A2C: https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)",
        "detail": "docs.lib.rl.agents.stablebaselines3.a2c.a2c",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "peekOfCode": "MlpPolicy = ActorCriticPolicy\nCnnPolicy = ActorCriticCnnPolicy\nMultiInputPolicy = MultiInputActorCriticPolicy",
        "detail": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "peekOfCode": "CnnPolicy = ActorCriticCnnPolicy\nMultiInputPolicy = MultiInputActorCriticPolicy",
        "detail": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "peekOfCode": "MultiInputPolicy = MultiInputActorCriticPolicy",
        "detail": "docs.lib.rl.agents.stablebaselines3.a2c.policies",
        "documentation": {}
    },
    {
        "label": "BitFlippingEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.bit_flipping_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.bit_flipping_env",
        "peekOfCode": "class BitFlippingEnv(Env):\n    \"\"\"\n    Simple bit flipping env, useful to test HER.\n    The goal is to flip all the bits to get a vector of ones.\n    In the continuous variant, if the ith action component has a value > 0,\n    then the ith bit will be flipped. Uses a ``MultiBinary`` observation space\n    by default.\n    :param n_bits: Number of bits to flip\n    :param continuous: Whether to use the continuous actions version or not,\n        by default, it uses the discrete one",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.bit_flipping_env",
        "documentation": {}
    },
    {
        "label": "IdentityEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "peekOfCode": "class IdentityEnv(gym.Env, Generic[T]):\n    def __init__(self, dim: Optional[int] = None, space: Optional[spaces.Space] = None, ep_length: int = 100):\n        \"\"\"\n        Identity environment for testing purposes\n        :param dim: the size of the action and observation dimension you want\n            to learn. Provide at most one of ``dim`` and ``space``. If both are\n            None, then initialization proceeds with ``dim=1`` and ``space=None``.\n        :param space: the action and observation space. Provide at most one of\n            ``dim`` and ``space``.\n        :param ep_length: the length of each episode in timesteps",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "documentation": {}
    },
    {
        "label": "IdentityEnvBox",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "peekOfCode": "class IdentityEnvBox(IdentityEnv[np.ndarray]):\n    def __init__(self, low: float = -1.0, high: float = 1.0, eps: float = 0.05, ep_length: int = 100):\n        \"\"\"\n        Identity environment for testing purposes\n        :param low: the lower bound of the box dim\n        :param high: the upper bound of the box dim\n        :param eps: the epsilon bound for correct value\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"\n        space = spaces.Box(low=low, high=high, shape=(1,), dtype=np.float32)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "documentation": {}
    },
    {
        "label": "IdentityEnvMultiDiscrete",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "peekOfCode": "class IdentityEnvMultiDiscrete(IdentityEnv[np.ndarray]):\n    def __init__(self, dim: int = 1, ep_length: int = 100) -> None:\n        \"\"\"\n        Identity environment for testing purposes\n        :param dim: the size of the dimensions you want to learn\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"\n        space = spaces.MultiDiscrete([dim, dim])\n        super().__init__(ep_length=ep_length, space=space)\nclass IdentityEnvMultiBinary(IdentityEnv[np.ndarray]):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "documentation": {}
    },
    {
        "label": "IdentityEnvMultiBinary",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "peekOfCode": "class IdentityEnvMultiBinary(IdentityEnv[np.ndarray]):\n    def __init__(self, dim: int = 1, ep_length: int = 100) -> None:\n        \"\"\"\n        Identity environment for testing purposes\n        :param dim: the size of the dimensions you want to learn\n        :param ep_length: the length of each episode in timesteps\n        \"\"\"\n        space = spaces.MultiBinary(dim)\n        super().__init__(ep_length=ep_length, space=space)\nclass FakeImageEnv(gym.Env):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "documentation": {}
    },
    {
        "label": "FakeImageEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "peekOfCode": "class FakeImageEnv(gym.Env):\n    \"\"\"\n    Fake image environment for testing purposes, it mimics Atari games.\n    :param action_dim: Number of discrete actions\n    :param screen_height: Height of the image\n    :param screen_width: Width of the image\n    :param n_channels: Number of color channels\n    :param discrete: Create discrete action space instead of continuous\n    :param channel_first: Put channels on first axis instead of last\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "peekOfCode": "T = TypeVar(\"T\", int, np.ndarray)\nclass IdentityEnv(gym.Env, Generic[T]):\n    def __init__(self, dim: Optional[int] = None, space: Optional[spaces.Space] = None, ep_length: int = 100):\n        \"\"\"\n        Identity environment for testing purposes\n        :param dim: the size of the action and observation dimension you want\n            to learn. Provide at most one of ``dim`` and ``space``. If both are\n            None, then initialization proceeds with ``dim=1`` and ``space=None``.\n        :param space: the action and observation space. Provide at most one of\n            ``dim`` and ``space``.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.identity_env",
        "documentation": {}
    },
    {
        "label": "SimpleMultiObsEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.envs.multi_input_envs",
        "description": "docs.lib.rl.agents.stablebaselines3.common.envs.multi_input_envs",
        "peekOfCode": "class SimpleMultiObsEnv(gym.Env):\n    \"\"\"\n    Base class for GridWorld-based MultiObs Environments 4x4  grid world.\n    .. code-block:: text\n        ____________\n       | 0  1  2   3|\n       | 4|56| 7|\n       | 8|_9_10_|11|\n       |12 13  14 15|\n       ",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.envs.multi_input_envs",
        "documentation": {}
    },
    {
        "label": "RMSpropTFLike",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.sb2_compat.rmsprop_tf_like",
        "description": "docs.lib.rl.agents.stablebaselines3.common.sb2_compat.rmsprop_tf_like",
        "peekOfCode": "class RMSpropTFLike(Optimizer):\n    r\"\"\"Implements RMSprop algorithm with closer match to Tensorflow version.\n    For reproducibility with original stable-baselines. Use this\n    version with e.g. A2C for stabler learning than with the PyTorch\n    RMSProp. Based on the PyTorch v1.5.0 implementation of RMSprop.\n    See a more throughout conversion in pytorch-image-models repository:\n        https://github.com/rwightman/pytorch-image-models/blob/master/timm/optim/rmsprop_tf.py\n    Changes to the original RMSprop:\n        - Move epsilon inside square root\n        - Initialize squared gradient to ones rather than zeros",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.sb2_compat.rmsprop_tf_like",
        "documentation": {}
    },
    {
        "label": "VecEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "class VecEnv(ABC):\n    \"\"\"\n    An abstract asynchronous, vectorized environment.\n    :param num_envs: Number of environments\n    :param observation_space: Observation space\n    :param action_space: Action space\n    \"\"\"\n    def __init__(\n        self,\n        num_envs: int,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvWrapper",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "class VecEnvWrapper(VecEnv):\n    \"\"\"\n    Vectorized environment base class\n    :param venv: the vectorized environment to wrap\n    :param observation_space: the observation space (can be None to load from venv)\n    :param action_space: the action space (can be None to load from venv)\n    \"\"\"\n    def __init__(\n        self,\n        venv: VecEnv,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "CloudpickleWrapper",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "class CloudpickleWrapper:\n    \"\"\"\n    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n    :param var: the variable you wish to wrap for pickling with cloudpickle\n    \"\"\"\n    def __init__(self, var: Any):\n        self.var = var\n    def __getstate__(self) -> Any:\n        return cloudpickle.dumps(self.var)\n    def __setstate__(self, var: Any) -> None:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "tile_images",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "def tile_images(images_nhwc: Sequence[np.ndarray]) -> np.ndarray:  # pragma: no cover\n    \"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n    :param images_nhwc: list or array of images, ndim=4 once turned into array.\n        n = batch index, h = height, w = width, c = channel\n    :return: img_HWc, ndim=3\n    \"\"\"\n    img_nhwc = np.asarray(images_nhwc)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvIndices",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "VecEnvIndices = Union[None, int, Iterable[int]]\n# VecEnvObs is what is returned by the reset() method\n# it contains the observation for each env\nVecEnvObs = Union[np.ndarray, Dict[str, np.ndarray], Tuple[np.ndarray, ...]]\n# VecEnvStepReturn is what is returned by the step() method\n# it contains the observation, reward, done, info for each env\nVecEnvStepReturn = Tuple[VecEnvObs, np.ndarray, np.ndarray, List[Dict]]\ndef tile_images(images_nhwc: Sequence[np.ndarray]) -> np.ndarray:  # pragma: no cover\n    \"\"\"\n    Tile N images into one big PxQ image",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvObs",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "VecEnvObs = Union[np.ndarray, Dict[str, np.ndarray], Tuple[np.ndarray, ...]]\n# VecEnvStepReturn is what is returned by the step() method\n# it contains the observation, reward, done, info for each env\nVecEnvStepReturn = Tuple[VecEnvObs, np.ndarray, np.ndarray, List[Dict]]\ndef tile_images(images_nhwc: Sequence[np.ndarray]) -> np.ndarray:  # pragma: no cover\n    \"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n    :param images_nhwc: list or array of images, ndim=4 once turned into array.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "VecEnvStepReturn",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "peekOfCode": "VecEnvStepReturn = Tuple[VecEnvObs, np.ndarray, np.ndarray, List[Dict]]\ndef tile_images(images_nhwc: Sequence[np.ndarray]) -> np.ndarray:  # pragma: no cover\n    \"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n    :param images_nhwc: list or array of images, ndim=4 once turned into array.\n        n = batch index, h = height, w = width, c = channel\n    :return: img_HWc, ndim=3\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.base_vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.dummy_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.dummy_vec_env",
        "peekOfCode": "class DummyVecEnv(VecEnv):\n    \"\"\"\n    Creates a simple vectorized wrapper for multiple environments, calling each environment in sequence on the current\n    Python process. This is useful for computationally simple environment such as ``Cartpole-v1``,\n    as the overhead of multiprocess or multithread outweighs the environment computation time.\n    This can also be used for RL methods that\n    require a vectorized environment, but that you want a single environments to train with.\n    :param env_fns: a list of functions\n        that return environments to vectorize\n    :raises ValueError: If the same environment instance is passed as the output of two or more different env_fn.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.dummy_vec_env",
        "documentation": {}
    },
    {
        "label": "StackedObservations",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.stacked_observations",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.stacked_observations",
        "peekOfCode": "class StackedObservations(Generic[TObs]):\n    \"\"\"\n    Frame stacking wrapper for data.\n    Dimension to stack over is either first (channels-first) or last (channels-last), which is detected automatically using\n    ``common.preprocessing.is_image_space_channels_first`` if observation is an image space.\n    :param num_envs: Number of environments\n    :param n_stack: Number of frames to stack\n    :param observation_space: Environment observation space\n    :param channels_order: If \"first\", stack on first image dimension. If \"last\", stack on last dimension.\n        If None, automatically detect channel to stack over in case of image observation or default to \"last\".",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.stacked_observations",
        "documentation": {}
    },
    {
        "label": "TObs",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.stacked_observations",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.stacked_observations",
        "peekOfCode": "TObs = TypeVar(\"TObs\", np.ndarray, Dict[str, np.ndarray])\nclass StackedObservations(Generic[TObs]):\n    \"\"\"\n    Frame stacking wrapper for data.\n    Dimension to stack over is either first (channels-first) or last (channels-last), which is detected automatically using\n    ``common.preprocessing.is_image_space_channels_first`` if observation is an image space.\n    :param num_envs: Number of environments\n    :param n_stack: Number of frames to stack\n    :param observation_space: Environment observation space\n    :param channels_order: If \"first\", stack on first image dimension. If \"last\", stack on last dimension.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.stacked_observations",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.subproc_vec_env",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.subproc_vec_env",
        "peekOfCode": "class SubprocVecEnv(VecEnv):\n    \"\"\"\n    Creates a multiprocess vectorized wrapper for multiple environments, distributing each environment to its own\n    process, allowing significant speed up when the environment is computationally complex.\n    For performance reasons, if your environment is not IO bound, the number of environments should not exceed the\n    number of logical cores on your CPU.\n    .. warning::\n        Only 'forkserver' and 'spawn' start methods are thread-safe,\n        which is important when TensorFlow sessions or other non thread-safe\n        libraries are used in the parent (see issue #217). However, compared to",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.subproc_vec_env",
        "documentation": {}
    },
    {
        "label": "copy_obs_dict",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "peekOfCode": "def copy_obs_dict(obs: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    \"\"\"\n    Deep-copy a dict of numpy arrays.\n    :param obs: a dict of numpy arrays.\n    :return: a dict of copied numpy arrays.\n    \"\"\"\n    assert isinstance(obs, OrderedDict), f\"unexpected type for observations '{type(obs)}'\"\n    return OrderedDict([(k, np.copy(v)) for k, v in obs.items()])\ndef dict_to_obs(obs_space: spaces.Space, obs_dict: Dict[Any, np.ndarray]) -> VecEnvObs:\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "documentation": {}
    },
    {
        "label": "dict_to_obs",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "peekOfCode": "def dict_to_obs(obs_space: spaces.Space, obs_dict: Dict[Any, np.ndarray]) -> VecEnvObs:\n    \"\"\"\n    Convert an internal representation raw_obs into the appropriate type\n    specified by space.\n    :param obs_space: an observation space.\n    :param obs_dict: a dict of numpy arrays.\n    :return: returns an observation of the same type as space.\n        If space is Dict, function is identity; if space is Tuple, converts dict to Tuple;\n        otherwise, space is unstructured and returns the value raw_obs[None].\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "documentation": {}
    },
    {
        "label": "obs_space_info",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "peekOfCode": "def obs_space_info(obs_space: spaces.Space) -> Tuple[List[str], Dict[Any, Tuple[int, ...]], Dict[Any, np.dtype]]:\n    \"\"\"\n    Get dict-structured information about a gym.Space.\n    Dict spaces are represented directly by their dict of subspaces.\n    Tuple spaces are converted into a dict with keys indexing into the tuple.\n    Unstructured spaces are represented by {None: obs_space}.\n    :param obs_space: an observation space\n    :return: A tuple (keys, shapes, dtypes):\n        keys: a list of dict keys.\n        shapes: a dict mapping keys to shapes.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.util",
        "documentation": {}
    },
    {
        "label": "VecCheckNan",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_check_nan",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_check_nan",
        "peekOfCode": "class VecCheckNan(VecEnvWrapper):\n    \"\"\"\n    NaN and inf checking wrapper for vectorized environment, will raise a warning by default,\n    allowing you to know from what the NaN of inf originated from.\n    :param venv: the vectorized environment to wrap\n    :param raise_exception: Whether to raise a ValueError, instead of a UserWarning\n    :param warn_once: Whether to only warn once.\n    :param check_inf: Whether to check for +inf or -inf as well\n    \"\"\"\n    def __init__(self, venv: VecEnv, raise_exception: bool = False, warn_once: bool = True, check_inf: bool = True) -> None:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_check_nan",
        "documentation": {}
    },
    {
        "label": "VecExtractDictObs",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_extract_dict_obs",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_extract_dict_obs",
        "peekOfCode": "class VecExtractDictObs(VecEnvWrapper):\n    \"\"\"\n    A vectorized wrapper for extracting dictionary observations.\n    :param venv: The vectorized environment\n    :param key: The key of the dictionary observation\n    \"\"\"\n    def __init__(self, venv: VecEnv, key: str):\n        self.key = key\n        assert isinstance(\n            venv.observation_space, spaces.Dict",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_extract_dict_obs",
        "documentation": {}
    },
    {
        "label": "VecFrameStack",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_frame_stack",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_frame_stack",
        "peekOfCode": "class VecFrameStack(VecEnvWrapper):\n    \"\"\"\n    Frame stacking wrapper for vectorized environment. Designed for image observations.\n    :param venv: Vectorized environment to wrap\n    :param n_stack: Number of frames to stack\n    :param channels_order: If \"first\", stack on first image dimension. If \"last\", stack on last dimension.\n        If None, automatically detect channel to stack over in case of image observation or default to \"last\" (default).\n        Alternatively channels_order can be a dictionary which can be used with environments with Dict observation spaces\n    \"\"\"\n    def __init__(self, venv: VecEnv, n_stack: int, channels_order: Optional[Union[str, Mapping[str, str]]] = None) -> None:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_frame_stack",
        "documentation": {}
    },
    {
        "label": "VecMonitor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_monitor",
        "peekOfCode": "class VecMonitor(VecEnvWrapper):\n    \"\"\"\n    A vectorized monitor wrapper for *vectorized* Gym environments,\n    it is used to record the episode reward, length, time and other data.\n    Some environments like `openai/procgen <https://github.com/openai/procgen>`_\n    or `gym3 <https://github.com/openai/gym3>`_ directly initialize the\n    vectorized environments, without giving us a chance to use the ``Monitor``\n    wrapper. So this class simply does the job of the ``Monitor`` wrapper on\n    a vectorized level.\n    :param venv: The vectorized environment",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_monitor",
        "documentation": {}
    },
    {
        "label": "VecNormalize",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_normalize",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_normalize",
        "peekOfCode": "class VecNormalize(VecEnvWrapper):\n    \"\"\"\n    A moving average, normalizing wrapper for vectorized environment.\n    has support for saving/loading moving average,\n    :param venv: the vectorized environment to wrap\n    :param training: Whether to update or not the moving average\n    :param norm_obs: Whether to normalize observation or not (default: True)\n    :param norm_reward: Whether to normalize rewards or not (default: True)\n    :param clip_obs: Max absolute value for observation\n    :param clip_reward: Max value absolute for discounted reward",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_normalize",
        "documentation": {}
    },
    {
        "label": "VecTransposeImage",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_transpose",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_transpose",
        "peekOfCode": "class VecTransposeImage(VecEnvWrapper):\n    \"\"\"\n    Re-order channels, from HxWxC to CxHxW.\n    It is required for PyTorch convolution layers.\n    :param venv:\n    :param skip: Skip this wrapper if needed as we rely on heuristic to apply it or not,\n        which may result in unwanted behavior, see GH issue #671.\n    \"\"\"\n    def __init__(self, venv: VecEnv, skip: bool = False):\n        assert is_image_space(venv.observation_space) or isinstance(",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_transpose",
        "documentation": {}
    },
    {
        "label": "VecVideoRecorder",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_video_recorder",
        "description": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_video_recorder",
        "peekOfCode": "class VecVideoRecorder(VecEnvWrapper):\n    \"\"\"\n    Wraps a VecEnv or VecEnvWrapper object to record rendered image as mp4 video.\n    It requires ffmpeg or avconv to be installed on the machine.\n    :param venv:\n    :param video_folder: Where to save videos\n    :param record_video_trigger: Function that defines when to start recording.\n                                        The function takes the current number of step,\n                                        and returns whether we should start recording or not.\n    :param video_length:  Length of recorded videos",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.vec_env.vec_video_recorder",
        "documentation": {}
    },
    {
        "label": "StickyActionEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class StickyActionEnv(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n    \"\"\"\n    Sticky action.\n    Paper: https://arxiv.org/abs/1709.06009\n    Official implementation: https://github.com/mgbellemare/Arcade-Learning-Environment\n    :param env: Environment to wrap\n    :param action_repeat_probability: Probability of repeating the last action\n    \"\"\"\n    def __init__(self, env: gym.Env, action_repeat_probability: float) -> None:\n        super().__init__(env)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "NoopResetEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class NoopResetEnv(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n    \"\"\"\n    Sample initial states by taking random number of no-ops on reset.\n    No-op is assumed to be action 0.\n    :param env: Environment to wrap\n    :param noop_max: Maximum value of no-ops to run\n    \"\"\"\n    def __init__(self, env: gym.Env, noop_max: int = 30) -> None:\n        super().__init__(env)\n        self.noop_max = noop_max",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "FireResetEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class FireResetEnv(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n    \"\"\"\n    Take action on reset for environments that are fixed until firing.\n    :param env: Environment to wrap\n    \"\"\"\n    def __init__(self, env: gym.Env) -> None:\n        super().__init__(env)\n        assert env.unwrapped.get_action_meanings()[1] == \"FIRE\"  # type: ignore[attr-defined]\n        assert len(env.unwrapped.get_action_meanings()) >= 3  # type: ignore[attr-defined]\n    def reset(self, **kwargs) -> AtariResetReturn:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "EpisodicLifeEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class EpisodicLifeEnv(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n    \"\"\"\n    Make end-of-life == end-of-episode, but only reset on true game over.\n    Done by DeepMind for the DQN and co. since it helps value estimation.\n    :param env: Environment to wrap\n    \"\"\"\n    def __init__(self, env: gym.Env) -> None:\n        super().__init__(env)\n        self.lives = 0\n        self.was_real_done = True",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "MaxAndSkipEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class MaxAndSkipEnv(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n    \"\"\"\n    Return only every ``skip``-th frame (frameskipping)\n    and return the max between the two last frames.\n    :param env: Environment to wrap\n    :param skip: Number of ``skip``-th frame\n        The same action will be taken ``skip`` times.\n    \"\"\"\n    def __init__(self, env: gym.Env, skip: int = 4) -> None:\n        super().__init__(env)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "ClipRewardEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class ClipRewardEnv(gym.RewardWrapper):\n    \"\"\"\n    Clip the reward to {+1, 0, -1} by its sign.\n    :param env: Environment to wrap\n    \"\"\"\n    def __init__(self, env: gym.Env) -> None:\n        super().__init__(env)\n    def reward(self, reward: SupportsFloat) -> float:\n        \"\"\"\n        Bin reward to {+1, 0, -1} by its sign.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "WarpFrame",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class WarpFrame(gym.ObservationWrapper[np.ndarray, int, np.ndarray]):\n    \"\"\"\n    Convert to grayscale and warp frames to 84x84 (default)\n    as done in the Nature paper and later work.\n    :param env: Environment to wrap\n    :param width: New frame width\n    :param height: New frame height\n    \"\"\"\n    def __init__(self, env: gym.Env, width: int = 84, height: int = 84) -> None:\n        super().__init__(env)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "AtariWrapper",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "peekOfCode": "class AtariWrapper(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n    \"\"\"\n    Atari 2600 preprocessings\n    Specifically:\n    * Noop reset: obtain initial state by taking random number of no-ops on reset.\n    * Frame skipping: 4 by default\n    * Max-pooling: most recent two observations\n    * Termination signal when a life is lost.\n    * Resize to a square image: 84x84 by default\n    * Grayscale observation",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.atari_wrappers",
        "documentation": {}
    },
    {
        "label": "BaseAlgorithm",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "description": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "peekOfCode": "class BaseAlgorithm(ABC):\n    \"\"\"\n    The base of RL algorithms\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from\n                (if registered in Gym, can be str. Can be None for loading trained models)\n    :param learning_rate: learning rate for the optimizer,\n        it can be a function of the current progress remaining (from 1 to 0)\n    :param policy_kwargs: Additional arguments to be passed to the policy on creation\n    :param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "documentation": {}
    },
    {
        "label": "maybe_make_env",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "description": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "peekOfCode": "def maybe_make_env(env: Union[GymEnv, str], verbose: int) -> GymEnv:\n    \"\"\"If env is a string, make the environment; otherwise, return env.\n    :param env: The environment to learn from.\n    :param verbose: Verbosity level: 0 for no output, 1 for indicating if envrironment is created\n    :return A Gym (vector) environment.\n    \"\"\"\n    if isinstance(env, str):\n        env_id = env\n        if verbose >= 1:\n            print(f\"Creating environment from the given name '{env_id}'\")",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "documentation": {}
    },
    {
        "label": "SelfBaseAlgorithm",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "description": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "peekOfCode": "SelfBaseAlgorithm = TypeVar(\"SelfBaseAlgorithm\", bound=\"BaseAlgorithm\")\ndef maybe_make_env(env: Union[GymEnv, str], verbose: int) -> GymEnv:\n    \"\"\"If env is a string, make the environment; otherwise, return env.\n    :param env: The environment to learn from.\n    :param verbose: Verbosity level: 0 for no output, 1 for indicating if envrironment is created\n    :return A Gym (vector) environment.\n    \"\"\"\n    if isinstance(env, str):\n        env_id = env\n        if verbose >= 1:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.base_class",
        "documentation": {}
    },
    {
        "label": "BaseBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "peekOfCode": "class BaseBuffer(ABC):\n    \"\"\"\n    Base class that represent a buffer (rollout or replay)\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device: PyTorch device\n        to which the values will be converted\n    :param n_envs: Number of parallel environments\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "peekOfCode": "class ReplayBuffer(BaseBuffer):\n    \"\"\"\n    Replay buffer used in off-policy algorithms like SAC/TD3.\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device: PyTorch device\n    :param n_envs: Number of parallel environments\n    :param optimize_memory_usage: Enable a memory efficient variant\n        of the replay buffer which reduces by almost a factor two the memory used,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "RolloutBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "peekOfCode": "class RolloutBuffer(BaseBuffer):\n    \"\"\"\n    Rollout buffer used in on-policy algorithms like A2C/PPO.\n    It corresponds to ``buffer_size`` transitions collected\n    using the current policy.\n    This experience will be discarded after the policy update.\n    In order to use PPO objective, we also store the current value of each state\n    and the log probability of each taken action.\n    The term rollout here refers to the model-free notion and should not\n    be used with the concept of rollout used in model-based RL or planning.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "DictReplayBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "peekOfCode": "class DictReplayBuffer(ReplayBuffer):\n    \"\"\"\n    Dict Replay buffer used in off-policy algorithms like SAC/TD3.\n    Extends the ReplayBuffer to use dictionary observations\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device: PyTorch device\n    :param n_envs: Number of parallel environments\n    :param optimize_memory_usage: Enable a memory efficient variant",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "DictRolloutBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "peekOfCode": "class DictRolloutBuffer(RolloutBuffer):\n    \"\"\"\n    Dict Rollout buffer used in on-policy algorithms like A2C/PPO.\n    Extends the RolloutBuffer to use dictionary observations\n    It corresponds to ``buffer_size`` transitions collected\n    using the current policy.\n    This experience will be discarded after the policy update.\n    In order to use PPO objective, we also store the current value of each state\n    and the log probability of each taken action.\n    The term rollout here refers to the model-free notion and should not",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.buffers",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class BaseCallback(ABC):\n    \"\"\"\n    Base class for callback.\n    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n    \"\"\"\n    # The RL model\n    # Type hint as string to avoid circular import\n    model: \"base_class.BaseAlgorithm\"\n    def __init__(self, verbose: int = 0):\n        super().__init__()",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "EventCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class EventCallback(BaseCallback):\n    \"\"\"\n    Base class for triggering callback on event.\n    :param callback: Callback that will be called\n        when an event is triggered.\n    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n    \"\"\"\n    def __init__(self, callback: Optional[BaseCallback] = None, verbose: int = 0):\n        super().__init__(verbose=verbose)\n        self.callback = callback",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "CallbackList",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class CallbackList(BaseCallback):\n    \"\"\"\n    Class for chaining callbacks.\n    :param callbacks: A list of callbacks that will be called\n        sequentially.\n    \"\"\"\n    def __init__(self, callbacks: List[BaseCallback]):\n        super().__init__()\n        assert isinstance(callbacks, list)\n        self.callbacks = callbacks",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "CheckpointCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class CheckpointCallback(BaseCallback):\n    \"\"\"\n    Callback for saving a model every ``save_freq`` calls\n    to ``env.step()``.\n    By default, it only saves model checkpoints,\n    you need to pass ``save_replay_buffer=True``,\n    and ``save_vecnormalize=True`` to also save replay buffer checkpoints\n    and normalization statistics checkpoints.\n    .. warning::\n      When using multiple environments, each call to  ``env.step()``",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "ConvertCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class ConvertCallback(BaseCallback):\n    \"\"\"\n    Convert functional callback (old-style) to object.\n    :param callback:\n    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n    \"\"\"\n    def __init__(self, callback: Optional[Callable[[Dict[str, Any], Dict[str, Any]], bool]], verbose: int = 0):\n        super().__init__(verbose)\n        self.callback = callback\n    def _on_step(self) -> bool:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "EvalCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class EvalCallback(EventCallback):\n    \"\"\"\n    Callback for evaluating an agent.\n    .. warning::\n      When using multiple environments, each call to  ``env.step()``\n      will effectively correspond to ``n_envs`` steps.\n      To account for that, you can use ``eval_freq = max(eval_freq // n_envs, 1)``\n    :param eval_env: The environment used for initialization\n    :param callback_on_new_best: Callback to trigger\n        when there is a new best model according to the ``mean_reward``",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "StopTrainingOnRewardThreshold",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class StopTrainingOnRewardThreshold(BaseCallback):\n    \"\"\"\n    Stop the training once a threshold in episodic reward\n    has been reached (i.e. when the model is good enough).\n    It must be used with the ``EvalCallback``.\n    :param reward_threshold:  Minimum expected reward per episode\n        to stop training.\n    :param verbose: Verbosity level: 0 for no output, 1 for indicating when training ended because episodic reward\n        threshold reached\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "EveryNTimesteps",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class EveryNTimesteps(EventCallback):\n    \"\"\"\n    Trigger a callback every ``n_steps`` timesteps\n    :param n_steps: Number of timesteps between two trigger.\n    :param callback: Callback that will be called\n        when the event is triggered.\n    \"\"\"\n    def __init__(self, n_steps: int, callback: BaseCallback):\n        super().__init__(callback)\n        self.n_steps = n_steps",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "StopTrainingOnMaxEpisodes",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class StopTrainingOnMaxEpisodes(BaseCallback):\n    \"\"\"\n    Stop the training once a maximum number of episodes are played.\n    For multiple environments presumes that, the desired behavior is that the agent trains on each env for ``max_episodes``\n    and in total for ``max_episodes * n_envs`` episodes.\n    :param max_episodes: Maximum number of episodes to stop training.\n    :param verbose: Verbosity level: 0 for no output, 1 for indicating information about when training ended by\n        reaching ``max_episodes``\n    \"\"\"\n    def __init__(self, max_episodes: int, verbose: int = 0):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "StopTrainingOnNoModelImprovement",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class StopTrainingOnNoModelImprovement(BaseCallback):\n    \"\"\"\n    Stop the training early if there is no new best model (new best mean reward) after more than N consecutive evaluations.\n    It is possible to define a minimum number of evaluations before start to count evaluations without improvement.\n    It must be used with the ``EvalCallback``.\n    :param max_no_improvement_evals: Maximum number of consecutive evaluations without a new best model.\n    :param min_evals: Number of evaluations before start to count evaluations without improvements.\n    :param verbose: Verbosity level: 0 for no output, 1 for indicating when training ended because no new best model\n    \"\"\"\n    parent: EvalCallback",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "ProgressBarCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "description": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "peekOfCode": "class ProgressBarCallback(BaseCallback):\n    \"\"\"\n    Display a progress bar when training SB3 agent\n    using tqdm and rich packages.\n    \"\"\"\n    pbar: tqdm\n    def __init__(self) -> None:\n        super().__init__()\n        if tqdm is None:\n            raise ImportError(",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "Distribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.distribution = None\n    @abstractmethod\n    def proba_distribution_net(self, *args, **kwargs) -> Union[nn.Module, Tuple[nn.Module, nn.Parameter]]:\n        \"\"\"Create the layers and parameters that represent the distribution.\n        Subclasses must define this, but the arguments and return type vary between\n        concrete classes.\"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "DiagGaussianDistribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class DiagGaussianDistribution(Distribution):\n    \"\"\"\n    Gaussian distribution with diagonal covariance matrix, for continuous actions.\n    :param action_dim:  Dimension of the action space.\n    \"\"\"\n    def __init__(self, action_dim: int):\n        super().__init__()\n        self.action_dim = action_dim\n        self.mean_actions = None\n        self.log_std = None",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SquashedDiagGaussianDistribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class SquashedDiagGaussianDistribution(DiagGaussianDistribution):\n    \"\"\"\n    Gaussian distribution with diagonal covariance matrix, followed by a squashing function (tanh) to ensure bounds.\n    :param action_dim: Dimension of the action space.\n    :param epsilon: small value to avoid NaN due to numerical imprecision.\n    \"\"\"\n    def __init__(self, action_dim: int, epsilon: float = 1e-6):\n        super().__init__(action_dim)\n        # Avoid NaN (prevents division by zero or log of zero)\n        self.epsilon = epsilon",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "CategoricalDistribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class CategoricalDistribution(Distribution):\n    \"\"\"\n    Categorical distribution for discrete actions.\n    :param action_dim: Number of discrete actions\n    \"\"\"\n    def __init__(self, action_dim: int):\n        super().__init__()\n        self.action_dim = action_dim\n    def proba_distribution_net(self, latent_dim: int) -> nn.Module:\n        \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "MultiCategoricalDistribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class MultiCategoricalDistribution(Distribution):\n    \"\"\"\n    MultiCategorical distribution for multi discrete actions.\n    :param action_dims: List of sizes of discrete action spaces\n    \"\"\"\n    def __init__(self, action_dims: List[int]):\n        super().__init__()\n        self.action_dims = action_dims\n    def proba_distribution_net(self, latent_dim: int) -> nn.Module:\n        \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "BernoulliDistribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class BernoulliDistribution(Distribution):\n    \"\"\"\n    Bernoulli distribution for MultiBinary action spaces.\n    :param action_dim: Number of binary actions\n    \"\"\"\n    def __init__(self, action_dims: int):\n        super().__init__()\n        self.action_dims = action_dims\n    def proba_distribution_net(self, latent_dim: int) -> nn.Module:\n        \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "StateDependentNoiseDistribution",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class StateDependentNoiseDistribution(Distribution):\n    \"\"\"\n    Distribution class for using generalized State Dependent Exploration (gSDE).\n    Paper: https://arxiv.org/abs/2005.05719\n    It is used to create the noise exploration matrix and\n    compute the log probability of an action with that noise.\n    :param action_dim: Dimension of the action space.\n    :param full_std: Whether to use (n_features x n_actions) parameters\n        for the std instead of only (n_features,)\n    :param use_expln: Use ``expln()`` function instead of ``exp()`` to ensure",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "TanhBijector",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "class TanhBijector:\n    \"\"\"\n    Bijective transformation of a probability distribution\n    using a squashing function (tanh)\n    :param epsilon: small value to avoid NaN due to numerical imprecision.\n    \"\"\"\n    def __init__(self, epsilon: float = 1e-6):\n        super().__init__()\n        self.epsilon = epsilon\n    @staticmethod",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "sum_independent_dims",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "def sum_independent_dims(tensor: th.Tensor) -> th.Tensor:\n    \"\"\"\n    Continuous actions are usually considered to be independent,\n    so we can sum components of the ``log_prob`` or the entropy.\n    :param tensor: shape: (n_batch, n_actions) or (n_batch,)\n    :return: shape: (n_batch,) for (n_batch, n_actions) input, scalar for (n_batch,) input\n    \"\"\"\n    if len(tensor.shape) > 1:\n        tensor = tensor.sum(dim=1)\n    else:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "make_proba_distribution",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "def make_proba_distribution(\n    action_space: spaces.Space, use_sde: bool = False, dist_kwargs: Optional[Dict[str, Any]] = None\n) -> Distribution:\n    \"\"\"\n    Return an instance of Distribution for the correct type of action space\n    :param action_space: the input action space\n    :param use_sde: Force the use of StateDependentNoiseDistribution\n        instead of DiagGaussianDistribution\n    :param dist_kwargs: Keyword arguments to pass to the probability distribution\n    :return: the appropriate Distribution object",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "kl_divergence",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "def kl_divergence(dist_true: Distribution, dist_pred: Distribution) -> th.Tensor:\n    \"\"\"\n    Wrapper for the PyTorch implementation of the full form KL Divergence\n    :param dist_true: the p distribution\n    :param dist_pred: the q distribution\n    :return: KL(dist_true||dist_pred)\n    \"\"\"\n    # KL Divergence for different distribution types is out of scope\n    assert dist_true.__class__ == dist_pred.__class__, \"Error: input distributions should be the same type\"\n    # MultiCategoricalDistribution is not a PyTorch Distribution subclass",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfDistribution = TypeVar(\"SelfDistribution\", bound=\"Distribution\")\nSelfDiagGaussianDistribution = TypeVar(\"SelfDiagGaussianDistribution\", bound=\"DiagGaussianDistribution\")\nSelfSquashedDiagGaussianDistribution = TypeVar(\n    \"SelfSquashedDiagGaussianDistribution\", bound=\"SquashedDiagGaussianDistribution\"\n)\nSelfCategoricalDistribution = TypeVar(\"SelfCategoricalDistribution\", bound=\"CategoricalDistribution\")\nSelfMultiCategoricalDistribution = TypeVar(\"SelfMultiCategoricalDistribution\", bound=\"MultiCategoricalDistribution\")\nSelfBernoulliDistribution = TypeVar(\"SelfBernoulliDistribution\", bound=\"BernoulliDistribution\")\nSelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfDiagGaussianDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfDiagGaussianDistribution = TypeVar(\"SelfDiagGaussianDistribution\", bound=\"DiagGaussianDistribution\")\nSelfSquashedDiagGaussianDistribution = TypeVar(\n    \"SelfSquashedDiagGaussianDistribution\", bound=\"SquashedDiagGaussianDistribution\"\n)\nSelfCategoricalDistribution = TypeVar(\"SelfCategoricalDistribution\", bound=\"CategoricalDistribution\")\nSelfMultiCategoricalDistribution = TypeVar(\"SelfMultiCategoricalDistribution\", bound=\"MultiCategoricalDistribution\")\nSelfBernoulliDistribution = TypeVar(\"SelfBernoulliDistribution\", bound=\"BernoulliDistribution\")\nSelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfSquashedDiagGaussianDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfSquashedDiagGaussianDistribution = TypeVar(\n    \"SelfSquashedDiagGaussianDistribution\", bound=\"SquashedDiagGaussianDistribution\"\n)\nSelfCategoricalDistribution = TypeVar(\"SelfCategoricalDistribution\", bound=\"CategoricalDistribution\")\nSelfMultiCategoricalDistribution = TypeVar(\"SelfMultiCategoricalDistribution\", bound=\"MultiCategoricalDistribution\")\nSelfBernoulliDistribution = TypeVar(\"SelfBernoulliDistribution\", bound=\"BernoulliDistribution\")\nSelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"\n    def __init__(self):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfCategoricalDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfCategoricalDistribution = TypeVar(\"SelfCategoricalDistribution\", bound=\"CategoricalDistribution\")\nSelfMultiCategoricalDistribution = TypeVar(\"SelfMultiCategoricalDistribution\", bound=\"MultiCategoricalDistribution\")\nSelfBernoulliDistribution = TypeVar(\"SelfBernoulliDistribution\", bound=\"BernoulliDistribution\")\nSelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.distribution = None\n    @abstractmethod",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfMultiCategoricalDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfMultiCategoricalDistribution = TypeVar(\"SelfMultiCategoricalDistribution\", bound=\"MultiCategoricalDistribution\")\nSelfBernoulliDistribution = TypeVar(\"SelfBernoulliDistribution\", bound=\"BernoulliDistribution\")\nSelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.distribution = None\n    @abstractmethod\n    def proba_distribution_net(self, *args, **kwargs) -> Union[nn.Module, Tuple[nn.Module, nn.Parameter]]:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfBernoulliDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfBernoulliDistribution = TypeVar(\"SelfBernoulliDistribution\", bound=\"BernoulliDistribution\")\nSelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.distribution = None\n    @abstractmethod\n    def proba_distribution_net(self, *args, **kwargs) -> Union[nn.Module, Tuple[nn.Module, nn.Parameter]]:\n        \"\"\"Create the layers and parameters that represent the distribution.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "SelfStateDependentNoiseDistribution",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "description": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "peekOfCode": "SelfStateDependentNoiseDistribution = TypeVar(\"SelfStateDependentNoiseDistribution\", bound=\"StateDependentNoiseDistribution\")\nclass Distribution(ABC):\n    \"\"\"Abstract base class for distributions.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.distribution = None\n    @abstractmethod\n    def proba_distribution_net(self, *args, **kwargs) -> Union[nn.Module, Tuple[nn.Module, nn.Parameter]]:\n        \"\"\"Create the layers and parameters that represent the distribution.\n        Subclasses must define this, but the arguments and return type vary between",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.distributions",
        "documentation": {}
    },
    {
        "label": "check_env",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.env_checker",
        "description": "docs.lib.rl.agents.stablebaselines3.common.env_checker",
        "peekOfCode": "def check_env(env: gym.Env, warn: bool = True, skip_render_check: bool = True) -> None:\n    \"\"\"\n    Check that an environment follows Gym API.\n    This is particularly useful when using a custom environment.\n    Please take a look at https://gymnasium.farama.org/api/env/\n    for more information about the API.\n    It also optionally check that the environment is compatible with Stable-Baselines.\n    :param env: The Gym environment that will be checked\n    :param warn: Whether to output additional warnings\n        mainly related to the interaction with Stable Baselines",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.env_checker",
        "documentation": {}
    },
    {
        "label": "unwrap_wrapper",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "peekOfCode": "def unwrap_wrapper(env: gym.Env, wrapper_class: Type[gym.Wrapper]) -> Optional[gym.Wrapper]:\n    \"\"\"\n    Retrieve a ``VecEnvWrapper`` object by recursively searching.\n    :param env: Environment to unwrap\n    :param wrapper_class: Wrapper to look for\n    :return: Environment unwrapped till ``wrapper_class`` if it has been wrapped with it\n    \"\"\"\n    env_tmp = env\n    while isinstance(env_tmp, gym.Wrapper):\n        if isinstance(env_tmp, wrapper_class):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "documentation": {}
    },
    {
        "label": "is_wrapped",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "peekOfCode": "def is_wrapped(env: gym.Env, wrapper_class: Type[gym.Wrapper]) -> bool:\n    \"\"\"\n    Check if a given environment has been wrapped with a given wrapper.\n    :param env: Environment to check\n    :param wrapper_class: Wrapper class to look for\n    :return: True if environment has been wrapped with ``wrapper_class``.\n    \"\"\"\n    return unwrap_wrapper(env, wrapper_class) is not None\ndef make_vec_env(\n    env_id: Union[str, Callable[..., gym.Env]],",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "documentation": {}
    },
    {
        "label": "make_vec_env",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "peekOfCode": "def make_vec_env(\n    env_id: Union[str, Callable[..., gym.Env]],\n    n_envs: int = 1,\n    seed: Optional[int] = None,\n    start_index: int = 0,\n    monitor_dir: Optional[str] = None,\n    wrapper_class: Optional[Callable[[gym.Env], gym.Env]] = None,\n    env_kwargs: Optional[Dict[str, Any]] = None,\n    vec_env_cls: Optional[Type[Union[DummyVecEnv, SubprocVecEnv]]] = None,\n    vec_env_kwargs: Optional[Dict[str, Any]] = None,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "documentation": {}
    },
    {
        "label": "make_atari_env",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "peekOfCode": "def make_atari_env(\n    env_id: Union[str, Callable[..., gym.Env]],\n    n_envs: int = 1,\n    seed: Optional[int] = None,\n    start_index: int = 0,\n    monitor_dir: Optional[str] = None,\n    wrapper_kwargs: Optional[Dict[str, Any]] = None,\n    env_kwargs: Optional[Dict[str, Any]] = None,\n    vec_env_cls: Optional[Union[Type[DummyVecEnv], Type[SubprocVecEnv]]] = None,\n    vec_env_kwargs: Optional[Dict[str, Any]] = None,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.env_util",
        "documentation": {}
    },
    {
        "label": "evaluate_policy",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.evaluation",
        "description": "docs.lib.rl.agents.stablebaselines3.common.evaluation",
        "peekOfCode": "def evaluate_policy(\n    model: \"type_aliases.PolicyPredictor\",\n    env: Union[gym.Env, VecEnv],\n    n_eval_episodes: int = 10,\n    deterministic: bool = True,\n    render: bool = False,\n    callback: Optional[Callable[[Dict[str, Any], Dict[str, Any]], None]] = None,\n    reward_threshold: Optional[float] = None,\n    return_episode_rewards: bool = False,\n    warn: bool = True,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.evaluation",
        "documentation": {}
    },
    {
        "label": "Video",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class Video:\n    \"\"\"\n    Video data class storing the video frames and the frame per seconds\n    :param frames: frames to create the video from\n    :param fps: frames per second\n    \"\"\"\n    def __init__(self, frames: th.Tensor, fps: float):\n        self.frames = frames\n        self.fps = fps\nclass Figure:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Figure",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class Figure:\n    \"\"\"\n    Figure data class storing a matplotlib figure and whether to close the figure after logging it\n    :param figure: figure to log\n    :param close: if true, close the figure after logging it\n    \"\"\"\n    def __init__(self, figure: matplotlib.figure.Figure, close: bool):\n        self.figure = figure\n        self.close = close\nclass Image:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Image",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class Image:\n    \"\"\"\n    Image data class storing an image and data format\n    :param image: image to log\n    :param dataformats: Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc.\n        More info in add_image method doc at https://pytorch.org/docs/stable/tensorboard.html\n        Gym envs normally use 'HWC' (channel last)\n    \"\"\"\n    def __init__(self, image: Union[th.Tensor, np.ndarray, str], dataformats: str):\n        self.image = image",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "HParam",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class HParam:\n    \"\"\"\n    Hyperparameter data class storing hyperparameters and metrics in dictionaries\n    :param hparam_dict: key-value pairs of hyperparameters to log\n    :param metric_dict: key-value pairs of metrics to log\n        A non-empty metrics dict is required to display hyperparameters in the corresponding Tensorboard section.\n    \"\"\"\n    def __init__(self, hparam_dict: Mapping[str, Union[bool, str, float, None]], metric_dict: Mapping[str, float]):\n        self.hparam_dict = hparam_dict\n        if not metric_dict:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "FormatUnsupportedError",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class FormatUnsupportedError(NotImplementedError):\n    \"\"\"\n    Custom error to display informative message when\n    a value is not supported by some formats.\n    :param unsupported_formats: A sequence of unsupported formats,\n        for instance ``[\"stdout\"]``.\n    :param value_description: Description of the value that cannot be logged by this format.\n    \"\"\"\n    def __init__(self, unsupported_formats: Sequence[str], value_description: str):\n        if len(unsupported_formats) > 1:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "KVWriter",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class KVWriter:\n    \"\"\"\n    Key Value writer\n    \"\"\"\n    def write(self, key_values: Dict[str, Any], key_excluded: Dict[str, Tuple[str, ...]], step: int = 0) -> None:\n        \"\"\"\n        Write a dictionary to file\n        :param key_values:\n        :param key_excluded:\n        :param step:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "SeqWriter",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class SeqWriter:\n    \"\"\"\n    sequence writer\n    \"\"\"\n    def write_sequence(self, sequence: List[str]) -> None:\n        \"\"\"\n        write_sequence an array to file\n        :param sequence:\n        \"\"\"\n        raise NotImplementedError",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "HumanOutputFormat",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class HumanOutputFormat(KVWriter, SeqWriter):\n    \"\"\"A human-readable output format producing ASCII tables of key-value pairs.\n    Set attribute ``max_length`` to change the maximum length of keys and values\n    to write to output (or specify it when calling ``__init__``).\n    :param filename_or_file: the file to write the log to\n    :param max_length: the maximum length of keys and values to write to output.\n        Outputs longer than this will be truncated. An error will be raised\n        if multiple keys are truncated to the same value. The maximum output\n        width will be ``2*max_length + 7``. The default of 36 produces output\n        no longer than 79 characters wide.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "JSONOutputFormat",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class JSONOutputFormat(KVWriter):\n    \"\"\"\n    Log to a file, in the JSON format\n    :param filename: the file to write the log to\n    \"\"\"\n    def __init__(self, filename: str):\n        self.file = open(filename, \"w\")\n    def write(self, key_values: Dict[str, Any], key_excluded: Dict[str, Tuple[str, ...]], step: int = 0) -> None:\n        def cast_to_json_serializable(value: Any):\n            if isinstance(value, Video):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "CSVOutputFormat",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class CSVOutputFormat(KVWriter):\n    \"\"\"\n    Log to a file, in a CSV format\n    :param filename: the file to write the log to\n    \"\"\"\n    def __init__(self, filename: str):\n        self.file = open(filename, \"w+t\")\n        self.keys: List[str] = []\n        self.separator = \",\"\n        self.quotechar = '\"'",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "TensorBoardOutputFormat",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class TensorBoardOutputFormat(KVWriter):\n    \"\"\"\n    Dumps key/value pairs into TensorBoard's numeric format.\n    :param folder: the folder to write the log to\n    \"\"\"\n    def __init__(self, folder: str):\n        assert SummaryWriter is not None, \"tensorboard is not installed, you can use `pip install tensorboard` to do so\"\n        self.writer = SummaryWriter(log_dir=folder)\n        self._is_closed = False\n    def write(self, key_values: Dict[str, Any], key_excluded: Dict[str, Tuple[str, ...]], step: int = 0) -> None:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Logger",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "class Logger:\n    \"\"\"\n    The logger class.\n    :param folder: the logging location\n    :param output_formats: the list of output formats\n    \"\"\"\n    def __init__(self, folder: Optional[str], output_formats: List[KVWriter]):\n        self.name_to_value: Dict[str, float] = defaultdict(float)  # values this iteration\n        self.name_to_count: Dict[str, int] = defaultdict(int)\n        self.name_to_excluded: Dict[str, Tuple[str, ...]] = {}",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "filter_excluded_keys",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "def filter_excluded_keys(key_values: Dict[str, Any], key_excluded: Dict[str, Tuple[str, ...]], _format: str) -> Dict[str, Any]:\n    \"\"\"\n    Filters the keys specified by ``key_exclude`` for the specified format\n    :param key_values: log dictionary to be filtered\n    :param key_excluded: keys to be excluded per format\n    :param _format: format for which this filter is run\n    :return: dict without the excluded keys\n    \"\"\"\n    def is_excluded(key: str) -> bool:\n        return key in key_excluded and key_excluded[key] is not None and _format in key_excluded[key]",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "make_output_format",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "def make_output_format(_format: str, log_dir: str, log_suffix: str = \"\") -> KVWriter:\n    \"\"\"\n    return a logger for the requested format\n    :param _format: the requested format to log to ('stdout', 'log', 'json' or 'csv' or 'tensorboard')\n    :param log_dir: the logging directory\n    :param log_suffix: the suffix for the log file\n    :return: the logger\n    \"\"\"\n    os.makedirs(log_dir, exist_ok=True)\n    if _format == \"stdout\":",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "def configure(folder: Optional[str] = None, format_strings: Optional[List[str]] = None) -> Logger:\n    \"\"\"\n    Configure the current logger.\n    :param folder: the save location\n        (if None, $SB3_LOGDIR, if still None, tempdir/SB3-[date & time])\n    :param format_strings: the output logging format\n        (if None, $SB3_LOG_FORMAT, if still None, ['stdout', 'log', 'csv'])\n    :return: The logger object.\n    \"\"\"\n    if folder is None:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "read_json",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "def read_json(filename: str) -> pandas.DataFrame:\n    \"\"\"\n    read a json file using pandas\n    :param filename: the file path to read\n    :return: the data in the json\n    \"\"\"\n    data = []\n    with open(filename) as file_handler:\n        for line in file_handler:\n            data.append(json.loads(line))",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "read_csv",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "def read_csv(filename: str) -> pandas.DataFrame:\n    \"\"\"\n    read a csv file using pandas\n    :param filename: the file path to read\n    :return: the data in the csv\n    \"\"\"\n    return pandas.read_csv(filename, index_col=None, comment=\"#\")",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "DEBUG = 10\nINFO = 20\nWARN = 30\nERROR = 40\nDISABLED = 50\nclass Video:\n    \"\"\"\n    Video data class storing the video frames and the frame per seconds\n    :param frames: frames to create the video from\n    :param fps: frames per second",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "INFO",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "INFO = 20\nWARN = 30\nERROR = 40\nDISABLED = 50\nclass Video:\n    \"\"\"\n    Video data class storing the video frames and the frame per seconds\n    :param frames: frames to create the video from\n    :param fps: frames per second\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "WARN",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "WARN = 30\nERROR = 40\nDISABLED = 50\nclass Video:\n    \"\"\"\n    Video data class storing the video frames and the frame per seconds\n    :param frames: frames to create the video from\n    :param fps: frames per second\n    \"\"\"\n    def __init__(self, frames: th.Tensor, fps: float):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "ERROR",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "ERROR = 40\nDISABLED = 50\nclass Video:\n    \"\"\"\n    Video data class storing the video frames and the frame per seconds\n    :param frames: frames to create the video from\n    :param fps: frames per second\n    \"\"\"\n    def __init__(self, frames: th.Tensor, fps: float):\n        self.frames = frames",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "DISABLED",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "description": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "peekOfCode": "DISABLED = 50\nclass Video:\n    \"\"\"\n    Video data class storing the video frames and the frame per seconds\n    :param frames: frames to create the video from\n    :param fps: frames per second\n    \"\"\"\n    def __init__(self, frames: th.Tensor, fps: float):\n        self.frames = frames\n        self.fps = fps",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "Monitor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "peekOfCode": "class Monitor(gym.Wrapper[ObsType, ActType, ObsType, ActType]):\n    \"\"\"\n    A monitor wrapper for Gym environments, it is used to know the episode reward, length, time and other data.\n    :param env: The environment\n    :param filename: the location to save a log file, can be None for no log\n    :param allow_early_resets: allows the reset of the environment before it is done\n    :param reset_keywords: extra keywords for the reset call,\n        if extra parameters are needed at reset\n    :param info_keywords: extra information to log, from the information return of env.step()\n    :param override_existing: appends to file if ``filename`` exists, otherwise",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "LoadMonitorResultsError",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "peekOfCode": "class LoadMonitorResultsError(Exception):\n    \"\"\"\n    Raised when loading the monitor log fails.\n    \"\"\"\n    pass\nclass ResultsWriter:\n    \"\"\"\n    A result writer that saves the data from the `Monitor` class\n    :param filename: the location to save a log file. When it does not end in\n        the string ``\"monitor.csv\"``, this suffix will be appended to it",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "ResultsWriter",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "peekOfCode": "class ResultsWriter:\n    \"\"\"\n    A result writer that saves the data from the `Monitor` class\n    :param filename: the location to save a log file. When it does not end in\n        the string ``\"monitor.csv\"``, this suffix will be appended to it\n    :param header: the header dictionary object of the saved csv\n    :param extra_keys: the extra information to log, typically is composed of\n        ``reset_keywords`` and ``info_keywords``\n    :param override_existing: appends to file if ``filename`` exists, otherwise\n        override existing files (default)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "get_monitor_files",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "peekOfCode": "def get_monitor_files(path: str) -> List[str]:\n    \"\"\"\n    get all the monitor files in the given path\n    :param path: the logging folder\n    :return: the log files\n    \"\"\"\n    return glob(os.path.join(path, \"*\" + Monitor.EXT))\ndef load_results(path: str) -> pandas.DataFrame:\n    \"\"\"\n    Load all Monitor logs from a given directory path matching ``*monitor.csv``",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "load_results",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "peekOfCode": "def load_results(path: str) -> pandas.DataFrame:\n    \"\"\"\n    Load all Monitor logs from a given directory path matching ``*monitor.csv``\n    :param path: the directory path containing the log file(s)\n    :return: the logged data\n    \"\"\"\n    monitor_files = get_monitor_files(path)\n    if len(monitor_files) == 0:\n        raise LoadMonitorResultsError(f\"No monitor files of the form *{Monitor.EXT} found in {path}\")\n    data_frames, headers = [], []",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "description": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "peekOfCode": "__all__ = [\"Monitor\", \"ResultsWriter\", \"get_monitor_files\", \"load_results\"]\nimport csv\nimport json\nimport os\nimport time\nfrom glob import glob\nfrom typing import Any, Dict, List, Optional, SupportsFloat, Tuple, Union\nimport gymnasium as gym\nimport pandas\nfrom gymnasium.core import ActType, ObsType",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.monitor",
        "documentation": {}
    },
    {
        "label": "ActionNoise",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "description": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "peekOfCode": "class ActionNoise(ABC):\n    \"\"\"\n    The action noise base class\n    \"\"\"\n    def __init__(self) -> None:\n        super().__init__()\n    def reset(self) -> None:\n        \"\"\"\n        Call end of episode reset for the noise\n        \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "description": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "peekOfCode": "class NormalActionNoise(ActionNoise):\n    \"\"\"\n    A Gaussian action noise.\n    :param mean: Mean value of the noise\n    :param sigma: Scale of the noise (std here)\n    :param dtype: Type of the output noise\n    \"\"\"\n    def __init__(self, mean: np.ndarray, sigma: np.ndarray, dtype: DTypeLike = np.float32) -> None:\n        self._mu = mean\n        self._sigma = sigma",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "description": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "peekOfCode": "class OrnsteinUhlenbeckActionNoise(ActionNoise):\n    \"\"\"\n    An Ornstein Uhlenbeck action noise, this is designed to approximate Brownian motion with friction.\n    Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n    :param mean: Mean of the noise\n    :param sigma: Scale of the noise\n    :param theta: Rate of mean reversion\n    :param dt: Timestep for the noise\n    :param initial_noise: Initial value for the noise output, (if None: 0)\n    :param dtype: Type of the output noise",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "VectorizedActionNoise",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "description": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "peekOfCode": "class VectorizedActionNoise(ActionNoise):\n    \"\"\"\n    A Vectorized action noise for parallel environments.\n    :param base_noise: Noise generator to use\n    :param n_envs: Number of parallel environments\n    \"\"\"\n    def __init__(self, base_noise: ActionNoise, n_envs: int) -> None:\n        try:\n            self.n_envs = int(n_envs)\n            assert self.n_envs > 0",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OffPolicyAlgorithm",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.off_policy_algorithm",
        "description": "docs.lib.rl.agents.stablebaselines3.common.off_policy_algorithm",
        "peekOfCode": "class OffPolicyAlgorithm(BaseAlgorithm):\n    \"\"\"\n    The base for Off-Policy algorithms (ex: SAC/TD3)\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from\n                (if registered in Gym, can be str. Can be None for loading trained models)\n    :param learning_rate: learning rate for the optimizer,\n        it can be a function of the current progress remaining (from 1 to 0)\n    :param buffer_size: size of the replay buffer\n    :param learning_starts: how many steps of the model to collect transitions for before learning starts",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.off_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "SelfOffPolicyAlgorithm",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.off_policy_algorithm",
        "description": "docs.lib.rl.agents.stablebaselines3.common.off_policy_algorithm",
        "peekOfCode": "SelfOffPolicyAlgorithm = TypeVar(\"SelfOffPolicyAlgorithm\", bound=\"OffPolicyAlgorithm\")\nclass OffPolicyAlgorithm(BaseAlgorithm):\n    \"\"\"\n    The base for Off-Policy algorithms (ex: SAC/TD3)\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from\n                (if registered in Gym, can be str. Can be None for loading trained models)\n    :param learning_rate: learning rate for the optimizer,\n        it can be a function of the current progress remaining (from 1 to 0)\n    :param buffer_size: size of the replay buffer",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.off_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "OnPolicyAlgorithm",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.on_policy_algorithm",
        "description": "docs.lib.rl.agents.stablebaselines3.common.on_policy_algorithm",
        "peekOfCode": "class OnPolicyAlgorithm(BaseAlgorithm):\n    \"\"\"\n    The base for On-Policy algorithms (ex: A2C/PPO).\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: The learning rate, it can be a function\n        of the current progress remaining (from 1 to 0)\n    :param n_steps: The number of steps to run for each environment per update\n        (i.e. batch size is n_steps * n_env where n_env is number of environment copies running in parallel)\n    :param gamma: Discount factor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.on_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "SelfOnPolicyAlgorithm",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.on_policy_algorithm",
        "description": "docs.lib.rl.agents.stablebaselines3.common.on_policy_algorithm",
        "peekOfCode": "SelfOnPolicyAlgorithm = TypeVar(\"SelfOnPolicyAlgorithm\", bound=\"OnPolicyAlgorithm\")\nclass OnPolicyAlgorithm(BaseAlgorithm):\n    \"\"\"\n    The base for On-Policy algorithms (ex: A2C/PPO).\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: The learning rate, it can be a function\n        of the current progress remaining (from 1 to 0)\n    :param n_steps: The number of steps to run for each environment per update\n        (i.e. batch size is n_steps * n_env where n_env is number of environment copies running in parallel)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.on_policy_algorithm",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "class BaseModel(nn.Module):\n    \"\"\"\n    The base model object: makes predictions in response to observations.\n    In the case of policies, the prediction is an action. In the case of critics, it is the\n    estimated value of the observation.\n    :param observation_space: The observation space of the environment\n    :param action_space: The action space of the environment\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments\n        to pass to the features extractor.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "class BasePolicy(BaseModel, ABC):\n    \"\"\"The base policy object.\n    Parameters are mostly the same as `BaseModel`; additions are documented below.\n    :param args: positional arguments passed through to `BaseModel`.\n    :param kwargs: keyword arguments passed through to `BaseModel`.\n    :param squash_output: For continuous actions, whether the output is squashed\n        or not using a ``tanh()`` function.\n    \"\"\"\n    features_extractor: BaseFeaturesExtractor\n    def __init__(self, *args, squash_output: bool = False, **kwargs):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "class ActorCriticPolicy(BasePolicy):\n    \"\"\"\n    Policy class for actor-critic algorithms (has both policy and value prediction).\n    Used by A2C, PPO and the likes.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param ortho_init: Whether to use or not orthogonal initialization",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ActorCriticCnnPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "class ActorCriticCnnPolicy(ActorCriticPolicy):\n    \"\"\"\n    CNN policy class for actor-critic algorithms (has both policy and value prediction).\n    Used by A2C, PPO and the likes.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param ortho_init: Whether to use or not orthogonal initialization",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputActorCriticPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "class MultiInputActorCriticPolicy(ActorCriticPolicy):\n    \"\"\"\n    MultiInputActorClass policy class for actor-critic algorithms (has both policy and value prediction).\n    Used by A2C, PPO and the likes.\n    :param observation_space: Observation space (Tuple)\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param ortho_init: Whether to use or not orthogonal initialization",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "ContinuousCritic",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "class ContinuousCritic(BaseModel):\n    \"\"\"\n    Critic network(s) for DDPG/SAC/TD3.\n    It represents the action-state value function (Q-value function).\n    Compared to A2C/PPO critics, this one represents the Q-value\n    and takes the continuous action as input. It is concatenated with the state\n    and then fed to the network which outputs a single value: Q(s, a).\n    For more recent algorithms like SAC/TD3, multiple networks\n    are created to give different estimates.\n    By default, it creates two critic networks used to reduce overestimation",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "SelfBaseModel",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "peekOfCode": "SelfBaseModel = TypeVar(\"SelfBaseModel\", bound=\"BaseModel\")\nclass BaseModel(nn.Module):\n    \"\"\"\n    The base model object: makes predictions in response to observations.\n    In the case of policies, the prediction is an action. In the case of critics, it is the\n    estimated value of the observation.\n    :param observation_space: The observation space of the environment\n    :param action_space: The action space of the environment\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.policies",
        "documentation": {}
    },
    {
        "label": "is_image_space_channels_first",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def is_image_space_channels_first(observation_space: spaces.Box) -> bool:\n    \"\"\"\n    Check if an image observation space (see ``is_image_space``)\n    is channels-first (CxHxW, True) or channels-last (HxWxC, False).\n    Use a heuristic that channel dimension is the smallest of the three.\n    If second dimension is smallest, raise an exception (no support).\n    :param observation_space:\n    :return: True if observation space is channels-first image, False if channels-last.\n    \"\"\"\n    smallest_dimension = np.argmin(observation_space.shape).item()",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "is_image_space",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def is_image_space(\n    observation_space: spaces.Space,\n    check_channels: bool = False,\n    normalized_image: bool = False,\n) -> bool:\n    \"\"\"\n    Check if a observation space has the shape, limits and dtype\n    of a valid image.\n    The check is conservative, so that it returns False if there is a doubt.\n    Valid images: RGB, RGBD, GrayScale with values in [0, 255]",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "maybe_transpose",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def maybe_transpose(observation: np.ndarray, observation_space: spaces.Space) -> np.ndarray:\n    \"\"\"\n    Handle the different cases for images as PyTorch use channel first format.\n    :param observation:\n    :param observation_space:\n    :return: channel first observation if observation is an image\n    \"\"\"\n    # Avoid circular import\n    from stable_baselines3.common.vec_env import VecTransposeImage\n    if is_image_space(observation_space):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "preprocess_obs",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def preprocess_obs(\n    obs: Union[th.Tensor, Dict[str, th.Tensor]],\n    observation_space: spaces.Space,\n    normalize_images: bool = True,\n) -> Union[th.Tensor, Dict[str, th.Tensor]]:\n    \"\"\"\n    Preprocess observation to be to a neural network.\n    For images, it normalizes the values by dividing them by 255 (to have values in [0, 1])\n    For discrete observations, it create a one hot vector.\n    :param obs: Observation",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_obs_shape",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def get_obs_shape(\n    observation_space: spaces.Space,\n) -> Union[Tuple[int, ...], Dict[str, Tuple[int, ...]]]:\n    \"\"\"\n    Get the shape of the observation (useful for the buffers).\n    :param observation_space:\n    :return:\n    \"\"\"\n    if isinstance(observation_space, spaces.Box):\n        return observation_space.shape",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_flattened_obs_dim",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def get_flattened_obs_dim(observation_space: spaces.Space) -> int:\n    \"\"\"\n    Get the dimension of the observation space when flattened.\n    It does not apply to image observation space.\n    Used by the ``FlattenExtractor`` to compute the input shape.\n    :param observation_space:\n    :return:\n    \"\"\"\n    # See issue https://github.com/openai/gym/issues/1915\n    # it may be a problem for Dict/Tuple spaces too...",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "get_action_dim",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def get_action_dim(action_space: spaces.Space) -> int:\n    \"\"\"\n    Get the dimension of the action space.\n    :param action_space:\n    :return:\n    \"\"\"\n    if isinstance(action_space, spaces.Box):\n        return int(np.prod(action_space.shape))\n    elif isinstance(action_space, spaces.Discrete):\n        # Action is an int",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "check_for_nested_spaces",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "description": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "peekOfCode": "def check_for_nested_spaces(obs_space: spaces.Space) -> None:\n    \"\"\"\n    Make sure the observation space does not have nested spaces (Dicts/Tuples inside Dicts/Tuples).\n    If so, raise an Exception informing that there is no support for this.\n    :param obs_space: an observation space\n    \"\"\"\n    if isinstance(obs_space, (spaces.Dict, spaces.Tuple)):\n        sub_spaces = obs_space.spaces.values() if isinstance(obs_space, spaces.Dict) else obs_space.spaces\n        for sub_space in sub_spaces:\n            if isinstance(sub_space, (spaces.Dict, spaces.Tuple)):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.preprocessing",
        "documentation": {}
    },
    {
        "label": "rolling_window",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "def rolling_window(array: np.ndarray, window: int) -> np.ndarray:\n    \"\"\"\n    Apply a rolling window to a np.ndarray\n    :param array: the input Array\n    :param window: length of the rolling window\n    :return: rolling window on the input array\n    \"\"\"\n    shape = array.shape[:-1] + (array.shape[-1] - window + 1, window)\n    strides = (*array.strides, array.strides[-1])\n    return np.lib.stride_tricks.as_strided(array, shape=shape, strides=strides)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "window_func",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "def window_func(var_1: np.ndarray, var_2: np.ndarray, window: int, func: Callable) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Apply a function to the rolling window of 2 arrays\n    :param var_1: variable 1\n    :param var_2: variable 2\n    :param window: length of the rolling window\n    :param func: function to apply on the rolling window on variable 2 (such as np.mean)\n    :return:  the rolling output with applied function\n    \"\"\"\n    var_2_window = rolling_window(var_2, window)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "ts2xy",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "def ts2xy(data_frame: pd.DataFrame, x_axis: str) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Decompose a data frame variable to x ans ys\n    :param data_frame: the input data\n    :param x_axis: the axis for the x and y output\n        (can be X_TIMESTEPS='timesteps', X_EPISODES='episodes' or X_WALLTIME='walltime_hrs')\n    :return: the x and y output\n    \"\"\"\n    if x_axis == X_TIMESTEPS:\n        x_var = np.cumsum(data_frame.l.values)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "plot_curves",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "def plot_curves(\n    xy_list: List[Tuple[np.ndarray, np.ndarray]], x_axis: str, title: str, figsize: Tuple[int, int] = (8, 2)\n) -> None:\n    \"\"\"\n    plot the curves\n    :param xy_list: the x and y coordinates to plot\n    :param x_axis: the axis for the x and y output\n        (can be X_TIMESTEPS='timesteps', X_EPISODES='episodes' or X_WALLTIME='walltime_hrs')\n    :param title: the title of the plot\n    :param figsize: Size of the figure (width, height)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "def plot_results(\n    dirs: List[str], num_timesteps: Optional[int], x_axis: str, task_name: str, figsize: Tuple[int, int] = (8, 2)\n) -> None:\n    \"\"\"\n    Plot the results using csv files from ``Monitor`` wrapper.\n    :param dirs: the save location of the results to plot\n    :param num_timesteps: only plot the points below this value\n    :param x_axis: the axis for the x and y output\n        (can be X_TIMESTEPS='timesteps', X_EPISODES='episodes' or X_WALLTIME='walltime_hrs')\n    :param task_name: the title of the task to plot",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "X_TIMESTEPS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "X_TIMESTEPS = \"timesteps\"\nX_EPISODES = \"episodes\"\nX_WALLTIME = \"walltime_hrs\"\nPOSSIBLE_X_AXES = [X_TIMESTEPS, X_EPISODES, X_WALLTIME]\nEPISODES_WINDOW = 100\ndef rolling_window(array: np.ndarray, window: int) -> np.ndarray:\n    \"\"\"\n    Apply a rolling window to a np.ndarray\n    :param array: the input Array\n    :param window: length of the rolling window",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "X_EPISODES",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "X_EPISODES = \"episodes\"\nX_WALLTIME = \"walltime_hrs\"\nPOSSIBLE_X_AXES = [X_TIMESTEPS, X_EPISODES, X_WALLTIME]\nEPISODES_WINDOW = 100\ndef rolling_window(array: np.ndarray, window: int) -> np.ndarray:\n    \"\"\"\n    Apply a rolling window to a np.ndarray\n    :param array: the input Array\n    :param window: length of the rolling window\n    :return: rolling window on the input array",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "X_WALLTIME",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "X_WALLTIME = \"walltime_hrs\"\nPOSSIBLE_X_AXES = [X_TIMESTEPS, X_EPISODES, X_WALLTIME]\nEPISODES_WINDOW = 100\ndef rolling_window(array: np.ndarray, window: int) -> np.ndarray:\n    \"\"\"\n    Apply a rolling window to a np.ndarray\n    :param array: the input Array\n    :param window: length of the rolling window\n    :return: rolling window on the input array\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "POSSIBLE_X_AXES",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "POSSIBLE_X_AXES = [X_TIMESTEPS, X_EPISODES, X_WALLTIME]\nEPISODES_WINDOW = 100\ndef rolling_window(array: np.ndarray, window: int) -> np.ndarray:\n    \"\"\"\n    Apply a rolling window to a np.ndarray\n    :param array: the input Array\n    :param window: length of the rolling window\n    :return: rolling window on the input array\n    \"\"\"\n    shape = array.shape[:-1] + (array.shape[-1] - window + 1, window)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "EPISODES_WINDOW",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "description": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "peekOfCode": "EPISODES_WINDOW = 100\ndef rolling_window(array: np.ndarray, window: int) -> np.ndarray:\n    \"\"\"\n    Apply a rolling window to a np.ndarray\n    :param array: the input Array\n    :param window: length of the rolling window\n    :return: rolling window on the input array\n    \"\"\"\n    shape = array.shape[:-1] + (array.shape[-1] - window + 1, window)\n    strides = (*array.strides, array.strides[-1])",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.results_plotter",
        "documentation": {}
    },
    {
        "label": "RunningMeanStd",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.running_mean_std",
        "description": "docs.lib.rl.agents.stablebaselines3.common.running_mean_std",
        "peekOfCode": "class RunningMeanStd:\n    def __init__(self, epsilon: float = 1e-4, shape: Tuple[int, ...] = ()):\n        \"\"\"\n        Calulates the running mean and std of a data stream\n        https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n        :param epsilon: helps with arithmetic issues\n        :param shape: the shape of the data stream's output\n        \"\"\"\n        self.mean = np.zeros(shape, np.float64)\n        self.var = np.ones(shape, np.float64)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.running_mean_std",
        "documentation": {}
    },
    {
        "label": "recursive_getattr",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def recursive_getattr(obj: Any, attr: str, *args) -> Any:\n    \"\"\"\n    Recursive version of getattr\n    taken from https://stackoverflow.com/questions/31174295\n    Ex:\n    > MyObject.sub_object = SubObject(name='test')\n    > recursive_getattr(MyObject, 'sub_object.name')  # return test\n    :param obj:\n    :param attr: Attribute to retrieve\n    :return: The attribute",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "recursive_setattr",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def recursive_setattr(obj: Any, attr: str, val: Any) -> None:\n    \"\"\"\n    Recursive version of setattr\n    taken from https://stackoverflow.com/questions/31174295\n    Ex:\n    > MyObject.sub_object = SubObject(name='test')\n    > recursive_setattr(MyObject, 'sub_object.name', 'hello')\n    :param obj:\n    :param attr: Attribute to set\n    :param val: New value of the attribute",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "is_json_serializable",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def is_json_serializable(item: Any) -> bool:\n    \"\"\"\n    Test if an object is serializable into JSON\n    :param item: The object to be tested for JSON serialization.\n    :return: True if object is JSON serializable, false otherwise.\n    \"\"\"\n    # Try with try-except struct.\n    json_serializable = True\n    try:\n        _ = json.dumps(item)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "data_to_json",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def data_to_json(data: Dict[str, Any]) -> str:\n    \"\"\"\n    Turn data (class parameters) into a JSON string for storing\n    :param data: Dictionary of class parameters to be\n        stored. Items that are not JSON serializable will be\n        pickled with Cloudpickle and stored as bytearray in\n        the JSON file\n    :return: JSON string of the data serialized.\n    \"\"\"\n    # First, check what elements can not be JSONfied,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "json_to_data",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def json_to_data(json_string: str, custom_objects: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n    \"\"\"\n    Turn JSON serialization of class-parameters back into dictionary.\n    :param json_string: JSON serialization of the class-parameters\n        that should be loaded.\n    :param custom_objects: Dictionary of objects to replace\n        upon loading. If a variable is present in this dictionary as a\n        key, it will not be deserialized and the corresponding item\n        will be used instead. Similar to custom_objects in\n        ``keras.models.load_model``. Useful when you have an object in",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "open_path",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def open_path(\n    path: Union[str, pathlib.Path, io.BufferedIOBase], mode: str, verbose: int = 0, suffix: Optional[str] = None\n) -> Union[io.BufferedWriter, io.BufferedReader, io.BytesIO]:\n    \"\"\"\n    Opens a path for reading or writing with a preferred suffix and raises debug information.\n    If the provided path is a derivative of io.BufferedIOBase it ensures that the file\n    matches the provided mode, i.e. If the mode is read (\"r\", \"read\") it checks that the path is readable.\n    If the mode is write (\"w\", \"write\") it checks that the file is writable.\n    If the provided path is a string or a pathlib.Path, it ensures that it exists. If the mode is \"read\"\n    it checks that it exists, if it doesn't exist it attempts to read path.suffix if a suffix is provided.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "open_path_str",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def open_path_str(path: str, mode: str, verbose: int = 0, suffix: Optional[str] = None) -> io.BufferedIOBase:\n    \"\"\"\n    Open a path given by a string. If writing to the path, the function ensures\n    that the path exists.\n    :param path: the path to open. If mode is \"w\" then it ensures that the path exists\n        by creating the necessary folders and renaming path if it points to a folder.\n    :param mode: how to open the file. \"w\" for writing, \"r\" for reading.\n    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n    :param suffix: The preferred suffix. If mode is \"w\" then the opened file has the suffix.\n        If mode is \"r\" then we attempt to open the path. If an error is raised and the suffix",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "open_path_pathlib",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def open_path_pathlib(path: pathlib.Path, mode: str, verbose: int = 0, suffix: Optional[str] = None) -> io.BufferedIOBase:\n    \"\"\"\n    Open a path given by a string. If writing to the path, the function ensures\n    that the path exists.\n    :param path: the path to check. If mode is \"w\" then it\n        ensures that the path exists by creating the necessary folders and\n        renaming path if it points to a folder.\n    :param mode: how to open the file. \"w\" for writing, \"r\" for reading.\n    :param verbose: Verbosity level: 0 for no output, 2 for indicating if path without suffix is not found when mode is \"r\"\n    :param suffix: The preferred suffix. If mode is \"w\" then the opened file has the suffix.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "save_to_zip_file",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def save_to_zip_file(\n    save_path: Union[str, pathlib.Path, io.BufferedIOBase],\n    data: Optional[Dict[str, Any]] = None,\n    params: Optional[Dict[str, Any]] = None,\n    pytorch_variables: Optional[Dict[str, Any]] = None,\n    verbose: int = 0,\n) -> None:\n    \"\"\"\n    Save model data to a zip archive.\n    :param save_path: Where to store the model.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "save_to_pkl",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def save_to_pkl(path: Union[str, pathlib.Path, io.BufferedIOBase], obj: Any, verbose: int = 0) -> None:\n    \"\"\"\n    Save an object to path creating the necessary folders along the way.\n    If the path exists and is a directory, it will raise a warning and rename the path.\n    If a suffix is provided in the path, it will use that suffix, otherwise, it will use '.pkl'.\n    :param path: the path to open.\n        if save_path is a str or pathlib.Path and mode is \"w\", single dispatch ensures that the\n        path actually exists. If path is a io.BufferedIOBase the path exists.\n    :param obj: The object to save.\n    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "load_from_pkl",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def load_from_pkl(path: Union[str, pathlib.Path, io.BufferedIOBase], verbose: int = 0) -> Any:\n    \"\"\"\n    Load an object from the path. If a suffix is provided in the path, it will use that suffix.\n    If the path does not exist, it will attempt to load using the .pkl suffix.\n    :param path: the path to open.\n        if save_path is a str or pathlib.Path and mode is \"w\", single dispatch ensures that the\n        path actually exists. If path is a io.BufferedIOBase the path exists.\n    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n    \"\"\"\n    file = open_path(path, \"r\", verbose=verbose, suffix=\"pkl\")",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "load_from_zip_file",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "description": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "peekOfCode": "def load_from_zip_file(\n    load_path: Union[str, pathlib.Path, io.BufferedIOBase],\n    load_data: bool = True,\n    custom_objects: Optional[Dict[str, Any]] = None,\n    device: Union[th.device, str] = \"auto\",\n    verbose: int = 0,\n    print_system_info: bool = False,\n) -> Tuple[Optional[Dict[str, Any]], TensorDict, Optional[TensorDict]]:\n    \"\"\"\n    Load model data from a .zip archive",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.save_util",
        "documentation": {}
    },
    {
        "label": "BaseFeaturesExtractor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "class BaseFeaturesExtractor(nn.Module):\n    \"\"\"\n    Base class that represents a features extractor.\n    :param observation_space:\n    :param features_dim: Number of features extracted.\n    \"\"\"\n    def __init__(self, observation_space: gym.Space, features_dim: int = 0) -> None:\n        super().__init__()\n        assert features_dim > 0\n        self._observation_space = observation_space",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "FlattenExtractor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "class FlattenExtractor(BaseFeaturesExtractor):\n    \"\"\"\n    Feature extract that flatten the input.\n    Used as a placeholder when feature extraction is not needed.\n    :param observation_space:\n    \"\"\"\n    def __init__(self, observation_space: gym.Space) -> None:\n        super().__init__(observation_space, get_flattened_obs_dim(observation_space))\n        self.flatten = nn.Flatten()\n    def forward(self, observations: th.Tensor) -> th.Tensor:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "NatureCNN",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "class NatureCNN(BaseFeaturesExtractor):\n    \"\"\"\n    CNN from DQN Nature paper:\n        Mnih, Volodymyr, et al.\n        \"Human-level control through deep reinforcement learning.\"\n        Nature 518.7540 (2015): 529-533.\n    :param observation_space:\n    :param features_dim: Number of features extracted.\n        This corresponds to the number of unit for the last layer.\n    :param normalized_image: Whether to assume that the image is already normalized",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "MlpExtractor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "class MlpExtractor(nn.Module):\n    \"\"\"\n    Constructs an MLP that receives the output from a previous features extractor (i.e. a CNN) or directly\n    the observations (if no features extractor is applied) as an input and outputs a latent representation\n    for the policy and a value network.\n    The ``net_arch`` parameter allows to specify the amount and size of the hidden layers.\n    It can be in either of the following forms:\n    1. ``dict(vf=[<list of layer sizes>], pi=[<list of layer sizes>])``: to specify the amount and size of the layers in the\n        policy and value nets individually. If it is missing any of the keys (pi or vf),\n        zero layers will be considered for that key.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "CombinedExtractor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "class CombinedExtractor(BaseFeaturesExtractor):\n    \"\"\"\n    Combined features extractor for Dict observation spaces.\n    Builds a features extractor for each key of the space. Input from each space\n    is fed through a separate submodule (CNN or MLP, depending on input shape),\n    the output features are concatenated and fed through additional MLP network (\"combined\").\n    :param observation_space:\n    :param cnn_output_dim: Number of features to output from each CNN submodule(s). Defaults to\n        256 to avoid exploding network sizes.\n    :param normalized_image: Whether to assume that the image is already normalized",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "create_mlp",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "def create_mlp(\n    input_dim: int,\n    output_dim: int,\n    net_arch: List[int],\n    activation_fn: Type[nn.Module] = nn.ReLU,\n    squash_output: bool = False,\n    with_bias: bool = True,\n) -> List[nn.Module]:\n    \"\"\"\n    Create a multi layer perceptron (MLP), which is",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "get_actor_critic_arch",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "description": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "peekOfCode": "def get_actor_critic_arch(net_arch: Union[List[int], Dict[str, List[int]]]) -> Tuple[List[int], List[int]]:\n    \"\"\"\n    Get the actor and critic network architectures for off-policy actor-critic algorithms (SAC, TD3, DDPG).\n    The ``net_arch`` parameter allows to specify the amount and size of the hidden layers,\n    which can be different for the actor and the critic.\n    It is assumed to be a list of ints or a dict.\n    1. If it is a list, actor and critic networks will have the same architecture.\n        The architecture is represented by a list of integers (of arbitrary length (zero allowed))\n        each specifying the number of units per layer.\n       If the number of ints is zero, the network will be linear.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.torch_layers",
        "documentation": {}
    },
    {
        "label": "RolloutBufferSamples",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor\n    old_values: th.Tensor\n    old_log_prob: th.Tensor\n    advantages: th.Tensor\n    returns: th.Tensor\nclass DictRolloutBufferSamples(NamedTuple):\n    observations: TensorDict\n    actions: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "DictRolloutBufferSamples",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class DictRolloutBufferSamples(NamedTuple):\n    observations: TensorDict\n    actions: th.Tensor\n    old_values: th.Tensor\n    old_log_prob: th.Tensor\n    advantages: th.Tensor\n    returns: th.Tensor\nclass ReplayBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "ReplayBufferSamples",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class ReplayBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor\n    next_observations: th.Tensor\n    dones: th.Tensor\n    rewards: th.Tensor\nclass DictReplayBufferSamples(NamedTuple):\n    observations: TensorDict\n    actions: th.Tensor\n    next_observations: TensorDict",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "DictReplayBufferSamples",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class DictReplayBufferSamples(NamedTuple):\n    observations: TensorDict\n    actions: th.Tensor\n    next_observations: TensorDict\n    dones: th.Tensor\n    rewards: th.Tensor\nclass RolloutReturn(NamedTuple):\n    episode_timesteps: int\n    n_episodes: int\n    continue_training: bool",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "RolloutReturn",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class RolloutReturn(NamedTuple):\n    episode_timesteps: int\n    n_episodes: int\n    continue_training: bool\nclass TrainFrequencyUnit(Enum):\n    STEP = \"step\"\n    EPISODE = \"episode\"\nclass TrainFreq(NamedTuple):\n    frequency: int\n    unit: TrainFrequencyUnit  # either \"step\" or \"episode\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TrainFrequencyUnit",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class TrainFrequencyUnit(Enum):\n    STEP = \"step\"\n    EPISODE = \"episode\"\nclass TrainFreq(NamedTuple):\n    frequency: int\n    unit: TrainFrequencyUnit  # either \"step\" or \"episode\"\nclass PolicyPredictor(Protocol):\n    def predict(\n        self,\n        observation: Union[np.ndarray, Dict[str, np.ndarray]],",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TrainFreq",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class TrainFreq(NamedTuple):\n    frequency: int\n    unit: TrainFrequencyUnit  # either \"step\" or \"episode\"\nclass PolicyPredictor(Protocol):\n    def predict(\n        self,\n        observation: Union[np.ndarray, Dict[str, np.ndarray]],\n        state: Optional[Tuple[np.ndarray, ...]] = None,\n        episode_start: Optional[np.ndarray] = None,\n        deterministic: bool = False,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "PolicyPredictor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "class PolicyPredictor(Protocol):\n    def predict(\n        self,\n        observation: Union[np.ndarray, Dict[str, np.ndarray]],\n        state: Optional[Tuple[np.ndarray, ...]] = None,\n        episode_start: Optional[np.ndarray] = None,\n        deterministic: bool = False,\n    ) -> Tuple[np.ndarray, Optional[Tuple[np.ndarray, ...]]]:\n        \"\"\"\n        Get the policy action from an observation (and optional hidden state).",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymEnv",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "GymEnv = Union[gym.Env, \"VecEnv\"]\nGymObs = Union[Tuple, Dict[str, Any], np.ndarray, int]\nGymResetReturn = Tuple[GymObs, Dict]\nAtariResetReturn = Tuple[np.ndarray, Dict[str, Any]]\nGymStepReturn = Tuple[GymObs, float, bool, bool, Dict]\nAtariStepReturn = Tuple[np.ndarray, SupportsFloat, bool, bool, Dict[str, Any]]\nTensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymObs",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "GymObs = Union[Tuple, Dict[str, Any], np.ndarray, int]\nGymResetReturn = Tuple[GymObs, Dict]\nAtariResetReturn = Tuple[np.ndarray, Dict[str, Any]]\nGymStepReturn = Tuple[GymObs, float, bool, bool, Dict]\nAtariStepReturn = Tuple[np.ndarray, SupportsFloat, bool, bool, Dict[str, Any]]\nTensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymResetReturn",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "GymResetReturn = Tuple[GymObs, Dict]\nAtariResetReturn = Tuple[np.ndarray, Dict[str, Any]]\nGymStepReturn = Tuple[GymObs, float, bool, bool, Dict]\nAtariStepReturn = Tuple[np.ndarray, SupportsFloat, bool, bool, Dict[str, Any]]\nTensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "AtariResetReturn",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "AtariResetReturn = Tuple[np.ndarray, Dict[str, Any]]\nGymStepReturn = Tuple[GymObs, float, bool, bool, Dict]\nAtariStepReturn = Tuple[np.ndarray, SupportsFloat, bool, bool, Dict[str, Any]]\nTensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "GymStepReturn",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "GymStepReturn = Tuple[GymObs, float, bool, bool, Dict]\nAtariStepReturn = Tuple[np.ndarray, SupportsFloat, bool, bool, Dict[str, Any]]\nTensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "AtariStepReturn",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "AtariStepReturn = Tuple[np.ndarray, SupportsFloat, bool, bool, Dict[str, Any]]\nTensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "TensorDict = Dict[str, th.Tensor]\nOptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "OptimizerStateDict",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "OptimizerStateDict = Dict[str, Any]\nMaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor\n    old_values: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "MaybeCallback",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "MaybeCallback = Union[None, Callable, List[\"BaseCallback\"], \"BaseCallback\"]\nPyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor\n    old_values: th.Tensor\n    old_log_prob: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "PyTorchObs",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "PyTorchObs = Union[th.Tensor, TensorDict]\n# A schedule takes the remaining progress as input\n# and ouputs a scalar (e.g. learning rate, clip range, ...)\nSchedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor\n    old_values: th.Tensor\n    old_log_prob: th.Tensor\n    advantages: th.Tensor",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "Schedule",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "description": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "peekOfCode": "Schedule = Callable[[float], float]\nclass RolloutBufferSamples(NamedTuple):\n    observations: th.Tensor\n    actions: th.Tensor\n    old_values: th.Tensor\n    old_log_prob: th.Tensor\n    advantages: th.Tensor\n    returns: th.Tensor\nclass DictRolloutBufferSamples(NamedTuple):\n    observations: TensorDict",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.type_aliases",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def set_random_seed(seed: int, using_cuda: bool = False) -> None:\n    \"\"\"\n    Seed the different random generators.\n    :param seed:\n    :param using_cuda:\n    \"\"\"\n    # Seed python RNG\n    random.seed(seed)\n    # Seed numpy RNG\n    np.random.seed(seed)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "explained_variance",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def explained_variance(y_pred: np.ndarray, y_true: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes fraction of variance that ypred explains about y.\n    Returns 1 - Var[y-ypred] / Var[y]\n    interpretation:\n        ev=0  =>  might as well have predicted zero\n        ev=1  =>  perfect prediction\n        ev<0  =>  worse than just predicting zero\n    :param y_pred: the prediction\n    :param y_true: the expected value",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "update_learning_rate",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def update_learning_rate(optimizer: th.optim.Optimizer, learning_rate: float) -> None:\n    \"\"\"\n    Update the learning rate for a given optimizer.\n    Useful when doing linear schedule.\n    :param optimizer: Pytorch optimizer\n    :param learning_rate: New learning rate value\n    \"\"\"\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = learning_rate\ndef get_schedule_fn(value_schedule: Union[Schedule, float]) -> Schedule:",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_schedule_fn",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def get_schedule_fn(value_schedule: Union[Schedule, float]) -> Schedule:\n    \"\"\"\n    Transform (if needed) learning rate and clip range (for PPO)\n    to callable.\n    :param value_schedule: Constant value of schedule function\n    :return: Schedule function (can return constant value)\n    \"\"\"\n    # If the passed schedule is a float\n    # create a constant function\n    if isinstance(value_schedule, (float, int)):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_linear_fn",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def get_linear_fn(start: float, end: float, end_fraction: float) -> Schedule:\n    \"\"\"\n    Create a function that interpolates linearly between start and end\n    between ``progress_remaining`` = 1 and ``progress_remaining`` = ``end_fraction``.\n    This is used in DQN for linearly annealing the exploration fraction\n    (epsilon for the epsilon-greedy strategy).\n    :params start: value to start with if ``progress_remaining`` = 1\n    :params end: value to end with if ``progress_remaining`` = 0\n    :params end_fraction: fraction of ``progress_remaining``\n        where end is reached e.g 0.1 then end is reached after 10%",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "constant_fn",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def constant_fn(val: float) -> Schedule:\n    \"\"\"\n    Create a function that returns a constant\n    It is useful for learning rate schedule (to avoid code duplication)\n    :param val: constant value\n    :return: Constant schedule function.\n    \"\"\"\n    def func(_):\n        return val\n    return func",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_device",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def get_device(device: Union[th.device, str] = \"auto\") -> th.device:\n    \"\"\"\n    Retrieve PyTorch device.\n    It checks that the requested device is available first.\n    For now, it supports only cpu and cuda.\n    By default, it tries to use the gpu.\n    :param device: One for 'auto', 'cuda', 'cpu'\n    :return: Supported Pytorch device\n    \"\"\"\n    # Cuda by default",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_latest_run_id",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def get_latest_run_id(log_path: str = \"\", log_name: str = \"\") -> int:\n    \"\"\"\n    Returns the latest run number for the given log name and log path,\n    by finding the greatest number in the directories.\n    :param log_path: Path to the log folder containing several runs.\n    :param log_name: Name of the experiment. Each run is stored\n        in a folder named ``log_name_1``, ``log_name_2``, ...\n    :return: latest run number\n    \"\"\"\n    max_run_id = 0",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "configure_logger",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def configure_logger(\n    verbose: int = 0,\n    tensorboard_log: Optional[str] = None,\n    tb_log_name: str = \"\",\n    reset_num_timesteps: bool = True,\n) -> Logger:\n    \"\"\"\n    Configure the logger's outputs.\n    :param verbose: Verbosity level: 0 for no output, 1 for the standard output to be part of the logger outputs\n    :param tensorboard_log: the log location for tensorboard (if None, no logging)",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "check_for_correct_spaces",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def check_for_correct_spaces(env: GymEnv, observation_space: spaces.Space, action_space: spaces.Space) -> None:\n    \"\"\"\n    Checks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\n    spaces match after loading the model with given env.\n    Checked parameters:\n    - observation_space\n    - action_space\n    :param env: Environment to check for valid spaces\n    :param observation_space: Observation space to check against\n    :param action_space: Action space to check against",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "check_shape_equal",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def check_shape_equal(space1: spaces.Space, space2: spaces.Space) -> None:\n    \"\"\"\n    If the spaces are Box, check that they have the same shape.\n    If the spaces are Dict, it recursively checks the subspaces.\n    :param space1: Space\n    :param space2: Other space\n    \"\"\"\n    if isinstance(space1, spaces.Dict):\n        assert isinstance(space2, spaces.Dict), \"spaces must be of the same type\"\n        assert space1.spaces.keys() == space2.spaces.keys(), \"spaces must have the same keys\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_box_observation",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def is_vectorized_box_observation(observation: np.ndarray, observation_space: spaces.Box) -> bool:\n    \"\"\"\n    For box observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"\n    if observation.shape == observation_space.shape:\n        return False",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_discrete_observation",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def is_vectorized_discrete_observation(observation: Union[int, np.ndarray], observation_space: spaces.Discrete) -> bool:\n    \"\"\"\n    For discrete observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"\n    if isinstance(observation, int) or observation.shape == ():  # A numpy array of a number, has shape empty tuple '()'\n        return False",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_multidiscrete_observation",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def is_vectorized_multidiscrete_observation(observation: np.ndarray, observation_space: spaces.MultiDiscrete) -> bool:\n    \"\"\"\n    For multidiscrete observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"\n    if observation.shape == (len(observation_space.nvec),):\n        return False",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_multibinary_observation",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def is_vectorized_multibinary_observation(observation: np.ndarray, observation_space: spaces.MultiBinary) -> bool:\n    \"\"\"\n    For multibinary observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"\n    if observation.shape == observation_space.shape:\n        return False",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_dict_observation",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def is_vectorized_dict_observation(observation: np.ndarray, observation_space: spaces.Dict) -> bool:\n    \"\"\"\n    For dict observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"\n    # We first assume that all observations are not vectorized\n    all_non_vectorized = True",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "is_vectorized_observation",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def is_vectorized_observation(observation: Union[int, np.ndarray], observation_space: spaces.Space) -> bool:\n    \"\"\"\n    For every observation type, detects and validates the shape,\n    then returns whether or not the observation is vectorized.\n    :param observation: the input observation to validate\n    :param observation_space: the observation space\n    :return: whether the given observation is vectorized or not\n    \"\"\"\n    is_vec_obs_func_dict = {\n        spaces.Box: is_vectorized_box_observation,",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "safe_mean",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def safe_mean(arr: Union[np.ndarray, list, deque]) -> float:\n    \"\"\"\n    Compute the mean of an array if there is at least one element.\n    For empty array, return NaN. It is used for logging only.\n    :param arr: Numpy array or list of values\n    :return:\n    \"\"\"\n    return np.nan if len(arr) == 0 else float(np.mean(arr))  # type: ignore[arg-type]\ndef get_parameters_by_name(model: th.nn.Module, included_names: Iterable[str]) -> List[th.Tensor]:\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_parameters_by_name",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def get_parameters_by_name(model: th.nn.Module, included_names: Iterable[str]) -> List[th.Tensor]:\n    \"\"\"\n    Extract parameters from the state dict of ``model``\n    if the name contains one of the strings in ``included_names``.\n    :param model: the model where the parameters come from.\n    :param included_names: substrings of names to include.\n    :return: List of parameters values (Pytorch tensors)\n        that matches the queried names.\n    \"\"\"\n    return [param for name, param in model.state_dict().items() if any([key in name for key in included_names])]",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "zip_strict",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def zip_strict(*iterables: Iterable) -> Iterable:\n    r\"\"\"\n    ``zip()`` function but enforces that iterables are of equal length.\n    Raises ``ValueError`` if iterables not of equal length.\n    Code inspired by Stackoverflow answer for question #32954486.\n    :param \\*iterables: iterables to ``zip()``\n    \"\"\"\n    # As in Stackoverflow #32954486, use\n    # new object for \"empty\" in case we have\n    # Nones in iterable.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "polyak_update",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def polyak_update(\n    params: Iterable[th.Tensor],\n    target_params: Iterable[th.Tensor],\n    tau: float,\n) -> None:\n    \"\"\"\n    Perform a Polyak average update on ``target_params`` using ``params``:\n    target parameters are slowly updated towards the main parameters.\n    ``tau``, the soft update coefficient controls the interpolation:\n    ``tau=1`` corresponds to copying the parameters to the target ones whereas nothing happens when ``tau=0``.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "obs_as_tensor",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def obs_as_tensor(obs: Union[np.ndarray, Dict[str, np.ndarray]], device: th.device) -> Union[th.Tensor, TensorDict]:\n    \"\"\"\n    Moves the observation to the given device.\n    :param obs:\n    :param device: PyTorch device\n    :return: PyTorch tensor of the observation on a desired device.\n    \"\"\"\n    if isinstance(obs, np.ndarray):\n        return th.as_tensor(obs, device=device)\n    elif isinstance(obs, dict):",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "should_collect_more_steps",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def should_collect_more_steps(\n    train_freq: TrainFreq,\n    num_collected_steps: int,\n    num_collected_episodes: int,\n) -> bool:\n    \"\"\"\n    Helper used in ``collect_rollouts()`` of off-policy algorithms\n    to determine the termination condition.\n    :param train_freq: How much experience should be collected before updating the policy.\n    :param num_collected_steps: The number of already collected steps.",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "get_system_info",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "description": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "peekOfCode": "def get_system_info(print_info: bool = True) -> Tuple[Dict[str, str], str]:\n    \"\"\"\n    Retrieve system and python env info for the current system.\n    :param print_info: Whether to print or not those infos\n    :return: Dictionary summing up the version for each relevant package\n        and a formatted string.\n    \"\"\"\n    env_info = {\n        # In OS, a regex is used to add a space between a \"#\" and a number to avoid\n        # wrongly linking to another issue on GitHub. Example: turn \"#42\" to \"# 42\".",
        "detail": "docs.lib.rl.agents.stablebaselines3.common.utils",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ddpg.ddpg",
        "description": "docs.lib.rl.agents.stablebaselines3.ddpg.ddpg",
        "peekOfCode": "class DDPG(TD3):\n    \"\"\"\n    Deep Deterministic Policy Gradient (DDPG).\n    Deterministic Policy Gradient: http://proceedings.mlr.press/v32/silver14.pdf\n    DDPG Paper: https://arxiv.org/abs/1509.02971\n    Introduction to DDPG: https://spinningup.openai.com/en/latest/algorithms/ddpg.html\n    Note: we treat DDPG as a special case of its successor TD3.\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: learning rate for adam optimizer,",
        "detail": "docs.lib.rl.agents.stablebaselines3.ddpg.ddpg",
        "documentation": {}
    },
    {
        "label": "SelfDDPG",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ddpg.ddpg",
        "description": "docs.lib.rl.agents.stablebaselines3.ddpg.ddpg",
        "peekOfCode": "SelfDDPG = TypeVar(\"SelfDDPG\", bound=\"DDPG\")\nclass DDPG(TD3):\n    \"\"\"\n    Deep Deterministic Policy Gradient (DDPG).\n    Deterministic Policy Gradient: http://proceedings.mlr.press/v32/silver14.pdf\n    DDPG Paper: https://arxiv.org/abs/1509.02971\n    Introduction to DDPG: https://spinningup.openai.com/en/latest/algorithms/ddpg.html\n    Note: we treat DDPG as a special case of its successor TD3.\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)",
        "detail": "docs.lib.rl.agents.stablebaselines3.ddpg.ddpg",
        "documentation": {}
    },
    {
        "label": "DQN",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.dqn",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.dqn",
        "peekOfCode": "class DQN(OffPolicyAlgorithm):\n    \"\"\"\n    Deep Q-Network (DQN)\n    Paper: https://arxiv.org/abs/1312.5602, https://www.nature.com/articles/nature14236\n    Default hyperparameters are taken from the Nature paper,\n    except for the optimizer and learning rate that were taken from Stable Baselines defaults.\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: The learning rate, it can be a function\n        of the current progress remaining (from 1 to 0)",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.dqn",
        "documentation": {}
    },
    {
        "label": "SelfDQN",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.dqn",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.dqn",
        "peekOfCode": "SelfDQN = TypeVar(\"SelfDQN\", bound=\"DQN\")\nclass DQN(OffPolicyAlgorithm):\n    \"\"\"\n    Deep Q-Network (DQN)\n    Paper: https://arxiv.org/abs/1312.5602, https://www.nature.com/articles/nature14236\n    Default hyperparameters are taken from the Nature paper,\n    except for the optimizer and learning rate that were taken from Stable Baselines defaults.\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: The learning rate, it can be a function",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.dqn",
        "documentation": {}
    },
    {
        "label": "QNetwork",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "peekOfCode": "class QNetwork(BasePolicy):\n    \"\"\"\n    Action-Value (Q-Value) network for DQN\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param normalize_images: Whether to normalize images or not,\n         dividing by 255.0 (True by default)\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "DQNPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "peekOfCode": "class DQNPolicy(BasePolicy):\n    \"\"\"\n    Policy class with Q-Value Net and target net for DQN\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "peekOfCode": "class CnnPolicy(DQNPolicy):\n    \"\"\"\n    Policy class for DQN when using images as input.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param normalize_images: Whether to normalize images or not,",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "peekOfCode": "class MultiInputPolicy(DQNPolicy):\n    \"\"\"\n    Policy class for DQN when using dict observations as input.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param normalize_images: Whether to normalize images or not,",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "peekOfCode": "MlpPolicy = DQNPolicy\nclass CnnPolicy(DQNPolicy):\n    \"\"\"\n    Policy class for DQN when using images as input.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.",
        "detail": "docs.lib.rl.agents.stablebaselines3.dqn.policies",
        "documentation": {}
    },
    {
        "label": "GoalSelectionStrategy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.her.goal_selection_strategy",
        "description": "docs.lib.rl.agents.stablebaselines3.her.goal_selection_strategy",
        "peekOfCode": "class GoalSelectionStrategy(Enum):\n    \"\"\"\n    The strategies for selecting new goals when\n    creating artificial transitions.\n    \"\"\"\n    # Select a goal that was achieved\n    # after the current step, in the same episode\n    FUTURE = 0\n    # Select the goal that was achieved\n    # at the end of the episode",
        "detail": "docs.lib.rl.agents.stablebaselines3.her.goal_selection_strategy",
        "documentation": {}
    },
    {
        "label": "KEY_TO_GOAL_STRATEGY",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.her.goal_selection_strategy",
        "description": "docs.lib.rl.agents.stablebaselines3.her.goal_selection_strategy",
        "peekOfCode": "KEY_TO_GOAL_STRATEGY = {\n    \"future\": GoalSelectionStrategy.FUTURE,\n    \"final\": GoalSelectionStrategy.FINAL,\n    \"episode\": GoalSelectionStrategy.EPISODE,\n}",
        "detail": "docs.lib.rl.agents.stablebaselines3.her.goal_selection_strategy",
        "documentation": {}
    },
    {
        "label": "HerReplayBuffer",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.her.her_replay_buffer",
        "description": "docs.lib.rl.agents.stablebaselines3.her.her_replay_buffer",
        "peekOfCode": "class HerReplayBuffer(DictReplayBuffer):\n    \"\"\"\n    Hindsight Experience Replay (HER) buffer.\n    Paper: https://arxiv.org/abs/1707.01495\n    Replay buffer for sampling HER (Hindsight Experience Replay) transitions.\n    .. note::\n      Compared to other implementations, the ``future`` goal sampling strategy is inclusive:\n      the current transition can be used when re-sampling.\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space",
        "detail": "docs.lib.rl.agents.stablebaselines3.her.her_replay_buffer",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "peekOfCode": "MlpPolicy = ActorCriticPolicy\nCnnPolicy = ActorCriticCnnPolicy\nMultiInputPolicy = MultiInputActorCriticPolicy",
        "detail": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "peekOfCode": "CnnPolicy = ActorCriticCnnPolicy\nMultiInputPolicy = MultiInputActorCriticPolicy",
        "detail": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "peekOfCode": "MultiInputPolicy = MultiInputActorCriticPolicy",
        "detail": "docs.lib.rl.agents.stablebaselines3.ppo.policies",
        "documentation": {}
    },
    {
        "label": "PPO",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ppo.ppo",
        "description": "docs.lib.rl.agents.stablebaselines3.ppo.ppo",
        "peekOfCode": "class PPO(OnPolicyAlgorithm):\n    \"\"\"\n    Proximal Policy Optimization algorithm (PPO) (clip version)\n    Paper: https://arxiv.org/abs/1707.06347\n    Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\n    https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n    Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\n    Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)",
        "detail": "docs.lib.rl.agents.stablebaselines3.ppo.ppo",
        "documentation": {}
    },
    {
        "label": "SelfPPO",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.ppo.ppo",
        "description": "docs.lib.rl.agents.stablebaselines3.ppo.ppo",
        "peekOfCode": "SelfPPO = TypeVar(\"SelfPPO\", bound=\"PPO\")\nclass PPO(OnPolicyAlgorithm):\n    \"\"\"\n    Proximal Policy Optimization algorithm (PPO) (clip version)\n    Paper: https://arxiv.org/abs/1707.06347\n    Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\n    https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n    Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\n    Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)",
        "detail": "docs.lib.rl.agents.stablebaselines3.ppo.ppo",
        "documentation": {}
    },
    {
        "label": "Actor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "class Actor(BasePolicy):\n    \"\"\"\n    Actor network (policy) for SAC.\n    :param observation_space: Obervation space\n    :param action_space: Action space\n    :param net_arch: Network architecture\n    :param features_extractor: Network to extract features\n        (a CNN when using images, a nn.Flatten() layer otherwise)\n    :param features_dim: Number of features\n    :param activation_fn: Activation function",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "SACPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "class SACPolicy(BasePolicy):\n    \"\"\"\n    Policy class (with both actor and critic) for SAC.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not\n    :param log_std_init: Initial value for the log standard deviation",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "class CnnPolicy(SACPolicy):\n    \"\"\"\n    Policy class (with both actor and critic) for SAC.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not\n    :param log_std_init: Initial value for the log standard deviation",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "class MultiInputPolicy(SACPolicy):\n    \"\"\"\n    Policy class (with both actor and critic) for SAC.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not\n    :param log_std_init: Initial value for the log standard deviation",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "LOG_STD_MAX",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "LOG_STD_MAX = 2\nLOG_STD_MIN = -20\nclass Actor(BasePolicy):\n    \"\"\"\n    Actor network (policy) for SAC.\n    :param observation_space: Obervation space\n    :param action_space: Action space\n    :param net_arch: Network architecture\n    :param features_extractor: Network to extract features\n        (a CNN when using images, a nn.Flatten() layer otherwise)",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "LOG_STD_MIN",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "LOG_STD_MIN = -20\nclass Actor(BasePolicy):\n    \"\"\"\n    Actor network (policy) for SAC.\n    :param observation_space: Obervation space\n    :param action_space: Action space\n    :param net_arch: Network architecture\n    :param features_extractor: Network to extract features\n        (a CNN when using images, a nn.Flatten() layer otherwise)\n    :param features_dim: Number of features",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "peekOfCode": "MlpPolicy = SACPolicy\nclass CnnPolicy(SACPolicy):\n    \"\"\"\n    Policy class (with both actor and critic) for SAC.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.policies",
        "documentation": {}
    },
    {
        "label": "SAC",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.sac",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.sac",
        "peekOfCode": "class SAC(OffPolicyAlgorithm):\n    \"\"\"\n    Soft Actor-Critic (SAC)\n    Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,\n    This implementation borrows code from original implementation (https://github.com/haarnoja/sac)\n    from OpenAI Spinning Up (https://github.com/openai/spinningup), from the softlearning repo\n    (https://github.com/rail-berkeley/softlearning/)\n    and from Stable Baselines (https://github.com/hill-a/stable-baselines)\n    Paper: https://arxiv.org/abs/1801.01290\n    Introduction to SAC: https://spinningup.openai.com/en/latest/algorithms/sac.html",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.sac",
        "documentation": {}
    },
    {
        "label": "SelfSAC",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.sac.sac",
        "description": "docs.lib.rl.agents.stablebaselines3.sac.sac",
        "peekOfCode": "SelfSAC = TypeVar(\"SelfSAC\", bound=\"SAC\")\nclass SAC(OffPolicyAlgorithm):\n    \"\"\"\n    Soft Actor-Critic (SAC)\n    Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,\n    This implementation borrows code from original implementation (https://github.com/haarnoja/sac)\n    from OpenAI Spinning Up (https://github.com/openai/spinningup), from the softlearning repo\n    (https://github.com/rail-berkeley/softlearning/)\n    and from Stable Baselines (https://github.com/hill-a/stable-baselines)\n    Paper: https://arxiv.org/abs/1801.01290",
        "detail": "docs.lib.rl.agents.stablebaselines3.sac.sac",
        "documentation": {}
    },
    {
        "label": "Actor",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "peekOfCode": "class Actor(BasePolicy):\n    \"\"\"\n    Actor network (policy) for TD3.\n    :param observation_space: Obervation space\n    :param action_space: Action space\n    :param net_arch: Network architecture\n    :param features_extractor: Network to extract features\n        (a CNN when using images, a nn.Flatten() layer otherwise)\n    :param features_dim: Number of features\n    :param activation_fn: Activation function",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "TD3Policy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "peekOfCode": "class TD3Policy(BasePolicy):\n    \"\"\"\n    Policy class (with both actor and critic) for TD3.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "CnnPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "peekOfCode": "class CnnPolicy(TD3Policy):\n    \"\"\"\n    Policy class (with both actor and critic) for TD3.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "MultiInputPolicy",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "peekOfCode": "class MultiInputPolicy(TD3Policy):\n    \"\"\"\n    Policy class (with both actor and critic) for TD3 to be used with Dict observation spaces.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "MlpPolicy",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "peekOfCode": "MlpPolicy = TD3Policy\nclass CnnPolicy(TD3Policy):\n    \"\"\"\n    Policy class (with both actor and critic) for TD3.\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.policies",
        "documentation": {}
    },
    {
        "label": "TD3",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.td3",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.td3",
        "peekOfCode": "class TD3(OffPolicyAlgorithm):\n    \"\"\"\n    Twin Delayed DDPG (TD3)\n    Addressing Function Approximation Error in Actor-Critic Methods.\n    Original implementation: https://github.com/sfujim/TD3\n    Paper: https://arxiv.org/abs/1802.09477\n    Introduction to TD3: https://spinningup.openai.com/en/latest/algorithms/td3.html\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)\n    :param learning_rate: learning rate for adam optimizer,",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.td3",
        "documentation": {}
    },
    {
        "label": "SelfTD3",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.td3.td3",
        "description": "docs.lib.rl.agents.stablebaselines3.td3.td3",
        "peekOfCode": "SelfTD3 = TypeVar(\"SelfTD3\", bound=\"TD3\")\nclass TD3(OffPolicyAlgorithm):\n    \"\"\"\n    Twin Delayed DDPG (TD3)\n    Addressing Function Approximation Error in Actor-Critic Methods.\n    Original implementation: https://github.com/sfujim/TD3\n    Paper: https://arxiv.org/abs/1802.09477\n    Introduction to TD3: https://spinningup.openai.com/en/latest/algorithms/td3.html\n    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n    :param env: The environment to learn from (if registered in Gym, can be str)",
        "detail": "docs.lib.rl.agents.stablebaselines3.td3.td3",
        "documentation": {}
    },
    {
        "label": "sample_ppo_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ppo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for PPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_trpo_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_trpo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TRPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_a2c_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_a2c_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for A2C hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    normalize_advantage = trial.suggest_categorical(",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_sac_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_sac_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for SAC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_td3_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_td3_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TD3 hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ddpg_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ddpg_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DDPG hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_dqn_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_dqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_her_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_her_params(\n    trial: optuna.Trial, hyperparams: dict[str, Any]\n) -> dict[str, Any]:\n    \"\"\"\n    Sampler for HerReplayBuffer hyperparams.\n    :param trial:\n    :parma hyperparams:\n    :return:\n    \"\"\"\n    her_kwargs = trial.her_kwargs.copy()",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_tqc_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_tqc_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TQC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is SAC + Distributional RL\n    hyperparams = sample_sac_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 50)\n    top_quantiles_to_drop_per_net = trial.suggest_int(",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_qrdqn_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_qrdqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for QR-DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is DQN + Distributional RL\n    hyperparams = sample_dqn_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 200)\n    hyperparams[\"policy_kwargs\"].update({\"n_quantiles\": n_quantiles})",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ars_params",
        "kind": 2,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ars_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for ARS hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # n_eval_episodes = trial.suggest_categorical(\"n_eval_episodes\", [1, 2])\n    n_delta = trial.suggest_categorical(\"n_delta\", [4, 8, 6, 32, 64])\n    # learning_rate = trial.suggest_categorical(\"learning_rate\", [0.01, 0.02, 0.025, 0.03])\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "HYPERPARAMS_SAMPLER",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "HYPERPARAMS_SAMPLER = {\n    \"a2c\": sample_a2c_params,\n    \"ars\": sample_ars_params,\n    \"ddpg\": sample_ddpg_params,\n    \"dqn\": sample_dqn_params,\n    \"qrdqn\": sample_qrdqn_params,\n    \"sac\": sample_sac_params,\n    \"tqc\": sample_tqc_params,\n    \"ppo\": sample_ppo_params,\n    \"td3\": sample_td3_params,",
        "detail": "docs.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "TensorboardCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.models",
        "description": "docs.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)\n    def _on_step(self) -> bool:\n        try:\n            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n        except BaseException as error:",
        "detail": "docs.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.models",
        "description": "docs.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Provides implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "docs.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.models",
        "description": "docs.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLEnsembleAgent:\n    @staticmethod\n    def get_model(\n        model_name,\n        env,\n        policy=\"MlpPolicy\",\n        policy_kwargs=None,\n        model_kwargs=None,\n        seed=None,\n        verbose=1,",
        "detail": "docs.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.models",
        "description": "docs.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\nMODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"",
        "detail": "docs.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODEL_KWARGS",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.models",
        "description": "docs.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):",
        "detail": "docs.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "NOISE",
        "kind": 5,
        "importPath": "docs.lib.rl.agents.stablebaselines3.models",
        "description": "docs.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "NOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)",
        "detail": "docs.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "LoggingCallback",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.tune_sb3",
        "description": "docs.lib.rl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class LoggingCallback:\n    def __init__(self, threshold: int, trial_number: int, patience: int):\n        \"\"\"\n        threshold:int tolerance for increase in sharpe ratio\n        trial_number: int Prune after minimum number of trials\n        patience: int patience for the threshold\n        \"\"\"\n        self.threshold = threshold\n        self.trial_number = trial_number\n        self.patience = patience",
        "detail": "docs.lib.rl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "TuneSB3Optuna",
        "kind": 6,
        "importPath": "docs.lib.rl.agents.stablebaselines3.tune_sb3",
        "description": "docs.lib.rl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class TuneSB3Optuna:\n    \"\"\"\n    Hyperparameter tuning of SB3 agents using Optuna\n    Attributes\n    ----------\n      env_train: Training environment for SB3\n      model_name: str\n      env_trade: testing environment\n      logging_callback: callback for tuning\n      total_timesteps: int",
        "detail": "docs.lib.rl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "calc_stockname_from_filename",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_stockname_from_filename(filename):\n    return filename.split(\"/\")[-1].split(\".csv\")[0]\ndef calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)\n    return paths2\ndef calc_stocknames(path):",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_stocknames",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_stocknames(path):\n    filenames = calc_all_filenames(path)\n    res = []\n    for filename in filenames:\n        stockname = calc_stockname_from_filename(filename)\n        res.append(stockname)\n    return res\ndef remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:\n        os.system(\"rm -f \" + path_of_data + \"/*\")\n    dir_list = os.listdir(path_of_data)\n    for file in dir_list:\n        if \"~\" in file:\n            os.system(\"rm -f \" + path_of_data + \"/\" + file)\n    dir_list = os.listdir(path_of_data)\n    if remove == 1:",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def date2str(dat: datetime.date) -> str:\n    return datetime.date.strftime(dat, \"%Y-%m-%d\")\ndef str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_dates",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)\n        dates.append(d)\n        dat += delta\n    return dates",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_starts_ends_if_rolling(\n    init_train_dates: list[str], init_trade_dates: list[str], rolling_window_length: int\n) -> tuple[list[str], list[str], list[str], list[str]]:\n    trade_dates_length = len(init_trade_dates)\n    train_window_length = len(init_train_dates)\n    trade_window_length = min(rolling_window_length, trade_dates_length)\n    num_subsets_if_rolling = int(np.ceil(trade_dates_length / trade_window_length))\n    print(\"num_subsets_if_rolling: \", num_subsets_if_rolling)\n    dates = np.concatenate((init_train_dates, init_trade_dates), axis=0)\n    train_starts = []",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.data_processors.func",
        "description": "docs.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_data(\n    i: int,\n    train_starts: list[str],\n    train_ends: list[str],\n    trade_starts: list[str],\n    trade_ends: list[str],\n    init_train_data: pd.DataFrame(),\n    init_trade_data: pd.DataFrame(),\n    date_col: str,\n) -> tuple[pd.DataFrame(), pd.DataFrame()]:",
        "detail": "docs.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processors.processor_alpaca",
        "description": "docs.lib.rl.meta.data_processors.processor_alpaca",
        "peekOfCode": "class AlpacaProcessor:\n    def __init__(self, API_KEY=None, API_SECRET=None, API_BASE_URL=None, api=None):\n        if api is None:\n            try:\n                self.api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, \"v2\")\n            except BaseException:\n                raise ValueError(\"Wrong Account Info!\")\n        else:\n            self.api = api\n    def _fetch_data_for_ticker(self, ticker, start_date, end_date, time_interval):",
        "detail": "docs.lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "CCXTEngineer",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processors.processor_ccxt",
        "description": "docs.lib.rl.meta.data_processors.processor_ccxt",
        "peekOfCode": "class CCXTEngineer:\n    def __init__(self):\n        self.binance = ccxt.binance()\n    def data_fetch(self, start, end, pair_list=[\"BTC/USDT\"], period=\"1m\"):\n        def min_ohlcv(dt, pair, limit):\n            since = calendar.timegm(dt.utctimetuple()) * 1000\n            ohlcv = self.binance.fetch_ohlcv(\n                symbol=pair, timeframe=\"1m\", since=since, limit=limit\n            )\n            return ohlcv",
        "detail": "docs.lib.rl.meta.data_processors.processor_ccxt",
        "documentation": {}
    },
    {
        "label": "JoinQuantEngineer",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processors.processor_joinquant",
        "description": "docs.lib.rl.meta.data_processors.processor_joinquant",
        "peekOfCode": "class JoinQuantEngineer:\n    def __init__(self):\n        pass\n    def auth(self, username, password):\n        jq.auth(username, password)\n    def data_fetch(self, stock_list, num, unit, end_dt):\n        df = jq.get_bars(\n            security=stock_list,\n            count=num,\n            unit=unit,",
        "detail": "docs.lib.rl.meta.data_processors.processor_joinquant",
        "documentation": {}
    },
    {
        "label": "QuantConnectEngineer",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processors.processor_quantconnect",
        "description": "docs.lib.rl.meta.data_processors.processor_quantconnect",
        "peekOfCode": "class QuantConnectEngineer:\n    def __init__(self):\n        pass\n    def data_fetch(start_time, end_time, stock_list, resolution=Resolution.Daily):\n        # resolution: Daily, Hour, Minute, Second\n        qb = QuantBook()\n        for stock in stock_list:\n            qb.AddEquity(stock)\n        history = qb.History(qb.Securities.Keys, start_time, end_time, resolution)\n        return history",
        "detail": "docs.lib.rl.meta.data_processors.processor_quantconnect",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processors.processor_wrds",
        "description": "docs.lib.rl.meta.data_processors.processor_wrds",
        "peekOfCode": "class WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,\n        time_interval,",
        "detail": "docs.lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "pd.options.mode.chained_assignment",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.data_processors.processor_wrds",
        "description": "docs.lib.rl.meta.data_processors.processor_wrds",
        "peekOfCode": "pd.options.mode.chained_assignment = None\nclass WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,",
        "detail": "docs.lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processors.processor_yahoofinance",
        "description": "docs.lib.rl.meta.data_processors.processor_yahoofinance",
        "peekOfCode": "class YahooFinanceProcessor:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    \"\"\"\n    def __init__(self):\n        pass\n    \"\"\"\n    Param\n    ----------\n        start_date : str",
        "detail": "docs.lib.rl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "BitcoinEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "description": "docs.lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "peekOfCode": "class BitcoinEnv:  # custom env\n    def __init__(\n        self,\n        data_cwd=None,\n        price_ary=None,\n        tech_ary=None,\n        time_frequency=15,\n        start=None,\n        mid1=172197,\n        mid2=216837,",
        "detail": "docs.lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "documentation": {}
    },
    {
        "label": "CryptoEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "description": "docs.lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "peekOfCode": "class CryptoEnv:  # custom env\n    def __init__(\n        self,\n        config,\n        lookback=1,\n        initial_capital=1e6,\n        buy_cost_pct=1e-3,\n        sell_cost_pct=1e-3,\n        gamma=0.99,\n    ):",
        "detail": "docs.lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "documentation": {}
    },
    {
        "label": "StockPortfolioEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "description": "docs.lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "peekOfCode": "class StockPortfolioEnv(gym.Env):\n    \"\"\"A single stock trading environment for OpenAI gym\n    Attributes\n    ----------\n        df: DataFrame\n            input data\n        stock_dim : int\n            number of unique stocks\n        hmax : int\n            maximum number of shares to trade",
        "detail": "docs.lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "documentation": {}
    },
    {
        "label": "PortfolioOptimizationEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "description": "docs.lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "peekOfCode": "class PortfolioOptimizationEnv(gym.Env):\n    \"\"\"A portfolio allocation environment for OpenAI gym.\n    This environment simulates the interactions between an agent and the financial market\n    based on data provided by a dataframe. The dataframe contains the time series of\n    features defined by the user (such as closing, high and low prices) and must have\n    a time and a tic column with a list of datetimes and ticker symbols respectively.\n    An example of dataframe is shown below::\n            date        high            low             close           tic\n        0   2020-12-23  0.157414        0.127420        0.136394        ADA-USD\n        1   2020-12-23  34.381519       30.074295       31.097898       BNB-USD",
        "detail": "docs.lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "StockEnvNAS100",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "description": "docs.lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "peekOfCode": "class StockEnvNAS100:\n    def __init__(\n        self,\n        cwd=\"./data/nas100\",\n        price_ary=None,\n        tech_ary=None,\n        turbulence_ary=None,\n        gamma=0.999,\n        turbulence_thresh=30,\n        min_stock_rate=0.1,",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "docs.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class AlpacaPaperTrading:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "docs.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "docs.lib.rl.meta.env_stock_trading.env_stocktrading",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {\"render.modes\": [\"human\"]}\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        stock_dim: int,\n        hmax: int,\n        initial_amount: int,\n        num_stock_shares: list[int],",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvCashpenalty",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "description": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "peekOfCode": "class StockTradingEnvCashpenalty(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model for not maintaining a reserve of cash.\n    This enables the model to manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) - initial_cash - max(0, sum(cash, asset_value)*cash_penalty_proportion-cash))/(days_elapsed)\n        This reward function takes into account a liquidity requirement, as well as long-term accrued rewards.\n    Parameters:\n        df (pandas.DataFrame): Dataframe containing data",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    def __init__(\n        self,\n        config,\n        initial_account=1e6,\n        gamma=0.99,\n        turbulence_thresh=99,\n        min_stock_rate=0.1,\n        max_stock=1e2,\n        initial_capital=1e6,",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvStopLoss",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "description": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "peekOfCode": "class StockTradingEnvStopLoss(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model if excedeed the stop-loss threshold, selling assets with under expectation %profit, and also\n    for not maintaining a reserve of cash.\n    This enables the model to do trading with high confidence and manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) + additional_reward - total_penalty - initial_cash) / initial_cash / days_elapsed\n        , where total_penalty = cash_penalty + stop_loss_penalty + low_profit_penalty\n                cash_penalty = max(0, sum(cash, asset_value)*cash_penalty_proportion-cash)",
        "detail": "docs.lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "documentation": {}
    },
    {
        "label": "PaperTradingAlpaca",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.alpaca",
        "description": "docs.lib.rl.meta.paper_trading.alpaca",
        "peekOfCode": "class PaperTradingAlpaca:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "docs.lib.rl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.alpaca",
        "description": "docs.lib.rl.meta.paper_trading.alpaca",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "docs.lib.rl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(\n            torch.zeros((1, action_dim)), requires_grad=True\n        )  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {\n                \"env_name\": None,\n                \"state_dim\": None,\n                \"action_dim\": None,\n                \"if_discrete\": None,",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class AgentBase:\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.state_dim = state_dim",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.if_off_policy = False",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < \"0.18.0\" else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        \"\"\"the necessary env information when you design a custom env\"\"\"\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class Evaluator:\n    def __init__(\n        self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = \".\"\n    ):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = (",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {\"unwrapped\", \"observation_space\", \"action_space\", \"spec\"}.issubset(\n        dir(env)\n    ):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = (\n            state_shape[0] if len(state_shape) == 1 else state_shape\n        )  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in (\"env_name\", \"state_dim\", \"action_dim\", \"if_discrete\"):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(\n        args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args\n    )\n    agent.states = env.reset()[np.newaxis, :]\n    evaluator = Evaluator(\n        eval_env=build_env(args.env_class, args.env_args),\n        eval_per_step=args.eval_per_step,",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def render_agent(\n    env_class,\n    env_args: dict,\n    net_dims: [int],\n    agent_class,\n    actor_path: str,\n    render_times: int = 8,\n):\n    env = build_env(env_class, env_args)\n    state_dim = env_args[\"state_dim\"]",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_rewards_and_steps(\n    env, actor, if_render: bool = False\n) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(\n            state, dtype=torch.float32, device=device",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_trading_days(start, end):\n    nyse = tc.get_calendar(\"NYSE\")\n    df = nyse.sessions_in_range(\n        pd.Timestamp(start, tz=pytz.UTC), pd.Timestamp(end, tz=pytz.UTC)\n    )\n    trading_days = []\n    for day in df:\n        trading_days.append(str(day)[:10])\n    return trading_days\ndef alpaca_history(key, secret, url, start, end):",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, \"v2\")\n    trading_days = get_trading_days(start, end)\n    df = pd.DataFrame()\n    for day in trading_days:\n        df = df.append(\n            api.get_portfolio_history(date_start=day, timeframe=\"5Min\").df.iloc[:78]\n        )\n    equities = df.equity.values\n    cumu_returns = equities / equities[0]",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def DIA_history(start):\n    data_df = yf.download([\"^DJI\"], start=start, interval=\"5m\")\n    data_df = data_df.iloc[:]\n    baseline_returns = data_df[\"Adj Close\"].values / data_df[\"Adj Close\"].values[0]\n    return data_df, baseline_returns\n# -----------------------------------------------------------------------------------------------------------------------------------------",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.paper_trading.common",
        "description": "docs.lib.rl.meta.paper_trading.common",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "docs.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "GroupByScaler",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.preprocessor.preprocessors",
        "description": "docs.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "class GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"\n    def __init__(self, by, scaler=MaxAbsScaler, columns=None, scaler_kwargs=None):\n        \"\"\"Initializes GoupBy scaler.\n        Args:\n            by: Name of column that will be used to group.",
        "detail": "docs.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.preprocessor.preprocessors",
        "description": "docs.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "class FeatureEngineer:\n    \"\"\"Provides methods for preprocessing the stock price data\n    Attributes\n    ----------\n        use_technical_indicator : boolean\n            we technical indicator or not\n        tech_indicator_list : list\n            a list of technical indicator names (modified from neofinrl_config.py)\n        use_turbulence : boolean\n            use turbulence index or not",
        "detail": "docs.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.preprocessor.preprocessors",
        "description": "docs.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def load_dataset(*, file_name: str) -> pd.DataFrame:\n    \"\"\"\n    load csv dataset from path\n    :return: (df) pandas dataframe\n    \"\"\"\n    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n    _data = pd.read_csv(file_name)\n    return _data\ndef data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"",
        "detail": "docs.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.preprocessor.preprocessors",
        "description": "docs.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"\n    split the dataset into training or testing using date\n    :param data: (df) pandas dataframe, start, end\n    :return: (df) pandas dataframe\n    \"\"\"\n    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n    data.index = data[target_date_col].factorize()[0]\n    return data",
        "detail": "docs.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "convert_to_datetime",
        "kind": 2,
        "importPath": "docs.lib.rl.meta.preprocessor.preprocessors",
        "description": "docs.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def convert_to_datetime(time):\n    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n    if isinstance(time, str):\n        return datetime.datetime.strptime(time, time_fmt)\nclass GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"",
        "detail": "docs.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "TushareDownloader",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.preprocessor.tusharedownloader",
        "description": "docs.lib.rl.meta.preprocessor.tusharedownloader",
        "peekOfCode": "class TushareDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    tushare API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from config.py)\n        end_date : str\n            end date of the data (modified from config.py)\n        ticker_list : list",
        "detail": "docs.lib.rl.meta.preprocessor.tusharedownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.preprocessor.yahoodownloader",
        "description": "docs.lib.rl.meta.preprocessor.yahoodownloader",
        "peekOfCode": "class YahooDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from neofinrl_config.py)\n        end_date : str\n            end date of the data (modified from neofinrl_config.py)\n        ticker_list : list",
        "detail": "docs.lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "kind": 6,
        "importPath": "docs.lib.rl.meta.data_processor",
        "description": "docs.lib.rl.meta.data_processor",
        "peekOfCode": "class DataProcessor:\n    def __init__(self, data_source, tech_indicator=None, vix=None, **kwargs):\n        if data_source == \"alpaca\":\n            try:\n                API_KEY = kwargs.get(\"API_KEY\")\n                API_SECRET = kwargs.get(\"API_SECRET\")\n                API_BASE_URL = kwargs.get(\"API_BASE_URL\")\n                self.processor = Alpaca(API_KEY, API_SECRET, API_BASE_URL)\n                print(\"Alpaca successfully connected\")\n            except BaseException:",
        "detail": "docs.lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "TRAIN_START_DATE = \"2019-01-01\"\nTRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "TRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "TEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "TEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "TRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "TRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "PATH_OF_DATA",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "PATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "READ_DATA_FROM_LOCAL",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "READ_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]\nFAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "FAANG_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "FAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]\n# Dow 30 constituents at 2019/01\nDOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",\n    \"NKE\",\n    \"DIS\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.meta.meta_config",
        "description": "docs.lib.rl.meta.meta_config",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "docs.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "kind": 6,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "class OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"\n    TRAILING_STOP = \"trailing_stop\"\nclass TimeInForce():",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "kind": 6,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "class OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"\n    TRAILING_STOP = \"trailing_stop\"\nclass TimeInForce():\n    DAY = \"day\"\n    GTC = \"gtc\"\n    OPG = \"opg\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "kind": 6,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "class TimeInForce():\n    DAY = \"day\"\n    GTC = \"gtc\"\n    OPG = \"opg\"\n    CLS = \"cls\"\n    IOC = \"ioc\"\n    FOK = \"fok\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "now = datetime.datetime.now().strftime(\"%Y%m%d-%Hh%M\")\nst.write(\"Current Date and Time:\", now)\nMAIN_RESULTS_DIR = 'pages/data' + now\nDATA_SAVE_DIR       = MAIN_RESULTS_DIR + \"/datasets\"\nTRAINED_MODEL_DIR   = MAIN_RESULTS_DIR + \"/trained_models\"\nTENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "MAIN_RESULTS_DIR",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "MAIN_RESULTS_DIR = 'pages/data' + now\nDATA_SAVE_DIR       = MAIN_RESULTS_DIR + \"/datasets\"\nTRAINED_MODEL_DIR   = MAIN_RESULTS_DIR + \"/trained_models\"\nTENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "A2C_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.0007}\nPPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "PPO_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "PPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DDPG_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TD3_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "SAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "ERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": 512,\n    \"target_step\": 5000,\n    \"eval_gap\": 30,\n    \"eval_times\": 64,  # bug fix:KeyError: 'eval_times' line 68, in get_model model.eval_times = model_kwargs[\"eval_times\"]\n}",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "RLlib_PARAMS = {\"lr\": 5e-5, \"train_batch_size\": 500, \"gamma\": 0.99}\n# Possible time zones\nTIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SHANGHAI",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_USEASTERN",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_PARIS",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_BERLIN",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_JAKARTA",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "TIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "USE_TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "USE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "ALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "ALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "docs.lib.rl.config",
        "description": "docs.lib.rl.config",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"",
        "detail": "docs.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "docs.lib.rl.config_private",
        "description": "docs.lib.rl.config_private",
        "peekOfCode": "ALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\n# ALPACA_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\"\n# ALPACA_API_SECRET = \"BxT64PIQtDBb*tnW\"\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\nGROQ_API_KEY= \"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\"",
        "detail": "docs.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "docs.lib.rl.config_private",
        "description": "docs.lib.rl.config_private",
        "peekOfCode": "ALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\n# ALPACA_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\"\n# ALPACA_API_SECRET = \"BxT64PIQtDBb*tnW\"\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\nGROQ_API_KEY= \"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\"",
        "detail": "docs.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.lib.rl.config_private",
        "description": "docs.lib.rl.config_private",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\n# ALPACA_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\"\n# ALPACA_API_SECRET = \"BxT64PIQtDBb*tnW\"\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\nGROQ_API_KEY= \"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\"",
        "detail": "docs.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "docs.lib.rl.config_private",
        "description": "docs.lib.rl.config_private",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\nGROQ_API_KEY= \"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\"",
        "detail": "docs.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "SINGLE_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "SINGLE_TICKER = [\"AAPL\"]\n# Dow 30 constituents in 2021/10\n# check https://wrds-www.wharton.upenn.edu/ for U.S. index constituents\nDOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",\n    \"CVX\",\n    \"GS\",\n    \"HD\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "HSI_50_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "HSI_50_TICKER = [\n    \"0011.HK\",\n    \"0005.HK\",\n    \"0012.HK\",\n    \"0006.HK\",\n    \"0003.HK\",\n    \"0016.HK\",\n    \"0019.HK\",\n    \"0002.HK\",\n    \"0001.HK\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SSE_50_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "SSE_50_TICKER = [\n    \"600000.XSHG\",\n    \"600036.XSHG\",\n    \"600104.XSHG\",\n    \"600030.XSHG\",\n    \"601628.XSHG\",\n    \"601166.XSHG\",\n    \"601318.XSHG\",\n    \"601328.XSHG\",\n    \"601088.XSHG\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CSI_300_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "CSI_300_TICKER = [\n    \"600000.XSHG\",\n    \"600004.XSHG\",\n    \"600009.XSHG\",\n    \"600010.XSHG\",\n    \"600011.XSHG\",\n    \"600015.XSHG\",\n    \"600016.XSHG\",\n    \"600018.XSHG\",\n    \"600019.XSHG\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CAC_40_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "CAC_40_TICKER = [\n    \"AC.PA\",\n    \"AI.PA\",\n    \"AIR.PA\",\n    \"MT.AS\",\n    \"ATO.PA\",\n    \"CS.PA\",\n    \"BNP.PA\",\n    \"EN.PA\",\n    \"CAP.PA\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DAX_30_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "DAX_30_TICKER = [\n    \"DHER.DE\",\n    \"RWE.DE\",\n    \"FRE.DE\",\n    \"MTX.DE\",\n    \"MRK.DE\",\n    \"LIN.DE\",\n    \"ALV.DE\",\n    \"VNA.DE\",\n    \"EOAN.DE\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "TECDAX_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "TECDAX_TICKER = [\n    \"ADV.DE\",\n    \"AFX.DE\",\n    \"AM3D.DE\",\n    \"BC8.DE\",\n    \"COK.DE\",\n    \"DLG.DE\",\n    \"DRI.DE\",\n    \"DRW3.DE\",\n    \"EVT.DE\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "MDAX_50_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "MDAX_50_TICKER = [\n    \"1COV.DE\",\n    \"AIR.DE\",\n    \"AOX.DE\",\n    \"ARL.DE\",\n    \"BNR.DE\",\n    \"BOSS.DE\",\n    \"DEQ.DE\",\n    \"DUE.DE\",\n    \"DWNI.DE\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SDAX_50_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "SDAX_50_TICKER = [\n    \"AAD.DE\",\n    \"ACX.DE\",\n    \"ADJ.DE\",\n    \"ADL.DE\",\n    \"BDT.DE\",\n    \"BIO3.DE\",\n    \"BVB.DE\",\n    \"BYW6.DE\",\n    \"CWC.DE\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "LQ45_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "LQ45_TICKER = [\n    \"ACES.JK\",\n    \"ADRO.JK\",\n    \"AKRA.JK\",\n    \"ANTM.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SRI_KEHATI_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "SRI_KEHATI_TICKER = [\n    \"AALI.JK\",\n    \"ADHI.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",\n    \"BMRI.JK\",\n    \"BSDE.JK\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "FX_TICKER",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "FX_TICKER = [\n    \"AUDCAD=X\",\n    \"AUDCHF=X\",\n    \"AUDJPY=X\",\n    \"AUDNZD=X\",\n    \"AUDSGD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "custom_index",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "custom_index = [\"MMM\", \"AXP\", \"BA\", \"CAT\", \"CSCO\"]\nsector_dict = {\n    \"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"META\", \"TSLA\"],\n    \"Healthcare\": [\"JNJ\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\"],\n    \"Finance\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"],\n    \"Consumer Discretionary\": [\"AMZN\", \"HD\", \"NKE\", \"MCD\", \"SBUX\"],\n    \"Energy\": [\"XOM\", \"CVX\", \"COP\", \"PSX\", \"VLO\"]\n}\nusa_dict = {\n    # usa_dict[S&P 500]",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "sector_dict",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "sector_dict = {\n    \"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"META\", \"TSLA\"],\n    \"Healthcare\": [\"JNJ\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\"],\n    \"Finance\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"],\n    \"Consumer Discretionary\": [\"AMZN\", \"HD\", \"NKE\", \"MCD\", \"SBUX\"],\n    \"Energy\": [\"XOM\", \"CVX\", \"COP\", \"PSX\", \"VLO\"]\n}\nusa_dict = {\n    # usa_dict[S&P 500]\n  \"NYSE\": SP_500_TICKER  ",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "usa_dict",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "usa_dict = {\n    # usa_dict[S&P 500]\n  \"NYSE\": SP_500_TICKER  \n}\nindex_dict = {\n    \"Dow 30\": DOW_30_TICKER,\n    \"Nasdaq 100\": NAS_100_TICKER,\n    \"S&P 500\": SP_500_TICKER,\n    \"Hang Seng Index\" : HSI_50_TICKER, \n    \"SSE 50\" :SSE_50_TICKER, ",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "kind": 5,
        "importPath": "docs.lib.rl.config_tickers",
        "description": "docs.lib.rl.config_tickers",
        "peekOfCode": "index_dict = {\n    \"Dow 30\": DOW_30_TICKER,\n    \"Nasdaq 100\": NAS_100_TICKER,\n    \"S&P 500\": SP_500_TICKER,\n    \"Hang Seng Index\" : HSI_50_TICKER, \n    \"SSE 50\" :SSE_50_TICKER, \n    \"CSI 300\" : CSI_300_TICKER, \n    \"CAC 40\" : CAC_40_TICKER, \n    \"DAX 30\" : DAX_30_TICKER, \n    \"TecDAX\" : TECDAX_TICKER, ",
        "detail": "docs.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "docs.lib.rl.main",
        "description": "docs.lib.rl.main",
        "peekOfCode": "def build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        dest=\"mode\",\n        help=\"start mode, train, download_data\" \" backtest\",\n        metavar=\"MODE\",\n        default=\"train\",\n    )\n    return parser",
        "detail": "docs.lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "kind": 2,
        "importPath": "docs.lib.rl.main",
        "description": "docs.lib.rl.main",
        "peekOfCode": "def check_and_make_directories(directories: list[str]):\n    for directory in directories:\n        if not os.path.exists(\"./\" + directory):\n            os.makedirs(\"./\" + directory)\ndef main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )",
        "detail": "docs.lib.rl.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.lib.rl.main",
        "description": "docs.lib.rl.main",
        "peekOfCode": "def main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )\n    if options.mode == \"train\":\n        from lib.rl import train\n        env = StockTradingEnv\n        # demo for elegantrl",
        "detail": "docs.lib.rl.main",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def get_daily_return(df, value_col_name=\"account_value\"):\n    df = deepcopy(df)\n    df[\"daily_return\"] = df[value_col_name].pct_change(1)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    df.set_index(\"date\", inplace=True, drop=True)\n    df.index = df.index.tz_localize(\"UTC\")\n    return pd.Series(df[\"daily_return\"], index=df.index)\ndef convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "convert_daily_return_to_pyfolio_ts",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n    del strategy_ret[\"date\"]\n    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\ndef backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(\n        returns=dr_test,\n        positions=None,\n        transactions=None,\n        turnover_denom=\"AGB\",\n    )\n    # jprint(perf_stats_all)\n    st.table(perf_stats_all)",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def backtest_plot(\n    account_value,\n    baseline_start=config.TRADE_START_DATE,\n    baseline_end=config.TRADE_END_DATE,\n    baseline_ticker=\"^DJI\",\n    value_col_name=\"account_value\",\n):\n    df = deepcopy(account_value)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    test_returns = get_daily_return(df, value_col_name=value_col_name)",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def get_baseline(ticker, start, end):\n    return YahooDownloader(\n        start_date=start, end_date=end, ticker_list=[ticker]\n    ).fetch_data()\ndef trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "trx_plot",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):\n        df_trx_temp = df_trx.iloc[:, i]\n        df_trx_temp_sign = np.sign(df_trx_temp)\n        buying_signal = df_trx_temp_sign.apply(lambda x: x > 0)\n        selling_signal = df_trx_temp_sign.apply(lambda x: x < 0)",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "transfer_date",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def transfer_date(str_dat):\n    return datetime.datetime.strptime(str_dat, \"%Y-%m-%d\").date().strftime(\"%m/%d/%Y\")\ndef plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result_from_csv",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    result = pd.read_csv(csv_file)",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def plot_result(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    columns = result.columns",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_if_overlap",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def get_if_overlap(fig, ax):\n    fig.canvas.draw()\n    # \n    bboxes = [label.get_window_extent() for label in ax.get_xticklabels()]\n    # \n    distances = [bboxes[i + 1].x0 - bboxes[i].x1 for i in range(len(bboxes) - 1)]\n    # 0\n    if any(distance < 0 for distance in distances):\n        if_overlap = True\n    else:",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def plot_return(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return_from_csv",
        "kind": 2,
        "importPath": "docs.lib.rl.plot",
        "description": "docs.lib.rl.plot",
        "peekOfCode": "def plot_return_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "docs.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "docs.lib.rl.test",
        "description": "docs.lib.rl.test",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.lib.rl.test",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 2,
        "importPath": "docs.lib.rl.trade",
        "description": "docs.lib.rl.trade",
        "peekOfCode": "def trade(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.lib.rl.trade",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "docs.lib.rl.train",
        "description": "docs.lib.rl.train",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "docs.lib.rl.train",
        "documentation": {}
    },
    {
        "label": "WorkflowScheduler",
        "kind": 6,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "class WorkflowScheduler:\n    def __init__(self):\n        # Define labels and date ranges for different workflow modes\n        self.labels = {\n            \"Train\": (TRAIN_START_DATE, TRAIN_END_DATE),\n            \"Test\": (TEST_START_DATE, TEST_END_DATE),\n            \"Trade\": (TRADE_START_DATE, TRADE_END_DATE),\n        }\n        self.train_start_date = self.labels[\"Train\"][0]\n        self.train_end_date = self.labels[\"Train\"][1]",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "setFirstPageTitle",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def setFirstPageTitle() : \n    custom_css = \"\"\"\n    <style>\n    body {\n    background-color: black; /* Background color (black) */\n    font-family: \"Times New Roman\", Times, serif; /* Font family (Times New Roman) */\n    color: white; /* Text color (white) */\n    line-height: 1.6; /* Line height for readability */\n    }\n    h1 {",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_inputs99",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def set_inputs99():\n    st.title(\"Dynamic Financial Reinforcement Learning\")\n    st.write(\"\"\"\n    This application simulates a dynamic dataset-driven financial reinforcement learning model, \n    which uses a rolling window technique to incrementally update the training and testing sets based on real-time market data.\n    The dataset is divided into training and testing segments, which adjust every W days to keep the model updated.\n    \"\"\")\nclass WorkflowScheduler:\n    def __init__(self):\n        # Define labels and date ranges for different workflow modes",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "get_full_path",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def get_full_path(fn):\n    file_path = os.path.join(DATA_FRAME_DIR, fn )\n    return file_path\ndef set_yahoo_data_frame(ticker_ls, wf) :\n  \"\"\"app.py: Waiting data collection From Yahoo downloader ...\"\"\"\n  df = YahooDownloader(start_date  = \n  wf.train_start_date,\n  end_date = wf.trade_end_date,\n  ticker_list = ticker_ls).fetch_data()\n  df.sort_values(['date','tic'],ignore_index=True).head()",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_yahoo_data_frame",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def set_yahoo_data_frame(ticker_ls, wf) :\n  \"\"\"app.py: Waiting data collection From Yahoo downloader ...\"\"\"\n  df = YahooDownloader(start_date  = \n  wf.train_start_date,\n  end_date = wf.trade_end_date,\n  ticker_list = ticker_ls).fetch_data()\n  df.sort_values(['date','tic'],ignore_index=True).head()\n  fe = FeatureEngineer(\n                    use_technical_indicator=True,\n                    tech_indicator_list = INDICATORS,",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def train_agent(agent, model_name = \"a2c\", total_timesteps=50000):\n    \"\"\"\n    Train a model with the provided agent and model_name and total_timesteps \n    \"\"\"\n    # Get the model for A2C if applicable\n    __cached__model_ = agent.get_model(model_name)\n    # Set up logger\n    _tmp_path = RESULTS_DIR + '/' + model_name\n    _new_logger = configure(_tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n    # Set the new logger",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "predict_with_models",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def predict_with_models(models, environment):\n      \"\"\"\n      Perform predictions using multiple trained models in the specified environment.\n      Parameters:\n      - models: A dictionary of trained models with names as keys.\n      - environment: The trading environment to be used for predictions.\n      Returns:\n      - results: A dictionary containing DataFrames of account values and actions for each model.\n      \"\"\"\n      results = {}",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "GetTickerList",
        "kind": 2,
        "importPath": "docs.lib.utility.inputs",
        "description": "docs.lib.utility.inputs",
        "peekOfCode": "def GetTickerList():\n    \"\"\"\n    Generate a list of tickers based on user selection (Index, Sector, or NYSE) in a Streamlit app.\n    Parameters:\n    - index_dict: Dictionary of indexes and their respective tickers.\n    - sector_dict: Dictionary of sectors and their respective tickers.\n    - usa_dict: Dictionary of NYSE-specific categories and tickers.\n    - SP_500_TICKER: List of tickers for the S&P 500.\n    Returns:\n    - final_ticker_list: List of selected tickers.",
        "detail": "docs.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "jprint",
        "kind": 2,
        "importPath": "docs.lib.utility.jprint",
        "description": "docs.lib.utility.jprint",
        "peekOfCode": "def jprint(s1 = '', s2 = '' , s3 = '', s4 = \"\"):\n  a1 = str(s1) + str(s2) + str(s3) +str(s4)\n  print   (a1)\n  st.write(a1)\n# def jprint2(*args):\n#     # Convert all inputs to strings and handle lists/arrays\n#     result = []\n#     for arg in args:\n#         if isinstance(arg, (list, tuple)):  # Check if the argument is a list or tuple\n#             result.extend(map(str, arg))    # Convert each item in the list to a string",
        "detail": "docs.lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "custom_css",
        "kind": 5,
        "importPath": "docs.pages.1_Stock_Sentiment",
        "description": "docs.pages.1_Stock_Sentiment",
        "peekOfCode": "custom_css = \"\"\"\n<style>\nbody {\nbackground-color: black; /* Background color (black) */\nfont-family: \"Times New Roman\", Times, serif; /* Font family (Times New Roman) */\ncolor: white; /* Text color (white) */\nline-height: 1.6; /* Line height for readability */\n}\nh1 {\ncolor: #3498db; /* Heading color (light blue) */",
        "detail": "docs.pages.1_Stock_Sentiment",
        "documentation": {}
    },
    {
        "label": "finviz_url",
        "kind": 5,
        "importPath": "docs.pages.1_Stock_Sentiment",
        "description": "docs.pages.1_Stock_Sentiment",
        "peekOfCode": "finviz_url = \"https://finviz.com/quote.ashx?t=\"\nexample_ticker_symbols = [\n\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\",\n\"JPM\", \"NFLX\", \"FB\", \"BRK.B\", \"V\",\n\"NVDA\", \"DIS\", \"BA\", \"IBM\", \"GE\",\n\"PG\", \"JNJ\", \"KO\", \"MCD\", \"T\",\n\"ADBE\", \"CRM\", \"INTC\", \"ORCL\", \"HD\"\n]\n# Use a selectbox to allow users to choose from example ticker symbols\nticker = st.selectbox(\"Select a stock ticker symbol or enter your own:\", example_ticker_symbols)",
        "detail": "docs.pages.1_Stock_Sentiment",
        "documentation": {}
    },
    {
        "label": "example_ticker_symbols",
        "kind": 5,
        "importPath": "docs.pages.1_Stock_Sentiment",
        "description": "docs.pages.1_Stock_Sentiment",
        "peekOfCode": "example_ticker_symbols = [\n\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\",\n\"JPM\", \"NFLX\", \"FB\", \"BRK.B\", \"V\",\n\"NVDA\", \"DIS\", \"BA\", \"IBM\", \"GE\",\n\"PG\", \"JNJ\", \"KO\", \"MCD\", \"T\",\n\"ADBE\", \"CRM\", \"INTC\", \"ORCL\", \"HD\"\n]\n# Use a selectbox to allow users to choose from example ticker symbols\nticker = st.selectbox(\"Select a stock ticker symbol or enter your own:\", example_ticker_symbols)\nnews_tables = {}",
        "detail": "docs.pages.1_Stock_Sentiment",
        "documentation": {}
    },
    {
        "label": "ticker",
        "kind": 5,
        "importPath": "docs.pages.1_Stock_Sentiment",
        "description": "docs.pages.1_Stock_Sentiment",
        "peekOfCode": "ticker = st.selectbox(\"Select a stock ticker symbol or enter your own:\", example_ticker_symbols)\nnews_tables = {}\nif ticker:\n      #Fetching stock price data\n            current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n            stock_data = yf.download(ticker, start=\"2000-01-01\", end=current_date)\n            if stock_data:\n                  combined_data = pd.concat(stock_data.values(), axis=1)\n                  print(combined_data.head())\n            else:",
        "detail": "docs.pages.1_Stock_Sentiment",
        "documentation": {}
    },
    {
        "label": "news_tables",
        "kind": 5,
        "importPath": "docs.pages.1_Stock_Sentiment",
        "description": "docs.pages.1_Stock_Sentiment",
        "peekOfCode": "news_tables = {}\nif ticker:\n      #Fetching stock price data\n            current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n            stock_data = yf.download(ticker, start=\"2000-01-01\", end=current_date)\n            if stock_data:\n                  combined_data = pd.concat(stock_data.values(), axis=1)\n                  print(combined_data.head())\n            else:\n                  print(\" No valid data retrieved! Check ticker names or API availability.\")",
        "detail": "docs.pages.1_Stock_Sentiment",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom lib.rl.config import (\n    OrderType,\n    OrderSide,\n    TimeInForce,\n)\n# from alpaca.trading.enums import OrderSide, TimeInForce, OrderType\nfrom lib.rl.config_tickers import DOW_30_TICKER\nfrom lib.rl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom lib.rl.meta.preprocessor.preprocessors import FeatureEngineer, data_split",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "TRAIN_START_DATE = '2009-04-01'\nTRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "TRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "TEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())\nst.write(df.tail())",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "TEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())\nst.write(df.tail())\nst.write(df.shape)",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())\nst.write(df.tail())\nst.write(df.shape)\nINDICATORS = ['macd',",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, ",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, ",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, ",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, ",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, ",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension, \n    \"reward_scaling\": 1e-4,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "SAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}\nTD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "TD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "timesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,\n    'td3' : 1\n}\ndf_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,\n    DDPG_model_kwargs,\n    SAC_model_kwargs,\n    TD3_model_kwargs,\n    timesteps_dict\n)\nst.write(df_summary)\nunique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value = pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value = pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\ndf_account_value.account_value.plot()",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df_account_value",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "df_account_value = pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\ndf_account_value.account_value.plot()\nst.line_chart(df_account_value['account_value'])",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "baseline_df",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "baseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "stats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX\nbacktest_plot(df_account_value, \n              baseline_ticker = '^DJI', \n              baseline_start = df_account_value.loc[0,'date'],\n              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "docs.pages.2_Stock_Trading",
        "description": "docs.pages.2_Stock_Trading",
        "peekOfCode": "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')\ntry:\n    account = api.get_account()\n    st.write(f\"Account status: {account.status}\")\n    symbol = 'CAT'\n    qty = 1  # Quantity to buy\n    if (sharpe > - 94):\n        buy_order = api.submit_order(\n            symbol=symbol,\n            qty=qty,",
        "detail": "docs.pages.2_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "read_config",
        "kind": 2,
        "importPath": "docs.pages.3_Setting",
        "description": "docs.pages.3_Setting",
        "peekOfCode": "def read_config(file_path):\n    config = {}\n    with open(file_path, 'r') as file:\n        exec(file.read(), config)\n    return config\ndef write_config(file_path, config):\n    with open(file_path, 'w') as file:\n        file.write(\"# Configuration File\\n\\n\")\n        for key, value in config.items():\n            if not key.startswith('__'):",
        "detail": "docs.pages.3_Setting",
        "documentation": {}
    },
    {
        "label": "write_config",
        "kind": 2,
        "importPath": "docs.pages.3_Setting",
        "description": "docs.pages.3_Setting",
        "peekOfCode": "def write_config(file_path, config):\n    with open(file_path, 'w') as file:\n        file.write(\"# Configuration File\\n\\n\")\n        for key, value in config.items():\n            if not key.startswith('__'):\n                if isinstance(value, str):\n                    file.write(f'{key} = \"{value}\"\\n')\n                elif isinstance(value, list):\n                    file.write(f'{key} = {value}\\n')\n                elif isinstance(value, dict):",
        "detail": "docs.pages.3_Setting",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.pages.3_Setting",
        "description": "docs.pages.3_Setting",
        "peekOfCode": "def main():\n    st.title(\"Settings Page\")\n    # Read the configuration\n    config = read_config(config_file_path)\n    # Convert date strings to date objects\n    def parse_date(date_str):\n        try:\n            return datetime.strptime(date_str, \"%Y-%m-%d\").date()\n        except ValueError:\n            return None",
        "detail": "docs.pages.3_Setting",
        "documentation": {}
    },
    {
        "label": "config_file_path",
        "kind": 5,
        "importPath": "docs.pages.3_Setting",
        "description": "docs.pages.3_Setting",
        "peekOfCode": "config_file_path = 'lib/utility/config.py'\ndef read_config(file_path):\n    config = {}\n    with open(file_path, 'r') as file:\n        exec(file.read(), config)\n    return config\ndef write_config(file_path, config):\n    with open(file_path, 'w') as file:\n        file.write(\"# Configuration File\\n\\n\")\n        for key, value in config.items():",
        "detail": "docs.pages.3_Setting",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.pages.4_ensemble_stock_trading",
        "description": "docs.pages.4_ensemble_stock_trading",
        "peekOfCode": "def main():\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    from lib.rl.config_tickers import DOW_30_TICKER",
        "detail": "docs.pages.4_ensemble_stock_trading",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "class MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(base_url=BASE_URL, key_id=API_KEY, secret_key=API_SECRET)\n    def position_sizing(self): \n        cash = self.get_cash() \n        last_price = self.get_last_price(self.symbol)",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "API_KEY = \"PKEJH4W0URAU56SHKQW3\" \nAPI_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nBASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nBASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "ALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}\nclass MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None ",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "start_date = datetime(2020,1,1)\nend_date = datetime(2023,12,31) \nbroker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, ",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "end_date = datetime(2023,12,31) \nbroker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, \n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":.5}",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "broker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, \n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":.5}\n)",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "strategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, \n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":.5}\n)\ntrader = Trader()",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "trader",
        "kind": 5,
        "importPath": "docs.pages.5_sent_bot",
        "description": "docs.pages.5_sent_bot",
        "peekOfCode": "trader = Trader()\ntrader.add_strategy(strategy)\ntrader.run_all()",
        "detail": "docs.pages.5_sent_bot",
        "documentation": {}
    },
    {
        "label": "get_gdp_data",
        "kind": 2,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "def get_gdp_data():\n    \"\"\"Grab GDP data from a CSV file.\n    This uses caching to avoid having to read the file every time. If we were\n    reading from an HTTP endpoint instead of a file, it's a good idea to set\n    a maximum age to the cache with the TTL argument: @st.cache_data(ttl='1d')\n    \"\"\"\n    # Instead of a CSV on disk, you could read from an HTTP endpoint here too.\n    DATA_FILENAME = Path(__file__).parent/'data/gdp_data.csv'\n    raw_gdp_df = pd.read_csv(DATA_FILENAME)\n    MIN_YEAR = 1960",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "gdp_df",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "gdp_df = get_gdp_data()\n# -----------------------------------------------------------------------------\n# Draw the actual page\n# Set the title that appears at the top of the page.\n'''\n# :earth_americas: GDP dashboard\nBrowse GDP data from the [World Bank Open Data](https://data.worldbank.org/) website. As you'll\nnotice, the data only goes to 2022 right now, and datapoints for certain years are often missing.\nBut it's otherwise a great (and did I mention _free_?) source of data.\n'''",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "min_value",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "min_value = gdp_df['Year'].min()\nmax_value = gdp_df['Year'].max()\nfrom_year, to_year = st.slider(\n    'Which years are you interested in?',\n    min_value=min_value,\n    max_value=max_value,\n    value=[min_value, max_value])\ncountries = gdp_df['Country Code'].unique()\nif not len(countries):\n    st.warning(\"Select at least one country\")",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "max_value",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "max_value = gdp_df['Year'].max()\nfrom_year, to_year = st.slider(\n    'Which years are you interested in?',\n    min_value=min_value,\n    max_value=max_value,\n    value=[min_value, max_value])\ncountries = gdp_df['Country Code'].unique()\nif not len(countries):\n    st.warning(\"Select at least one country\")\nselected_countries = st.multiselect(",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "countries",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "countries = gdp_df['Country Code'].unique()\nif not len(countries):\n    st.warning(\"Select at least one country\")\nselected_countries = st.multiselect(\n    'Which countries would you like to view?',\n    countries,\n    ['DEU', 'FRA', 'GBR', 'BRA', 'MEX', 'JPN'])\n''\n''\n''",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "selected_countries",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "selected_countries = st.multiselect(\n    'Which countries would you like to view?',\n    countries,\n    ['DEU', 'FRA', 'GBR', 'BRA', 'MEX', 'JPN'])\n''\n''\n''\n# Filter the data\nfiltered_gdp_df = gdp_df[\n    (gdp_df['Country Code'].isin(selected_countries))",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "filtered_gdp_df",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "filtered_gdp_df = gdp_df[\n    (gdp_df['Country Code'].isin(selected_countries))\n    & (gdp_df['Year'] <= to_year)\n    & (from_year <= gdp_df['Year'])\n]\nst.header('GDP over time', divider='gray')\n''\nst.line_chart(\n    filtered_gdp_df,\n    x='Year',",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "first_year",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "first_year = gdp_df[gdp_df['Year'] == from_year]\nlast_year = gdp_df[gdp_df['Year'] == to_year]\nst.header(f'GDP in {to_year}', divider='gray')\n''\ncols = st.columns(4)\nfor i, country in enumerate(selected_countries):\n    col = cols[i % len(cols)]\n    with col:\n        first_gdp = first_year[first_year['Country Code'] == country]['GDP'].iat[0] / 1000000000\n        last_gdp = last_year[last_year['Country Code'] == country]['GDP'].iat[0] / 1000000000",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "last_year",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "last_year = gdp_df[gdp_df['Year'] == to_year]\nst.header(f'GDP in {to_year}', divider='gray')\n''\ncols = st.columns(4)\nfor i, country in enumerate(selected_countries):\n    col = cols[i % len(cols)]\n    with col:\n        first_gdp = first_year[first_year['Country Code'] == country]['GDP'].iat[0] / 1000000000\n        last_gdp = last_year[last_year['Country Code'] == country]['GDP'].iat[0] / 1000000000\n        if math.isnan(first_gdp):",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "cols",
        "kind": 5,
        "importPath": "docs.pages.6_GDP_dashboard",
        "description": "docs.pages.6_GDP_dashboard",
        "peekOfCode": "cols = st.columns(4)\nfor i, country in enumerate(selected_countries):\n    col = cols[i % len(cols)]\n    with col:\n        first_gdp = first_year[first_year['Country Code'] == country]['GDP'].iat[0] / 1000000000\n        last_gdp = last_year[last_year['Country Code'] == country]['GDP'].iat[0] / 1000000000\n        if math.isnan(first_gdp):\n            growth = 'n/a'\n            delta_color = 'off'\n        else:",
        "detail": "docs.pages.6_GDP_dashboard",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "TRAIN_START_DATE = '2009-04-01'\nTRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "TRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "TEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "TEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :\ndf = YahooDownloader(start_date = TRAIN_START_DATE,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "tic",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "tic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = tic).fetch_data()",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "tic",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "tic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = tic).fetch_data()\ndf.sort_values(['date','tic']).head()",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = tic).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())\nprint(df.shape)\nst.write(len(df.tic.unique()))",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, ",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, ",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, ",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, ",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension, \n    \"reward_scaling\": 1e-4,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "SAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}\nTD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "TD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {\n    'a2c': 10,  # Example value, adjust as needed\n    'ppo': 10,\n    'ddpg': 10,\n    'sac' : 10,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "timesteps_dict = {\n    'a2c': 10,  # Example value, adjust as needed\n    'ppo': 10,\n    'ddpg': 10,\n    'sac' : 10,\n    'td3' : 10\n}\ndf_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,\n    DDPG_model_kwargs,\n    SAC_model_kwargs,\n    TD3_model_kwargs,\n    timesteps_dict\n)\nprint(df_summary)\nst.write(df_summary)",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv(RESULTS_DIR + '/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    # temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\nst.write('Sharpe Ratio: ',sharpe)",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv(RESULTS_DIR + '/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    # temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "baseline_df",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "baseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "stats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX\nbacktest_plot(df_account_value, \n              baseline_ticker = '^DJI', \n              baseline_start = df_account_value.loc[0,'date'],",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "docs.pages.ml_Stock_Training",
        "description": "docs.pages.ml_Stock_Training",
        "peekOfCode": "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')\ntry:\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    st.write(f\"Account status: {account.status}\")\n    symbol = 'CAT'\n    qty = 1  # Quantity to buy\n    if (sharpe > - 94):\n        buy_order = api.submit_order(\n            symbol=symbol,",
        "detail": "docs.pages.ml_Stock_Training",
        "documentation": {}
    },
    {
        "label": "ProgressState",
        "kind": 6,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "class ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)\n        self.trading_days = len(dates)\n    def update(self, current_date):",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "DailyProgressStrategy",
        "kind": 6,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "class DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())\n        time.sleep(0.01)  # Allow UI updates",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "backtest_worker",
        "kind": 2,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "def backtest_worker():\n    try:\n        from lumibot.credentials import ALPACA_CREDS\n        broker = Alpaca(\n            ALPACA_CREDS, \n            connect_stream=False\n        )\n        start_date = datetime(2023, 1, 1)\n        end_date = datetime(2023, 12, 31)\n        progress.start_date = start_date",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE']",
        "kind": 5,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE'] = '1'\n# Global progress state\nclass ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "progress",
        "kind": 5,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "progress = ProgressState()\nclass DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "placeholder",
        "kind": 5,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "placeholder = st.empty()\nprogress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "kind": 5,
        "importPath": "docs.pages.t10",
        "description": "docs.pages.t10",
        "peekOfCode": "progress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition\n        if current_value >= 0.999:",
        "detail": "docs.pages.t10",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingExampleStrategy",
        "kind": 6,
        "importPath": "docs.pages_2.ccxt_backtesting_example",
        "description": "docs.pages_2.ccxt_backtesting_example",
        "peekOfCode": "class CcxtBacktestingExampleStrategy(Strategy):\n    def initialize(self, asset:tuple[Asset,Asset] = None,\n                   cash_at_risk:float=.25,window:int=21):\n        if asset is None:\n            raise ValueError(\"You must provide a valid asset pair\")\n        # for crypto, market is 24/7\n        self.set_market(\"24/7\")\n        self.sleeptime = \"1D\"\n        self.asset = asset\n        self.base, self.quote = asset",
        "detail": "docs.pages_2.ccxt_backtesting_example",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "kind": 6,
        "importPath": "docs.pages_2.crypto_important_functions",
        "description": "docs.pages_2.crypto_important_functions",
        "peekOfCode": "class ImportantFunctions(Strategy):\n    def initialize(self):\n        # Set the time between trading iterations\n        self.sleeptime = \"30S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n    def on_trading_iteration(self):\n        ###########################\n        # Placing an Order\n        ###########################",
        "detail": "docs.pages_2.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "kind": 6,
        "importPath": "docs.pages_2.drift_rebalancer",
        "description": "docs.pages_2.drift_rebalancer",
        "peekOfCode": "class DriftRebalancer(Strategy):\n    \"\"\"The DriftRebalancer strategy rebalances a portfolio based on drift from target weights.\n    The strategy calculates the drift of each asset in the portfolio and triggers a rebalance if the drift exceeds\n    the drift_threshold. The strategy will sell assets that have drifted above the threshold and\n    buy assets that have drifted below the threshold.\n    The current version of the DriftRebalancer strategy only supports limit orders and whole share quantities.\n    Submit an issue if you need market orders or fractional shares. It should be pretty easy to add.\n    Example parameters:\n    parameters = {\n        ### Standard lumibot strategy parameters",
        "detail": "docs.pages_2.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftCalculationLogic",
        "kind": 6,
        "importPath": "docs.pages_2.drift_rebalancer",
        "description": "docs.pages_2.drift_rebalancer",
        "peekOfCode": "class DriftCalculationLogic:\n    def __init__(self, target_weights: Dict[str, Decimal]) -> None:\n        self.df = pd.DataFrame({\n            \"symbol\": target_weights.keys(),\n            \"is_quote_asset\": False,\n            \"current_quantity\": Decimal(0),\n            \"current_value\": Decimal(0),\n            \"current_weight\": Decimal(0),\n            \"target_weight\": [Decimal(weight) for weight in target_weights.values()],\n            \"target_value\": Decimal(0),",
        "detail": "docs.pages_2.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LimitOrderRebalanceLogic",
        "kind": 6,
        "importPath": "docs.pages_2.drift_rebalancer",
        "description": "docs.pages_2.drift_rebalancer",
        "peekOfCode": "class LimitOrderRebalanceLogic:\n    def __init__(\n            self,\n            *,\n            strategy: Strategy,\n            df: pd.DataFrame,\n            fill_sleeptime: int = 15,\n            acceptable_slippage: Decimal = Decimal(\"0.005\"),\n            shorting: bool = False\n    ) -> None:",
        "detail": "docs.pages_2.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LifecycleLogger",
        "kind": 6,
        "importPath": "docs.pages_2.lifecycle_logger",
        "description": "docs.pages_2.lifecycle_logger",
        "peekOfCode": "class LifecycleLogger(Strategy):\n    \"\"\"\n    A strategy that logs key lifecycle events during a trading session.\n    It does not execute trades but provides valuable insights into:\n    - Market opening and closing times\n    - Trading session start and end\n    - Iterative trading loops\n    Useful for debugging and understanding the trading lifecycle.\n    \"\"\"\n    parameters = {",
        "detail": "docs.pages_2.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "docs.pages_2.lifecycle_logger",
        "description": "docs.pages_2.lifecycle_logger",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LifecycleLogger(Strategy):\n    \"\"\"\n    A strategy that logs key lifecycle events during a trading session.\n    It does not execute trades but provides valuable insights into:\n    - Market opening and closing times\n    - Trading session start and end\n    - Iterative trading loops\n    Useful for debugging and understanding the trading lifecycle.\n    \"\"\"",
        "detail": "docs.pages_2.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "OptionsHoldToExpiry",
        "kind": 6,
        "importPath": "docs.pages_2.options_hold_to_expiry",
        "description": "docs.pages_2.options_hold_to_expiry",
        "peekOfCode": "class OptionsHoldToExpiry(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"expiry\": datetime(2023, 10, 20),\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants\n        # Built in Variables\n        self.sleeptime = \"1D\"",
        "detail": "docs.pages_2.options_hold_to_expiry",
        "documentation": {}
    },
    {
        "label": "MyStrategy",
        "kind": 6,
        "importPath": "docs.pages_2.simple_start_single_file",
        "description": "docs.pages_2.simple_start_single_file",
        "peekOfCode": "class MyStrategy(Strategy):\n    def initialize(self, symbol=\"\"):\n        # Will make on_trading_iteration() run every 180 minutes\n        self.sleeptime = 180\n        # Custom parameters\n        self.symbol = symbol\n        self.quantity = 1\n        self.side = \"buy\"\n    def on_trading_iteration(self):\n        self.order = self.create_order(self.symbol, self.quantity, self.side)",
        "detail": "docs.pages_2.simple_start_single_file",
        "documentation": {}
    },
    {
        "label": "StockBracket",
        "kind": 6,
        "importPath": "docs.pages_2.stock_bracket",
        "description": "docs.pages_2.stock_bracket",
        "peekOfCode": "class StockBracket(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "docs.pages_2.stock_bracket",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "docs.pages_2.stock_buy_and_hold",
        "description": "docs.pages_2.stock_buy_and_hold",
        "peekOfCode": "class BuyAndHold(Strategy):\n    parameters = {\n        \"buy_symbol\": \"QQQ\",\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the sleep time to one day (the strategy will run once per day)\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        \"\"\"Buys the self.buy_symbol once, then never again\"\"\"",
        "detail": "docs.pages_2.stock_buy_and_hold",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage",
        "kind": 6,
        "importPath": "docs.pages_2.stock_diversified_leverage",
        "description": "docs.pages_2.stock_diversified_leverage",
        "peekOfCode": "class DiversifiedLeverage(Strategy):\n    # =====Overloading lifecycle methods=============\n    parameters = {\n        \"portfolio\": [\n            {\n                \"symbol\": \"TQQQ\",  # 3x Leveraged Nasdaq\n                \"weight\": 0.20,\n            },\n            {\n                \"symbol\": \"UPRO\",  # 3x Leveraged S&P 500",
        "detail": "docs.pages_2.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "LimitAndTrailingStop",
        "kind": 6,
        "importPath": "docs.pages_2.stock_limit_and_trailing_stops",
        "description": "docs.pages_2.stock_limit_and_trailing_stops",
        "peekOfCode": "class LimitAndTrailingStop(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"limit_buy_price\": 403,\n        \"limit_sell_price\": 407,\n        \"trail_percent\": 0.02,\n        \"trail_price\": 7,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):",
        "detail": "docs.pages_2.stock_limit_and_trailing_stops",
        "documentation": {}
    },
    {
        "label": "Momentum",
        "kind": 6,
        "importPath": "docs.pages_2.stock_momentum",
        "description": "docs.pages_2.stock_momentum",
        "peekOfCode": "class Momentum(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self, symbols=None):\n        # Setting the waiting period (in days)\n        self.period = 2\n        # The counter for the number of days we have been holding the current asset\n        self.counter = 0\n        # There is only one trading operation per day\n        # No need to sleep between iterations\n        self.sleeptime = 0",
        "detail": "docs.pages_2.stock_momentum",
        "documentation": {}
    },
    {
        "label": "StockOco",
        "kind": 6,
        "importPath": "docs.pages_2.stock_oco",
        "description": "docs.pages_2.stock_oco",
        "peekOfCode": "class StockOco(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "docs.pages_2.stock_oco",
        "documentation": {}
    },
    {
        "label": "StockSentiment",
        "kind": 6,
        "importPath": "docs.pages_2.stock_sentiment",
        "description": "docs.pages_2.stock_sentiment",
        "peekOfCode": "class StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],\n            base_url=BASE_URL",
        "detail": "docs.pages_2.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "docs.pages_2.stock_sentiment",
        "description": "docs.pages_2.stock_sentiment",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nclass StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],",
        "detail": "docs.pages_2.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "Strangle",
        "kind": 6,
        "importPath": "docs.pages_2.strangle",
        "description": "docs.pages_2.strangle",
        "peekOfCode": "class Strangle(Strategy):\n    \"\"\"Strategy Description: Strangle\n    In a long stranglethe more common strategythe investor simultaneously buys an\n    out-of-the-money call and an out-of-the-money put option. The call option's strike\n    price is higher than the underlying asset's current market price, while the put has a\n    strike price that is lower than the asset's market price. This strategy has large profit\n    potential since the call option has theoretically unlimited upside if the underlying\n    asset rises in price, while the put option can profit if the underlying asset falls.\n    The risk on the trade is limited to the premium paid for the two options.\n    Place the strangle two weeks before earnings announcement.",
        "detail": "docs.pages_2.strangle",
        "documentation": {}
    },
    {
        "label": "BrokerTest",
        "kind": 6,
        "importPath": "docs.pages_2.test_broker_functions",
        "description": "docs.pages_2.test_broker_functions",
        "peekOfCode": "class BrokerTest(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the time between trading iterations\n        # strategy runs every 20 seconds.\n        self.sleeptime = \"20S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n        # Record the last trade time\n        self.last_trade_time = None",
        "detail": "docs.pages_2.test_broker_functions",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "project = \"FinRL\"\ncopyright = \"2021, FinRL\"\nauthor = \"FinRL\"\n# The short X.Y version\nversion = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "copyright = \"2021, FinRL\"\nauthor = \"FinRL\"\n# The short X.Y version\nversion = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "author",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "author = \"FinRL\"\n# The short X.Y version\nversion = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n# Add any Sphinx extension module names here, as strings. They can be",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "version = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "release",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "release = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "extensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx.ext.githubpages\",\n    \"sphinx.ext.autosectionlabel\",\n    \"recommonmark\",  # for including markdown\n    #     'sphinx_markdown_tables'  # Support rendering tables in markdown\n]\nautodoc_mock_imports = [",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "autodoc_mock_imports",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "autodoc_mock_imports = [\n    \"gym\",\n    \"matplotlib\",\n    \"numpy\",\n    \"pybullet\",\n    \"torch\",\n    \"opencv-python\",\n]\npygments_style = \"sphinx\"\n# Add any paths that contain templates here, relative to this directory.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "pygments_style = \"sphinx\"\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n# The master toctree document.\nmaster_doc = \"index\"",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "templates_path = [\"_templates\"]\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n# The master toctree document.\nmaster_doc = \"index\"\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "source_suffix",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "source_suffix = \".rst\"\n# The master toctree document.\nmaster_doc = \"index\"\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "master_doc",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "master_doc = \"index\"\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "language",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "language = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n# -- Options for HTML output -------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "exclude_patterns",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "exclude_patterns = []\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n# -- Options for HTML output -------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "pygments_style = None\n# -- Options for HTML output -------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "html_theme = \"sphinx_rtd_theme\"\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "html_theme_path",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "html_logo",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "html_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "html_theme_options",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "html_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n# Add any paths that contain custom static files (such as style sheets) here,",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "html_static_path",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "html_static_path = [\"_static\"]\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don't match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``['localtoc.html', 'relations.html', 'sourcelink.html',\n# 'searchbox.html']``.\n#\n# html_sidebars = {}",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "htmlhelp_basename",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "htmlhelp_basename = \"FinRLdoc\"\n# -- Options for LaTeX output ------------------------------------------------\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "latex_elements",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "latex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "latex_documents",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "latex_documents = [\n    (master_doc, \"FinRL.tex\", \"FinRL Documentation\", \"FinRL\", \"manual\"),\n]\n# -- Options for manual page output ------------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \"finrl\", \"FinRL Documentation\", [author], 1)]\n# -- Options for Texinfo output ----------------------------------------------\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "man_pages",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "man_pages = [(master_doc, \"finrl\", \"FinRL Documentation\", [author], 1)]\n# -- Options for Texinfo output ----------------------------------------------\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        \"FinRL\",\n        \"FinRL Documentation\",",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "texinfo_documents",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "texinfo_documents = [\n    (\n        master_doc,\n        \"FinRL\",\n        \"FinRL Documentation\",\n        author,\n        \"FinRL\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    ),",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "epub_title",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "epub_title = project\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = ''\n# A unique identification for the text.\n#\n# epub_uid = ''\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\"search.html\"]",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "epub_exclude_files",
        "kind": 5,
        "importPath": "docs.resources.conf",
        "description": "docs.resources.conf",
        "peekOfCode": "epub_exclude_files = [\"search.html\"]\n# -- Extension configuration -------------------------------------------------",
        "detail": "docs.resources.conf",
        "documentation": {}
    },
    {
        "label": "sentiment_Vader",
        "kind": 2,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "def sentiment_Vader(text):\n    over_all_polarity = sid.polarity_scores(text)\n    if over_all_polarity['compound'] >= 0.05:\n        return \"positive\"\n    elif over_all_polarity['compound'] <= -0.05:\n        return \"negative\"\n    else:\n        return \"neutral\"\n# Apply sentiment analysis using VADER\nsid = SentimentIntensityAnalyzer()",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "url = 'https://www.flipkart.com/hamtex-polycotton-double-bed-cover/product-reviews/itma5c9f08efe504?pid=BCVG2ZGSDZ3WSGTF&lid=LSTBCVG2ZGSDZ3WSGTFDBZ9IO&marketplace=FLIPKART'\nresponse = requests.get(url)\ncontent = response.content\nsoup = BeautifulSoup(content, 'html.parser')\nreviews_container = soup.find('div', {'class': '_1YokD2 _3Mn1Gg col-9-12'})\nreview_divs = reviews_container.find_all('div', {'class': 't-ZTKy'})\nreviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "response = requests.get(url)\ncontent = response.content\nsoup = BeautifulSoup(content, 'html.parser')\nreviews_container = soup.find('div', {'class': '_1YokD2 _3Mn1Gg col-9-12'})\nreview_divs = reviews_container.find_all('div', {'class': 't-ZTKy'})\nreviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()\n    reviews.append(text)",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "content",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "content = response.content\nsoup = BeautifulSoup(content, 'html.parser')\nreviews_container = soup.find('div', {'class': '_1YokD2 _3Mn1Gg col-9-12'})\nreview_divs = reviews_container.find_all('div', {'class': 't-ZTKy'})\nreviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()\n    reviews.append(text)\n# Save the reviews to an Excel file in current directory",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "soup",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "soup = BeautifulSoup(content, 'html.parser')\nreviews_container = soup.find('div', {'class': '_1YokD2 _3Mn1Gg col-9-12'})\nreview_divs = reviews_container.find_all('div', {'class': 't-ZTKy'})\nreviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()\n    reviews.append(text)\n# Save the reviews to an Excel file in current directory\ndata = pd.DataFrame({'review': reviews})",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "reviews_container",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "reviews_container = soup.find('div', {'class': '_1YokD2 _3Mn1Gg col-9-12'})\nreview_divs = reviews_container.find_all('div', {'class': 't-ZTKy'})\nreviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()\n    reviews.append(text)\n# Save the reviews to an Excel file in current directory\ndata = pd.DataFrame({'review': reviews})\ndata.to_excel('reviews.xlsx', index=False)",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "review_divs",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "review_divs = reviews_container.find_all('div', {'class': 't-ZTKy'})\nreviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()\n    reviews.append(text)\n# Save the reviews to an Excel file in current directory\ndata = pd.DataFrame({'review': reviews})\ndata.to_excel('reviews.xlsx', index=False)\ndef sentiment_Vader(text):",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "reviews",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "reviews = []\nfor child in review_divs:\n    third_div = child.div.div\n    text = third_div.text.strip()\n    reviews.append(text)\n# Save the reviews to an Excel file in current directory\ndata = pd.DataFrame({'review': reviews})\ndata.to_excel('reviews.xlsx', index=False)\ndef sentiment_Vader(text):\n    over_all_polarity = sid.polarity_scores(text)",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "data = pd.DataFrame({'review': reviews})\ndata.to_excel('reviews.xlsx', index=False)\ndef sentiment_Vader(text):\n    over_all_polarity = sid.polarity_scores(text)\n    if over_all_polarity['compound'] >= 0.05:\n        return \"positive\"\n    elif over_all_polarity['compound'] <= -0.05:\n        return \"negative\"\n    else:\n        return \"neutral\"",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "sid",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "sid = SentimentIntensityAnalyzer()\ndata['polarity'] = data['review'].apply(lambda review: sentiment_Vader(review))\nresult_data = data.to_excel('G:/DS Programs/WebScrapingEnv/sentiment_result.xlsx')",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "data['polarity']",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "data['polarity'] = data['review'].apply(lambda review: sentiment_Vader(review))\nresult_data = data.to_excel('G:/DS Programs/WebScrapingEnv/sentiment_result.xlsx')",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "result_data",
        "kind": 5,
        "importPath": "docs.Sentiment-Analysis-Using-Vader",
        "description": "docs.Sentiment-Analysis-Using-Vader",
        "peekOfCode": "result_data = data.to_excel('G:/DS Programs/WebScrapingEnv/sentiment_result.xlsx')",
        "detail": "docs.Sentiment-Analysis-Using-Vader",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.Stock_Market_prediction",
        "description": "docs.Stock_Market_prediction",
        "peekOfCode": "def main(ticker_list, _wf):\n  import pandas as pd\n  mvo_df, env_kwargs, trade, processed_full, models = set_yahoo_data_frame(ticker_list, _wf)\n  def get_e_trade_gym_results():\n    data_risk_indicator = processed_full[(processed_full.date<wf.train_end_date) & (processed_full.date>= wf.train_start_date)]\n    insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n    st.write(f\"Vix Indicator: {insample_risk_indicator.vix.quantile(0.996)}\")\n    st.write(insample_risk_indicator.vix.describe())\n    st.write(insample_risk_indicator.turbulence.describe())\n    st.write(insample_risk_indicator.turbulence.quantile(0.996))",
        "detail": "docs.Stock_Market_prediction",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "docs.news",
        "description": "docs.news",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"  # Use Alpaca paper trading for testing\nALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\",\n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\",\n    \"PAPER\": True\n}\n# List of DJI 30 stocks\nDJI_30_SYMBOLS = [\n    \"AAPL\", \"MSFT\", \"JPM\", \"JNJ\", \"V\", \"UNH\", \"PG\", \"HD\", \"DIS\", \"INTC\",\n    \"WMT\", \"IBM\", \"MMM\", \"KO\", \"MRK\", \"NKE\", \"PFE\", \"TRV\", \"CSCO\", \"AXP\",",
        "detail": "docs.news",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "docs.news",
        "description": "docs.news",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\",\n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\",\n    \"PAPER\": True\n}\n# List of DJI 30 stocks\nDJI_30_SYMBOLS = [\n    \"AAPL\", \"MSFT\", \"JPM\", \"JNJ\", \"V\", \"UNH\", \"PG\", \"HD\", \"DIS\", \"INTC\",\n    \"WMT\", \"IBM\", \"MMM\", \"KO\", \"MRK\", \"NKE\", \"PFE\", \"TRV\", \"CSCO\", \"AXP\",\n    \"VZ\", \"BA\", \"CVX\", \"XOM\", \"CAT\", \"MCD\", \"GS\", \"WBA\", \"DOW\", \"AMGN\", \"SPY\"",
        "detail": "docs.news",
        "documentation": {}
    },
    {
        "label": "DJI_30_SYMBOLS",
        "kind": 5,
        "importPath": "docs.news",
        "description": "docs.news",
        "peekOfCode": "DJI_30_SYMBOLS = [\n    \"AAPL\", \"MSFT\", \"JPM\", \"JNJ\", \"V\", \"UNH\", \"PG\", \"HD\", \"DIS\", \"INTC\",\n    \"WMT\", \"IBM\", \"MMM\", \"KO\", \"MRK\", \"NKE\", \"PFE\", \"TRV\", \"CSCO\", \"AXP\",\n    \"VZ\", \"BA\", \"CVX\", \"XOM\", \"CAT\", \"MCD\", \"GS\", \"WBA\", \"DOW\", \"AMGN\", \"SPY\"\n]\n# Streamlit app title\nst.title(\"Sentiment-Based Trading Bot with Live Trading\")\n# Initialize Alpaca REST API\napi = REST(\n    key_id=ALPACA_CREDS[\"API_KEY\"],",
        "detail": "docs.news",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "docs.news",
        "description": "docs.news",
        "peekOfCode": "api = REST(\n    key_id=ALPACA_CREDS[\"API_KEY\"],\n    secret_key=ALPACA_CREDS[\"API_SECRET\"],\n    base_url=BASE_URL\n)\n# Default dates for date inputs\ntoday = datetime.now()\nthree_days_ago = today - timedelta(days=3)\n# Create a row with symbol selection and date inputs\nst.subheader(\"News and Date Selection\")",
        "detail": "docs.news",
        "documentation": {}
    },
    {
        "label": "today",
        "kind": 5,
        "importPath": "docs.news",
        "description": "docs.news",
        "peekOfCode": "today = datetime.now()\nthree_days_ago = today - timedelta(days=3)\n# Create a row with symbol selection and date inputs\nst.subheader(\"News and Date Selection\")\ncol1, col2, col3 = st.columns([1, 1, 1])\n# Symbol selection in the first column\nwith col1:\n    symbol = st.selectbox(\"Select Symbol for News\", DJI_30_SYMBOLS, index=DJI_30_SYMBOLS.index(\"SPY\"))\n# Start date input in the second column\nwith col2:",
        "detail": "docs.news",
        "documentation": {}
    },
    {
        "label": "three_days_ago",
        "kind": 5,
        "importPath": "docs.news",
        "description": "docs.news",
        "peekOfCode": "three_days_ago = today - timedelta(days=3)\n# Create a row with symbol selection and date inputs\nst.subheader(\"News and Date Selection\")\ncol1, col2, col3 = st.columns([1, 1, 1])\n# Symbol selection in the first column\nwith col1:\n    symbol = st.selectbox(\"Select Symbol for News\", DJI_30_SYMBOLS, index=DJI_30_SYMBOLS.index(\"SPY\"))\n# Start date input in the second column\nwith col2:\n    start_date = st.date_input(\"Start Date\", value=three_days_ago)",
        "detail": "docs.news",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "class MLTrader(): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5):\n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api =REST(key_id=ALPACA_CREDS[\"API_KEY\"], secret_key=ALPACA_CREDS[\"API_SECRET\"],base_url=BASE_URL)\n        st.write(f\"Cash at risk: {self.cash_at_risk}\")\n    def position_sizing(self): \n        # cash = self.get_cash() ",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nimport yfinance as yf\nfrom lib.MLTradingBot.finbert_utils import estimate_sentiment\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()\n# print(analyzer.polarity_scores(\"This is a great day!\"))\ncustom_css = \"\"\"\n<style>",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "analyzer = SentimentIntensityAnalyzer()\n# print(analyzer.polarity_scores(\"This is a great day!\"))\ncustom_css = \"\"\"\n<style>\nbody {\nbackground-color: black; /* Background color (black) */\nfont-family: \"Times New Roman\", Times, serif; /* Font family (Times New Roman) */\ncolor: white; /* Text color (white) */\nline-height: 1.6; /* Line height for readability */\n}",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "custom_css",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "custom_css = \"\"\"\n<style>\nbody {\nbackground-color: black; /* Background color (black) */\nfont-family: \"Times New Roman\", Times, serif; /* Font family (Times New Roman) */\ncolor: white; /* Text color (white) */\nline-height: 1.6; /* Line height for readability */\n}\nh1 {\ncolor: #3498db; /* Heading color (light blue) */",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", \n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\", \n    \"PAPER\": True\n}\nexample_ticker_symbols = [\"SPY\",\n\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\",\n\"JPM\", \"NFLX\", \"FB\", \"BRK.B\", \"V\",\n\"NVDA\", \"DIS\", \"BA\", \"IBM\", \"GE\",",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", \n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\", \n    \"PAPER\": True\n}\nexample_ticker_symbols = [\"SPY\",\n\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\",\n\"JPM\", \"NFLX\", \"FB\", \"BRK.B\", \"V\",\n\"NVDA\", \"DIS\", \"BA\", \"IBM\", \"GE\",\n\"PG\", \"JNJ\", \"KO\", \"MCD\", \"T\",",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "example_ticker_symbols",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "example_ticker_symbols = [\"SPY\",\n\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\",\n\"JPM\", \"NFLX\", \"FB\", \"BRK.B\", \"V\",\n\"NVDA\", \"DIS\", \"BA\", \"IBM\", \"GE\",\n\"PG\", \"JNJ\", \"KO\", \"MCD\", \"T\",\n\"ADBE\", \"CRM\", \"INTC\", \"ORCL\", \"HD\"\n]\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# Use a selectbox to allow users to choose from example ticker symbols",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "ticker",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "ticker = st.selectbox(\"Select a stock ticker symbol or enter your own:\", example_ticker_symbols)\n# User inputs\n# symbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\ndata = {\n    \"date\": pd.date_range(start=start_date, end=end_date),\n    \"news\": [f\"Sample headline for {ticker} on day {i}\" for i in range(len(pd.date_range(start=start_date, end=end_date)))],\n}",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "start_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\ndata = {\n    \"date\": pd.date_range(start=start_date, end=end_date),\n    \"news\": [f\"Sample headline for {ticker} on day {i}\" for i in range(len(pd.date_range(start=start_date, end=end_date)))],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(\"Performing sentiment analysis...\")",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "end_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\ndata = {\n    \"date\": pd.date_range(start=start_date, end=end_date),\n    \"news\": [f\"Sample headline for {ticker} on day {i}\" for i in range(len(pd.date_range(start=start_date, end=end_date)))],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(\"Performing sentiment analysis...\")\naa = analyzer.polarity_scores(\"This is a great day!\")",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "sentiment_threshold",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "sentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\ndata = {\n    \"date\": pd.date_range(start=start_date, end=end_date),\n    \"news\": [f\"Sample headline for {ticker} on day {i}\" for i in range(len(pd.date_range(start=start_date, end=end_date)))],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(\"Performing sentiment analysis...\")\naa = analyzer.polarity_scores(\"This is a great day!\")\nst.write(f\"This is a great day! {aa}\")",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "data = {\n    \"date\": pd.date_range(start=start_date, end=end_date),\n    \"news\": [f\"Sample headline for {ticker} on day {i}\" for i in range(len(pd.date_range(start=start_date, end=end_date)))],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(\"Performing sentiment analysis...\")\naa = analyzer.polarity_scores(\"This is a great day!\")\nst.write(f\"This is a great day! {aa}\")\nst.write(df)",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "df = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(\"Performing sentiment analysis...\")\naa = analyzer.polarity_scores(\"This is a great day!\")\nst.write(f\"This is a great day! {aa}\")\nst.write(df)\nst.line_chart(df[\"sentiment\"])\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    sentiment_threshold = -1 ",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "df[\"sentiment\"]",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "df[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(\"Performing sentiment analysis...\")\naa = analyzer.polarity_scores(\"This is a great day!\")\nst.write(f\"This is a great day! {aa}\")\nst.write(df)\nst.line_chart(df[\"sentiment\"])\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    sentiment_threshold = -1 \n    for index, row in df.iterrows():",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "aa",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "aa = analyzer.polarity_scores(\"This is a great day!\")\nst.write(f\"This is a great day! {aa}\")\nst.write(df)\nst.line_chart(df[\"sentiment\"])\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    sentiment_threshold = -1 \n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {ticker} on {row['date']} (Sentiment: {row['sentiment']})\")",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "strat",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "strat = MLTrader()\nstrat.initialize(ticker, 0.5)\nstrat.on_trading_iteration()\n# ====================\nnews_tables = {}\nif ticker:\n      #Fetching stock price data\n            current_date = datetime.now().strftime(\"%Y-%m-%d\")\n            stock_data = yf.download(ticker, start=\"2000-01-01\", end=current_date)\n            finviz_url = \"https://finviz.com/quote.ashx?t=\"",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "news_tables",
        "kind": 5,
        "importPath": "docs.senti_all",
        "description": "docs.senti_all",
        "peekOfCode": "news_tables = {}\nif ticker:\n      #Fetching stock price data\n            current_date = datetime.now().strftime(\"%Y-%m-%d\")\n            stock_data = yf.download(ticker, start=\"2000-01-01\", end=current_date)\n            finviz_url = \"https://finviz.com/quote.ashx?t=\"\n            url = finviz_url + ticker\n            req = Request(url=url, headers={\"user-agent\": \"my-app\"})\n            response = urlopen(req)\n            html = BeautifulSoup(response, features=\"html.parser\")",
        "detail": "docs.senti_all",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "docs.utils",
        "description": "docs.utils",
        "peekOfCode": "ALPACA_API_KEY = \"PKVD6WOSPEMKS0UI6A3K\"\nALPACA_API_SECRET  = \"BxT64PIQtDBb*tnW\"\nALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'",
        "detail": "docs.utils",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "docs.utils",
        "description": "docs.utils",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'",
        "detail": "docs.utils",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "extensions = ['sphinx.ext.autodoc', 'sphinx.ext.githubpages',\n              'sphinx.ext.napoleon']\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n# The master toctree document.",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "templates_path = ['_templates']\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n# The master toctree document.\nmaster_doc = 'index'\n# General information about the project.\nproject = 'empyrical'",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "source_suffix",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "source_suffix = '.rst'\n# The master toctree document.\nmaster_doc = 'index'\n# General information about the project.\nproject = 'empyrical'\ncopyright = '2018, Quantopian'\nauthor = 'Quantopian'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "master_doc",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "master_doc = 'index'\n# General information about the project.\nproject = 'empyrical'\ncopyright = '2018, Quantopian'\nauthor = 'Quantopian'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "project = 'empyrical'\ncopyright = '2018, Quantopian'\nauthor = 'Quantopian'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nver = empyrical.__version__\nversion = ver[:ver.find('+')]  # get only the main part of the version",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "copyright = '2018, Quantopian'\nauthor = 'Quantopian'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nver = empyrical.__version__\nversion = ver[:ver.find('+')]  # get only the main part of the version\n# The full version, including alpha/beta/rc tags.",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "author",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "author = 'Quantopian'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nver = empyrical.__version__\nversion = ver[:ver.find('+')]  # get only the main part of the version\n# The full version, including alpha/beta/rc tags.\nrelease = version",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "ver",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "ver = empyrical.__version__\nversion = ver[:ver.find('+')]  # get only the main part of the version\n# The full version, including alpha/beta/rc tags.\nrelease = version\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "version = ver[:ver.find('+')]  # get only the main part of the version\n# The full version, including alpha/beta/rc tags.\nrelease = version\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "release",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "release = version\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "language",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "language = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store', '**tests**']\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n# -- Options for HTML output ----------------------------------------------",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "exclude_patterns",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store', '**tests**']\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n# -- Options for HTML output ----------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = 'default'",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "pygments_style = 'sphinx'\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n# -- Options for HTML output ----------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = 'default'\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "todo_include_todos",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "todo_include_todos = False\n# -- Options for HTML output ----------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = 'default'\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "html_theme = 'default'\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_static_path",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "html_static_path = ['_static']\n# -- Options for HTMLHelp output ------------------------------------------\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'empyricaldoc'\n# -- Options for LaTeX output ---------------------------------------------\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "htmlhelp_basename",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "htmlhelp_basename = 'empyricaldoc'\n# -- Options for LaTeX output ---------------------------------------------\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "latex_elements",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "latex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "latex_documents",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "latex_documents = [\n    (master_doc, 'empyrical.tex', 'empyrical Documentation',\n     'Quontopian', 'manual'),\n]\n# -- Options for manual page output ---------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, 'empyrical', 'empyrical Documentation',\n     [author], 1)",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "man_pages",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "man_pages = [\n    (master_doc, 'empyrical', 'empyrical Documentation',\n     [author], 1)\n]\n# -- Options for Texinfo output -------------------------------------------\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, 'empyrical', 'empyrical Documentation',",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "texinfo_documents",
        "kind": 5,
        "importPath": "empyrical.docs.conf",
        "description": "empyrical.docs.conf",
        "peekOfCode": "texinfo_documents = [\n    (master_doc, 'empyrical', 'empyrical Documentation',\n     author, 'empyrical', 'One line description of project.',\n     'Miscellaneous'),\n]",
        "detail": "empyrical.docs.conf",
        "documentation": {}
    },
    {
        "label": "PerfAttribTestCase",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_perf_attrib",
        "description": "empyrical.empyrical.tests.test_perf_attrib",
        "peekOfCode": "class PerfAttribTestCase(unittest.TestCase):\n    def test_perf_attrib_simple(self):\n        start_date = '2017-01-01'\n        periods = 2\n        dts = pd.date_range(start_date, periods=periods)\n        dts.name = 'dt'\n        tickers = ['stock1', 'stock2']\n        styles = ['risk_factor1', 'risk_factor2']\n        returns = pd.Series(data=[0.1, 0.1], index=dts)\n        factor_returns = pd.DataFrame(",
        "detail": "empyrical.empyrical.tests.test_perf_attrib",
        "documentation": {}
    },
    {
        "label": "BaseTestCase",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class BaseTestCase(TestCase):\n    def assert_indexes_match(self, result, expected):\n        \"\"\"\n        Assert that two pandas objects have the same indices.\n        This is a method instead of a free function so that we can override it\n        to be a no-op in suites like TestStatsArrays that unwrap pandas objects\n        into ndarrays.\n        \"\"\"\n        assert_index_equal(result.index, expected.index)\n        if isinstance(result, pd.DataFrame) and \\",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "TestStats",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class TestStats(BaseTestCase):\n    # Simple benchmark, no drawdown\n    simple_benchmark = pd.Series(\n        np.array([0., 1., 0., 1., 0., 1., 0., 1., 0.]) / 100,\n        index=pd.date_range('2000-1-30', periods=9, freq='D'))\n    # All positive returns, small variance\n    positive_returns = pd.Series(\n        np.array([1., 2., 1., 1., 1., 1., 1., 1., 1.]) / 100,\n        index=pd.date_range('2000-1-30', periods=9, freq='D'))\n    # All negative returns",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "TestStatsArrays",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class TestStatsArrays(TestStats):\n    \"\"\"\n    Tests pass np.ndarray inputs to empyrical and assert that outputs are of\n    type np.ndarray or float.\n    \"\"\"\n    @property\n    def empyrical(self):\n        return PassArraysEmpyricalProxy(self, (np.ndarray, float))\n    def assert_indexes_match(self, result, expected):\n        pass",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "TestStatsIntIndex",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class TestStatsIntIndex(TestStats):\n    \"\"\"\n    Tests pass int-indexed pd.Series inputs to empyrical and assert that\n    outputs are of type pd.Series or float.\n    This prevents a regression where we're indexing with ints into a pd.Series\n    to find the last item and get a KeyError when the series is int-indexed.\n    \"\"\"\n    @property\n    def empyrical(self):\n        return ConvertPandasEmpyricalProxy(",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "TestHelpers",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class TestHelpers(BaseTestCase):\n    \"\"\"\n    Tests for helper methods and utils.\n    \"\"\"\n    def setUp(self):\n        self.ser_length = 120\n        self.window = 12\n        self.returns = pd.Series(\n            rand.randn(1, 120)[0]/100.,\n            index=pd.date_range('2000-1-30', periods=120, freq='M'))",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "Test2DStats",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class Test2DStats(BaseTestCase):\n    \"\"\"\n    Tests for functions that are capable of outputting a DataFrame.\n    \"\"\"\n    input_one = [np.nan, 0.01322056, 0.03063862, -0.01422057,\n                 -0.00489779, 0.01268925, -0.03357711, 0.01797036]\n    input_two = [0.01846232, 0.00793951, -0.01448395, 0.00422537,\n                 -0.00339611, 0.03756813, 0.0151531, np.nan]\n    expected_0_one = [0.000000, 0.013221, 0.044264, 0.029414, 0.024372,\n                      0.037371, 0.002539, 0.020555]",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "Test2DStatsArrays",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class Test2DStatsArrays(Test2DStats):\n    \"\"\"\n    Tests pass np.ndarray inputs to empyrical and assert that outputs are of\n    type np.ndarray.\n    \"\"\"\n    @property\n    def empyrical(self):\n        return PassArraysEmpyricalProxy(self, np.ndarray)\n    def assert_indexes_match(self, result, expected):\n        pass",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "ReturnTypeEmpyricalProxy",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class ReturnTypeEmpyricalProxy(object):\n    \"\"\"\n    A wrapper around the empyrical module which, on each function call, asserts\n    that the type of the return value is in a given set.\n    Also asserts that inputs were not modified by the empyrical function call.\n    Calling an instance with kwargs will return a new copy with those\n    attributes overridden.\n    \"\"\"\n    def __init__(self, test_case, return_types):\n        self._test_case = test_case",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "ConvertPandasEmpyricalProxy",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class ConvertPandasEmpyricalProxy(ReturnTypeEmpyricalProxy):\n    \"\"\"\n    A ReturnTypeEmpyricalProxy which also converts pandas NDFrame inputs to\n    empyrical functions according to the given conversion method.\n    Calling an instance with a truthy pandas_only will return a new instance\n    which will skip the test when an empyrical function is called.\n    \"\"\"\n    def __init__(self, test_case, return_types, convert, pandas_only=False):\n        super(ConvertPandasEmpyricalProxy, self).__init__(test_case,\n                                                          return_types)",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "PassArraysEmpyricalProxy",
        "kind": 6,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "class PassArraysEmpyricalProxy(ConvertPandasEmpyricalProxy):\n    \"\"\"\n    A ConvertPandasEmpyricalProxy which converts NDFrame inputs to empyrical\n    functions to numpy arrays.\n    Calls the underlying\n    empyrical.[alpha|beta|alpha_beta]_aligned functions directly, instead of\n    the wrappers which align Series first.\n    \"\"\"\n    def __init__(self, test_case, return_types):\n        super(PassArraysEmpyricalProxy, self).__init__(",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "DECIMAL_PLACES",
        "kind": 5,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "DECIMAL_PLACES = 8\nrand = np.random.RandomState(1337)\nclass BaseTestCase(TestCase):\n    def assert_indexes_match(self, result, expected):\n        \"\"\"\n        Assert that two pandas objects have the same indices.\n        This is a method instead of a free function so that we can override it\n        to be a no-op in suites like TestStatsArrays that unwrap pandas objects\n        into ndarrays.\n        \"\"\"",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "rand",
        "kind": 5,
        "importPath": "empyrical.empyrical.tests.test_stats",
        "description": "empyrical.empyrical.tests.test_stats",
        "peekOfCode": "rand = np.random.RandomState(1337)\nclass BaseTestCase(TestCase):\n    def assert_indexes_match(self, result, expected):\n        \"\"\"\n        Assert that two pandas objects have the same indices.\n        This is a method instead of a free function so that we can override it\n        to be a no-op in suites like TestStatsArrays that unwrap pandas objects\n        into ndarrays.\n        \"\"\"\n        assert_index_equal(result.index, expected.index)",
        "detail": "empyrical.empyrical.tests.test_stats",
        "documentation": {}
    },
    {
        "label": "VersioneerConfig",
        "kind": 6,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "class VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\ndef get_config():\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "NotThisMethod",
        "kind": 6,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "class NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\nLONG_VERSION_PY = {}\nHANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "get_keywords",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def get_keywords():\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"$Format:%d$\"\n    git_full = \"$Format:%H$\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full}\n    return keywords",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "get_config",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def get_config():\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"empyrical-\"\n    cfg.versionfile_source = \"empyrical/_version.py\"",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "register_vcs_handler",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "versions_from_parentdir",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n    Source tarballs conventionally unpack into a directory that includes\n    both the project name and a version string.\n    \"\"\"\n    dirname = os.path.basename(root)\n    if not dirname.startswith(parentdir_prefix):\n        if verbose:\n            print(\"guessing rootdir is '%s', but '%s' doesn't start with \"\n                  \"prefix '%s'\" % (root, dirname, parentdir_prefix))",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "git_get_keywords",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def git_get_keywords(versionfile_abs):\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, \"r\")\n        for line in f.readlines():",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "git_versions_from_keywords",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "git_pieces_from_vcs",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    if not os.path.exists(os.path.join(root, \".git\")):\n        if verbose:\n            print(\"no .git in %s\" % root)\n        raise NotThisMethod(\"no .git directory\")",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "plus_or_dot",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\ndef render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n    Exceptions:",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render_pep440",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render_pep440_pre",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render_pep440_pre(pieces):\n    \"\"\"TAG[.post.devDISTANCE] -- No -dirty.\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post.dev%d\" % pieces[\"distance\"]\n    else:",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render_pep440_post",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render_pep440_post(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render_pep440_old",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render_pep440_old(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n    The \".dev0\" means dirty.\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render_git_describe",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render_git_describe(pieces):\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n    Like 'git describe --tags --dirty --always'.\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render_git_describe_long",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render_git_describe_long(pieces):\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "render",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def render(pieces, style):\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"]}\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n    if style == \"pep440\":",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "get_versions",
        "kind": 2,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "def get_versions():\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n    cfg = get_config()\n    verbose = cfg.verbose\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "LONG_VERSION_PY",
        "kind": 5,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "LONG_VERSION_PY = {}\nHANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "HANDLERS",
        "kind": 5,
        "importPath": "empyrical.empyrical._version",
        "description": "empyrical.empyrical._version",
        "peekOfCode": "HANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate",
        "detail": "empyrical.empyrical._version",
        "documentation": {}
    },
    {
        "label": "deprecated",
        "kind": 2,
        "importPath": "empyrical.empyrical.deprecate",
        "description": "empyrical.empyrical.deprecate",
        "peekOfCode": "def deprecated(msg=None, stacklevel=2):\n    \"\"\"\n    Used to mark a function as deprecated.\n    Parameters\n    ----------\n    msg : str\n        The message to display in the deprecation warning.\n    stacklevel : int\n        How far up the stack the warning needs to go, before\n        showing the relevant calling lines.",
        "detail": "empyrical.empyrical.deprecate",
        "documentation": {}
    },
    {
        "label": "perf_attrib",
        "kind": 2,
        "importPath": "empyrical.empyrical.perf_attrib",
        "description": "empyrical.empyrical.perf_attrib",
        "peekOfCode": "def perf_attrib(returns,\n                positions,\n                factor_returns,\n                factor_loadings):\n    \"\"\"\n    Attributes the performance of a returns stream to a set of risk factors.\n    Performance attribution determines how much each risk factor, e.g.,\n    momentum, the technology sector, etc., contributed to total returns, as\n    well as the daily exposure to each of the risk factors. The returns that\n    can be attributed to one of the given risk factors are the",
        "detail": "empyrical.empyrical.perf_attrib",
        "documentation": {}
    },
    {
        "label": "compute_exposures",
        "kind": 2,
        "importPath": "empyrical.empyrical.perf_attrib",
        "description": "empyrical.empyrical.perf_attrib",
        "peekOfCode": "def compute_exposures(positions, factor_loadings):\n    \"\"\"\n    Compute daily risk factor exposures.\n    Parameters\n    ----------\n    positions: pd.Series\n        A series of holdings as percentages indexed by date and ticker.\n        - Examples:\n            dt          ticker\n            2017-01-01  AAPL      0.417582",
        "detail": "empyrical.empyrical.perf_attrib",
        "documentation": {}
    },
    {
        "label": "APPROX_BDAYS_PER_MONTH",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "APPROX_BDAYS_PER_MONTH = 21\nAPPROX_BDAYS_PER_YEAR = 252\nMONTHS_PER_YEAR = 12\nWEEKS_PER_YEAR = 52\nQTRS_PER_YEAR = 4\nDAILY = 'daily'\nWEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "APPROX_BDAYS_PER_YEAR",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "APPROX_BDAYS_PER_YEAR = 252\nMONTHS_PER_YEAR = 12\nWEEKS_PER_YEAR = 52\nQTRS_PER_YEAR = 4\nDAILY = 'daily'\nWEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "MONTHS_PER_YEAR",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "MONTHS_PER_YEAR = 12\nWEEKS_PER_YEAR = 52\nQTRS_PER_YEAR = 4\nDAILY = 'daily'\nWEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "WEEKS_PER_YEAR",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "WEEKS_PER_YEAR = 52\nQTRS_PER_YEAR = 4\nDAILY = 'daily'\nWEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "QTRS_PER_YEAR",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "QTRS_PER_YEAR = 4\nDAILY = 'daily'\nWEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "DAILY",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "DAILY = 'daily'\nWEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,\n    QUARTERLY: QTRS_PER_YEAR,",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "WEEKLY",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "WEEKLY = 'weekly'\nMONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,\n    QUARTERLY: QTRS_PER_YEAR,\n    YEARLY: 1",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "MONTHLY",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "MONTHLY = 'monthly'\nQUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,\n    QUARTERLY: QTRS_PER_YEAR,\n    YEARLY: 1\n}",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "QUARTERLY",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "QUARTERLY = 'quarterly'\nYEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,\n    QUARTERLY: QTRS_PER_YEAR,\n    YEARLY: 1\n}",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "YEARLY",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "YEARLY = 'yearly'\nANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,\n    QUARTERLY: QTRS_PER_YEAR,\n    YEARLY: 1\n}",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "ANNUALIZATION_FACTORS",
        "kind": 5,
        "importPath": "empyrical.empyrical.periods",
        "description": "empyrical.empyrical.periods",
        "peekOfCode": "ANNUALIZATION_FACTORS = {\n    DAILY: APPROX_BDAYS_PER_YEAR,\n    WEEKLY: WEEKS_PER_YEAR,\n    MONTHLY: MONTHS_PER_YEAR,\n    QUARTERLY: QTRS_PER_YEAR,\n    YEARLY: 1\n}",
        "detail": "empyrical.empyrical.periods",
        "documentation": {}
    },
    {
        "label": "annualization_factor",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def annualization_factor(period, annualization):\n    \"\"\"\n    Return annualization factor from period entered or if a custom\n    value is passed in.\n    Parameters\n    ----------\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "simple_returns",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def simple_returns(prices):\n    \"\"\"\n    Compute simple returns from a timeseries of prices.\n    Parameters\n    ----------\n    prices : pd.Series, pd.DataFrame or np.ndarray\n        Prices of assets in wide-format, with assets as columns,\n        and indexed by datetimes.\n    Returns\n    -------",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "cum_returns",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def cum_returns(returns, starting_value=0, out=None):\n    \"\"\"\n    Compute cumulative returns from simple returns.\n    Parameters\n    ----------\n    returns : pd.Series, np.ndarray, or pd.DataFrame\n        Returns of the strategy as a percentage, noncumulative.\n         - Time series with decimal returns.\n         - Example::\n            2015-07-16   -0.012143",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "cum_returns_final",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def cum_returns_final(returns, starting_value=0):\n    \"\"\"\n    Compute total returns from simple returns.\n    Parameters\n    ----------\n    returns : pd.DataFrame, pd.Series, or np.ndarray\n       Noncumulative simple returns of one or more timeseries.\n    starting_value : float, optional\n       The starting returns.\n    Returns",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "aggregate_returns",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def aggregate_returns(returns, convert_to):\n    \"\"\"\n    Aggregates returns by week, month, or year.\n    Parameters\n    ----------\n    returns : pd.Series\n       Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    convert_to : str\n        Can be 'weekly', 'monthly', or 'yearly'.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "max_drawdown",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def max_drawdown(returns, out=None):\n    \"\"\"\n    Determines the maximum drawdown of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    out : array-like, optional\n        Array to use as output buffer.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "annual_return",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def annual_return(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Determines the mean annual growth rate of returns. This is equivilent\n    to the compound annual growth rate.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Periodic returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    period : str, optional",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "cagr",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def cagr(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Compute compound annual growth rate. Alias function for\n    :func:`~empyrical.stats.annual_return`\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    period : str, optional",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "annual_volatility",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def annual_volatility(returns,\n                      period=DAILY,\n                      alpha=2.0,\n                      annualization=None,\n                      out=None):\n    \"\"\"\n    Determines the annual volatility of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "calmar_ratio",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def calmar_ratio(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Determines the Calmar ratio, or drawdown ratio, of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "omega_ratio",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def omega_ratio(returns, risk_free=0.0, required_return=0.0,\n                annualization=APPROX_BDAYS_PER_YEAR):\n    \"\"\"Determines the Omega ratio of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    risk_free : int, float\n        Constant risk-free return throughout the period",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "sharpe_ratio",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def sharpe_ratio(returns,\n                 risk_free=0,\n                 period=DAILY,\n                 annualization=None,\n                 out=None):\n    \"\"\"\n    Determines the Sharpe ratio of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "sortino_ratio",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def sortino_ratio(returns,\n                  required_return=0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None,\n                  _downside_risk=None):\n    \"\"\"\n    Determines the Sortino ratio of a strategy.\n    Parameters\n    ----------",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "downside_risk",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def downside_risk(returns,\n                  required_return=0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None):\n    \"\"\"\n    Determines the downside deviation below a threshold\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray or pd.DataFrame",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "excess_sharpe",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def excess_sharpe(returns, factor_returns, out=None):\n    \"\"\"\n    Determines the Excess Sharpe of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns: float / series\n        Benchmark return to compare returns against.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "alpha_beta",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def alpha_beta(returns,\n               factor_returns,\n               risk_free=0.0,\n               period=DAILY,\n               annualization=None,\n               out=None):\n    \"\"\"Calculates annualized alpha and beta.\n    Parameters\n    ----------\n    returns : pd.Series",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_alpha_beta",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def roll_alpha_beta(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes alpha and beta over a rolling window.\n    Parameters\n    ----------\n    lhs : array-like\n        The first array to pass to the rolling alpha-beta.\n    rhs : array-like\n        The second array to pass to the rolling alpha-beta.\n    window : int",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "alpha_beta_aligned",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def alpha_beta_aligned(returns,\n                       factor_returns,\n                       risk_free=0.0,\n                       period=DAILY,\n                       annualization=None,\n                       out=None):\n    \"\"\"Calculates annualized alpha and beta.\n    If they are pd.Series, expects returns and factor_returns have already\n    been aligned on their labels.  If np.ndarray, these arguments should have\n    the same shape.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "alpha",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def alpha(returns,\n          factor_returns,\n          risk_free=0.0,\n          period=DAILY,\n          annualization=None,\n          out=None,\n          _beta=None):\n    \"\"\"Calculates annualized alpha.\n    Parameters\n    ----------",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "alpha_aligned",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def alpha_aligned(returns,\n                  factor_returns,\n                  risk_free=0.0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None,\n                  _beta=None):\n    \"\"\"Calculates annualized alpha.\n    If they are pd.Series, expects returns and factor_returns have already\n    been aligned on their labels.  If np.ndarray, these arguments should have",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "beta",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def beta(returns, factor_returns, risk_free=0.0, out=None):\n    \"\"\"Calculates beta.\n    Parameters\n    ----------\n    returns : pd.Series\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series\n         Daily noncumulative returns of the factor to which beta is\n         computed. Usually a benchmark such as the market.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "beta_aligned",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def beta_aligned(returns, factor_returns, risk_free=0.0, out=None):\n    \"\"\"Calculates beta.\n    If they are pd.Series, expects returns and factor_returns have already\n    been aligned on their labels.  If np.ndarray, these arguments should have\n    the same shape.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "stability_of_timeseries",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def stability_of_timeseries(returns):\n    \"\"\"Determines R-squared of a linear fit to the cumulative\n    log returns. Computes an ordinary least squares linear fit,\n    and returns R-squared.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    Returns",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "tail_ratio",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def tail_ratio(returns):\n    \"\"\"Determines the ratio between the right (95%) and left tail (5%).\n    For example, a ratio of 0.25 means that losses are four times\n    as bad as profits.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n         - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    Returns",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def capture(returns, factor_returns, period=DAILY):\n    \"\"\"Compute capture ratio.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "beta_fragility_heuristic",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def beta_fragility_heuristic(returns, factor_returns):\n    \"\"\"Estimate fragility to drops in beta.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n         Daily noncumulative returns of the factor to which beta is\n         computed. Usually a benchmark such as the market.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "beta_fragility_heuristic_aligned",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def beta_fragility_heuristic_aligned(returns, factor_returns):\n    \"\"\"Estimate fragility to drops in beta\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n         Daily noncumulative returns of the factor to which beta is\n         computed. Usually a benchmark such as the market.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_risk_estimates",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_risk_estimates(returns, var_p=0.01):\n    \"\"\"Estimate VaR and ES using the Generalized Pareto Distribution (GPD)\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    var_p : float\n        The percentile to use for estimating the VaR and ES\n    Returns",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_risk_estimates_aligned",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_risk_estimates_aligned(returns, var_p=0.01):\n    \"\"\"Estimate VaR and ES using the Generalized Pareto Distribution (GPD)\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    var_p : float\n        The percentile to use for estimating the VaR and ES\n    Returns",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_es_calculator",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_es_calculator(var_estimate, threshold, scale_param,\n                      shape_param):\n    result = 0\n    if ((1 - shape_param) != 0):\n        # this formula is from Gilli and Kellezi pg. 8\n        var_ratio = (var_estimate/(1 - shape_param))\n        param_ratio = ((scale_param - (shape_param * threshold)) /\n                       (1 - shape_param))\n        result = var_ratio + param_ratio\n    return result",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_var_calculator",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_var_calculator(threshold, scale_param, shape_param,\n                       probability, total_n, exceedance_n):\n    result = 0\n    if (exceedance_n > 0 and shape_param > 0):\n        # this formula is from Gilli and Kellezi pg. 12\n        param_ratio = scale_param / shape_param\n        prob_ratio = (total_n/exceedance_n) * probability\n        result = threshold + (param_ratio *\n                              (pow(prob_ratio, -shape_param) - 1))\n    return result",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood_minimizer_aligned",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood_minimizer_aligned(price_data):\n    result = [False, False]\n    DEFAULT_SCALE_PARAM = 1\n    DEFAULT_SHAPE_PARAM = 1\n    if (len(price_data) > 0):\n        gpd_loglikelihood_lambda = \\\n            gpd_loglikelihood_factory(price_data)\n        optimization_results = \\\n            optimize.minimize(gpd_loglikelihood_lambda,\n                              [DEFAULT_SCALE_PARAM,",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood_factory",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood_factory(price_data):\n    return lambda params: gpd_loglikelihood(params, price_data)\ndef gpd_loglikelihood(params, price_data):\n    if (params[1] != 0):\n        return -gpd_loglikelihood_scale_and_shape(params[0],\n                                                  params[1],\n                                                  price_data)\n    else:\n        return -gpd_loglikelihood_scale_only(params[0], price_data)\ndef gpd_loglikelihood_scale_and_shape_factory(price_data):",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood(params, price_data):\n    if (params[1] != 0):\n        return -gpd_loglikelihood_scale_and_shape(params[0],\n                                                  params[1],\n                                                  price_data)\n    else:\n        return -gpd_loglikelihood_scale_only(params[0], price_data)\ndef gpd_loglikelihood_scale_and_shape_factory(price_data):\n    # minimize a function of two variables requires a list of params\n    # we are expecting the lambda below to be called as follows:",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood_scale_and_shape_factory",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood_scale_and_shape_factory(price_data):\n    # minimize a function of two variables requires a list of params\n    # we are expecting the lambda below to be called as follows:\n    # parameters = [scale, shape]\n    # the final outer negative is added because scipy only minimizes\n    return lambda params: \\\n        -gpd_loglikelihood_scale_and_shape(params[0],\n                                           params[1],\n                                           price_data)\ndef gpd_loglikelihood_scale_and_shape(scale, shape, price_data):",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood_scale_and_shape",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood_scale_and_shape(scale, shape, price_data):\n    n = len(price_data)\n    result = -1 * float_info.max\n    if (scale != 0):\n        param_factor = shape / scale\n        if (shape != 0 and param_factor >= 0 and scale >= 0):\n            result = ((-n * np.log(scale)) -\n                      (((1 / shape) + 1) *\n                       (np.log((shape / scale * price_data) + 1)).sum()))\n    return result",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood_scale_only_factory",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood_scale_only_factory(price_data):\n    # the negative is added because scipy only minimizes\n    return lambda scale: \\\n        -gpd_loglikelihood_scale_only(scale, price_data)\ndef gpd_loglikelihood_scale_only(scale, price_data):\n    n = len(price_data)\n    data_sum = price_data.sum()\n    result = -1 * float_info.max\n    if (scale >= 0):\n        result = ((-n*np.log(scale)) - (data_sum/scale))",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "gpd_loglikelihood_scale_only",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def gpd_loglikelihood_scale_only(scale, price_data):\n    n = len(price_data)\n    data_sum = price_data.sum()\n    result = -1 * float_info.max\n    if (scale >= 0):\n        result = ((-n*np.log(scale)) - (data_sum/scale))\n    return result\ndef up_capture(returns, factor_returns, **kwargs):\n    \"\"\"\n    Compute the capture ratio for periods when the benchmark return is positive",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "up_capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def up_capture(returns, factor_returns, **kwargs):\n    \"\"\"\n    Compute the capture ratio for periods when the benchmark return is positive\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "down_capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def down_capture(returns, factor_returns, **kwargs):\n    \"\"\"\n    Compute the capture ratio for periods when the benchmark return is negative\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "up_down_capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def up_down_capture(returns, factor_returns, **kwargs):\n    \"\"\"\n    Computes the ratio of up_capture to down_capture.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "up_alpha_beta",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def up_alpha_beta(returns, factor_returns, **kwargs):\n    \"\"\"\n    Computes alpha and beta for periods when the benchmark return is positive.\n    Parameters\n    ----------\n    see documentation for `alpha_beta`.\n    Returns\n    -------\n    float\n        Alpha.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "down_alpha_beta",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def down_alpha_beta(returns, factor_returns, **kwargs):\n    \"\"\"\n    Computes alpha and beta for periods when the benchmark return is negative.\n    Parameters\n    ----------\n    see documentation for `alpha_beta`.\n    Returns\n    -------\n    alpha : float\n    beta : float",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_up_capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def roll_up_capture(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes the up capture measure over a rolling window.\n    see documentation for :func:`~empyrical.stats.up_capture`.\n    (pass all args, kwargs required)\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_down_capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def roll_down_capture(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes the down capture measure over a rolling window.\n    see documentation for :func:`~empyrical.stats.down_capture`.\n    (pass all args, kwargs required)\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_up_down_capture",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def roll_up_down_capture(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes the up/down capture measure over a rolling window.\n    see documentation for :func:`~empyrical.stats.up_down_capture`.\n    (pass all args, kwargs required)\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "value_at_risk",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def value_at_risk(returns, cutoff=0.05):\n    \"\"\"\n    Value at risk (VaR) of a returns stream.\n    Parameters\n    ----------\n    returns : pandas.Series or 1-D numpy.array\n        Non-cumulative daily returns.\n    cutoff : float, optional\n        Decimal representing the percentage cutoff for the bottom percentile of\n        returns. Defaults to 0.05.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "conditional_value_at_risk",
        "kind": 2,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "def conditional_value_at_risk(returns, cutoff=0.05):\n    \"\"\"\n    Conditional value at risk (CVaR) of a returns stream.\n    CVaR measures the expected single-day returns of an asset on that asset's\n    worst performing days, where \"worst-performing\" is defined as falling below\n    ``cutoff`` as a percentile of all daily returns.\n    Parameters\n    ----------\n    returns : pandas.Series or 1-D numpy.array\n        Non-cumulative daily returns.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_max_drawdown",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_max_drawdown = _create_unary_vectorized_roll_function(max_drawdown)\ndef annual_return(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Determines the mean annual growth rate of returns. This is equivilent\n    to the compound annual growth rate.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Periodic returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_cagr",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_cagr = _create_unary_vectorized_roll_function(cagr)\ndef annual_volatility(returns,\n                      period=DAILY,\n                      alpha=2.0,\n                      annualization=None,\n                      out=None):\n    \"\"\"\n    Determines the annual volatility of a strategy.\n    Parameters\n    ----------",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_annual_volatility",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_annual_volatility = _create_unary_vectorized_roll_function(\n    annual_volatility,\n)\ndef calmar_ratio(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Determines the Calmar ratio, or drawdown ratio, of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_sharpe_ratio",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_sharpe_ratio = _create_unary_vectorized_roll_function(sharpe_ratio)\ndef sortino_ratio(returns,\n                  required_return=0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None,\n                  _downside_risk=None):\n    \"\"\"\n    Determines the Sortino ratio of a strategy.\n    Parameters",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_sortino_ratio",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_sortino_ratio = _create_unary_vectorized_roll_function(sortino_ratio)\ndef downside_risk(returns,\n                  required_return=0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None):\n    \"\"\"\n    Determines the downside deviation below a threshold\n    Parameters\n    ----------",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_downsize_risk",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_downsize_risk = _create_unary_vectorized_roll_function(downside_risk)\ndef excess_sharpe(returns, factor_returns, out=None):\n    \"\"\"\n    Determines the Excess Sharpe of a strategy.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns: float / series",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_excess_sharpe",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_excess_sharpe = _create_binary_vectorized_roll_function(excess_sharpe)\ndef _to_pandas(ob):\n    \"\"\"Convert an array-like to a pandas object.\n    Parameters\n    ----------\n    ob : array-like\n        The object to convert.\n    Returns\n    -------\n    pandas_structure : pd.Series or pd.DataFrame",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_alpha_beta_aligned",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_alpha_beta_aligned = _create_binary_vectorized_roll_function(\n    alpha_beta_aligned,\n)\ndef alpha(returns,\n          factor_returns,\n          risk_free=0.0,\n          period=DAILY,\n          annualization=None,\n          out=None,\n          _beta=None):",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_alpha",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_alpha = _create_binary_vectorized_roll_function(alpha)\ndef alpha_aligned(returns,\n                  factor_returns,\n                  risk_free=0.0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None,\n                  _beta=None):\n    \"\"\"Calculates annualized alpha.\n    If they are pd.Series, expects returns and factor_returns have already",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_alpha_aligned",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_alpha_aligned = _create_binary_vectorized_roll_function(alpha_aligned)\ndef beta(returns, factor_returns, risk_free=0.0, out=None):\n    \"\"\"Calculates beta.\n    Parameters\n    ----------\n    returns : pd.Series\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series\n         Daily noncumulative returns of the factor to which beta is",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_beta",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_beta = _create_binary_vectorized_roll_function(beta)\ndef beta_aligned(returns, factor_returns, risk_free=0.0, out=None):\n    \"\"\"Calculates beta.\n    If they are pd.Series, expects returns and factor_returns have already\n    been aligned on their labels.  If np.ndarray, these arguments should have\n    the same shape.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll_beta_aligned",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "roll_beta_aligned = _create_binary_vectorized_roll_function(beta_aligned)\ndef stability_of_timeseries(returns):\n    \"\"\"Determines R-squared of a linear fit to the cumulative\n    log returns. Computes an ordinary least squares linear fit,\n    and returns R-squared.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "SIMPLE_STAT_FUNCS",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "SIMPLE_STAT_FUNCS = [\n    cum_returns_final,\n    annual_return,\n    annual_volatility,\n    sharpe_ratio,\n    calmar_ratio,\n    stability_of_timeseries,\n    max_drawdown,\n    omega_ratio,\n    sortino_ratio,",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "FACTOR_STAT_FUNCS",
        "kind": 5,
        "importPath": "empyrical.empyrical.stats",
        "description": "empyrical.empyrical.stats",
        "peekOfCode": "FACTOR_STAT_FUNCS = [\n    excess_sharpe,\n    alpha,\n    beta,\n    beta_fragility_heuristic,\n    gpd_risk_estimates,\n    capture,\n    up_capture,\n    down_capture\n]",
        "detail": "empyrical.empyrical.stats",
        "documentation": {}
    },
    {
        "label": "roll",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def roll(*args, **kwargs):\n    \"\"\"\n    Calculates a given statistic across a rolling time period.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns (optional): float / series\n        Benchmark return to compare returns against.",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "up",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def up(returns, factor_returns, **kwargs):\n    \"\"\"\n    Calculates a given statistic filtering only positive factor return periods.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns (optional): float / series\n        Benchmark return to compare returns against.",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "down",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def down(returns, factor_returns, **kwargs):\n    \"\"\"\n    Calculates a given statistic filtering only negative factor return periods.\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns (optional): float / series\n        Benchmark return to compare returns against.",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "cache_dir",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def cache_dir(environ=environ):\n    try:\n        return environ['EMPYRICAL_CACHE_DIR']\n    except KeyError:\n        return join(\n            environ.get(\n                'XDG_CACHE_HOME',\n                expanduser('~/.cache/'),\n            ),\n            'empyrical',",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "data_path",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def data_path(name):\n    return join(cache_dir(), name)\n@deprecated(msg=DATAREADER_DEPRECATION_WARNING)\ndef ensure_directory(path):\n    \"\"\"\n    Ensure that a directory named \"path\" exists.\n    \"\"\"\n    try:\n        makedirs(path)\n    except OSError as exc:",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "ensure_directory",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def ensure_directory(path):\n    \"\"\"\n    Ensure that a directory named \"path\" exists.\n    \"\"\"\n    try:\n        makedirs(path)\n    except OSError as exc:\n        if exc.errno != errno.EEXIST or not isdir(path):\n            raise\ndef get_utc_timestamp(dt):",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "get_utc_timestamp",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def get_utc_timestamp(dt):\n    \"\"\"\n    Returns the Timestamp/DatetimeIndex\n    with either localized or converted to UTC.\n    Parameters\n    ----------\n    dt : Timestamp/DatetimeIndex\n        the date(s) to be converted\n    Returns\n    -------",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "get_fama_french",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def get_fama_french():\n    \"\"\"\n    Retrieve Fama-French factors via pandas-datareader\n    Returns\n    -------\n    pandas.DataFrame\n        Percent change of Fama-French factors\n    \"\"\"\n    start = '1/1/1970'\n    research_factors = web.DataReader('F-F_Research_Data_Factors_daily',",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "get_returns_cached",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def get_returns_cached(filepath, update_func, latest_dt, **kwargs):\n    \"\"\"\n    Get returns from a cached file if the cache is recent enough,\n    otherwise, try to retrieve via a provided update function and\n    update the cache file.\n    Parameters\n    ----------\n    filepath : str\n        Path to cached csv file\n    update_func : function",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "load_portfolio_risk_factors",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def load_portfolio_risk_factors(filepath_prefix=None, start=None, end=None):\n    \"\"\"\n    Load risk factors Mkt-Rf, SMB, HML, Rf, and UMD.\n    Data is stored in HDF5 file. If the data is more than 2\n    days old, redownload from Dartmouth.\n    Returns\n    -------\n    five_factors : pd.DataFrame\n        Risk factors timeseries.\n    \"\"\"",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "get_treasury_yield",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def get_treasury_yield(start=None, end=None, period='3MO'):\n    \"\"\"\n    Load treasury yields from FRED.\n    Parameters\n    ----------\n    start : date, optional\n        Earliest date to fetch data for.\n        Defaults to earliest date available.\n    end : date, optional\n        Latest date to fetch data for.",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns_from_yahoo",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def get_symbol_returns_from_yahoo(symbol, start=None, end=None):\n    \"\"\"\n    Wrapper for pandas.io.data.get_data_yahoo().\n    Retrieves prices for symbol from yahoo and computes returns\n    based on adjusted closing prices.\n    Parameters\n    ----------\n    symbol : str\n        Symbol name to load, e.g. 'SPY'\n    start : pandas.Timestamp compatible, optional",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "default_returns_func",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def default_returns_func(symbol, start=None, end=None):\n    \"\"\"\n    Gets returns for a symbol.\n    Queries Yahoo Finance. Attempts to cache SPY.\n    Parameters\n    ----------\n    symbol : str\n        Ticker symbol, e.g. APPL.\n    start : date, optional\n        Earliest date to fetch data for.",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "rolling_window",
        "kind": 2,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "def rolling_window(array, length, mutable=False):\n    \"\"\"\n    Restride an array of shape\n        (X_0, ... X_N)\n    into an array of shape\n        (length, X_0 - length + 1, ... X_N)\n    where each slice at index i along the first axis is equivalent to\n        result[i] = array[length * i:length * (i + 1)]\n    Parameters\n    ----------",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "DATAREADER_DEPRECATION_WARNING",
        "kind": 5,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "DATAREADER_DEPRECATION_WARNING = \\\n        (\"Yahoo and Google Finance have suffered large API breaks with no \"\n         \"stable replacement. As a result, any data reading functionality \"\n         \"in empyrical has been deprecated and will be removed in a future \"\n         \"version. See README.md for more details: \"\n         \"\\n\\n\"\n         \"\\thttps://github.com/quantopian/pyfolio/blob/master/README.md\")\ntry:\n    # fast versions\n    import bottleneck as bn",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "_1_bday",
        "kind": 5,
        "importPath": "empyrical.empyrical.utils",
        "description": "empyrical.empyrical.utils",
        "peekOfCode": "_1_bday = BDay()\ndef _1_bday_ago():\n    return pd.Timestamp.now().normalize() - _1_bday\n@deprecated(msg=DATAREADER_DEPRECATION_WARNING)\ndef get_fama_french():\n    \"\"\"\n    Retrieve Fama-French factors via pandas-datareader\n    Returns\n    -------\n    pandas.DataFrame",
        "detail": "empyrical.empyrical.utils",
        "documentation": {}
    },
    {
        "label": "DISTNAME",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "DISTNAME = \"empyrical\"\nDESCRIPTION = \"\"\"empyrical is a Python library with performance and risk \\\nstatistics commonly used in quantitative finance\"\"\"\nLONG_DESCRIPTION = \"\"\"empyrical is a Python library with performance and risk\nstatistics commonly used in quantitative finance by `Quantopian Inc`_.\n.. _Quantopian Inc: https://www.quantopian.com\n.. _Zipline: https://zipline.io\n.. _pyfolio: https://quantopian.github.io/pyfolio/\n\"\"\"\nMAINTAINER = \"Quantopian Inc\"",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "DESCRIPTION",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "DESCRIPTION = \"\"\"empyrical is a Python library with performance and risk \\\nstatistics commonly used in quantitative finance\"\"\"\nLONG_DESCRIPTION = \"\"\"empyrical is a Python library with performance and risk\nstatistics commonly used in quantitative finance by `Quantopian Inc`_.\n.. _Quantopian Inc: https://www.quantopian.com\n.. _Zipline: https://zipline.io\n.. _pyfolio: https://quantopian.github.io/pyfolio/\n\"\"\"\nMAINTAINER = \"Quantopian Inc\"\nMAINTAINER_EMAIL = \"opensource@quantopian.com\"",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "LONG_DESCRIPTION",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "LONG_DESCRIPTION = \"\"\"empyrical is a Python library with performance and risk\nstatistics commonly used in quantitative finance by `Quantopian Inc`_.\n.. _Quantopian Inc: https://www.quantopian.com\n.. _Zipline: https://zipline.io\n.. _pyfolio: https://quantopian.github.io/pyfolio/\n\"\"\"\nMAINTAINER = \"Quantopian Inc\"\nMAINTAINER_EMAIL = \"opensource@quantopian.com\"\nAUTHOR = \"Quantopian Inc\"\nAUTHOR_EMAIL = \"opensource@quantopian.com\"",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "MAINTAINER",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "MAINTAINER = \"Quantopian Inc\"\nMAINTAINER_EMAIL = \"opensource@quantopian.com\"\nAUTHOR = \"Quantopian Inc\"\nAUTHOR_EMAIL = \"opensource@quantopian.com\"\nURL = \"https://github.com/quantopian/empyrical\"\nLICENSE = \"Apache License, Version 2.0\"\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "MAINTAINER_EMAIL",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "MAINTAINER_EMAIL = \"opensource@quantopian.com\"\nAUTHOR = \"Quantopian Inc\"\nAUTHOR_EMAIL = \"opensource@quantopian.com\"\nURL = \"https://github.com/quantopian/empyrical\"\nLICENSE = \"Apache License, Version 2.0\"\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "AUTHOR",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "AUTHOR = \"Quantopian Inc\"\nAUTHOR_EMAIL = \"opensource@quantopian.com\"\nURL = \"https://github.com/quantopian/empyrical\"\nLICENSE = \"Apache License, Version 2.0\"\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 2.7\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "AUTHOR_EMAIL",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "AUTHOR_EMAIL = \"opensource@quantopian.com\"\nURL = \"https://github.com/quantopian/empyrical\"\nLICENSE = \"Apache License, Version 2.0\"\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 2.7\",\n    \"Programming Language :: Python :: 3.4\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "URL = \"https://github.com/quantopian/empyrical\"\nLICENSE = \"Apache License, Version 2.0\"\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 2.7\",\n    \"Programming Language :: Python :: 3.4\",\n    \"Programming Language :: Python :: 3.5\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "LICENSE",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "LICENSE = \"Apache License, Version 2.0\"\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 2.7\",\n    \"Programming Language :: Python :: 3.4\",\n    \"Programming Language :: Python :: 3.5\",\n    \"License :: OSI Approved :: Apache Software License\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "classifiers",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "classifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 2.7\",\n    \"Programming Language :: Python :: 3.4\",\n    \"Programming Language :: Python :: 3.5\",\n    \"License :: OSI Approved :: Apache Software License\",\n    \"Intended Audience :: Science/Research\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "test_reqs",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "test_reqs = [\n    \"nose>=1.3.7\",\n    \"parameterized>=0.6.1\"\n]\nrequirements = [\n    'numpy>=1.9.2',\n    'pandas>=0.16.1',\n    'scipy>=0.15.1',\n    'six',\n    \"pandas-datareader>=0.2\"",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "requirements",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "requirements = [\n    'numpy>=1.9.2',\n    'pandas>=0.16.1',\n    'scipy>=0.15.1',\n    'six',\n    \"pandas-datareader>=0.2\"\n]\nextras_requirements = {\n    \"dev\": [\n        \"nose==1.3.7\",",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "extras_requirements",
        "kind": 5,
        "importPath": "empyrical.setup",
        "description": "empyrical.setup",
        "peekOfCode": "extras_requirements = {\n    \"dev\": [\n        \"nose==1.3.7\",\n        \"parameterized==0.6.1\",\n        \"flake8==2.5.1\"\n    ]\n}\nif __name__ == \"__main__\":\n    setup(\n        name=DISTNAME,",
        "detail": "empyrical.setup",
        "documentation": {}
    },
    {
        "label": "VersioneerConfig",
        "kind": 6,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "class VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\ndef get_root():\n    \"\"\"Get the project root directory.\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    \"\"\"\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, \"setup.py\")\n    versioneer_py = os.path.join(root, \"versioneer.py\")",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "NotThisMethod",
        "kind": 6,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "class NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "VersioneerConfig",
        "kind": 6,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "class VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\ndef get_config():\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"%(STYLE)s\"\n    cfg.tag_prefix = \"%(TAG_PREFIX)s\"",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "NotThisMethod",
        "kind": 6,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "class NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\nLONG_VERSION_PY = {}\nHANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "VersioneerBadRootError",
        "kind": 6,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "class VersioneerBadRootError(Exception):\n    \"\"\"The project root directory is unknown or missing key files.\"\"\"\ndef get_versions(verbose=False):\n    \"\"\"Get the project version from whatever source is available.\n    Returns dict with two keys: 'version' and 'full'.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[\"versioneer\"]\n    root = get_root()",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_root",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_root():\n    \"\"\"Get the project root directory.\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    \"\"\"\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, \"setup.py\")\n    versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow 'python path/to/setup.py COMMAND'",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_config_from_root",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_config_from_root(root):\n    \"\"\"Read the project setup.cfg file to determine Versioneer config.\"\"\"\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks \"VCS=\"). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, \"setup.cfg\")\n    # parser = configparser.SafeConfigParser()\n    parser = configparser.RawConfigParser\n    with open(setup_cfg, \"r\") as f:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "register_vcs_handler",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_keywords",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_keywords():\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"%(DOLLAR)sFormat:%%d%(DOLLAR)s\"\n    git_full = \"%(DOLLAR)sFormat:%%H%(DOLLAR)s\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full}\n    return keywords",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_config",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_config():\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"%(STYLE)s\"\n    cfg.tag_prefix = \"%(TAG_PREFIX)s\"\n    cfg.parentdir_prefix = \"%(PARENTDIR_PREFIX)s\"\n    cfg.versionfile_source = \"%(VERSIONFILE_SOURCE)s\"",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "register_vcs_handler",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "versions_from_parentdir",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n    Source tarballs conventionally unpack into a directory that includes\n    both the project name and a version string.\n    \"\"\"\n    dirname = os.path.basename(root)\n    if not dirname.startswith(parentdir_prefix):\n        if verbose:\n            print(\"guessing rootdir is '%%s', but '%%s' doesn't start with \"\n                  \"prefix '%%s'\" %% (root, dirname, parentdir_prefix))",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "git_get_keywords",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def git_get_keywords(versionfile_abs):\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, \"r\")\n        for line in f.readlines():",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "git_versions_from_keywords",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "git_pieces_from_vcs",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    if not os.path.exists(os.path.join(root, \".git\")):\n        if verbose:\n            print(\"no .git in %%s\" %% root)\n        raise NotThisMethod(\"no .git directory\")",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "plus_or_dot",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\ndef render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n    Exceptions:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440_pre",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440_pre(pieces):\n    \"\"\"TAG[.post.devDISTANCE] -- No -dirty.\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post.dev%%d\" %% pieces[\"distance\"]\n    else:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440_post",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440_post(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440_old",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440_old(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n    The \".dev0\" means dirty.\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_git_describe",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_git_describe(pieces):\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n    Like 'git describe --tags --dirty --always'.\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_git_describe_long",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_git_describe_long(pieces):\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render(pieces, style):\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"]}\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n    if style == \"pep440\":",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_versions",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_versions():\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n    cfg = get_config()\n    verbose = cfg.verbose\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "git_get_keywords",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def git_get_keywords(versionfile_abs):\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, \"r\")\n        for line in f.readlines():",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "git_versions_from_keywords",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "git_pieces_from_vcs",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    if not os.path.exists(os.path.join(root, \".git\")):\n        if verbose:\n            print(\"no .git in %s\" % root)\n        raise NotThisMethod(\"no .git directory\")",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "do_vcs_install",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def do_vcs_install(manifest_in, versionfile_source, ipy):\n    \"\"\"Git-specific installation logic for Versioneer.\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-time keyword substitution.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    files = [manifest_in, versionfile_source]\n    if ipy:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "versions_from_parentdir",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n    Source tarballs conventionally unpack into a directory that includes\n    both the project name and a version string.\n    \"\"\"\n    dirname = os.path.basename(root)\n    if not dirname.startswith(parentdir_prefix):\n        if verbose:\n            print(\"guessing rootdir is '%s', but '%s' doesn't start with \"\n                  \"prefix '%s'\" % (root, dirname, parentdir_prefix))",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_versions",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_versions():\n    return json.loads(version_json)\n\"\"\"\ndef versions_from_file(filename):\n    \"\"\"Try to determine the version from _version.py if present.\"\"\"\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(\"unable to read _version.py\")",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "versions_from_file",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def versions_from_file(filename):\n    \"\"\"Try to determine the version from _version.py if present.\"\"\"\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(\"unable to read _version.py\")\n    mo = re.search(r\"version_json = '''\\n(.*)'''  # END VERSION_JSON\",\n                   contents, re.M | re.S)\n    if not mo:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "write_to_version_file",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def write_to_version_file(filename, versions):\n    \"\"\"Write the given version number to the given _version.py file.\"\"\"\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=(\",\", \": \"))\n    with open(filename, \"w\") as f:\n        f.write(SHORT_VERSION_PY % contents)\n    print(\"set %s to '%s'\" % (filename, versions[\"version\"]))\ndef plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "plus_or_dot",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\ndef render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n    Exceptions:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440_pre",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440_pre(pieces):\n    \"\"\"TAG[.post.devDISTANCE] -- No -dirty.\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post.dev%d\" % pieces[\"distance\"]\n    else:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440_post",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440_post(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_pep440_old",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_pep440_old(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n    The \".dev0\" means dirty.\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_git_describe",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_git_describe(pieces):\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n    Like 'git describe --tags --dirty --always'.\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render_git_describe_long",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render_git_describe_long(pieces):\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "render",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def render(pieces, style):\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"]}\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n    if style == \"pep440\":",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_versions",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_versions(verbose=False):\n    \"\"\"Get the project version from whatever source is available.\n    Returns dict with two keys: 'version' and 'full'.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[\"versioneer\"]\n    root = get_root()\n    cfg = get_config_from_root(root)\n    assert cfg.VCS is not None, \"please set [versioneer]VCS= in setup.cfg\"",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_version",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_version():\n    \"\"\"Get the short version string for this project.\"\"\"\n    return get_versions()[\"version\"]\ndef get_cmdclass():\n    \"\"\"Get the custom setuptools/distutils subclasses used by Versioneer.\"\"\"\n    if \"versioneer\" in sys.modules:\n        del sys.modules[\"versioneer\"]\n        # this fixes the \"python setup.py develop\" case (also 'install' and\n        # 'easy_install .'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "get_cmdclass",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def get_cmdclass():\n    \"\"\"Get the custom setuptools/distutils subclasses used by Versioneer.\"\"\"\n    if \"versioneer\" in sys.modules:\n        del sys.modules[\"versioneer\"]\n        # this fixes the \"python setup.py develop\" case (also 'install' and\n        # 'easy_install .'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A's setup.py imports A's Versioneer, leaving it in\n        # sys.modules by the time B's setup.py is executed, causing B to run",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "do_setup",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def do_setup():\n    \"\"\"Main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(\"Adding sample versioneer config to setup.cfg\",\n                  file=sys.stderr)",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "scan_setup_py",
        "kind": 2,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "def scan_setup_py():\n    \"\"\"Validate the contents of setup.py against Versioneer's expectations.\"\"\"\n    found = set()\n    setters = False\n    errors = 0\n    with open(\"setup.py\", \"r\") as f:\n        for line in f.readlines():\n            if \"import versioneer\" in line:\n                found.add(\"import\")\n            if \"versioneer.get_cmdclass()\" in line:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "LONG_VERSION_PY",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "LONG_VERSION_PY = {}\nHANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "HANDLERS",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "HANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "LONG_VERSION_PY['git']",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "LONG_VERSION_PY['git'] = '''\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n# This file is released into the public domain. Generated by\n# versioneer-0.16 (https://github.com/warner/python-versioneer)\n\"\"\"Git implementation of _version.py.\"\"\"\nimport errno",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "LONG_VERSION_PY",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "LONG_VERSION_PY = {}\nHANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "HANDLERS",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "HANDLERS = {}\ndef register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Decorator to mark a method as the handler for a particular VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "SHORT_VERSION_PY",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "SHORT_VERSION_PY = \"\"\"\n# This file was generated by 'versioneer.py' (0.16) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\nimport json\nimport sys\nversion_json = '''\n%s\n'''  # END VERSION_JSON",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "version_json",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "version_json = '''\n%s\n'''  # END VERSION_JSON\ndef get_versions():\n    return json.loads(version_json)\n\"\"\"\ndef versions_from_file(filename):\n    \"\"\"Try to determine the version from _version.py if present.\"\"\"\n    try:\n        with open(filename) as f:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "CONFIG_ERROR",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "CONFIG_ERROR = \"\"\"\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "SAMPLE_CONFIG",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "SAMPLE_CONFIG = \"\"\"\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run 'versioneer.py setup' after changing this section, and commit the\n# resulting files.\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "#VCS",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\"\"\"\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "#style",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\"\"\"\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "#versionfile_source",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\"\"\"\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "#versionfile_build",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\"\"\"\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\ndef do_setup():",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "#tag_prefix",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "#tag_prefix =\n#parentdir_prefix =\n\"\"\"\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\ndef do_setup():\n    \"\"\"Main VCS-independent setup function for installing Versioneer.\"\"\"",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "#parentdir_prefix",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "#parentdir_prefix =\n\"\"\"\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\ndef do_setup():\n    \"\"\"Main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "INIT_PY_SNIPPET",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "INIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\ndef do_setup():\n    \"\"\"Main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "empyrical.versioneer",
        "description": "empyrical.versioneer",
        "peekOfCode": "__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\ndef do_setup():\n    \"\"\"Main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:",
        "detail": "empyrical.versioneer",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "kind": 6,
        "importPath": "lib.LumibotML.credentials",
        "description": "lib.LumibotML.credentials",
        "peekOfCode": "class AlpacaConfig:\n    # Put your own Alpaca api key here:\n    # API_KEY = \"PK674RO5M858JZ217SPM\"\n    API_KEY = \"PKEJH4W0URAU56SHKQW3\"\n    # Put your own Alpaca secret here:\n    API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\n    # API_SECRET = \"uWm6opmroTTWuZ9Yr81XRTMsOMLNv8nvBmmLO4Dt\"\n    # If you want to go live, you must change this\n    ENDPOINT = \"https://paper-api.alpaca.markets\"\n    def __init__(self, load_from_secret_manager=True):",
        "detail": "lib.LumibotML.credentials",
        "documentation": {}
    },
    {
        "label": "symbols",
        "kind": 5,
        "importPath": "lib.LumibotML.download_price_data_alpha_vantage",
        "description": "lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "symbols = [\"VIX\", \"VXX\", \"XIV\", \"PBP\", \"SPXL\"]\ninterval = \"1min\"\napi_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):",
        "detail": "lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "interval",
        "kind": 5,
        "importPath": "lib.LumibotML.download_price_data_alpha_vantage",
        "description": "lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "interval = \"1min\"\napi_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):",
        "detail": "lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "lib.LumibotML.download_price_data_alpha_vantage",
        "description": "lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "api_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"",
        "detail": "lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "years",
        "kind": 5,
        "importPath": "lib.LumibotML.download_price_data_alpha_vantage",
        "description": "lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "years = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"\n                url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval={interval}&slice={slice}&apikey={api_key}\"\n                df = pd.read_csv(url)",
        "detail": "lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "months",
        "kind": 5,
        "importPath": "lib.LumibotML.download_price_data_alpha_vantage",
        "description": "lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "months = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"\n                url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval={interval}&slice={slice}&apikey={api_key}\"\n                df = pd.read_csv(url)\n                dfs.append(df)",
        "detail": "lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "MachineLearningCrypto",
        "kind": 6,
        "importPath": "lib.LumibotML.ml_strategy_crypto",
        "description": "lib.LumibotML.ml_strategy_crypto",
        "peekOfCode": "class MachineLearningCrypto(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "lib.LumibotML.ml_strategy_crypto",
        "documentation": {}
    },
    {
        "label": "MachineLearningStocks",
        "kind": 6,
        "importPath": "lib.LumibotML.ml_strategy_stocks",
        "description": "lib.LumibotML.ml_strategy_stocks",
        "peekOfCode": "class MachineLearningStocks(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "lib.LumibotML.ml_strategy_stocks",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "peekOfCode": "MODELS = {\n    \"ddpg\": AgentDDPG,\n    \"td3\": AgentTD3,\n    \"sac\": AgentSAC,\n    \"ppo\": AgentPPO,\n    \"a2c\": AgentA2C,\n}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}",
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "lib.rl.agents.elegantrl.models",
        "description": "lib.rl.agents.elegantrl.models",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "PolicyGradient",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.algorithms",
        "description": "lib.rl.agents.portfolio_optimization.algorithms",
        "peekOfCode": "class PolicyGradient:\n    \"\"\"Class implementing policy gradient algorithm to train portfolio\n    optimization agents.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        train_env: Environment used to train the agent\n        train_policy: Policy used in training.",
        "detail": "lib.rl.agents.portfolio_optimization.algorithms",
        "documentation": {}
    },
    {
        "label": "EIIE",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.architectures",
        "description": "lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EIIE(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_size=3,\n        conv_mid_features=2,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",\n    ):",
        "detail": "lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "EI3",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.architectures",
        "description": "lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EI3(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",",
        "detail": "lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "GPM",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.architectures",
        "description": "lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class GPM(nn.Module):\n    def __init__(\n        self,\n        edge_index,\n        edge_type,\n        nodes_to_select,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,",
        "detail": "lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.models",
        "description": "lib.rl.agents.portfolio_optimization.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"\n    def __init__(self, env):",
        "detail": "lib.rl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "lib.rl.agents.portfolio_optimization.models",
        "description": "lib.rl.agents.portfolio_optimization.models",
        "peekOfCode": "MODELS = {\"pg\": PolicyGradient}\nclass DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"",
        "detail": "lib.rl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "PVM",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.utils",
        "description": "lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class PVM:\n    def __init__(self, capacity, portfolio_size):\n        \"\"\"Initializes portfolio vector memory.\n        Args:\n          capacity: Max capacity of memory.\n          portfolio_size: Portfolio size.\n        \"\"\"\n        # initially, memory will have the same actions\n        self.capacity = capacity\n        self.portfolio_size = portfolio_size",
        "detail": "lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.utils",
        "description": "lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class ReplayBuffer:\n    def __init__(self, capacity):\n        \"\"\"Initializes replay buffer.\n        Args:\n          capacity: Max capacity of buffer.\n        \"\"\"\n        self.buffer = deque(maxlen=capacity)\n    def __len__(self):\n        \"\"\"Represents the size of the buffer\n        Returns:",
        "detail": "lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "RLDataset",
        "kind": 6,
        "importPath": "lib.rl.agents.portfolio_optimization.utils",
        "description": "lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class RLDataset(IterableDataset):\n    def __init__(self, buffer):\n        \"\"\"Initializes reinforcement learning dataset.\n        Args:\n            buffer: replay buffer to become iterable dataset.\n        Note:\n            It's a subclass of pytorch's IterableDataset,\n            check https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n        \"\"\"\n        self.buffer = buffer",
        "detail": "lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "apply_portfolio_noise",
        "kind": 2,
        "importPath": "lib.rl.agents.portfolio_optimization.utils",
        "description": "lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "def apply_portfolio_noise(portfolio, epsilon=0.0):\n    \"\"\"Apply noise to portfolio distribution considering its constrains.\n    Arg:\n        portfolio: initial portfolio distribution.\n        epsilon: maximum rebalancing.\n    Returns:\n        New portolio distribution with noise applied.\n    \"\"\"\n    portfolio_size = portfolio.shape[0]\n    new_portfolio = portfolio.copy()",
        "detail": "lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "DRLlibv2",
        "kind": 6,
        "importPath": "lib.rl.agents.rllib.drllibv2",
        "description": "lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "class DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:\n        Training environment instance\n    train_env_name: str",
        "detail": "lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "psutil_memory_in_bytes",
        "kind": 5,
        "importPath": "lib.rl.agents.rllib.drllibv2",
        "description": "lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "psutil_memory_in_bytes = psutil.virtual_memory().total\nray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter",
        "detail": "lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "ray._private.utils.get_system_memory",
        "kind": 5,
        "importPath": "lib.rl.agents.rllib.drllibv2",
        "description": "lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "ray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:",
        "detail": "lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "lib.rl.agents.rllib.models",
        "description": "lib.rl.agents.rllib.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data\n        tech_array: numpy array\n            techical data",
        "detail": "lib.rl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "lib.rl.agents.rllib.models",
        "description": "lib.rl.agents.rllib.models",
        "peekOfCode": "MODELS = {\"a2c\": a2c, \"ddpg\": ddpg, \"td3\": td3, \"sac\": sac, \"ppo\": ppo}\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nclass DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data",
        "detail": "lib.rl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "sample_ppo_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ppo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for PPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_trpo_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_trpo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TRPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_a2c_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_a2c_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for A2C hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    normalize_advantage = trial.suggest_categorical(",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_sac_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_sac_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for SAC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_td3_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_td3_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TD3 hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ddpg_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ddpg_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DDPG hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_dqn_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_dqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_her_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_her_params(\n    trial: optuna.Trial, hyperparams: dict[str, Any]\n) -> dict[str, Any]:\n    \"\"\"\n    Sampler for HerReplayBuffer hyperparams.\n    :param trial:\n    :parma hyperparams:\n    :return:\n    \"\"\"\n    her_kwargs = trial.her_kwargs.copy()",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_tqc_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_tqc_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TQC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is SAC + Distributional RL\n    hyperparams = sample_sac_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 50)\n    top_quantiles_to_drop_per_net = trial.suggest_int(",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_qrdqn_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_qrdqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for QR-DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is DQN + Distributional RL\n    hyperparams = sample_dqn_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 200)\n    hyperparams[\"policy_kwargs\"].update({\"n_quantiles\": n_quantiles})",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ars_params",
        "kind": 2,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ars_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for ARS hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # n_eval_episodes = trial.suggest_categorical(\"n_eval_episodes\", [1, 2])\n    n_delta = trial.suggest_categorical(\"n_delta\", [4, 8, 6, 32, 64])\n    # learning_rate = trial.suggest_categorical(\"learning_rate\", [0.01, 0.02, 0.025, 0.03])\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "HYPERPARAMS_SAMPLER",
        "kind": 5,
        "importPath": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "HYPERPARAMS_SAMPLER = {\n    \"a2c\": sample_a2c_params,\n    \"ars\": sample_ars_params,\n    \"ddpg\": sample_ddpg_params,\n    \"dqn\": sample_dqn_params,\n    \"qrdqn\": sample_qrdqn_params,\n    \"sac\": sample_sac_params,\n    \"tqc\": sample_tqc_params,\n    \"ppo\": sample_ppo_params,\n    \"td3\": sample_td3_params,",
        "detail": "lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "TensorboardCallback",
        "kind": 6,
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)\n    def _on_step(self) -> bool:\n        try:\n            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n        except BaseException as error:",
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Provides implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "kind": 6,
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLEnsembleAgent:\n    @staticmethod\n    def get_model(\n        model_name,\n        env,\n        policy=\"MlpPolicy\",\n        policy_kwargs=None,\n        model_kwargs=None,\n        seed=None,\n        verbose=1,",
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\nMODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"",
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODEL_KWARGS",
        "kind": 5,
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):",
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "NOISE",
        "kind": 5,
        "importPath": "lib.rl.agents.stablebaselines3.models",
        "description": "lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "NOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)",
        "detail": "lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "LoggingCallback",
        "kind": 6,
        "importPath": "lib.rl.agents.stablebaselines3.tune_sb3",
        "description": "lib.rl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class LoggingCallback:\n    def __init__(self, threshold: int, trial_number: int, patience: int):\n        \"\"\"\n        threshold:int tolerance for increase in sharpe ratio\n        trial_number: int Prune after minimum number of trials\n        patience: int patience for the threshold\n        \"\"\"\n        self.threshold = threshold\n        self.trial_number = trial_number\n        self.patience = patience",
        "detail": "lib.rl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "TuneSB3Optuna",
        "kind": 6,
        "importPath": "lib.rl.agents.stablebaselines3.tune_sb3",
        "description": "lib.rl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class TuneSB3Optuna:\n    \"\"\"\n    Hyperparameter tuning of SB3 agents using Optuna\n    Attributes\n    ----------\n      env_train: Training environment for SB3\n      model_name: str\n      env_trade: testing environment\n      logging_callback: callback for tuning\n      total_timesteps: int",
        "detail": "lib.rl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "calc_stockname_from_filename",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_stockname_from_filename(filename):\n    return filename.split(\"/\")[-1].split(\".csv\")[0]\ndef calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)\n    return paths2\ndef calc_stocknames(path):",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_stocknames",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_stocknames(path):\n    filenames = calc_all_filenames(path)\n    res = []\n    for filename in filenames:\n        stockname = calc_stockname_from_filename(filename)\n        res.append(stockname)\n    return res\ndef remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:\n        os.system(\"rm -f \" + path_of_data + \"/*\")\n    dir_list = os.listdir(path_of_data)\n    for file in dir_list:\n        if \"~\" in file:\n            os.system(\"rm -f \" + path_of_data + \"/\" + file)\n    dir_list = os.listdir(path_of_data)\n    if remove == 1:",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def date2str(dat: datetime.date) -> str:\n    return datetime.date.strftime(dat, \"%Y-%m-%d\")\ndef str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_dates",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)\n        dates.append(d)\n        dat += delta\n    return dates",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_starts_ends_if_rolling(\n    init_train_dates: list[str], init_trade_dates: list[str], rolling_window_length: int\n) -> tuple[list[str], list[str], list[str], list[str]]:\n    trade_dates_length = len(init_trade_dates)\n    train_window_length = len(init_train_dates)\n    trade_window_length = min(rolling_window_length, trade_dates_length)\n    num_subsets_if_rolling = int(np.ceil(trade_dates_length / trade_window_length))\n    print(\"num_subsets_if_rolling: \", num_subsets_if_rolling)\n    dates = np.concatenate((init_train_dates, init_trade_dates), axis=0)\n    train_starts = []",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "kind": 2,
        "importPath": "lib.rl.meta.data_processors.func",
        "description": "lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_data(\n    i: int,\n    train_starts: list[str],\n    train_ends: list[str],\n    trade_starts: list[str],\n    trade_ends: list[str],\n    init_train_data: pd.DataFrame(),\n    init_trade_data: pd.DataFrame(),\n    date_col: str,\n) -> tuple[pd.DataFrame(), pd.DataFrame()]:",
        "detail": "lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processors.processor_alpaca",
        "description": "lib.rl.meta.data_processors.processor_alpaca",
        "peekOfCode": "class AlpacaProcessor:\n    def __init__(self, API_KEY=None, API_SECRET=None, API_BASE_URL=None, api=None):\n        if api is None:\n            try:\n                self.api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, \"v2\")\n            except BaseException:\n                raise ValueError(\"Wrong Account Info!\")\n        else:\n            self.api = api\n    def download_data(self, ticker_list, start_date, end_date, time_interval) -> pd.DataFrame:",
        "detail": "lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "CCXTEngineer",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processors.processor_ccxt",
        "description": "lib.rl.meta.data_processors.processor_ccxt",
        "peekOfCode": "class CCXTEngineer:\n    def __init__(self):\n        self.binance = ccxt.binance()\n    def data_fetch(self, start, end, pair_list=[\"BTC/USDT\"], period=\"1m\"):\n        def min_ohlcv(dt, pair, limit):\n            since = calendar.timegm(dt.utctimetuple()) * 1000\n            ohlcv = self.binance.fetch_ohlcv(\n                symbol=pair, timeframe=\"1m\", since=since, limit=limit\n            )\n            return ohlcv",
        "detail": "lib.rl.meta.data_processors.processor_ccxt",
        "documentation": {}
    },
    {
        "label": "JoinQuantEngineer",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processors.processor_joinquant",
        "description": "lib.rl.meta.data_processors.processor_joinquant",
        "peekOfCode": "class JoinQuantEngineer:\n    def __init__(self):\n        pass\n    def auth(self, username, password):\n        jq.auth(username, password)\n    def data_fetch(self, stock_list, num, unit, end_dt):\n        df = jq.get_bars(\n            security=stock_list,\n            count=num,\n            unit=unit,",
        "detail": "lib.rl.meta.data_processors.processor_joinquant",
        "documentation": {}
    },
    {
        "label": "QuantConnectEngineer",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processors.processor_quantconnect",
        "description": "lib.rl.meta.data_processors.processor_quantconnect",
        "peekOfCode": "class QuantConnectEngineer:\n    def __init__(self):\n        pass\n    def data_fetch(start_time, end_time, stock_list, resolution=Resolution.Daily):\n        # resolution: Daily, Hour, Minute, Second\n        qb = QuantBook()\n        for stock in stock_list:\n            qb.AddEquity(stock)\n        history = qb.History(qb.Securities.Keys, start_time, end_time, resolution)\n        return history",
        "detail": "lib.rl.meta.data_processors.processor_quantconnect",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processors.processor_wrds",
        "description": "lib.rl.meta.data_processors.processor_wrds",
        "peekOfCode": "class WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,\n        time_interval,",
        "detail": "lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "pd.options.mode.chained_assignment",
        "kind": 5,
        "importPath": "lib.rl.meta.data_processors.processor_wrds",
        "description": "lib.rl.meta.data_processors.processor_wrds",
        "peekOfCode": "pd.options.mode.chained_assignment = None\nclass WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,",
        "detail": "lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processors.processor_yahoofinance",
        "description": "lib.rl.meta.data_processors.processor_yahoofinance",
        "peekOfCode": "class YahooFinanceProcessor:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    \"\"\"\n    def __init__(self):\n        pass\n    \"\"\"\n    Param\n    ----------\n        start_date : str",
        "detail": "lib.rl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "BitcoinEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "description": "lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "peekOfCode": "class BitcoinEnv:  # custom env\n    def __init__(\n        self,\n        data_cwd=None,\n        price_ary=None,\n        tech_ary=None,\n        time_frequency=15,\n        start=None,\n        mid1=172197,\n        mid2=216837,",
        "detail": "lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "documentation": {}
    },
    {
        "label": "CryptoEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "description": "lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "peekOfCode": "class CryptoEnv:  # custom env\n    def __init__(\n        self,\n        config,\n        lookback=1,\n        initial_capital=1e6,\n        buy_cost_pct=1e-3,\n        sell_cost_pct=1e-3,\n        gamma=0.99,\n    ):",
        "detail": "lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "documentation": {}
    },
    {
        "label": "StockPortfolioEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "description": "lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "peekOfCode": "class StockPortfolioEnv(gym.Env):\n    \"\"\"A single stock trading environment for OpenAI gym\n    Attributes\n    ----------\n        df: DataFrame\n            input data\n        stock_dim : int\n            number of unique stocks\n        hmax : int\n            maximum number of shares to trade",
        "detail": "lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "documentation": {}
    },
    {
        "label": "PortfolioOptimizationEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "description": "lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "peekOfCode": "class PortfolioOptimizationEnv(gym.Env):\n    \"\"\"A portfolio allocation environment for OpenAI gym.\n    This environment simulates the interactions between an agent and the financial market\n    based on data provided by a dataframe. The dataframe contains the time series of\n    features defined by the user (such as closing, high and low prices) and must have\n    a time and a tic column with a list of datetimes and ticker symbols respectively.\n    An example of dataframe is shown below::\n            date        high            low             close           tic\n        0   2020-12-23  0.157414        0.127420        0.136394        ADA-USD\n        1   2020-12-23  34.381519       30.074295       31.097898       BNB-USD",
        "detail": "lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "StockEnvNAS100",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "description": "lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "peekOfCode": "class StockEnvNAS100:\n    def __init__(\n        self,\n        cwd=\"./data/nas100\",\n        price_ary=None,\n        tech_ary=None,\n        turbulence_ary=None,\n        gamma=0.999,\n        turbulence_thresh=30,\n        min_stock_rate=0.1,",
        "detail": "lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class AlpacaPaperTrading:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {\"render.modes\": [\"human\"]}\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        stock_dim: int,\n        hmax: int,\n        initial_amount: int,\n        num_stock_shares: list[int],",
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvCashpenalty",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "peekOfCode": "class StockTradingEnvCashpenalty(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model for not maintaining a reserve of cash.\n    This enables the model to manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) - initial_cash - max(0, sum(cash, asset_value)*cash_penalty_proportion-cash))/(days_elapsed)\n        This reward function takes into account a liquidity requirement, as well as long-term accrued rewards.\n    Parameters:\n        df (pandas.DataFrame): Dataframe containing data",
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    def __init__(\n        self,\n        config,\n        initial_account=1e6,\n        gamma=0.99,\n        turbulence_thresh=99,\n        min_stock_rate=0.1,\n        max_stock=1e2,\n        initial_capital=1e6,",
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvStopLoss",
        "kind": 6,
        "importPath": "lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "description": "lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "peekOfCode": "class StockTradingEnvStopLoss(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model if excedeed the stop-loss threshold, selling assets with under expectation %profit, and also\n    for not maintaining a reserve of cash.\n    This enables the model to do trading with high confidence and manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) + additional_reward - total_penalty - initial_cash) / initial_cash / days_elapsed\n        , where total_penalty = cash_penalty + stop_loss_penalty + low_profit_penalty\n                cash_penalty = max(0, sum(cash, asset_value)*cash_penalty_proportion-cash)",
        "detail": "lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "documentation": {}
    },
    {
        "label": "PaperTradingAlpaca",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.alpaca",
        "description": "lib.rl.meta.paper_trading.alpaca",
        "peekOfCode": "class PaperTradingAlpaca:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "lib.rl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.alpaca",
        "description": "lib.rl.meta.paper_trading.alpaca",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "lib.rl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(\n            torch.zeros((1, action_dim)), requires_grad=True\n        )  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {\n                \"env_name\": None,\n                \"state_dim\": None,\n                \"action_dim\": None,\n                \"if_discrete\": None,",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class AgentBase:\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.state_dim = state_dim",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.if_off_policy = False",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < \"0.18.0\" else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        \"\"\"the necessary env information when you design a custom env\"\"\"\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class Evaluator:\n    def __init__(\n        self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = \".\"\n    ):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = (",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {\"unwrapped\", \"observation_space\", \"action_space\", \"spec\"}.issubset(\n        dir(env)\n    ):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = (\n            state_shape[0] if len(state_shape) == 1 else state_shape\n        )  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in (\"env_name\", \"state_dim\", \"action_dim\", \"if_discrete\"):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(\n        args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args\n    )\n    agent.states = env.reset()[np.newaxis, :]\n    evaluator = Evaluator(\n        eval_env=build_env(args.env_class, args.env_args),\n        eval_per_step=args.eval_per_step,",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def render_agent(\n    env_class,\n    env_args: dict,\n    net_dims: [int],\n    agent_class,\n    actor_path: str,\n    render_times: int = 8,\n):\n    env = build_env(env_class, env_args)\n    state_dim = env_args[\"state_dim\"]",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_rewards_and_steps(\n    env, actor, if_render: bool = False\n) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(\n            state, dtype=torch.float32, device=device",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_trading_days(start, end):\n    nyse = tc.get_calendar(\"NYSE\")\n    df = nyse.sessions_in_range(\n        pd.Timestamp(start, tz=pytz.UTC), pd.Timestamp(end, tz=pytz.UTC)\n    )\n    trading_days = []\n    for day in df:\n        trading_days.append(str(day)[:10])\n    return trading_days\ndef alpaca_history(key, secret, url, start, end):",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, \"v2\")\n    trading_days = get_trading_days(start, end)\n    df = pd.DataFrame()\n    for day in trading_days:\n        df = df.append(\n            api.get_portfolio_history(date_start=day, timeframe=\"5Min\").df.iloc[:78]\n        )\n    equities = df.equity.values\n    cumu_returns = equities / equities[0]",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "kind": 2,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "def DIA_history(start):\n    data_df = yf.download([\"^DJI\"], start=start, interval=\"5m\")\n    data_df = data_df.iloc[:]\n    baseline_returns = data_df[\"Adj Close\"].values / data_df[\"Adj Close\"].values[0]\n    return data_df, baseline_returns\n# -----------------------------------------------------------------------------------------------------------------------------------------",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "lib.rl.meta.paper_trading.common",
        "description": "lib.rl.meta.paper_trading.common",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "GroupByScaler",
        "kind": 6,
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "class GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"\n    def __init__(self, by, scaler=MaxAbsScaler, columns=None, scaler_kwargs=None):\n        \"\"\"Initializes GoupBy scaler.\n        Args:\n            by: Name of column that will be used to group.",
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "kind": 6,
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "class FeatureEngineer:\n    \"\"\"Provides methods for preprocessing the stock price data\n    Attributes\n    ----------\n        use_technical_indicator : boolean\n            we technical indicator or not\n        tech_indicator_list : list\n            a list of technical indicator names (modified from neofinrl_config.py)\n        use_turbulence : boolean\n            use turbulence index or not",
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def load_dataset(*, file_name: str) -> pd.DataFrame:\n    \"\"\"\n    load csv dataset from path\n    :return: (df) pandas dataframe\n    \"\"\"\n    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n    _data = pd.read_csv(file_name)\n    return _data\ndef data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"",
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "kind": 2,
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"\n    split the dataset into training or testing using date\n    :param data: (df) pandas dataframe, start, end\n    :return: (df) pandas dataframe\n    \"\"\"\n    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n    data.index = data[target_date_col].factorize()[0]\n    return data",
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "convert_to_datetime",
        "kind": 2,
        "importPath": "lib.rl.meta.preprocessor.preprocessors",
        "description": "lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def convert_to_datetime(time):\n    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n    if isinstance(time, str):\n        return datetime.datetime.strptime(time, time_fmt)\nclass GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"",
        "detail": "lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "TushareDownloader",
        "kind": 6,
        "importPath": "lib.rl.meta.preprocessor.tusharedownloader",
        "description": "lib.rl.meta.preprocessor.tusharedownloader",
        "peekOfCode": "class TushareDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    tushare API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from config.py)\n        end_date : str\n            end date of the data (modified from config.py)\n        ticker_list : list",
        "detail": "lib.rl.meta.preprocessor.tusharedownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "kind": 6,
        "importPath": "lib.rl.meta.preprocessor.yahoodownloader",
        "description": "lib.rl.meta.preprocessor.yahoodownloader",
        "peekOfCode": "class YahooDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from neofinrl_config.py)\n        end_date : str\n            end date of the data (modified from neofinrl_config.py)\n        ticker_list : list",
        "detail": "lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "kind": 6,
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "peekOfCode": "class DataProcessor:\n    def __init__(self, data_source, tech_indicator=None, vix=None, **kwargs):\n        if data_source == \"alpaca\":\n            try:\n                API_KEY      = ALPACA_API_KEY\n                API_SECRET   = ALPACA_API_SECRET\n                API_BASE_URL = ALPACA_API_BASE_URL\n                self.processor = Alpaca(\n                    API_KEY, API_SECRET, API_BASE_URL)\n                (\"===============Alpaca successfully connected with class DataProcessor: meta/data_processor.py==========================\")",
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "lib.rl.meta.data_processor",
        "description": "lib.rl.meta.data_processor",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom alpaca.data.historical import StockHistoricalDataClient\nfrom alpaca.data.requests import StockBarsRequest\nfrom alpaca.data.models.bars import BarSet\nimport alpaca_trade_api as tradeapi \nclass DataProcessor:\n    def __init__(self, data_source, tech_indicator=None, vix=None, **kwargs):\n        if data_source == \"alpaca\":\n            try:\n                API_KEY      = ALPACA_API_KEY",
        "detail": "lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "TRAIN_START_DATE = \"2019-01-01\"\nTRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "TRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "TEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "TEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "TRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "TRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "PATH_OF_DATA",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "PATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "READ_DATA_FROM_LOCAL",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "READ_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]\nFAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "FAANG_TICKER",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "FAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]\n# Dow 30 constituents at 2019/01\nDOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",\n    \"NKE\",\n    \"DIS\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "lib.rl.meta.meta_config",
        "description": "lib.rl.meta.meta_config",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "kind": 6,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "class OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"\n    TRAILING_STOP = \"trailing_stop\"\nclass TimeInForce():",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "kind": 6,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "class OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"\n    TRAILING_STOP = \"trailing_stop\"\nclass TimeInForce():\n    DAY = \"day\"\n    GTC = \"gtc\"\n    OPG = \"opg\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "kind": 6,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "class TimeInForce():\n    DAY = \"day\"\n    GTC = \"gtc\"\n    OPG = \"opg\"\n    CLS = \"cls\"\n    IOC = \"ioc\"\n    FOK = \"fok\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "now = datetime.datetime.now().strftime(\"%Y%m%d-%Hh%M\")\nst.write(\"Current Date and Time:\", now)\nMAIN_RESULTS_DIR = 'pages/data' + now\nDATA_SAVE_DIR       = MAIN_RESULTS_DIR + \"/datasets\"\nTRAINED_MODEL_DIR   = MAIN_RESULTS_DIR + \"/trained_models\"\nTENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "MAIN_RESULTS_DIR",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "MAIN_RESULTS_DIR = 'pages/data' + now\nDATA_SAVE_DIR       = MAIN_RESULTS_DIR + \"/datasets\"\nTRAINED_MODEL_DIR   = MAIN_RESULTS_DIR + \"/trained_models\"\nTENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "A2C_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.0007}\nPPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "PPO_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "PPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DDPG_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TD3_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "SAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "ERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": 512,\n    \"target_step\": 5000,\n    \"eval_gap\": 30,\n    \"eval_times\": 64,  # bug fix:KeyError: 'eval_times' line 68, in get_model model.eval_times = model_kwargs[\"eval_times\"]\n}",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "RLlib_PARAMS = {\"lr\": 5e-5, \"train_batch_size\": 500, \"gamma\": 0.99}\n# Possible time zones\nTIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SHANGHAI",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_USEASTERN",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_PARIS",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_BERLIN",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_JAKARTA",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "TIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "USE_TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "USE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "ALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "ALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "lib.rl.config",
        "description": "lib.rl.config",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"",
        "detail": "lib.rl.config",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\nGROQ_API_KEY= \"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\"\nALPACA_API_KEY = \"PKKR2EEEBE9Q3MLXWXFT\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"dJw28M9E5S4WujgUwPRBnfk4DLttQM66YCvhdC5X\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "peekOfCode": "ALPACA_API_KEY = \"PKKR2EEEBE9Q3MLXWXFT\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"dJw28M9E5S4WujgUwPRBnfk4DLttQM66YCvhdC5X\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "peekOfCode": "ALPACA_API_SECRET = \"dJw28M9E5S4WujgUwPRBnfk4DLttQM66YCvhdC5X\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "lib.rl.config_private",
        "description": "lib.rl.config_private",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "SINGLE_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "SINGLE_TICKER = [\"AAPL\"]\n# Dow 30 constituents in 2021/10\n# check https://wrds-www.wharton.upenn.edu/ for U.S. index constituents\nDOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",\n    \"CVX\",\n    \"GS\",\n    \"HD\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "HSI_50_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "HSI_50_TICKER = [\n    \"0011.HK\",\n    \"0005.HK\",\n    \"0012.HK\",\n    \"0006.HK\",\n    \"0003.HK\",\n    \"0016.HK\",\n    \"0019.HK\",\n    \"0002.HK\",\n    \"0001.HK\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SSE_50_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "SSE_50_TICKER = [\n    \"600000.XSHG\",\n    \"600036.XSHG\",\n    \"600104.XSHG\",\n    \"600030.XSHG\",\n    \"601628.XSHG\",\n    \"601166.XSHG\",\n    \"601318.XSHG\",\n    \"601328.XSHG\",\n    \"601088.XSHG\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CSI_300_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "CSI_300_TICKER = [\n    \"600000.XSHG\",\n    \"600004.XSHG\",\n    \"600009.XSHG\",\n    \"600010.XSHG\",\n    \"600011.XSHG\",\n    \"600015.XSHG\",\n    \"600016.XSHG\",\n    \"600018.XSHG\",\n    \"600019.XSHG\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CAC_40_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "CAC_40_TICKER = [\n    \"AC.PA\",\n    \"AI.PA\",\n    \"AIR.PA\",\n    \"MT.AS\",\n    \"ATO.PA\",\n    \"CS.PA\",\n    \"BNP.PA\",\n    \"EN.PA\",\n    \"CAP.PA\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DAX_30_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "DAX_30_TICKER = [\n    \"DHER.DE\",\n    \"RWE.DE\",\n    \"FRE.DE\",\n    \"MTX.DE\",\n    \"MRK.DE\",\n    \"LIN.DE\",\n    \"ALV.DE\",\n    \"VNA.DE\",\n    \"EOAN.DE\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "TECDAX_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "TECDAX_TICKER = [\n    \"ADV.DE\",\n    \"AFX.DE\",\n    \"AM3D.DE\",\n    \"BC8.DE\",\n    \"COK.DE\",\n    \"DLG.DE\",\n    \"DRI.DE\",\n    \"DRW3.DE\",\n    \"EVT.DE\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "MDAX_50_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "MDAX_50_TICKER = [\n    \"1COV.DE\",\n    \"AIR.DE\",\n    \"AOX.DE\",\n    \"ARL.DE\",\n    \"BNR.DE\",\n    \"BOSS.DE\",\n    \"DEQ.DE\",\n    \"DUE.DE\",\n    \"DWNI.DE\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SDAX_50_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "SDAX_50_TICKER = [\n    \"AAD.DE\",\n    \"ACX.DE\",\n    \"ADJ.DE\",\n    \"ADL.DE\",\n    \"BDT.DE\",\n    \"BIO3.DE\",\n    \"BVB.DE\",\n    \"BYW6.DE\",\n    \"CWC.DE\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "LQ45_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "LQ45_TICKER = [\n    \"ACES.JK\",\n    \"ADRO.JK\",\n    \"AKRA.JK\",\n    \"ANTM.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SRI_KEHATI_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "SRI_KEHATI_TICKER = [\n    \"AALI.JK\",\n    \"ADHI.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",\n    \"BMRI.JK\",\n    \"BSDE.JK\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "FX_TICKER",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "FX_TICKER = [\n    \"AUDCAD=X\",\n    \"AUDCHF=X\",\n    \"AUDJPY=X\",\n    \"AUDNZD=X\",\n    \"AUDSGD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "custom_index",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "custom_index = [\"MMM\", \"AXP\", \"BA\", \"CAT\", \"CSCO\"]\nsector_dict = {\n    \"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"META\", \"TSLA\"],\n    \"Healthcare\": [\"JNJ\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\"],\n    \"Finance\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"],\n    \"Consumer Discretionary\": [\"AMZN\", \"HD\", \"NKE\", \"MCD\", \"SBUX\"],\n    \"Energy\": [\"XOM\", \"CVX\", \"COP\", \"PSX\", \"VLO\"]\n}\nusa_dict = {\n    # usa_dict[S&P 500]",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "sector_dict",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "sector_dict = {\n    \"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"META\", \"TSLA\"],\n    \"Healthcare\": [\"JNJ\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\"],\n    \"Finance\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"],\n    \"Consumer Discretionary\": [\"AMZN\", \"HD\", \"NKE\", \"MCD\", \"SBUX\"],\n    \"Energy\": [\"XOM\", \"CVX\", \"COP\", \"PSX\", \"VLO\"]\n}\nusa_dict = {\n    # usa_dict[S&P 500]\n  \"NYSE\": SP_500_TICKER  ",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "usa_dict",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "usa_dict = {\n    # usa_dict[S&P 500]\n  \"NYSE\": SP_500_TICKER  \n}\nindex_dict = {\n    \"Dow 30\": DOW_30_TICKER,\n    \"Nasdaq 100\": NAS_100_TICKER,\n    \"S&P 500\": SP_500_TICKER,\n    \"Hang Seng Index\" : HSI_50_TICKER, \n    \"SSE 50\" :SSE_50_TICKER, ",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "kind": 5,
        "importPath": "lib.rl.config_tickers",
        "description": "lib.rl.config_tickers",
        "peekOfCode": "index_dict = {\n    \"Dow 30\": DOW_30_TICKER,\n    \"Nasdaq 100\": NAS_100_TICKER,\n    \"S&P 500\": SP_500_TICKER,\n    \"Hang Seng Index\" : HSI_50_TICKER, \n    \"SSE 50\" :SSE_50_TICKER, \n    \"CSI 300\" : CSI_300_TICKER, \n    \"CAC 40\" : CAC_40_TICKER, \n    \"DAX 30\" : DAX_30_TICKER, \n    \"TecDAX\" : TECDAX_TICKER, ",
        "detail": "lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "peekOfCode": "def build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        dest=\"mode\",\n        help=\"start mode, train, download_data\" \" backtest\",\n        metavar=\"MODE\",\n        default=\"train\",\n    )\n    return parser",
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "kind": 2,
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "peekOfCode": "def check_and_make_directories(directories: list[str]):\n    for directory in directories:\n        if not os.path.exists(\"./\" + directory):\n            os.makedirs(\"./\" + directory)\ndef main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )",
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "lib.rl.main",
        "description": "lib.rl.main",
        "peekOfCode": "def main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )\n    if options.mode == \"train\":\n        from lib.rl import train\n        env = StockTradingEnv\n        # demo for elegantrl",
        "detail": "lib.rl.main",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def get_daily_return(df, value_col_name=\"account_value\"):\n    df = deepcopy(df)\n    df[\"daily_return\"] = df[value_col_name].pct_change(1)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    df.set_index(\"date\", inplace=True, drop=True)\n    df.index = df.index.tz_localize(\"UTC\")\n    return pd.Series(df[\"daily_return\"], index=df.index)\ndef convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "convert_daily_return_to_pyfolio_ts",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n    del strategy_ret[\"date\"]\n    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\ndef backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(\n        returns=dr_test,\n        positions=None,\n        transactions=None,\n        turnover_denom=\"AGB\",\n    )\n    # jprint(perf_stats_all)\n    st.table(perf_stats_all)",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def backtest_plot(\n    account_value,\n    baseline_start=config.TRADE_START_DATE,\n    baseline_end=config.TRADE_END_DATE,\n    baseline_ticker=\"^DJI\",\n    value_col_name=\"account_value\",\n):\n    df = deepcopy(account_value)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    test_returns = get_daily_return(df, value_col_name=value_col_name)",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def get_baseline(ticker, start, end):\n    return YahooDownloader(\n        start_date=start, end_date=end, ticker_list=[ticker]\n    ).fetch_data()\ndef trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "trx_plot",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):\n        df_trx_temp = df_trx.iloc[:, i]\n        df_trx_temp_sign = np.sign(df_trx_temp)\n        buying_signal = df_trx_temp_sign.apply(lambda x: x > 0)\n        selling_signal = df_trx_temp_sign.apply(lambda x: x < 0)",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "transfer_date",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def transfer_date(str_dat):\n    return datetime.datetime.strptime(str_dat, \"%Y-%m-%d\").date().strftime(\"%m/%d/%Y\")\ndef plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result_from_csv",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    result = pd.read_csv(csv_file)",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def plot_result(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    columns = result.columns",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_if_overlap",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def get_if_overlap(fig, ax):\n    fig.canvas.draw()\n    # \n    bboxes = [label.get_window_extent() for label in ax.get_xticklabels()]\n    # \n    distances = [bboxes[i + 1].x0 - bboxes[i].x1 for i in range(len(bboxes) - 1)]\n    # 0\n    if any(distance < 0 for distance in distances):\n        if_overlap = True\n    else:",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def plot_return(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return_from_csv",
        "kind": 2,
        "importPath": "lib.rl.plot",
        "description": "lib.rl.plot",
        "peekOfCode": "def plot_return_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "lib.rl.test",
        "description": "lib.rl.test",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "lib.rl.test",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 2,
        "importPath": "lib.rl.trade",
        "description": "lib.rl.trade",
        "peekOfCode": "def trade(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "lib.rl.trade",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "lib.rl.train",
        "description": "lib.rl.train",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "lib.rl.train",
        "documentation": {}
    },
    {
        "label": "WorkflowScheduler",
        "kind": 6,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "class WorkflowScheduler:\n    def __init__(self):\n        # Define labels and date ranges for different workflow modes\n        self.labels = {\n            \"Train\": (TRAIN_START_DATE, TRAIN_END_DATE),\n            \"Test\": (TEST_START_DATE, TEST_END_DATE),\n            \"Trade\": (TRADE_START_DATE, TRADE_END_DATE),\n        }\n        self.train_start_date = self.labels[\"Train\"][0]\n        self.train_end_date = self.labels[\"Train\"][1]",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "setFirstPageTitle",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def setFirstPageTitle() : \n    custom_css = \"\"\"\n    <style>\n    body {\n    background-color: black; /* Background color (black) */\n    font-family: \"Times New Roman\", Times, serif; /* Font family (Times New Roman) */\n    color: white; /* Text color (white) */\n    line-height: 1.6; /* Line height for readability */\n    }\n    h1 {",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_inputs99",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def set_inputs99():\n    st.title(\"Dynamic Financial Reinforcement Learning\")\n    st.write(\"\"\"\n    This application simulates a dynamic dataset-driven financial reinforcement learning model, \n    which uses a rolling window technique to incrementally update the training and testing sets based on real-time market data.\n    The dataset is divided into training and testing segments, which adjust every W days to keep the model updated.\n    \"\"\")\nclass WorkflowScheduler:\n    def __init__(self):\n        # Define labels and date ranges for different workflow modes",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "get_full_path",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def get_full_path(fn):\n    file_path = os.path.join(DATA_FRAME_DIR, fn )\n    return file_path\ndef set_yahoo_data_frame(ticker_ls, wf) :\n  \"\"\"app.py: Waiting data collection From Yahoo downloader ...\"\"\"\n  df = YahooDownloader(start_date  = \n  wf.train_start_date,\n  end_date = wf.trade_end_date,\n  ticker_list = ticker_ls).fetch_data()\n  df.sort_values(['date','tic'],ignore_index=True).head()",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_yahoo_data_frame",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def set_yahoo_data_frame(ticker_ls, wf) :\n  \"\"\"app.py: Waiting data collection From Yahoo downloader ...\"\"\"\n  df = YahooDownloader(start_date  = \n  wf.train_start_date,\n  end_date = wf.trade_end_date,\n  ticker_list = ticker_ls).fetch_data()\n  df.sort_values(['date','tic'],ignore_index=True).head()\n  fe = FeatureEngineer(\n                    use_technical_indicator=True,\n                    tech_indicator_list = INDICATORS,",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def train_agent(agent, model_name = \"a2c\", total_timesteps=50000):\n    \"\"\"\n    Train a model with the provided agent and model_name and total_timesteps \n    \"\"\"\n    # Get the model for A2C if applicable\n    __cached__model_ = agent.get_model(model_name)\n    # Set up logger\n    _tmp_path = RESULTS_DIR + '/' + model_name\n    _new_logger = configure(_tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n    # Set the new logger",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "predict_with_models",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def predict_with_models(models, environment):\n      \"\"\"\n      Perform predictions using multiple trained models in the specified environment.\n      Parameters:\n      - models: A dictionary of trained models with names as keys.\n      - environment: The trading environment to be used for predictions.\n      Returns:\n      - results: A dictionary containing DataFrames of account values and actions for each model.\n      \"\"\"\n      results = {}",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "GetTickerList",
        "kind": 2,
        "importPath": "lib.utility.inputs",
        "description": "lib.utility.inputs",
        "peekOfCode": "def GetTickerList():\n    \"\"\"\n    Generate a list of tickers based on user selection (Index, Sector, or NYSE) in a Streamlit app.\n    Parameters:\n    - index_dict: Dictionary of indexes and their respective tickers.\n    - sector_dict: Dictionary of sectors and their respective tickers.\n    - usa_dict: Dictionary of NYSE-specific categories and tickers.\n    - SP_500_TICKER: List of tickers for the S&P 500.\n    Returns:\n    - final_ticker_list: List of selected tickers.",
        "detail": "lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "jprint",
        "kind": 2,
        "importPath": "lib.utility.jprint",
        "description": "lib.utility.jprint",
        "peekOfCode": "def jprint(s1 = '', s2 = '' , s3 = '', s4 = \"\"):\n  a1 = str(s1) + str(s2) + str(s3) +str(s4)\n  print   (a1)\n  st.write(a1)\n# def jprint2(*args):\n#     # Convert all inputs to strings and handle lists/arrays\n#     result = []\n#     for arg in args:\n#         if isinstance(arg, (list, tuple)):  # Check if the argument is a list or tuple\n#             result.extend(map(str, arg))    # Convert each item in the list to a string",
        "detail": "lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "get_ticker_start_end_date",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_ticker_start_end_date():\n    # Select Index Category\n    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])\n    with col1:\n        selected_index = st.selectbox(\" Select Index Category:\", list(index_dict.keys()))\n        TICKERS = index_dict[selected_index]  # Update TICKERS based on selection\n    with col2:\n        ticker = st.selectbox(\" Select a Stock Ticker:\", TICKERS)\n    with col3:\n        start_date = st.date_input(\" Start Date\", datetime.date(2025, 1, 1))",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_real_time_price",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_real_time_price(ticker):\n    try:\n        api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=\"https://paper-api.alpaca.markets\")\n        trade = api.get_latest_trade(ticker)\n        return trade.price  #  Return price if trade exists\n    except tradeapi.rest.APIError as e:\n        print(f\" Alpaca API Error: {e}\")  #  Log the error\n        return None  #  Return None if no trade is found\n# Original alpaca_hist (still used for stock universe)\ndef get_stock_client():",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\n# Initialize Alpaca Data Client\nstock_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\nimport pandas as pd\nfrom datetime import date, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom alpaca.data.historical import StockHistoricalDataClient\nfrom alpaca.data.requests import StockBarsRequest\nfrom alpaca.data.timeframe import TimeFrame",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_baseline2",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_baseline2(ticker: str, start: str, end: str) -> pd.DataFrame:\n    print(f\" Fetching baseline: {ticker} from {start} to {end}\")\n    # Replace ^DJI or unsupported indices with valid ETF tickers\n    if ticker in [\"^DJI\", \"^GSPC\", \"^NDX\"]:\n        print(f\" Replacing unsupported index ticker {ticker} with SPY\")\n        ticker = \"SPY\"\n    start_date = dt.strptime(start, \"%Y-%m-%d\").date()\n    end_date = dt.strptime(end, \"%Y-%m-%d\").date()\n    try:\n        request = StockBarsRequest(",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\n@st.cache_data\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_stock_data",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def fetch_stock_data(ticker, start_date, end_date):\n    \"\"\"Fetch historical stock data from Alpaca.\"\"\"\n    try:\n        # client = get_stock_client()\n        # request_params = StockBarsRequest(symbol_or_symbols=[ticker], timeframe=TimeFrame.Day, start=start_date, end=end_date)\n        # return client.get_stock_bars(request_params)\n        if not ticker:\n            raise ValueError(\"Ticker is empty or None.\")\n        client = get_stock_client()\n        request_params = StockBarsRequest(",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "load_and_plot_stock_data",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def load_and_plot_stock_data(ticker, start_date, end_date):\n    from lib.utility.util import fetch_stock_data, convert_barSet_to_DataFrame\n    barset = fetch_stock_data(ticker, start_date, end_date)\n    df, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\n    return df, close_col\n#  Convert Alpaca Data to DataFrame\ndef convert_alpaca_data_to_df(stock_data):\n    \"\"\"Converts Alpaca BarSet to a Pandas DataFrame for visualization.\"\"\"\n    if isinstance(stock_data, BarSet):\n        data_list = []",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_alpaca_data_to_df",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def convert_alpaca_data_to_df(stock_data):\n    \"\"\"Converts Alpaca BarSet to a Pandas DataFrame for visualization.\"\"\"\n    if isinstance(stock_data, BarSet):\n        data_list = []\n        for symbol, bars in stock_data.data.items():\n            for bar in bars:\n                data_list.append({\n                    \"timestamp\": bar.timestamp,\n                    \"open\": bar.open,\n                    \"high\": bar.high,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_news_data",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def fetch_news_data(ticker):\n    \"\"\"Retrieve news headlines from Finviz and ensure date values exist.\"\"\"\n    try:\n        req = Request(url=FINVIZ_URL + ticker, headers={\"user-agent\": \"Mozilla/5.0\"})\n        html = BeautifulSoup(urlopen(req), \"html.parser\")\n        news_table = html.find(id=\"news-table\")\n        if not news_table:\n            st.warning(f\" No news data found for {ticker}.\")\n            return None\n        news_list = []",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def analyze_sentiment(news_list):\n    if not news_list:\n        return None\n    df_sentiment = pd.DataFrame(news_list)\n    df_sentiment[\"Date\"] = pd.to_datetime(df_sentiment[\"date\"], errors=\"coerce\").dt.date\n    df_sentiment[\"Compound Score\"] = df_sentiment[\"title\"].apply(lambda title: SentimentIntensityAnalyzer().polarity_scores(title)[\"compound\"])\n    return df_sentiment\n#  Display Sentiment Summary\ndef display_sentiment_summary(df_sentiment):\n    st.subheader(\" Sentiment Summary\")",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "display_sentiment_summary",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def display_sentiment_summary(df_sentiment):\n    st.subheader(\" Sentiment Summary\")\n    avg_score = df_sentiment[\"Compound Score\"].mean() * 100\n    sentiment_icon = \"\" if avg_score > 10 else \"\" if avg_score < -10 else \"\"\n    st.metric(label=f\" Average Sentiment Score {sentiment_icon}\", value=f\"{avg_score:.2f}%\")\n    summary = {\n        \" Positive\": f\"{(df_sentiment['Compound Score'] > 0).sum() / len(df_sentiment) * 100:.2f}%\",\n        \" Negative\": f\"{(df_sentiment['Compound Score'] < 0).sum() / len(df_sentiment) * 100:.2f}%\",\n        \" Neutral\": f\"{(df_sentiment['Compound Score'] == 0).sum() / len(df_sentiment) * 100:.2f}%\"\n    }",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "plot_stock_data",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def plot_stock_data(stock_data, ticker):\n    \"\"\"Processes stock data and plots it.\"\"\"\n    df_stock = convert_alpaca_data_to_df(stock_data)\n    if not df_stock.empty:\n        st.subheader(f\" {ticker} Stock Price Movements\")\n        st.line_chart(df_stock[[\"close\"]])\n    else:\n        st.warning(\" No valid stock data available.\")\n#  Compute Moving Averages\ndef compute_moving_averages(df_stock, close_col):",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def compute_moving_averages(df_stock, close_col):\n    \"\"\"Computes SMA & EMA indicators.\"\"\"\n    df_stock[\"SMA_50\"] = df_stock[close_col].rolling(window=50, min_periods=1).mean()\n    df_stock[\"EMA_20\"] = df_stock[close_col].ewm(span=20, adjust=False).mean()\n    return df_stock\n#  Generate Buy/Sell Signals\ndef generate_trade_signals(df_stock, df_news, close_col):\n    if df_stock is None or df_news is None or close_col not in df_stock.columns:\n        st.warning(\" Cannot generate trade signals due to missing price or sentiment data.\")\n        return pd.DataFrame()",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "generate_trade_signals",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def generate_trade_signals(df_stock, df_news, close_col):\n    if df_stock is None or df_news is None or close_col not in df_stock.columns:\n        st.warning(\" Cannot generate trade signals due to missing price or sentiment data.\")\n        return pd.DataFrame()\n    df_news = df_news.copy()\n    if \"Date\" not in df_news.columns and df_news.index.name == \"Date\":\n        df_news = df_news.reset_index()\n    df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"], errors=\"coerce\", utc=True)\n    df_news.set_index(\"Date\", inplace=True)\n    df_merged = df_stock.merge(",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_barSet_to_DataFrame",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def convert_barSet_to_DataFrame(stock_data, _, ticker):\n    if isinstance(stock_data, BarSet):\n        data_list = []\n        for symbol, bars in stock_data.data.items():\n            for bar in bars:\n                data_list.append({\n                    \"timestamp\": bar.timestamp,\n                    \"open\": bar.open,\n                    \"high\": bar.high,\n                    \"low\": bar.low,",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def compute_moving_averages(df_stock_, ticker, df_news):\n        close_col = f\"{ticker}_close\" if f\"{ticker}_close\" in df_stock_.columns else None\n        if close_col:\n            #  Compute Moving Averages\n            df_stock_[\"SMA_50\"] = df_stock_[close_col].rolling(window=50, min_periods=1).mean()\n            df_stock_[\"EMA_20\"] = df_stock_[close_col].ewm(span=20, adjust=False).mean()\n            #  Convert df_news[\"Date\"] to datetime & set as index\n            df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"], errors=\"coerce\", utc=True)\n            df_news.set_index(\"Date\", inplace=True)\n            #  Merge Sentiment and Stock Data (Fixed: Ensure both indices are datetime64[ns, UTC])",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "collapsible_detailed_description",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def collapsible_detailed_description(s1,s2):          \n  with st.expander(s1):\n    st.markdown(s2)  \n@st.cache_data\ndef fetch_twitter_sentiment(ticker):\n    # Placeholder/mock: In real app, integrate Twitter API or snscrape\n    mock_data = [\n        {\"text\": f\"{ticker} is going to the moon! \", \"sentiment\": 0.8},\n        {\"text\": f\"I'm not sure about {ticker}, looks weak.\", \"sentiment\": -0.3},\n    ]",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_twitter_sentiment",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def fetch_twitter_sentiment(ticker):\n    # Placeholder/mock: In real app, integrate Twitter API or snscrape\n    mock_data = [\n        {\"text\": f\"{ticker} is going to the moon! \", \"sentiment\": 0.8},\n        {\"text\": f\"I'm not sure about {ticker}, looks weak.\", \"sentiment\": -0.3},\n    ]\n    df = pd.DataFrame(mock_data)\n    df[\"source\"] = \"Twitter\"\n    return df    \n@st.cache_data",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_reddit_sentiment",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def fetch_reddit_sentiment(ticker):\n    mock_data = [\n        {\"text\": f\"{ticker} YOLO play on r/wallstreetbets\", \"sentiment\": 0.7},\n        {\"text\": f\"{ticker} is overhyped.\", \"sentiment\": -0.2},\n    ]\n    df = pd.DataFrame(mock_data)\n    df[\"source\"] = \"Reddit\"\n    return df\n@st.cache_data\ndef fetch_google_trends(ticker):",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_google_trends",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def fetch_google_trends(ticker):\n    from pytrends.request import TrendReq\n    pytrends = TrendReq()\n    kw_list = [ticker]\n    pytrends.build_payload(kw_list, timeframe=\"now 7-d\")\n    interest = pytrends.interest_over_time()\n    if not interest.empty:\n        df = interest.reset_index()[[\"date\", ticker]]\n        df.rename(columns={ticker: \"interest\"}, inplace=True)\n        return df",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alternative_data_source",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def alternative_data_source():\n    from pytrends.request import TrendReq\n    pytrends = TrendReq()\n    pytrends.build_payload([ticker], timeframe=\"now 7-d\", geo=\"US\")\n    trends_data = pytrends.interest_over_time()\n    st.subheader(\" Google Trends Interest\")\n    st.line_chart(trends_data)\n#  5. Portfolio Analysis\n#  Features Added:\n# Tracks multiple stocks.",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "calculate_portfolio_value",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def calculate_portfolio_value(portfolio):\n    portfolio = {\n    \"AAPL\": {\"quantity\": 5, \"buy_price\": 150},\n    \"TSLA\": {\"quantity\": 3, \"buy_price\": 700}\n    }\n    total_value = 0\n    for stock, details in portfolio.items():\n        current_price = get_real_time_price(stock)\n        total_value += details[\"quantity\"] * current_price\n    return total_value",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "place_trade",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def place_trade(order_type, ticker, qty):\n    import alpaca_trade_api as tradeapi\n    api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=\"https://paper-api.alpaca.markets\")\n    api.submit_order(\n        symbol=ticker,\n        qty=qty,\n        side=order_type,\n        type=\"market\",\n        time_in_force=\"gtc\"\n    )",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "stock_prediction",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def stock_prediction():\n    import tensorflow as tf\n    from keras.models import Sequential\n    from keras.layers import LSTM, Dense\n    model = Sequential([\n        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n        LSTM(50, return_sequences=False),\n        Dense(25),\n        Dense(1)\n    ])",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "daily_market_summary",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def daily_market_summary():\n    st.subheader(\" Market Summary\")\n    market_summary = {\n        \" Top Gainer\": \"NVDA (+12.5%)\",\n        \" Top Loser\": \"TSLA (-8.2%)\",\n        \" Market Trend\": \"Bullish \"\n    }\n    st.json(market_summary)\n# 3. AI-Based Sentiment Classification (GPT-4)\n#  Features Added:",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_sentiment_gpt4",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def get_sentiment_gpt4(news_headline):\n    import openai\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": f\"Analyze the sentiment of this stock-related news: {news_headline}\"}]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"]\ndef compute_price_features(df, close_col, short_window=50, long_window=100):\n    \"\"\"\n    Compute SMA, EMA, and percentage change on the closing price column.",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_price_features",
        "kind": 2,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "def compute_price_features(df, close_col, short_window=50, long_window=100):\n    \"\"\"\n    Compute SMA, EMA, and percentage change on the closing price column.\n    Args:\n        df (pd.DataFrame): Stock price data.\n        close_col (str): Column name for close prices (e.g. 'AAPL_close').\n        short_window (int): Window for short-term SMA.\n        long_window (int): Window for long-term SMA.\n    Returns:\n        pd.DataFrame: DataFrame with new SMA, EMA, and % Change columns added.",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "FINVIZ_URL",
        "kind": 5,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "FINVIZ_URL = \"https://finviz.com/quote.ashx?t=\"\n#  Download NLTK dependencies\nnltk.download(\"vader_lexicon\")\n#  Fetch Real-Time Stock Price\nimport alpaca_trade_api as tradeapi\nfrom datetime import datetime as dt\ndef get_ticker_start_end_date():\n    # Select Index Category\n    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])\n    with col1:",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "stock_client",
        "kind": 5,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "stock_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\nimport pandas as pd\nfrom datetime import date, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom alpaca.data.historical import StockHistoricalDataClient\nfrom alpaca.data.requests import StockBarsRequest\nfrom alpaca.data.timeframe import TimeFrame\nimport os\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\nfrom datetime import datetime as dt  #  alias to avoid conflicts",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "stock_client",
        "kind": 5,
        "importPath": "lib.utility.util",
        "description": "lib.utility.util",
        "peekOfCode": "stock_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef get_baseline2(ticker: str, start: str, end: str) -> pd.DataFrame:\n    print(f\" Fetching baseline: {ticker} from {start} to {end}\")\n    # Replace ^DJI or unsupported indices with valid ETF tickers\n    if ticker in [\"^DJI\", \"^GSPC\", \"^NDX\"]:\n        print(f\" Replacing unsupported index ticker {ticker} with SPY\")\n        ticker = \"SPY\"\n    start_date = dt.strptime(start, \"%Y-%m-%d\").date()\n    end_date = dt.strptime(end, \"%Y-%m-%d\").date()\n    try:",
        "detail": "lib.utility.util",
        "documentation": {}
    },
    {
        "label": "AlpacaBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.alpaca_backtesting",
        "description": "lumibot.backtesting.alpaca_backtesting",
        "peekOfCode": "class AlpacaBacktesting(DataSourceBacktesting, AlpacaData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        raise Exception(\"DOV AlpacaBacktesting is not currently operational\")\n        AlpacaData.__init__(self, **kwargs)\n        DataSourceBacktesting.__init__(self, datetime_start, datetime_end)\n# class DataSourceBacktesting(AlpacaData):\n#     \"\"\"\n#     AlpacaDataBacktesting is a DataSourceBacktesting that uses AlpacaData as a\n#     backtesting data source.\n#     \"\"\"",
        "detail": "lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "AlphaVantageBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.alpha_vantage_backtesting",
        "description": "lumibot.backtesting.alpha_vantage_backtesting",
        "peekOfCode": "class AlphaVantageBacktesting(DataSourceBacktesting, AlphaVantageData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        raise Exception(\"AlphaVantageBacktesting is not currently operational\")\n        AlphaVantageData.__init__(self, **kwargs)\n        DataSourceBacktesting.__init__(self, datetime_start, datetime_end)",
        "detail": "lumibot.backtesting.alpha_vantage_backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "kind": 6,
        "importPath": "lumibot.backtesting.backtesting_broker",
        "description": "lumibot.backtesting.backtesting_broker",
        "peekOfCode": "class BacktestingBroker(Broker):\n    # Metainfo\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, data_source, option_source=None, connect_stream=True, max_workers=20, config=None, **kwargs):\n        super().__init__(name=\"backtesting\", data_source=data_source,\n                         option_source=option_source, connect_stream=connect_stream, **kwargs)\n        # Calling init methods\n        self.max_workers = max_workers\n        self.market = \"NASDAQ\"\n        self.option_source = option_source",
        "detail": "lumibot.backtesting.backtesting_broker",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.backtesting.backtesting_broker",
        "description": "lumibot.backtesting.backtesting_broker",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass BacktestingBroker(Broker):\n    # Metainfo\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, data_source, option_source=None, connect_stream=True, max_workers=20, config=None, **kwargs):\n        super().__init__(name=\"backtesting\", data_source=data_source,\n                         option_source=option_source, connect_stream=connect_stream, **kwargs)\n        # Calling init methods\n        self.max_workers = max_workers\n        self.market = \"NASDAQ\"",
        "detail": "lumibot.backtesting.backtesting_broker",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.ccxt_backtesting",
        "description": "lumibot.backtesting.ccxt_backtesting",
        "peekOfCode": "class CcxtBacktesting(CcxtBacktestingData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        CcxtBacktestingData.__init__(self, datetime_start, datetime_end, **kwargs)",
        "detail": "lumibot.backtesting.ccxt_backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.pandas_backtesting",
        "description": "lumibot.backtesting.pandas_backtesting",
        "peekOfCode": "class PandasDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of the PandasData class.  This class is just kept around for legacy purposes.\n    Please just use PandasData directly instead.\n    \"\"\"\n    def __init__(self, *args, pandas_data=None, **kwargs):\n        super().__init__(*args, pandas_data=pandas_data, **kwargs)",
        "detail": "lumibot.backtesting.pandas_backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.polygon_backtesting",
        "description": "lumibot.backtesting.polygon_backtesting",
        "peekOfCode": "class PolygonDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of Polygon\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,\n        api_key=None,",
        "detail": "lumibot.backtesting.polygon_backtesting",
        "documentation": {}
    },
    {
        "label": "START_BUFFER",
        "kind": 5,
        "importPath": "lumibot.backtesting.polygon_backtesting",
        "description": "lumibot.backtesting.polygon_backtesting",
        "peekOfCode": "START_BUFFER = timedelta(days=5)\nclass PolygonDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of Polygon\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,",
        "detail": "lumibot.backtesting.polygon_backtesting",
        "documentation": {}
    },
    {
        "label": "ThetaDataBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.thetadata_backtesting",
        "description": "lumibot.backtesting.thetadata_backtesting",
        "peekOfCode": "class ThetaDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of ThetaData\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,\n        username=None,",
        "detail": "lumibot.backtesting.thetadata_backtesting",
        "documentation": {}
    },
    {
        "label": "START_BUFFER",
        "kind": 5,
        "importPath": "lumibot.backtesting.thetadata_backtesting",
        "description": "lumibot.backtesting.thetadata_backtesting",
        "peekOfCode": "START_BUFFER = timedelta(days=5)\nclass ThetaDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of ThetaData\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,",
        "detail": "lumibot.backtesting.thetadata_backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "kind": 6,
        "importPath": "lumibot.backtesting.yahoo_backtesting",
        "description": "lumibot.backtesting.yahoo_backtesting",
        "peekOfCode": "class YahooDataBacktesting(YahooData):\n    \"\"\"\n    YahooDataBacktesting is a DataSourceBacktesting that uses YahooData as a\n    backtesting data source.\n    \"\"\"\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        YahooData.__init__(self, datetime_start, datetime_end, **kwargs)",
        "detail": "lumibot.backtesting.yahoo_backtesting",
        "documentation": {}
    },
    {
        "label": "OrderData",
        "kind": 6,
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "peekOfCode": "class OrderData:\n    def __init__(self, **kwargs):\n        self.__dict__.update(kwargs)\n    def to_request_fields(self):\n        return self.__dict__\nclass Alpaca(Broker):\n    \"\"\"A broker class that connects to Alpaca\n    Attributes\n    ----------\n    api : tradeapi.REST",
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "kind": 6,
        "importPath": "lumibot.brokers.alpaca",
        "description": "lumibot.brokers.alpaca",
        "peekOfCode": "class Alpaca(Broker):\n    \"\"\"A broker class that connects to Alpaca\n    Attributes\n    ----------\n    api : tradeapi.REST\n        Alpaca API object\n    Methods\n    -------\n    get_timestamp()\n        Returns the current UNIX timestamp representation from Alpaca",
        "detail": "lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "CustomLoggerAdapter",
        "kind": 6,
        "importPath": "lumibot.brokers.broker",
        "description": "lumibot.brokers.broker",
        "peekOfCode": "class CustomLoggerAdapter(logging.LoggerAdapter):\n    def process(self, msg, kwargs):\n        # Check if the level is enabled to avoid formatting costs if not necessary\n        if self.logger.isEnabledFor(kwargs.get('level', logging.INFO)):\n            # Lazy formatting of the message\n            return f'[{self.extra[\"strategy_name\"]}] {msg}', kwargs\n        else:\n            return msg, kwargs\n    def update_strategy_name(self, new_strategy_name):\n        self.extra['strategy_name'] = new_strategy_name",
        "detail": "lumibot.brokers.broker",
        "documentation": {}
    },
    {
        "label": "Broker",
        "kind": 6,
        "importPath": "lumibot.brokers.broker",
        "description": "lumibot.brokers.broker",
        "peekOfCode": "class Broker(ABC):\n    # Metainfo\n    IS_BACKTESTING_BROKER = False\n    # Trading events flags\n    NEW_ORDER = \"new\"\n    CANCELED_ORDER = \"canceled\"\n    FILLED_ORDER = \"fill\"\n    PARTIALLY_FILLED_ORDER = \"partial_fill\"\n    CASH_SETTLED = \"cash_settled\"\n    ERROR_ORDER = \"error\"",
        "detail": "lumibot.brokers.broker",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "kind": 6,
        "importPath": "lumibot.brokers.ccxt",
        "description": "lumibot.brokers.ccxt",
        "peekOfCode": "class Ccxt(Broker):\n    \"\"\"\n    Crypto broker using CCXT.\n    \"\"\"\n    def __init__(self, config, data_source: CcxtData = None, max_workers=20, chunk_size=100, **kwargs):\n        if data_source is None:\n            data_source = CcxtData(config, max_workers=max_workers, chunk_size=chunk_size)\n        super().__init__(name=\"ccxt\", config=config, data_source=data_source, max_workers=max_workers, **kwargs)\n        self.market = \"24/7\"\n        self.fetch_open_orders_last_request_time = None",
        "detail": "lumibot.brokers.ccxt",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "kind": 6,
        "importPath": "lumibot.brokers.example_broker",
        "description": "lumibot.brokers.example_broker",
        "peekOfCode": "class ExampleBroker(Broker):\n    \"\"\"\n    Example broker that demonstrates how to connect to an API.\n    \"\"\"\n    NAME = \"ExampleBroker\"\n    def __init__(\n            self,\n            config=None,\n            data_source=None,\n    ):",
        "detail": "lumibot.brokers.example_broker",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "kind": 6,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "class InteractiveBrokers(Broker):\n    \"\"\"Inherit InteractiveBrokerData first and all the price market\n    methods than inherits broker\"\"\"\n    def __init__(self, config, max_workers=20, chunk_size=100, data_source=None, **kwargs):\n        if data_source is None:\n            data_source = InteractiveBrokersData(config, max_workers=max_workers, chunk_size=chunk_size)\n        super().__init__(\n            name=\"interactive_brokers\", \n            config=config, \n            data_source=data_source, ",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBWrapper",
        "kind": 6,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBWrapper(EWrapper):\n    \"\"\"Listens and collects data from IB.\"\"\"\n    # Error handling code.\n    def init_error(self):\n        error_queue = queue.Queue()\n        self.my_errors_queue = error_queue\n    def is_error(self):\n        error_exist = not self.my_errors_queue.empty()\n        return error_exist\n    def get_error(self, timeout=6):",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBClient",
        "kind": 6,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBClient(EClient):\n    \"\"\"Sends data to IB\"\"\"\n    def __init__(self, wrapper):\n        ## Set up with a wrapper inside\n        EClient.__init__(self, wrapper)\n        self.max_wait_time = 13\n        self.reqId = 10000\n    def get_reqid(self):\n        self.reqId += 1\n        return self.reqId",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBApp",
        "kind": 6,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBApp(IBWrapper, IBClient):\n    def __init__(self, ip_address, socket_port, client_id, subaccount=None, ib_broker=None):\n        IBWrapper.__init__(self)\n        IBClient.__init__(self, wrapper=self)\n        self.ip_address = ip_address\n        self.socket_port = socket_port\n        self.client_id = client_id\n        self.ib_broker = ib_broker\n        self.subaccount = subaccount\n        self.reqAutoOpenOrders(True)",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nDATE_MAP = dict(\n    future=\"%Y%m%d\",",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "DATE_MAP",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "DATE_MAP = dict(\n    future=\"%Y%m%d\",\n    option=\"%Y%m%d\",\n)\nORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "ORDERTYPE_MAPPING",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers",
        "description": "lumibot.brokers.interactive_brokers",
        "peekOfCode": "ORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",\n)\nclass InteractiveBrokers(Broker):\n    \"\"\"Inherit InteractiveBrokerData first and all the price market\n    methods than inherits broker\"\"\"",
        "detail": "lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "kind": 6,
        "importPath": "lumibot.brokers.interactive_brokers_rest",
        "description": "lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "class InteractiveBrokersREST(Broker):\n    \"\"\"\n    Broker that connects to the Interactive Brokers REST API.\n    \"\"\"\n    NAME = \"InteractiveBrokersREST\"\n    def __init__(self, config, data_source=None):\n        if data_source is None:\n            data_source = InteractiveBrokersRESTData(config)\n        super().__init__(name=self.NAME, data_source=data_source, config=config)\n        self.market = \"NYSE\"  # The default market is NYSE.",
        "detail": "lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers_rest",
        "description": "lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nDATE_MAP = dict(\n    future=\"%Y%m%d\",",
        "detail": "lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "DATE_MAP",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers_rest",
        "description": "lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "DATE_MAP = dict(\n    future=\"%Y%m%d\",\n    option=\"%Y%m%d\",\n)\nORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",",
        "detail": "lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "ORDERTYPE_MAPPING",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers_rest",
        "description": "lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "ORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",\n)\nSPREAD_CONID_MAP = {\n    \"AUD\": 61227077,\n    \"CAD\": 61227082,",
        "detail": "lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "SPREAD_CONID_MAP",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers_rest",
        "description": "lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "SPREAD_CONID_MAP = {\n    \"AUD\": 61227077,\n    \"CAD\": 61227082,\n    \"CHF\": 61227087,\n    \"CNH\": 136000441,\n    \"GBP\": 58666491,\n    \"HKD\": 61227072,\n    \"INR\": 136000444,\n    \"JPY\": 61227069,\n    \"KRW\": 136000424,",
        "detail": "lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "ASSET_CLASS_MAPPING",
        "kind": 5,
        "importPath": "lumibot.brokers.interactive_brokers_rest",
        "description": "lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "ASSET_CLASS_MAPPING = {\n    \"STK\": Asset.AssetType.STOCK,\n    \"OPT\": Asset.AssetType.OPTION,\n    \"FUT\": Asset.AssetType.FUTURE,\n    \"CASH\": Asset.AssetType.FOREX,\n}\nclass InteractiveBrokersREST(Broker):\n    \"\"\"\n    Broker that connects to the Interactive Brokers REST API.\n    \"\"\"",
        "detail": "lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "kind": 6,
        "importPath": "lumibot.brokers.tradier",
        "description": "lumibot.brokers.tradier",
        "peekOfCode": "class Tradier(Broker):\n    \"\"\"\n    Broker that connects to Tradier API to place orders and retrieve data. Tradier API only supports Order streaming\n    for live accounts, paper trading accounts must use a 'polling' method to retrieve order updates. This class will\n    still use a CustomStream object to process order updates (which can be confusing!), but this will more seamlessly\n    match what other LumiBrokers are doing without requiring changes to the stategy_executor. This\n    polling method will also work for Live accounts, so it will be used by default. However, future updates will be\n    made to natively support websocket streaming for Live accounts.\n    \"\"\"\n    POLL_EVENT = PollingStream.POLL_EVENT",
        "detail": "lumibot.brokers.tradier",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "kind": 6,
        "importPath": "lumibot.data_sources.alpaca_data",
        "description": "lumibot.data_sources.alpaca_data",
        "peekOfCode": "class AlpacaData(DataSource):\n    SOURCE = \"ALPACA\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"minute\",\n            \"representations\": [TimeFrame.Minute, \"minute\"],\n        },\n        {\n            \"timestep\": \"5 minutes\",",
        "detail": "lumibot.data_sources.alpaca_data",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "kind": 6,
        "importPath": "lumibot.data_sources.alpha_vantage_data",
        "description": "lumibot.data_sources.alpha_vantage_data",
        "peekOfCode": "class AlphaVantageData(DataSource):\n    SOURCE = \"ALPHA_VANTAGE\"\n    MIN_TIMESTEP = \"minute\"\n    DATA_STALE_AFTER = timedelta(days=1)\n    def __init__(self, config=None, auto_adjust=True, **kwargs):\n        self.name = \"alpha vantage\"\n        self.auto_adjust = auto_adjust\n        self._data_store = {}\n        self.config = config\n    def _append_data(self, asset, data):",
        "detail": "lumibot.data_sources.alpha_vantage_data",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingData",
        "kind": 6,
        "importPath": "lumibot.data_sources.ccxt_backtesting_data",
        "description": "lumibot.data_sources.ccxt_backtesting_data",
        "peekOfCode": "class CcxtBacktestingData(DataSourceBacktesting):\n    \"\"\"Use CcxtCacheDB to download and cache data.\n    \"\"\"\n    # SOURCE must be `CCXT` for the DataSourceBacktesting to work\n    # `CCXT` is used in DataSource name\n    SOURCE = \"CCXT\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"minute\", \"representations\": [\"1m\"]},\n        {\"timestep\": \"day\", \"representations\": [\"1d\"]},",
        "detail": "lumibot.data_sources.ccxt_backtesting_data",
        "documentation": {}
    },
    {
        "label": "CcxtData",
        "kind": 6,
        "importPath": "lumibot.data_sources.ccxt_data",
        "description": "lumibot.data_sources.ccxt_data",
        "peekOfCode": "class CcxtData(DataSource):\n    SOURCE = \"CCXT\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"minute\", \"representations\": [\"1m\"]},\n        {\"timestep\": \"day\", \"representations\": [\"1d\"]},\n    ]\n    IS_BACKTESTING_DATA_SOURCE = False\n    \"\"\"Common base class for data_sources/ccxt and brokers/ccxt\"\"\"\n    @staticmethod",
        "detail": "lumibot.data_sources.ccxt_data",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "kind": 6,
        "importPath": "lumibot.data_sources.data_source",
        "description": "lumibot.data_sources.data_source",
        "peekOfCode": "class DataSource(ABC):\n    SOURCE = \"\"\n    IS_BACKTESTING_DATA_SOURCE = False\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = []\n    DEFAULT_TIMEZONE = LUMIBOT_DEFAULT_TIMEZONE\n    DEFAULT_PYTZ = LUMIBOT_DEFAULT_PYTZ\n    def __init__(self, api_key=None, delay=None):\n        \"\"\"\n        Parameters",
        "detail": "lumibot.data_sources.data_source",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "kind": 6,
        "importPath": "lumibot.data_sources.data_source_backtesting",
        "description": "lumibot.data_sources.data_source_backtesting",
        "peekOfCode": "class DataSourceBacktesting(DataSource, ABC):\n    \"\"\"\n    This class is the base class for all backtesting data sources.  It is also an abstract class and should not be\n    instantiated directly because it does not define all necessary methods. Instead, instantiate one of the\n    child classes like PandasData.\n    \"\"\"\n    IS_BACKTESTING_DATA_SOURCE = True\n    def __init__(\n        self,\n        datetime_start,",
        "detail": "lumibot.data_sources.data_source_backtesting",
        "documentation": {}
    },
    {
        "label": "ExampleBrokerData",
        "kind": 6,
        "importPath": "lumibot.data_sources.example_broker_data",
        "description": "lumibot.data_sources.example_broker_data",
        "peekOfCode": "class ExampleBrokerData(DataSource):\n    \"\"\"\n    Data source that connects to the Example Broker API.\n    \"\"\"\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"ExampleBroker\"\n    def __init__(self):\n        super().__init__()\n    # Method stubs with logging for not yet implemented methods\n    def get_chains(self, asset: Asset, quote: Asset = None) -> dict:",
        "detail": "lumibot.data_sources.example_broker_data",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "kind": 6,
        "importPath": "lumibot.data_sources.exceptions",
        "description": "lumibot.data_sources.exceptions",
        "peekOfCode": "class NoDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoDataFound, self).__init__(message)\nclass UnavailabeTimestep(Exception):\n    def __init__(self, source, timestep):\n        message = \"%s data source does not have data with %r timestep\" % (",
        "detail": "lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "UnavailabeTimestep",
        "kind": 6,
        "importPath": "lumibot.data_sources.exceptions",
        "description": "lumibot.data_sources.exceptions",
        "peekOfCode": "class UnavailabeTimestep(Exception):\n    def __init__(self, source, timestep):\n        message = \"%s data source does not have data with %r timestep\" % (\n            source,\n            timestep,\n        )\n        super(UnavailabeTimestep, self).__init__(message)",
        "detail": "lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersData",
        "kind": 6,
        "importPath": "lumibot.data_sources.interactive_brokers_data",
        "description": "lumibot.data_sources.interactive_brokers_data",
        "peekOfCode": "class InteractiveBrokersData(DataSource):\n    \"\"\"Make Interactive Brokers connection and gets data.\n    Create connection to Interactive Brokers market through either Gateway or TWS\n    which must be running locally for connection to be made.\n    \"\"\"\n    SOURCE = \"InteractiveBrokers\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"second\",",
        "detail": "lumibot.data_sources.interactive_brokers_data",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "lumibot.data_sources.interactive_brokers_data",
        "description": "lumibot.data_sources.interactive_brokers_data",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nclass InteractiveBrokersData(DataSource):\n    \"\"\"Make Interactive Brokers connection and gets data.",
        "detail": "lumibot.data_sources.interactive_brokers_data",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersRESTData",
        "kind": 6,
        "importPath": "lumibot.data_sources.interactive_brokers_rest_data",
        "description": "lumibot.data_sources.interactive_brokers_rest_data",
        "peekOfCode": "class InteractiveBrokersRESTData(DataSource):\n    \"\"\"\n    Data source that connects to the Interactive Brokers REST API.\n    \"\"\"\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"InteractiveBrokersREST\"\n    def __init__(self, config):\n        if config[\"API_URL\"] is None:\n            self.port = \"4234\"\n            self.base_url = f\"https://localhost:{self.port}/v1/api\"",
        "detail": "lumibot.data_sources.interactive_brokers_rest_data",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "lumibot.data_sources.interactive_brokers_rest_data",
        "description": "lumibot.data_sources.interactive_brokers_rest_data",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nclass InteractiveBrokersRESTData(DataSource):\n    \"\"\"",
        "detail": "lumibot.data_sources.interactive_brokers_rest_data",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "kind": 6,
        "importPath": "lumibot.data_sources.pandas_data",
        "description": "lumibot.data_sources.pandas_data",
        "peekOfCode": "class PandasData(DataSourceBacktesting):\n    \"\"\"\n    PandasData is a Backtesting-only DataSource that uses a Pandas DataFrame (read from CSV) as the source of\n    data for a backtest run. It is not possible to use this class to run a live trading strategy.\n    \"\"\"\n    SOURCE = \"PANDAS\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1D\", \"day\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1M\", \"minute\"]},\n    ]",
        "detail": "lumibot.data_sources.pandas_data",
        "documentation": {}
    },
    {
        "label": "TradierAPIError",
        "kind": 6,
        "importPath": "lumibot.data_sources.tradier_data",
        "description": "lumibot.data_sources.tradier_data",
        "peekOfCode": "class TradierAPIError(Exception):\n    pass\nclass TradierData(DataSource):\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"Tradier\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"tick\",\n            \"representations\": [\n                \"tick\",",
        "detail": "lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "TradierData",
        "kind": 6,
        "importPath": "lumibot.data_sources.tradier_data",
        "description": "lumibot.data_sources.tradier_data",
        "peekOfCode": "class TradierData(DataSource):\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"Tradier\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"tick\",\n            \"representations\": [\n                \"tick\",\n            ],\n        },",
        "detail": "lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "YahooData",
        "kind": 6,
        "importPath": "lumibot.data_sources.yahoo_data",
        "description": "lumibot.data_sources.yahoo_data",
        "peekOfCode": "class YahooData(DataSourceBacktesting):\n    SOURCE = \"YAHOO\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1d\", \"day\"]},\n        {\"timestep\": \"15 minutes\", \"representations\": [\"15m\", \"15 minutes\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1m\", \"1 minute\"]},\n    ]\n    def __init__(self, *args, auto_adjust=True, **kwargs):\n        super().__init__(*args, **kwargs)",
        "detail": "lumibot.data_sources.yahoo_data",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.data_sources.yahoo_data",
        "description": "lumibot.data_sources.yahoo_data",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass YahooData(DataSourceBacktesting):\n    SOURCE = \"YAHOO\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1d\", \"day\"]},\n        {\"timestep\": \"15 minutes\", \"representations\": [\"15m\", \"15 minutes\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1m\", \"1 minute\"]},\n    ]\n    def __init__(self, *args, auto_adjust=True, **kwargs):",
        "detail": "lumibot.data_sources.yahoo_data",
        "documentation": {}
    },
    {
        "label": "Asset",
        "kind": 6,
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "peekOfCode": "class Asset:\n    \"\"\"\n    This is a base class for Assets including stocks, futures, options,\n    forex, and crypto.\n    Parameters\n    ----------\n    symbol : str\n        Symbol of the stock or underlying in case of futures/options.\n    asset_type : str\n        Type of the asset. Asset types are only 'stock', 'option', 'future', 'forex', 'crypto'",
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "kind": 6,
        "importPath": "lumibot.entities.asset",
        "description": "lumibot.entities.asset",
        "peekOfCode": "class AssetsMapping(UserDict):\n    def __init__(self, mapping):\n        UserDict.__init__(self, mapping)\n        symbols_mapping = {k.symbol: v for k, v in mapping.items()}\n        self._symbols_mapping = symbols_mapping\n    def __missing__(self, key):\n        if isinstance(key, str):\n            if key in self._symbols_mapping:\n                return self._symbols_mapping[key]\n        raise KeyError(key)",
        "detail": "lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Bar",
        "kind": 6,
        "importPath": "lumibot.entities.bar",
        "description": "lumibot.entities.bar",
        "peekOfCode": "class Bar(ComparaisonMixin):\n    \"\"\"\n    The Bar class represents a single bar (OHLC) of data.\n    Attributes\n    ----------\n    timestamp : datetime.datetime\n        The timestamp of the bar.\n    open : float\n        The opening price of the bar.\n    high : float",
        "detail": "lumibot.entities.bar",
        "documentation": {}
    },
    {
        "label": "Bars",
        "kind": 6,
        "importPath": "lumibot.entities.bars",
        "description": "lumibot.entities.bars",
        "peekOfCode": "class Bars:\n    \"\"\"Pricing and financial data for given Symbol.\n    The OHLCV, and if available, dividends, stock splits for a given\n    financial instrument. Price change, dividend yield and return\n    are calculated if appropriate.\n    Parameters\n    ----------\n    df : Pandas Dataframe\n        Dataframe with:\n            datetime.datetime index time zone aware.",
        "detail": "lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "NoBarDataFound",
        "kind": 6,
        "importPath": "lumibot.entities.bars",
        "description": "lumibot.entities.bars",
        "peekOfCode": "class NoBarDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoBarDataFound, self).__init__(message)\n    def aggregate_bars(self, frequency):\n        \"\"\"\n        Will convert a set of bars to a different timeframe (eg. 1 min to 15 min)",
        "detail": "lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "NoBarDataFound",
        "kind": 6,
        "importPath": "lumibot.entities.bars",
        "description": "lumibot.entities.bars",
        "peekOfCode": "class NoBarDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoBarDataFound, self).__init__(message)",
        "detail": "lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "Data",
        "kind": 6,
        "importPath": "lumibot.entities.data",
        "description": "lumibot.entities.data",
        "peekOfCode": "class Data:\n    \"\"\"Input and manage Pandas dataframes for backtesting.\n    Parameters\n    ----------\n    asset : Asset Object\n        Asset to which this data is attached.\n    df : dataframe\n        Pandas dataframe containing OHLCV etc. trade data. Loaded by user\n        from csv.\n        Index is date and must be pandas datetime64.",
        "detail": "lumibot.entities.data",
        "documentation": {}
    },
    {
        "label": "Dataline",
        "kind": 6,
        "importPath": "lumibot.entities.dataline",
        "description": "lumibot.entities.dataline",
        "peekOfCode": "class Dataline:\n    def __init__(self, asset, name, dataline, dtype):\n        self.asset = asset\n        self.name = name\n        self.dataline = dataline\n        self.dtype = dtype",
        "detail": "lumibot.entities.dataline",
        "documentation": {}
    },
    {
        "label": "Order",
        "kind": 6,
        "importPath": "lumibot.entities.order",
        "description": "lumibot.entities.order",
        "peekOfCode": "class Order:\n    Transaction = namedtuple(\"Transaction\", [\"quantity\", \"price\"])\n    class OrderClass:\n        BRACKET = \"bracket\"\n        OCO = \"oco\"\n        OTO = \"oto\"\n        MULTILEG = \"multileg\"\n    class OrderType:\n        MARKET = \"market\"\n        LIMIT = \"limit\"",
        "detail": "lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "SELL",
        "kind": 5,
        "importPath": "lumibot.entities.order",
        "description": "lumibot.entities.order",
        "peekOfCode": "SELL = \"sell\"\nBUY = \"buy\"\nVALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status",
        "detail": "lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "BUY",
        "kind": 5,
        "importPath": "lumibot.entities.order",
        "description": "lumibot.entities.order",
        "peekOfCode": "BUY = \"buy\"\nVALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status",
        "detail": "lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "VALID_STATUS",
        "kind": 5,
        "importPath": "lumibot.entities.order",
        "description": "lumibot.entities.order",
        "peekOfCode": "VALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status\n    \"presubmitted\": \"new\",  # IBKR status",
        "detail": "lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "STATUS_ALIAS_MAP",
        "kind": 5,
        "importPath": "lumibot.entities.order",
        "description": "lumibot.entities.order",
        "peekOfCode": "STATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status\n    \"presubmitted\": \"new\",  # IBKR status\n    \"rejected\": \"error\",  # Tradier status",
        "detail": "lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "Position",
        "kind": 6,
        "importPath": "lumibot.entities.position",
        "description": "lumibot.entities.position",
        "peekOfCode": "class Position:\n    \"\"\"\n    This is a Position object. It is used to keep track of the quantity of an asset owned in a strategy.\n    Position objects are retreived from the broker using the get_positions() or get_position() methods.\n    Attributes\n    ----------\n    strategy : str\n        The strategy that owns this position.\n    asset : Asset\n        The asset that this position is for.",
        "detail": "lumibot.entities.position",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "kind": 6,
        "importPath": "lumibot.entities.trading_fee",
        "description": "lumibot.entities.trading_fee",
        "peekOfCode": "class TradingFee:\n    \"\"\"TradingFee class. Used to define the trading fees for a broker in a strategy/backtesting.\"\"\"\n    def __init__(self, flat_fee=0.0, percent_fee=0.0, maker=True, taker=True):\n        \"\"\"\n        Parameters\n        ----------\n        flat_fee : Decimal, float, or None\n            Flat fee to pay for each order. This is a fixed fee that is paid for each order in the quote currency.\n        percent_fee : Decimal, float, or None\n            Percentage fee to pay for each order. This is a percentage of the order value that is paid for each order in the quote currency.",
        "detail": "lumibot.entities.trading_fee",
        "documentation": {}
    },
    {
        "label": "Developing_Momentum_Trading_Strategy",
        "kind": 6,
        "importPath": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "class Developing_Momentum_Trading_Strategy:\n    # https://github.com/mjmacarty/alphavantage/blob/main/3-momentum_algorithmic.ipynb\n    # Many services for this, some paid some free\n    # Yahoo Finance API\n    # Typically trading \"systems\" involve a number of securities\n    # For this demonstration we are just going to look at GLD --> the gold ETF\n    import numpy as np\n    import pandas as pd\n    import pandas_datareader as pdr\n    import matplotlib.pyplot as plt   ",
        "detail": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "FastTrading",
        "kind": 6,
        "importPath": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "class FastTrading(Strategy):\n    # =========over loading life cycle methods\n    def initialize(self, momentum_length = 2, max_assets = 4):\n        self.momentum_length =  momentum_length # in minutes\n        self.sleeptime = 1\n         # set symbols tht we want to be monitoring\n        self.symbols = ['TSLA', 'SPY', 'GLD', 'TLT', 'MSFT', 'MCHI', 'SPXL', 'SPXS']\n        # Initialise our variables  \n        self.assets_quantity = {symbol:0 for symbol in self.symbols}\n        self.max_assets = min(max_assets, len(self.symbols))",
        "detail": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass Developing_Momentum_Trading_Strategy:\n    # https://github.com/mjmacarty/alphavantage/blob/main/3-momentum_algorithmic.ipynb\n    # Many services for this, some paid some free\n    # Yahoo Finance API\n    # Typically trading \"systems\" involve a number of securities\n    # For this demonstration we are just going to look at GLD --> the gold ETF\n    import numpy as np\n    import pandas as pd\n    import pandas_datareader as pdr",
        "detail": "lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "FastTrading",
        "kind": 6,
        "importPath": "lumibot.example_strategies.FastTrading.fasttrading_2",
        "description": "lumibot.example_strategies.FastTrading.fasttrading_2",
        "peekOfCode": "class FastTrading(Strategy):\n    IS_BACKTESTING = False\n    # ===== Overloading Lifecycle Methods =====\n    def initialize(self, momentum_length=2, max_assets=4):\n        # Set symbols we want to monitor\n        self.symbols = ['TSLA', 'SPY', 'GLD', 'TLT', 'MSFT', 'MCHI', 'SPXL', 'SPXS']\n        self.momentum_length = momentum_length  # in minutes\n        self.sleeptime = 1  # Optional: For slowing down execution\n        self.frequency = \"minute\"  # For minute-level trading\n        self.max_assets = min(max_assets, len(self.symbols))  # Limit max assets to trade",
        "detail": "lumibot.example_strategies.FastTrading.fasttrading_2",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "AlpacaConfig = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}  \nlogfile = \"logs/test.log\"\ntrader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "logfile",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "logfile = \"logs/test.log\"\ntrader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" ",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "trader",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "trader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "broker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "strategy_name",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "strategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:\n    ###\n    # 1. Backtest the strtegy\n    ###\nbacktesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:\n    ###\n    # 1. Backtest the strtegy\n    ###\nbacktesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)\ndatestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "backtesting_start",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "backtesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)\ndatestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")\nstats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "datestring",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "datestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")\nstats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,\n    stats_file=stats_file\n) ",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "stats_file",
        "kind": 5,
        "importPath": "lumibot.example_strategies.FastTrading.main",
        "description": "lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "stats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,\n    stats_file=stats_file\n) \n###",
        "detail": "lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingExampleStrategy",
        "kind": 6,
        "importPath": "lumibot.example_strategies.ccxt_backtesting_example",
        "description": "lumibot.example_strategies.ccxt_backtesting_example",
        "peekOfCode": "class CcxtBacktestingExampleStrategy(Strategy):\n    def initialize(self, asset:tuple[Asset,Asset] = None,\n                   cash_at_risk:float=.25,window:int=21):\n        if asset is None:\n            raise ValueError(\"You must provide a valid asset pair\")\n        # for crypto, market is 24/7\n        self.set_market(\"24/7\")\n        self.sleeptime = \"1D\"\n        self.asset = asset\n        self.base, self.quote = asset",
        "detail": "lumibot.example_strategies.ccxt_backtesting_example",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "kind": 6,
        "importPath": "lumibot.example_strategies.crypto_important_functions",
        "description": "lumibot.example_strategies.crypto_important_functions",
        "peekOfCode": "class ImportantFunctions(Strategy):\n    def initialize(self):\n        # Set the time between trading iterations\n        self.sleeptime = \"30S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n    def on_trading_iteration(self):\n        ###########################\n        # Placing an Order\n        ###########################",
        "detail": "lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "kind": 6,
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class DriftRebalancer(Strategy):\n    \"\"\"The DriftRebalancer strategy rebalances a portfolio based on drift from target weights.\n    The strategy calculates the drift of each asset in the portfolio and triggers a rebalance if the drift exceeds\n    the drift_threshold. The strategy will sell assets that have drifted above the threshold and\n    buy assets that have drifted below the threshold.\n    The current version of the DriftRebalancer strategy only supports limit orders and whole share quantities.\n    Submit an issue if you need market orders or fractional shares. It should be pretty easy to add.\n    Example parameters:\n    parameters = {\n        ### Standard lumibot strategy parameters",
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftCalculationLogic",
        "kind": 6,
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class DriftCalculationLogic:\n    def __init__(self, target_weights: Dict[str, Decimal]) -> None:\n        self.df = pd.DataFrame({\n            \"symbol\": target_weights.keys(),\n            \"is_quote_asset\": False,\n            \"current_quantity\": Decimal(0),\n            \"current_value\": Decimal(0),\n            \"current_weight\": Decimal(0),\n            \"target_weight\": [Decimal(weight) for weight in target_weights.values()],\n            \"target_value\": Decimal(0),",
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LimitOrderRebalanceLogic",
        "kind": 6,
        "importPath": "lumibot.example_strategies.drift_rebalancer",
        "description": "lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class LimitOrderRebalanceLogic:\n    def __init__(\n            self,\n            *,\n            strategy: Strategy,\n            df: pd.DataFrame,\n            fill_sleeptime: int = 15,\n            acceptable_slippage: Decimal = Decimal(\"0.005\"),\n            shorting: bool = False\n    ) -> None:",
        "detail": "lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LifecycleLogger",
        "kind": 6,
        "importPath": "lumibot.example_strategies.lifecycle_logger",
        "description": "lumibot.example_strategies.lifecycle_logger",
        "peekOfCode": "class LifecycleLogger(Strategy):\n    parameters = {\n        \"sleeptime\": \"10s\",\n        \"market\": \"24/7\",\n    }\n    def initialize(self, symbol=\"\"):\n        self.sleeptime = self.parameters[\"sleeptime\"]\n        self.set_market(self.parameters[\"market\"])\n    def before_market_opens(self):\n        dt = self.get_datetime()",
        "detail": "lumibot.example_strategies.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.example_strategies.lifecycle_logger",
        "description": "lumibot.example_strategies.lifecycle_logger",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LifecycleLogger(Strategy):\n    parameters = {\n        \"sleeptime\": \"10s\",\n        \"market\": \"24/7\",\n    }\n    def initialize(self, symbol=\"\"):\n        self.sleeptime = self.parameters[\"sleeptime\"]\n        self.set_market(self.parameters[\"market\"])\n    def before_market_opens(self):",
        "detail": "lumibot.example_strategies.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "OptionsHoldToExpiry",
        "kind": 6,
        "importPath": "lumibot.example_strategies.options_hold_to_expiry",
        "description": "lumibot.example_strategies.options_hold_to_expiry",
        "peekOfCode": "class OptionsHoldToExpiry(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"expiry\": datetime(2023, 10, 20),\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants\n        # Built in Variables\n        self.sleeptime = \"1D\"",
        "detail": "lumibot.example_strategies.options_hold_to_expiry",
        "documentation": {}
    },
    {
        "label": "MyStrategy",
        "kind": 6,
        "importPath": "lumibot.example_strategies.simple_start_single_file",
        "description": "lumibot.example_strategies.simple_start_single_file",
        "peekOfCode": "class MyStrategy(Strategy):\n    def initialize(self, symbol=\"\"):\n        # Will make on_trading_iteration() run every 180 minutes\n        self.sleeptime = 180\n        # Custom parameters\n        self.symbol = symbol\n        self.quantity = 1\n        self.side = \"buy\"\n    def on_trading_iteration(self):\n        self.order = self.create_order(self.symbol, self.quantity, self.side)",
        "detail": "lumibot.example_strategies.simple_start_single_file",
        "documentation": {}
    },
    {
        "label": "StockBracket",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_bracket",
        "description": "lumibot.example_strategies.stock_bracket",
        "peekOfCode": "class StockBracket(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "lumibot.example_strategies.stock_bracket",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_buy_and_hold",
        "description": "lumibot.example_strategies.stock_buy_and_hold",
        "peekOfCode": "class BuyAndHold(Strategy):\n    parameters = {\n        \"buy_symbol\": \"QQQ\",\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the sleep time to one day (the strategy will run once per day)\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        \"\"\"Buys the self.buy_symbol once, then never again\"\"\"",
        "detail": "lumibot.example_strategies.stock_buy_and_hold",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_diversified_leverage",
        "description": "lumibot.example_strategies.stock_diversified_leverage",
        "peekOfCode": "class DiversifiedLeverage(Strategy):\n    # =====Overloading lifecycle methods=============\n    parameters = {\n        \"portfolio\": [\n            {\n                \"symbol\": \"TQQQ\",  # 3x Leveraged Nasdaq\n                \"weight\": 0.20,\n            },\n            {\n                \"symbol\": \"UPRO\",  # 3x Leveraged S&P 500",
        "detail": "lumibot.example_strategies.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "LimitAndTrailingStop",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_limit_and_trailing_stops",
        "description": "lumibot.example_strategies.stock_limit_and_trailing_stops",
        "peekOfCode": "class LimitAndTrailingStop(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"limit_buy_price\": 403,\n        \"limit_sell_price\": 407,\n        \"trail_percent\": 0.02,\n        \"trail_price\": 7,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):",
        "detail": "lumibot.example_strategies.stock_limit_and_trailing_stops",
        "documentation": {}
    },
    {
        "label": "Momentum",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_momentum",
        "description": "lumibot.example_strategies.stock_momentum",
        "peekOfCode": "class Momentum(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self, symbols=None):\n        # Setting the waiting period (in days)\n        self.period = 2\n        # The counter for the number of days we have been holding the current asset\n        self.counter = 0\n        # There is only one trading operation per day\n        # No need to sleep between iterations\n        self.sleeptime = 0",
        "detail": "lumibot.example_strategies.stock_momentum",
        "documentation": {}
    },
    {
        "label": "StockOco",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_oco",
        "description": "lumibot.example_strategies.stock_oco",
        "peekOfCode": "class StockOco(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "lumibot.example_strategies.stock_oco",
        "documentation": {}
    },
    {
        "label": "StockSentiment",
        "kind": 6,
        "importPath": "lumibot.example_strategies.stock_sentiment",
        "description": "lumibot.example_strategies.stock_sentiment",
        "peekOfCode": "class StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],\n            base_url=BASE_URL",
        "detail": "lumibot.example_strategies.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "lumibot.example_strategies.stock_sentiment",
        "description": "lumibot.example_strategies.stock_sentiment",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nclass StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],",
        "detail": "lumibot.example_strategies.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "Strangle",
        "kind": 6,
        "importPath": "lumibot.example_strategies.strangle",
        "description": "lumibot.example_strategies.strangle",
        "peekOfCode": "class Strangle(Strategy):\n    \"\"\"Strategy Description: Strangle\n    In a long stranglethe more common strategythe investor simultaneously buys an\n    out-of-the-money call and an out-of-the-money put option. The call option's strike\n    price is higher than the underlying asset's current market price, while the put has a\n    strike price that is lower than the asset's market price. This strategy has large profit\n    potential since the call option has theoretically unlimited upside if the underlying\n    asset rises in price, while the put option can profit if the underlying asset falls.\n    The risk on the trade is limited to the premium paid for the two options.\n    Place the strangle two weeks before earnings announcement.",
        "detail": "lumibot.example_strategies.strangle",
        "documentation": {}
    },
    {
        "label": "BrokerTest",
        "kind": 6,
        "importPath": "lumibot.example_strategies.test_broker_functions",
        "description": "lumibot.example_strategies.test_broker_functions",
        "peekOfCode": "class BrokerTest(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the time between trading iterations\n        # strategy runs every 20 seconds.\n        self.sleeptime = \"20S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n        # Record the last trade time\n        self.last_trade_time = None",
        "detail": "lumibot.example_strategies.test_broker_functions",
        "documentation": {}
    },
    {
        "label": "CustomLoggerAdapter",
        "kind": 6,
        "importPath": "lumibot.strategies._strategy",
        "description": "lumibot.strategies._strategy",
        "peekOfCode": "class CustomLoggerAdapter(logging.LoggerAdapter):\n    def __init__(self, logger, extra):\n        super().__init__(logger, extra)\n        self.prefix = f'[{self.extra[\"strategy_name\"]}] '\n    def process(self, msg, kwargs):\n        try:\n            return self.prefix + msg, kwargs\n        except Exception as e:\n            return msg, kwargs\nclass Vars:",
        "detail": "lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "Vars",
        "kind": 6,
        "importPath": "lumibot.strategies._strategy",
        "description": "lumibot.strategies._strategy",
        "peekOfCode": "class Vars:\n    def __init__(self):\n        super().__setattr__('_vars_dict', {})\n    def __getattr__(self, name):\n        try:\n            return self._vars_dict[name]\n        except KeyError:\n            raise AttributeError(f\"'Vars' object has no attribute '{name}'\")\n    def __setattr__(self, name, value):\n        self._vars_dict[name] = value",
        "detail": "lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "_Strategy",
        "kind": 6,
        "importPath": "lumibot.strategies._strategy",
        "description": "lumibot.strategies._strategy",
        "peekOfCode": "class _Strategy:\n    IS_BACKTESTABLE = True\n    _trader = None\n    def __init__(\n        self,\n        broker=None,\n        minutes_before_closing=1,\n        minutes_before_opening=60,\n        minutes_after_closing=0,\n        sleeptime=\"1M\",",
        "detail": "lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "peekOfCode": "class Strategy(_Strategy):\n    @property\n    def name(self):\n        \"\"\"Returns the name of the strategy.\n        Returns:\n            str: The name of the strategy.\n        Example\n        -------\n        >>> self.log_message(f'Strategy name: {self.name}')\n        \"\"\"",
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "STATS_TABLE_NAME",
        "kind": 5,
        "importPath": "lumibot.strategies.strategy",
        "description": "lumibot.strategies.strategy",
        "peekOfCode": "STATS_TABLE_NAME = \"strategy_tracker\"\nclass Strategy(_Strategy):\n    @property\n    def name(self):\n        \"\"\"Returns the name of the strategy.\n        Returns:\n            str: The name of the strategy.\n        Example\n        -------\n        >>> self.log_message(f'Strategy name: {self.name}')",
        "detail": "lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "StrategyExecutor",
        "kind": 6,
        "importPath": "lumibot.strategies.strategy_executor",
        "description": "lumibot.strategies.strategy_executor",
        "peekOfCode": "class StrategyExecutor(Thread):\n    # Trading events flags\n    NEW_ORDER = \"new\"\n    CANCELED_ORDER = \"canceled\"\n    FILLED_ORDER = \"fill\"\n    PARTIALLY_FILLED_ORDER = \"partial_fill\"\n    def __init__(self, strategy):\n        super(StrategyExecutor, self).__init__()\n        self.daemon = True\n        self.stop_event = Event()",
        "detail": "lumibot.strategies.strategy_executor",
        "documentation": {}
    },
    {
        "label": "GK",
        "kind": 6,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "class GK:\n    \"\"\"Garman-Kohlhagen\n\tUsed for pricing European options on currencies\n\tGK([underlyingPrice, strikePrice, domesticRate, foreignRate, \\\n\t\t\tdaysToExpiration], volatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "BS",
        "kind": 6,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "class BS:\n    \"\"\"Black-Scholes\n\tUsed for pricing European options on stocks without dividends\n\tBS([underlyingPrice, strikePrice, interestRate, daysToExpiration], \\\n\t\t\tvolatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "Me",
        "kind": 6,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "class Me:\n    \"\"\"Merton\n\tUsed for pricing European options on stocks with dividends\n\tMe([underlyingPrice, strikePrice, interestRate, annualDividends, \\\n\t\t\tdaysToExpiration], volatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.Me([52, 50, 1, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "impliedVolatility",
        "kind": 2,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "def impliedVolatility(className, args, callPrice=None, putPrice=None, high=500.0, low=0.0):\n    \"\"\"Returns the estimated implied volatility\"\"\"\n    if callPrice:\n        target = callPrice\n        restimate = eval(className)(args, volatility=high, performance=True).callPrice\n        if restimate < target:\n            return high\n        if args[0] > args[1] + callPrice:\n            return 0.001\n    if putPrice:",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRhoD\t\t\t\t# Returns the call domestic rho",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], putPrice=0.03)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], putPrice=0.03)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.domesticRate = float(args[2]) / 100\n        self.foreignRate = float(args[3]) / 100",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.domesticRate = float(args[2]) / 100\n        self.foreignRate = float(args[3]) / 100\n        self.daysToExpiration = float(args[4]) / 365\n        for i in [",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRho\t\t\t\t# Returns the call rho",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.daysToExpiration = float(args[3]) / 365",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.daysToExpiration = float(args[3]) / 365\n        for i in [\n            \"callPrice\",",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRho\t\t\t\t# Returns the call rho",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.dividend = float(args[3])",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "lumibot.tools.black_scholes",
        "description": "lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.dividend = float(args[3])\n        self.dividendYield = self.dividend / self.underlyingPrice\n        self.daysToExpiration = float(args[4]) / 365",
        "detail": "lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "CcxtCacheDB",
        "kind": 6,
        "importPath": "lumibot.tools.ccxt_data_store",
        "description": "lumibot.tools.ccxt_data_store",
        "peekOfCode": "class CcxtCacheDB:\n    \"\"\"A ccxt data cache class using duckdb.\n    The data being cached is OHLCV data and is stored in UTC.\n    After importing the data, you'll need to change the timezone if necessary.\n    Create an exchange_id folder in the cache folder, and create a symbol_timeframe.duckdb file under it.\n    ex) Create a BTC_USDT_1m.duckdb file in the binance folder.\n    If there is an existing cache file, it will use it to fetch the data, otherwise it will use ccxt to fetch the data.\n    If a cache file exists, but the requested data range is not in the cache file, the data will be fetched using ccxt.\n    For example, if the cache file contains data from 2023-01-01 to 2023-01-10, and you request data from 2023-01-05 to 2023-01-15,\n    the data from 2023-01-05 to 2023-01-10 will be fetched from the cache file, and the data from 2023-01-11 to 2023-01-15 will be fetched using ccxt.",
        "detail": "lumibot.tools.ccxt_data_store",
        "documentation": {}
    },
    {
        "label": "PerfCounters",
        "kind": 6,
        "importPath": "lumibot.tools.debugers",
        "description": "lumibot.tools.debugers",
        "peekOfCode": "class PerfCounters:\n    def __init__(self):\n        self.counters = {}\n    def add_counter(self, name):\n        self.counters[name] = [0, 0]\n    def tic_counter(self, name):\n        self.counters[name][1] = perf_counter()\n    def toc_counter(self, name):\n        toc = perf_counter()\n        counter = self.counters[name]",
        "detail": "lumibot.tools.debugers",
        "documentation": {}
    },
    {
        "label": "perf_counters",
        "kind": 5,
        "importPath": "lumibot.tools.debugers",
        "description": "lumibot.tools.debugers",
        "peekOfCode": "perf_counters = PerfCounters()",
        "detail": "lumibot.tools.debugers",
        "documentation": {}
    },
    {
        "label": "staticdecorator",
        "kind": 2,
        "importPath": "lumibot.tools.decorators",
        "description": "lumibot.tools.decorators",
        "peekOfCode": "def staticdecorator(func):\n    \"\"\"Makes a function decorated with staticmethod executable\"\"\"\n    return func.__get__(\"\")\ndef call_function_get_frame(func, *args, **kwargs):\n    \"\"\"\n    Calls the function *func* with the specified arguments and keyword\n    arguments and snatches its local frame before it actually executes.\n    \"\"\"\n    frame = None\n    trace = sys.gettrace()",
        "detail": "lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "call_function_get_frame",
        "kind": 2,
        "importPath": "lumibot.tools.decorators",
        "description": "lumibot.tools.decorators",
        "peekOfCode": "def call_function_get_frame(func, *args, **kwargs):\n    \"\"\"\n    Calls the function *func* with the specified arguments and keyword\n    arguments and snatches its local frame before it actually executes.\n    \"\"\"\n    frame = None\n    trace = sys.gettrace()\n    def snatch_locals(_frame, name, arg):\n        nonlocal frame\n        if frame is None and name == \"call\":",
        "detail": "lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "snatch_locals",
        "kind": 2,
        "importPath": "lumibot.tools.decorators",
        "description": "lumibot.tools.decorators",
        "peekOfCode": "def snatch_locals(store):\n    \"\"\"Snatch a function local variables\n    and store them in store variable\"\"\"\n    def wrapper(func_input):\n        @wraps(func_input)\n        def func_output(*args, **kwargs):\n            global store\n            frame, result = call_function_get_frame(func_input, *args, **kwargs)\n            store = frame.f_locals\n            return result",
        "detail": "lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "append_locals",
        "kind": 2,
        "importPath": "lumibot.tools.decorators",
        "description": "lumibot.tools.decorators",
        "peekOfCode": "def append_locals(func_input):\n    \"\"\"Snatch a function local variables\n    and store them in store variable\"\"\"\n    @wraps(func_input)\n    def func_output(*args, **kwargs):\n        frame, result = call_function_get_frame(func_input, *args, **kwargs)\n        if frame is not None:\n            func_output.locals = frame.f_locals\n        else:\n            func_output.locals = None",
        "detail": "lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "execute_after",
        "kind": 2,
        "importPath": "lumibot.tools.decorators",
        "description": "lumibot.tools.decorators",
        "peekOfCode": "def execute_after(actions):\n    def decorator_func(input_func):\n        @wraps(input_func)\n        def output_func(*args, **kwargs):\n            input_func(*args, **kwargs)\n            for action in actions:\n                action()\n        return output_func\n    return decorator_func",
        "detail": "lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "ComparaisonMixin",
        "kind": 6,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "class ComparaisonMixin:\n    COMPARAISON_PROP = \"timestamp\"\n    def __eq__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) == getattr(other, self.COMPARAISON_PROP)\n    def __ne__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) != getattr(other, self.COMPARAISON_PROP)\n    def __gt__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) > getattr(other, self.COMPARAISON_PROP)\n    def __ge__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) >= getattr(other, self.COMPARAISON_PROP)",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_chunks",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def get_chunks(l, chunk_size):\n    chunks = []\n    for i in range(0, len(l), chunk_size):\n        chunks.append(l[i: i + chunk_size])\n    return chunks\ndef deduplicate_sequence(seq, key=\"\"):\n    seen = set()\n    pos = 0\n    if key:\n        get_ref = lambda item: getattr(item, key)",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "deduplicate_sequence",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def deduplicate_sequence(seq, key=\"\"):\n    seen = set()\n    pos = 0\n    if key:\n        get_ref = lambda item: getattr(item, key)\n    else:\n        get_ref = lambda item: item\n    for item in seq:\n        ref = get_ref(item)\n        if ref not in seen:",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def get_trading_days(market=\"NYSE\", start_date=\"1950-01-01\", end_date=None):\n    format_datetime = lambda dt: dt.to_pydatetime().astimezone(LUMIBOT_DEFAULT_PYTZ)\n    start_date = to_datetime_aware(pd.to_datetime(start_date))\n    today = get_lumibot_datetime()\n    # macl's \"24/7\" calendar doesn't return consecutive days, so need to be generated manually.\n    if market == \"24/7\":\n        market_open = pd.date_range(\n            start=start_date, end=end_date or today).to_frame(index=False,name=\"market_open\")\n        market_close = pd.date_range(\n            start=start_date.replace(hour=23,minute=59,second=59,microsecond=999999), ",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "print_progress_bar",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def print_progress_bar(\n    value,\n    start_value,\n    end_value,\n    backtesting_started,\n    file=sys.stdout,\n    length=None,\n    prefix=\"Progress\",\n    suffix=\"\",\n    decimals=2,",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_lumibot_datetime",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def get_lumibot_datetime():\n    return dt.datetime.now().astimezone(LUMIBOT_DEFAULT_PYTZ)\ndef to_datetime_aware(dt_in):\n    \"\"\"Convert naive time to datetime aware on default timezone.\"\"\"\n    if not dt_in:\n        return dt_in\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo is None):\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo.utcoffset(dt_in) is None):\n        # TODO: This will fail because an exception is thrown if tzinfo is not None.",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def to_datetime_aware(dt_in):\n    \"\"\"Convert naive time to datetime aware on default timezone.\"\"\"\n    if not dt_in:\n        return dt_in\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo is None):\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo.utcoffset(dt_in) is None):\n        # TODO: This will fail because an exception is thrown if tzinfo is not None.\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    else:",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_symbol",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def parse_symbol(symbol):\n    \"\"\"\n    Parse the given symbol and determine if it's an option or a stock.\n    For options, extract and return the stock symbol, expiration date (as a datetime.date object),\n    type (call or put), and strike price.\n    For stocks, simply return the stock symbol.\n    TODO: Crypto and Forex support\n    \"\"\"\n    # Check that the symbol is a string\n    if not isinstance(symbol, str):",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def create_options_symbol(stock_symbol, expiration_date, option_type, strike_price):\n    \"\"\"\n    Create an option symbol string from its components.\n    Parameters\n    ----------\n    stock_symbol : str\n        The stock symbol, e.g., 'AAPL'.\n    expiration_date : dt.date or dt.datetime\n        The expiration date of the option.\n    option_type : str",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "kind": 2,
        "importPath": "lumibot.tools.helpers",
        "description": "lumibot.tools.helpers",
        "peekOfCode": "def parse_timestep_qty_and_unit(timestep):\n    \"\"\"\n    Parse the timestep string and return the quantity and unit.\n    Parameters\n    ----------\n    timestep : str\n        The timestep string to parse.\n    Returns\n    -------\n    tuple",
        "detail": "lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "total_return",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def total_return(_df):\n    \"\"\"Calculate the cumulative return in a dataframe\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    df = df.sort_index(ascending=True)\n    df[\"cum_return\"] = (1 + df[\"return\"]).cumprod()\n    total_ret = df[\"cum_return\"].iloc[-1] - 1\n    return total_ret",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "cagr",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def cagr(_df):\n    \"\"\"Calculate the Compound Annual Growth Rate\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    Example:\n    >>> df = pd.DataFrame({\"return\": [0.1, 0.2, 0.3, 0.4, 0.5]})\n    >>> cagr(df)\n    0.3125\n    \"\"\"\n    df = _df.copy()",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "volatility",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def volatility(_df):\n    \"\"\"Calculate the volatility (standard deviation)\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    start = datetime.fromtimestamp(df.index.values[0].astype(\"O\") / 1e9, pytz.UTC)\n    end = datetime.fromtimestamp(df.index.values[-1].astype(\"O\") / 1e9, pytz.UTC)\n    period_years = (end - start).days / 365.25\n    if period_years == 0:",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "sharpe",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def sharpe(_df, risk_free_rate):\n    \"\"\"Calculate the Sharpe Rate, or (CAGR - risk_free_rate) / volatility\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily).\n    risk_free_rate should be either LIBOR, or the shortest possible US Treasury Rate\n    \"\"\"\n    ret = cagr(_df)\n    vol = volatility(_df)\n    if vol == 0:\n        return 0",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "max_drawdown",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def max_drawdown(_df):\n    \"\"\"Calculate the Max Drawdown, or the biggest percentage drop\n    from peak to trough.\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    if _df.shape[0] == 1:\n        return {\"drawdown\": 0, \"date\": _df.index[0]}\n    df = _df.copy()\n    df = df.sort_index(ascending=True)",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "romad",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def romad(_df):\n    \"\"\"Calculate the Return Over Maximum Drawdown (RoMaD)\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    ret = cagr(_df)\n    mdd = max_drawdown(_df)\n    if mdd[\"drawdown\"] == 0:\n        return 0\n    romad = ret / mdd[\"drawdown\"]",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "stats_summary",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def stats_summary(_df, risk_free_rate):\n    return {\n        \"cagr\": cagr(_df),\n        \"volatility\": volatility(_df),\n        \"sharpe\": sharpe(_df, risk_free_rate),\n        \"max_drawdown\": max_drawdown(_df),\n        \"romad\": romad(_df),\n        \"total_return\": total_return(_df),\n    }\ndef performance(_df, risk_free, prefix=\"\"):",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "performance",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def performance(_df, risk_free, prefix=\"\"):\n    \"\"\"Calculate and print out all of our performance indicators\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    cagr_adj = cagr(_df)\n    vol_adj = volatility(_df)\n    sharpe_adj = sharpe(_df, risk_free)\n    maxdown_adj = max_drawdown(_df)\n    romad_adj = romad(_df)",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def get_symbol_returns(symbol, start=datetime(1900, 1, 1), end=datetime.now()):\n    \"\"\"Get the returns for a symbol between two dates\n    Parameters\n    ----------\n    symbol : str\n        The symbol to get the returns for\n    start : datetime, optional\n        The start date, by default datetime(1900, 1, 1)\n    end : datetime, optional\n        The end date, by default datetime.now()",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "calculate_returns",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def calculate_returns(symbol, start=datetime(1900, 1, 1), end=datetime.now()):\n    start = to_datetime_aware(start)\n    end = to_datetime_aware(end)\n    benchmark_df = get_symbol_returns(symbol, start, end)\n    risk_free_rate = get_risk_free_rate()\n    performance(benchmark_df, risk_free_rate, symbol)\ndef plot_indicators(\n    plot_file_html=\"indicators.html\",\n    chart_markers_df=None,\n    chart_lines_df=None,",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "plot_indicators",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def plot_indicators(\n    plot_file_html=\"indicators.html\",\n    chart_markers_df=None,\n    chart_lines_df=None,\n    strategy_name=None,\n    show_indicators=True,\n):\n    # If show plot is False, then we don't want to open the plot in the browser\n    if not show_indicators:\n        logger.debug(\"show_indicators is False, not creating the plot file.\")",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "plot_returns",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def plot_returns(\n    strategy_df,\n    strategy_name,\n    benchmark_df,\n    benchmark_name,\n    plot_file_html=\"backtest_result.html\",\n    trades_df=None,\n    show_plot=True,\n    initial_budget=1,\n    # chart_markers_df=None,",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "create_tearsheet",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def create_tearsheet(\n    # =========BY DOV========\n    strategy_df: pd.DataFrame.to_numpy,\n    strat_name: str,\n    tearsheet_file: str,\n    benchmark_df: pd.DataFrame.to_numpy,\n    benchmark_asset,  # This is causing a circular import: Asset,\n    show_tearsheet: bool,\n    save_tearsheet: bool,\n    risk_free_rate: float,",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "get_risk_free_rate",
        "kind": 2,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "def get_risk_free_rate(dt: datetime = None):\n    try:\n        result = yh.get_risk_free_rate(dt=dt)\n    except Exception as e:\n        logging.error(f\"Error getting the risk free rate: {e}\")\n        result = 0\n    return result",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.tools.indicators",
        "description": "lumibot.tools.indicators",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef total_return(_df):\n    \"\"\"Calculate the cumulative return in a dataframe\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    df = df.sort_index(ascending=True)\n    df[\"cum_return\"] = (1 + df[\"return\"]).cumprod()\n    total_ret = df[\"cum_return\"].iloc[-1] - 1",
        "detail": "lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "warning_time_sleep",
        "kind": 2,
        "importPath": "lumibot.tools.lumibot_time",
        "description": "lumibot.tools.lumibot_time",
        "peekOfCode": "def warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):\n            warned_against_calling_time_sleep = True\n            # TODO: Look into this warning being handled more gracefully. Right now it",
        "detail": "lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "default_time_sleep",
        "kind": 5,
        "importPath": "lumibot.tools.lumibot_time",
        "description": "lumibot.tools.lumibot_time",
        "peekOfCode": "default_time_sleep = time.sleep\nwarned_against_calling_time_sleep = False\ndef warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):",
        "detail": "lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "warned_against_calling_time_sleep",
        "kind": 5,
        "importPath": "lumibot.tools.lumibot_time",
        "description": "lumibot.tools.lumibot_time",
        "peekOfCode": "warned_against_calling_time_sleep = False\ndef warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):\n            warned_against_calling_time_sleep = True",
        "detail": "lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "time.sleep",
        "kind": 5,
        "importPath": "lumibot.tools.lumibot_time",
        "description": "lumibot.tools.lumibot_time",
        "peekOfCode": "time.sleep = warning_time_sleep",
        "detail": "lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "day_deduplicate",
        "kind": 2,
        "importPath": "lumibot.tools.pandas",
        "description": "lumibot.tools.pandas",
        "peekOfCode": "def day_deduplicate(df_):\n    df_copy = df_.copy()\n    df_copy = df_copy.groupby(level=0).head(1)\n    return df_copy\ndef is_daily_data(df_):\n    times = pd.Series(df_.index).apply(lambda x: x.time()).unique()\n    if len(times) == 1 and times[0] == time(0, 0):\n        return True\n    return False\ndef fill_void(df_, interval, end):",
        "detail": "lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "is_daily_data",
        "kind": 2,
        "importPath": "lumibot.tools.pandas",
        "description": "lumibot.tools.pandas",
        "peekOfCode": "def is_daily_data(df_):\n    times = pd.Series(df_.index).apply(lambda x: x.time()).unique()\n    if len(times) == 1 and times[0] == time(0, 0):\n        return True\n    return False\ndef fill_void(df_, interval, end):\n    n_rows = len(df_.index)\n    missing_lines = pd.DataFrame()\n    for index, row in df_.iterrows():\n        position = df_.index.get_loc(index)",
        "detail": "lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "fill_void",
        "kind": 2,
        "importPath": "lumibot.tools.pandas",
        "description": "lumibot.tools.pandas",
        "peekOfCode": "def fill_void(df_, interval, end):\n    n_rows = len(df_.index)\n    missing_lines = pd.DataFrame()\n    for index, row in df_.iterrows():\n        position = df_.index.get_loc(index)\n        if position + 1 == n_rows:\n            if index < end:\n                n_missing = (end - index) // interval\n                missing_days = [index + (i + 1) * interval for i in range(n_missing)]\n                missing_lines = pd.concat(",
        "detail": "lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "print_full_pandas_dataframes",
        "kind": 2,
        "importPath": "lumibot.tools.pandas",
        "description": "lumibot.tools.pandas",
        "peekOfCode": "def print_full_pandas_dataframes():\n    \"\"\"\n    Show the whole dataframe when printing pandas dataframes\n    \"\"\"\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_colwidth', None)\n    pd.set_option('display.max_rows', None)\n    pd.set_option('display.width', 1000)\ndef set_pandas_float_precision(precision: int = 5):\n    format_str = '{:.' + str(precision) + 'f}'",
        "detail": "lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "set_pandas_float_precision",
        "kind": 2,
        "importPath": "lumibot.tools.pandas",
        "description": "lumibot.tools.pandas",
        "peekOfCode": "def set_pandas_float_precision(precision: int = 5):\n    format_str = '{:.' + str(precision) + 'f}'\n    pd.set_option('display.float_format', format_str.format)\ndef prettify_dataframe_with_decimals(df: pd.DataFrame, decimal_places: int = 5) -> str:\n    def decimal_formatter(x):\n        if isinstance(x, Decimal):\n            return f\"{x:.{decimal_places}f}\"\n        return x\n    return df.to_string(formatters={col: decimal_formatter for col in df.columns})",
        "detail": "lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "prettify_dataframe_with_decimals",
        "kind": 2,
        "importPath": "lumibot.tools.pandas",
        "description": "lumibot.tools.pandas",
        "peekOfCode": "def prettify_dataframe_with_decimals(df: pd.DataFrame, decimal_places: int = 5) -> str:\n    def decimal_formatter(x):\n        if isinstance(x, Decimal):\n            return f\"{x:.{decimal_places}f}\"\n        return x\n    return df.to_string(formatters={col: decimal_formatter for col in df.columns})",
        "detail": "lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "PolygonClient",
        "kind": 6,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "class PolygonClient(RESTClient):\n    ''' Rate Limited RESTClient with factory method '''\n    WAIT_SECONDS_RETRY = 60\n    @classmethod\n    def create(cls, *args, **kwargs) -> RESTClient:\n        \"\"\"\n        Factory method to create a RESTClient or PolygonClient instance.\n        The method uses environment variables to determine default values for the API key \n        and subscription type. If the `api_key` is not provided in `kwargs`, it defaults \n        to the value of the `POLYGON_API_KEY` environment variable.",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_cached_schedule",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache\n    if cache_key in schedule_cache:\n        return schedule_cache[cache_key]",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_price_data_from_polygon",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def get_price_data_from_polygon(\n    api_key: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    force_cache_update: bool = False,\n):\n    \"\"\"",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "validate_cache",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def validate_cache(force_cache_update: bool, asset: Asset, cache_file: Path, api_key: str):\n    \"\"\"\n    If the list of splits for a stock have changed then we need to invalidate its cache\n    because all of the prices will have changed (because we're using split adjusted prices).\n    Get the splits data from Polygon only once per day per stock.\n    Use the timestamp on the splits feather file to determine if we need to get the splits again.\n    When invalidating we delete the cache file and return force_cache_update=True too.\n    \"\"\"\n    if asset.asset_type not in [Asset.AssetType.STOCK, Asset.AssetType.OPTION]:\n        return force_cache_update",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_trading_dates",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def get_trading_dates(asset: Asset, start: datetime, end: datetime):\n    \"\"\"\n    Get a list of trading days for the asset between the start and end dates\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    start : datetime\n        Start date for the data requested\n    end : datetime",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_polygon_symbol",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def get_polygon_symbol(asset, polygon_client, quote_asset=None):\n    \"\"\"\n    Get the symbol for the asset in a format that Polygon will understand\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    polygon_client : RESTClient\n        The RESTClient connection for Polygon Stock-Equity API\n    quote_asset : Asset",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "build_cache_filename",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def build_cache_filename(asset: Asset, timespan: str):\n    \"\"\"Helper function to create the cache filename for a given asset and timespan\"\"\"\n    lumibot_polygon_cache_folder = Path(LUMIBOT_CACHE_FOLDER) / \"polygon\"\n    # If It's an option then also add the expiration date, strike price and right to the filename\n    if asset.asset_type == \"option\":\n        if asset.expiration is None:\n            raise ValueError(f\"Expiration date is required for option {asset} but it is None\")\n        # Make asset.expiration datetime into a string like \"YYMMDD\"\n        expiry_string = asset.expiration.strftime(\"%y%m%d\")\n        uniq_str = f\"{asset.symbol}_{expiry_string}_{asset.strike}_{asset.right}\"",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_missing_dates",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def get_missing_dates(df_all, asset, start, end):\n    \"\"\"\n    Check if we have data for the full range\n    Later Query to Polygon will pad an extra full day to start/end dates so that there should never\n    be any gap with intraday data missing.\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        Data loaded from the cache file\n    asset : Asset",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def load_cache(cache_file):\n    \"\"\"Load the data from the cache file and return a DataFrame with a DateTimeIndex\"\"\"\n    df_feather = pd.read_feather(cache_file)\n    # Set the 'datetime' column as the index of the DataFrame\n    df_feather.set_index(\"datetime\", inplace=True)\n    df_feather.index = pd.to_datetime(\n        df_feather.index\n    )  # TODO: Is there some way to speed this up? It takes several times longer than just reading the feather file\n    df_feather = df_feather.sort_index()\n    # Check if the index is already timezone aware",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "update_cache",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def update_cache(cache_file, df_all, missing_dates=None):\n    \"\"\"Update the cache file with the new data.  Missing dates are added as empty (all NaN) \n    rows before it is saved to the cache file.\n    Parameters\n    ----------\n    cache_file : Path\n        The path to the cache file\n    df_all : pd.DataFrame\n        The DataFrame with the data we want to cache\n    missing_dates : list[datetime.date]",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "update_polygon_data",
        "kind": 2,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "def update_polygon_data(df_all, result):\n    \"\"\"\n    Update the DataFrame with the new data from Polygon\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        A DataFrame with the data we already have\n    result : list\n        A List of dictionaries with the new data from Polygon\n        Format: [{'o': 1.0, 'h': 2.0, 'l': 3.0, 'c': 4.0, 'v': 5.0, 't': 116120000000}]",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "MAX_POLYGON_DAYS",
        "kind": 5,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "MAX_POLYGON_DAYS = 30\n# Define a cache dictionary to store schedules and a global dictionary for buffered schedules\nschedule_cache = {}\nbuffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "schedule_cache",
        "kind": 5,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "schedule_cache = {}\nbuffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "buffered_schedules",
        "kind": 5,
        "importPath": "lumibot.tools.polygon_helper",
        "description": "lumibot.tools.polygon_helper",
        "peekOfCode": "buffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache\n    if cache_key in schedule_cache:",
        "detail": "lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_price_data",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    dt=None,\n    datastyle: str = \"ohlc\"",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_trading_dates",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_trading_dates(asset: Asset, start: datetime, end: datetime):\n    \"\"\"\n    Get a list of trading days for the asset between the start and end dates\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    start : datetime\n        Start date for the data requested\n    end : datetime",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "build_cache_filename",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def build_cache_filename(asset: Asset, timespan: str, datastyle: str = \"ohlc\"):\n    \"\"\"Helper function to create the cache filename for a given asset and timespan\"\"\"\n    lumibot_cache_folder = Path(LUMIBOT_CACHE_FOLDER) / CACHE_SUBFOLDER\n    # If It's an option then also add the expiration date, strike price and right to the filename\n    if asset.asset_type == \"option\":\n        if asset.expiration is None:\n            raise ValueError(f\"Expiration date is required for option {asset} but it is None\")\n        # Make asset.expiration datetime into a string like \"YYMMDD\"\n        expiry_string = asset.expiration.strftime(\"%y%m%d\")\n        uniq_str = f\"{asset.symbol}_{expiry_string}_{asset.strike}_{asset.right}\"",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_missing_dates",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_missing_dates(df_all, asset, start, end):\n    \"\"\"\n    Check if we have data for the full range\n    Later Query to Polygon will pad an extra full day to start/end dates so that there should never\n    be any gap with intraday data missing.\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        Data loaded from the cache file\n    asset : Asset",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def load_cache(cache_file):\n    \"\"\"Load the data from the cache file and return a DataFrame with a DateTimeIndex\"\"\"\n    df_feather = pd.read_feather(cache_file)\n    # Set the 'datetime' column as the index of the DataFrame\n    df_feather.set_index(\"datetime\", inplace=True)\n    df_feather.index = pd.to_datetime(\n        df_feather.index\n    )  # TODO: Is there some way to speed this up? It takes several times longer than just reading the feather file\n    df_feather = df_feather.sort_index()\n    # Check if the index is already timezone aware",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "update_cache",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def update_cache(cache_file, df_all, df_feather):\n    \"\"\"Update the cache file with the new data\"\"\"\n    # Check if df_all is different from df_feather (if df_feather exists)\n    if df_all is not None and len(df_all) > 0:\n        # Check if the dataframes are the same\n        if df_all.equals(df_feather):\n            return\n        # Create the directory if it doesn't exist\n        cache_file.parent.mkdir(parents=True, exist_ok=True)\n        # Reset the index to convert DatetimeIndex to a regular column",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "update_df",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def update_df(df_all, result):\n    \"\"\"\n    Update the DataFrame with the new data from ThetaData\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        A DataFrame with the data we already have\n    result : pandas DataFrame\n        A List of dictionaries with the new data from Polygon\n        Format:",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "start_theta_data_client",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def start_theta_data_client(username: str, password: str):\n    # First try shutting down any existing connection\n    try:\n        requests.get(f\"{BASE_URL}/v2/system/terminal/shutdown\")\n    except Exception:\n        pass\n    client = ThetaClient(username=username, passwd=password)\n    time.sleep(1)\n    return client\ndef check_connection(username: str, password: str):",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "check_connection",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def check_connection(username: str, password: str):\n    # Do endless while loop and check if connected every 100 milliseconds\n    MAX_RETRIES = 15\n    counter = 0\n    client = None\n    connected = False\n    while True:\n        try:\n            time.sleep(0.5)\n            res = requests.get(f\"{BASE_URL}/v2/system/mdds/status\", timeout=1)",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_request",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_request(url: str, headers: dict, querystring: dict, username: str, password: str):\n    counter = 0\n    while True:\n        try:\n            response = requests.get(url, headers=headers, params=querystring)\n            # If status code is not 200, then we are not connected\n            if response.status_code != 200:\n                check_connection(username=username, password=password)\n            else:\n                json_resp = response.json()",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_historical_data",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_historical_data(asset: Asset, start_dt: datetime, end_dt: datetime, ivl: int, username: str, password: str, datastyle:str = \"ohlc\"):\n    \"\"\"\n    Get data from ThetaData\n    Parameters\n    ----------\n    asset : Asset\n        The asset we are getting data for\n    start_dt : datetime\n        The start date/time for the data we want\n    end_dt : datetime",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_expirations",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_expirations(username: str, password: str, ticker: str, after_date: date):\n    \"\"\"\n    Get a list of expiration dates for the given ticker\n    Parameters\n    ----------\n    username : str\n        Your ThetaData username\n    password : str\n        Your ThetaData password\n    ticker : str",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_strikes",
        "kind": 2,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_strikes(username: str, password: str, ticker: str, expiration: datetime):\n    \"\"\"\n    Get a list of strike prices for the given ticker and expiration date\n    Parameters\n    ----------\n    username : str\n        Your ThetaData username\n    password : str\n        Your ThetaData password\n    ticker : str",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "WAIT_TIME",
        "kind": 5,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "WAIT_TIME = 60\nMAX_DAYS = 30\nCACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "MAX_DAYS",
        "kind": 5,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "MAX_DAYS = 30\nCACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "CACHE_SUBFOLDER",
        "kind": 5,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "CACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "lumibot.tools.thetadata_helper",
        "description": "lumibot.tools.thetadata_helper",
        "peekOfCode": "BASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    dt=None,",
        "detail": "lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "check_numeric",
        "kind": 2,
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "peekOfCode": "def check_numeric(\n    input, type, error_message, positive=True, strict=False, nullable=False, ratio=False, allow_negative=True\n):\n    if nullable and input is None:\n        return None\n    error = ValueError(error_message)\n    if isinstance(input, str) or (type == Decimal and not isinstance(input, Decimal)):\n        try:\n            input = type(input)\n        except:",
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_positive",
        "kind": 2,
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "peekOfCode": "def check_positive(input, type, custom_message=\"\", strict=False):\n    if strict:\n        error_message = \"%r is not a strictly positive value.\" % input\n    else:\n        error_message = \"%r is not a positive value.\" % input\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    result = check_numeric(\n        input,\n        type,",
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_quantity",
        "kind": 2,
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "peekOfCode": "def check_quantity(quantity, custom_message=\"\"):\n    error_message = \"%r is not a positive Decimal.\" % quantity\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    quantity = Decimal(quantity)\n    result = check_numeric(\n        quantity,\n        Decimal,\n        error_message,\n        strict=True,",
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_price",
        "kind": 2,
        "importPath": "lumibot.tools.types",
        "description": "lumibot.tools.types",
        "peekOfCode": "def check_price(price, custom_message=\"\", nullable=True, allow_negative=True):\n    error_message = \"%r is not a valid price.\" % price\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    result = check_numeric(price, float, error_message, strict=True, nullable=nullable, allow_negative=allow_negative)\n    return result",
        "detail": "lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "_YahooData",
        "kind": 6,
        "importPath": "lumibot.tools.yahoo_helper",
        "description": "lumibot.tools.yahoo_helper",
        "peekOfCode": "class _YahooData:\n    def __init__(self, symbol, type, data):\n        self.symbol = symbol\n        self.type = type.lower()\n        self.data = data\n        self.file_name = f\"{symbol}_{type.lower()}.pickle\"\n    def is_up_to_date(self, last_needed_datetime=None):\n        if last_needed_datetime is None:\n            last_needed_datetime = get_lumibot_datetime()\n        if self.type == '1d':",
        "detail": "lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "YahooHelper",
        "kind": 6,
        "importPath": "lumibot.tools.yahoo_helper",
        "description": "lumibot.tools.yahoo_helper",
        "peekOfCode": "class YahooHelper:\n    # =========Internal initialization parameters and methods============\n    CACHING_ENABLED = False\n    LUMIBOT_YAHOO_CACHE_FOLDER = os.path.join(LUMIBOT_CACHE_FOLDER, \"yahoo\")\n    if not os.path.exists(LUMIBOT_YAHOO_CACHE_FOLDER):\n        try:\n            os.makedirs(LUMIBOT_YAHOO_CACHE_FOLDER)\n            CACHING_ENABLED = True\n        except Exception as e:\n            pass",
        "detail": "lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "INFO_DATA",
        "kind": 5,
        "importPath": "lumibot.tools.yahoo_helper",
        "description": "lumibot.tools.yahoo_helper",
        "peekOfCode": "INFO_DATA = \"info\"\nclass _YahooData:\n    def __init__(self, symbol, type, data):\n        self.symbol = symbol\n        self.type = type.lower()\n        self.data = data\n        self.file_name = f\"{symbol}_{type.lower()}.pickle\"\n    def is_up_to_date(self, last_needed_datetime=None):\n        if last_needed_datetime is None:\n            last_needed_datetime = get_lumibot_datetime()",
        "detail": "lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "DebugLogTrader",
        "kind": 6,
        "importPath": "lumibot.traders.debug_log_trader",
        "description": "lumibot.traders.debug_log_trader",
        "peekOfCode": "class DebugLogTrader(Trader):\n    \"\"\"I'm just a trader instance with debug turned on by default\"\"\"\n    def __init__(self, logfile=\"\", backtest=False, debug=True, strategies=None, quiet_logs=False):\n        super().__init__(logfile=logfile, backtest=backtest, debug=debug, strategies=strategies, quiet_logs=quiet_logs)",
        "detail": "lumibot.traders.debug_log_trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "kind": 6,
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "peekOfCode": "class Trader:\n    def __init__(self, logfile=\"\", backtest=False, debug=False, strategies=None, quiet_logs=False):\n        \"\"\"\n        Parameters\n        ----------\n        logfile: str\n            The path to the logfile. If not specified, the logfile will be saved in the user's log directory.\n        backtest: bool\n            Whether to run the strategies in backtest mode or not. This is used as a safety check to make sure you\n            don't mix backtesting and live strategies.",
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.traders.trader",
        "description": "lumibot.traders.trader",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# import streamlit as st\nclass Trader:\n    def __init__(self, logfile=\"\", backtest=False, debug=False, strategies=None, quiet_logs=False):\n        \"\"\"\n        Parameters\n        ----------\n        logfile: str\n            The path to the logfile. If not specified, the logfile will be saved in the user's log directory.\n        backtest: bool",
        "detail": "lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "CustomStream",
        "kind": 6,
        "importPath": "lumibot.trading_builtins.custom_stream",
        "description": "lumibot.trading_builtins.custom_stream",
        "peekOfCode": "class CustomStream:\n    def __init__(self):\n        self._queue = Queue(100)\n        self._actions_mapping = {}\n    def dispatch(self, event, wait_until_complete=False, **payload):\n        self._queue.put((event, payload), block=False)\n        # Primarily used for backtesting. If wait_until_complete is True, the function will block until the queue is\n        # empty. This is useful for ensuring that all events have been processed before moving on to the next step.\n        if wait_until_complete:\n            self._queue.join()",
        "detail": "lumibot.trading_builtins.custom_stream",
        "documentation": {}
    },
    {
        "label": "PollingStream",
        "kind": 6,
        "importPath": "lumibot.trading_builtins.custom_stream",
        "description": "lumibot.trading_builtins.custom_stream",
        "peekOfCode": "class PollingStream(CustomStream):\n    \"\"\"\n    A stream that polls an API endpoint at a regular interval and dispatches events based on the response. It is\n    required that a polling action is registered with the stream using add_action(). The polling action should make a\n    request to the API and dispatch events based on the response. A user can also dispatch events to the stream manually\n    using dispatch(), including the poll event to force an off-cycle poll action to occur.\n    \"\"\"\n    POLL_EVENT = \"poll\"\n    def __init__(self, polling_interval=5.0):\n        \"\"\"",
        "detail": "lumibot.trading_builtins.custom_stream",
        "documentation": {}
    },
    {
        "label": "SafeList",
        "kind": 6,
        "importPath": "lumibot.trading_builtins.safe_list",
        "description": "lumibot.trading_builtins.safe_list",
        "peekOfCode": "class SafeList:\n    def __init__(self, lock, initial=None):\n        if not isinstance(lock, rlock_type):\n            raise ValueError(\"lock must be a threading.RLock\")\n        if initial is None:\n            initial = []\n        self.__lock = lock\n        self.__items = initial\n    def __repr__(self):\n        return repr(self.__items)",
        "detail": "lumibot.trading_builtins.safe_list",
        "documentation": {}
    },
    {
        "label": "find_and_load_dotenv",
        "kind": 2,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "def find_and_load_dotenv(base_dir) -> bool:\n    for root, dirs, files in os.walk(base_dir):\n        logger.debug(f\"Checking {root} for .env file\")\n        if '.env' in files:\n            dotenv_path = os.path.join(root, '.env')\n            load_dotenv(dotenv_path)\n            # Create a colored message for the log using termcolor\n            colored_message = termcolor.colored(f\".env file loaded from: {dotenv_path}\", \"green\")\n            logger.info(colored_message)\n            return True",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef find_and_load_dotenv(base_dir) -> bool:\n    for root, dirs, files in os.walk(base_dir):\n        logger.debug(f\"Checking {root} for .env file\")\n        if '.env' in files:\n            dotenv_path = os.path.join(root, '.env')\n            load_dotenv(dotenv_path)\n            # Create a colored message for the log using termcolor\n            colored_message = termcolor.colored(f\".env file loaded from: {dotenv_path}\", \"green\")\n            logger.info(colored_message)",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "script_dir",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\nlogger.debug(f\"script_dir: {script_dir}\")\nfound_dotenv = find_and_load_dotenv(script_dir)\nif not found_dotenv:\n    # Get the root directory of the project\n    cwd_dir = os.getcwd()\n    logger.debug(f\"cwd_dir: {cwd_dir}\")\n    found_dotenv = find_and_load_dotenv(cwd_dir)\n# If no .env file was found, print a warning message\nif not found_dotenv:",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "found_dotenv",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "found_dotenv = find_and_load_dotenv(script_dir)\nif not found_dotenv:\n    # Get the root directory of the project\n    cwd_dir = os.getcwd()\n    logger.debug(f\"cwd_dir: {cwd_dir}\")\n    found_dotenv = find_and_load_dotenv(cwd_dir)\n# If no .env file was found, print a warning message\nif not found_dotenv:\n    # Create a colored message for the log using termcolor\n    colored_message = termcolor.colored(\"No .env file found. This is ok if you are using environment variables or secrets (like on Replit, AWS, etc), but if you are not, please create a .env file in the root directory of the project.\", \"yellow\")",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "is_backtesting",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "is_backtesting = os.environ.get(\"IS_BACKTESTING\")\nif not is_backtesting or is_backtesting.lower() == \"false\":\n    IS_BACKTESTING = False\nelif is_backtesting.lower() == \"true\":\n    IS_BACKTESTING = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"IS_BACKTESTING must be set to 'true' or 'false'. Got '{is_backtesting}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    IS_BACKTESTING = False",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "hide_trades",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "hide_trades = os.environ.get(\"HIDE_TRADES\")\nif not hide_trades or hide_trades.lower() == \"false\":\n    HIDE_TRADES = False\nelif hide_trades.lower() == \"true\":\n    HIDE_TRADES = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"HIDE_TRADES must be set to 'true' or 'false'. Got '{hide_trades}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    HIDE_TRADES = False",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "hide_positions",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "hide_positions = os.environ.get(\"HIDE_POSITIONS\")\nif not hide_positions or hide_positions.lower() == \"false\":\n    HIDE_POSITIONS = False\nelif hide_positions.lower() == \"true\":\n    HIDE_POSITIONS = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"HIDE_POSITIONS must be set to 'true' or 'false'. Got '{hide_positions}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    HIDE_POSITIONS = False",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "STRATEGY_NAME",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "STRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")\n# Market to be traded\nMARKET = os.environ.get(\"MARKET\")\n# Live trading configuration (if applicable)\nLIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "MARKET",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "MARKET = os.environ.get(\"MARKET\")\n# Live trading configuration (if applicable)\nLIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "LIVE_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "LIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DISCORD_WEBHOOK_URL",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "DISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_PLOT",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "SHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_INDICATORS",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "SHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_TEARSHEET",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "SHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):\n    DB_CONNECTION_STR = os.environ.get(\"DB_CONNECTION_STR\")",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DB_CONNECTION_STR",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "DB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):\n    DB_CONNECTION_STR = os.environ.get(\"DB_CONNECTION_STR\")\n# Name for the strategy to be used in the database\nSTRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "STRATEGY_NAME",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "STRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")\n# Set a hard limit on the memory polygon uses\nPOLYGON_MAX_MEMORY_BYTES = os.environ.get(\"POLYGON_MAX_MEMORY_BYTES\")\nPOLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_MAX_MEMORY_BYTES",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "POLYGON_MAX_MEMORY_BYTES = os.environ.get(\"POLYGON_MAX_MEMORY_BYTES\")\nPOLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,\n}\n# Polygon API Key",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "POLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,\n}\n# Polygon API Key\nPOLYGON_API_KEY = POLYGON_CONFIG['API_KEY']",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_API_KEY",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "POLYGON_API_KEY = POLYGON_CONFIG['API_KEY']\n# Thetadata Configuration\nTHETADATA_CONFIG = {\n    # Get the ThetaData API key from the .env file or secrets\n    \"THETADATA_USERNAME\": os.environ.get(\"THETADATA_USERNAME\"),\n    \"THETADATA_PASSWORD\": os.environ.get(\"THETADATA_PASSWORD\")\n}\n# Alpaca Configuration\nALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "THETADATA_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "THETADATA_CONFIG = {\n    # Get the ThetaData API key from the .env file or secrets\n    \"THETADATA_USERNAME\": os.environ.get(\"THETADATA_USERNAME\"),\n    \"THETADATA_PASSWORD\": os.environ.get(\"THETADATA_PASSWORD\")\n}\n# Alpaca Configuration\nALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"ALPACA_API_KEY\"),\n    \"API_SECRET\": os.environ.get(\"ALPACA_API_SECRET\"),",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "ALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"ALPACA_API_KEY\"),\n    \"API_SECRET\": os.environ.get(\"ALPACA_API_SECRET\"),\n    \"PAPER\": os.environ.get(\"ALPACA_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"ALPACA_IS_PAPER\")\n    else True,\n}\nALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", ",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", \n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\", \n    \"PAPER\": True\n}\nBASE_URL = \"https://paper-api.alpaca.markets\"\n# Tradier Configuration\nTRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\n# Tradier Configuration\nTRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),\n    \"ACCOUNT_NUMBER\": os.environ.get(\"TRADIER_ACCOUNT_NUMBER\"),\n    \"PAPER\": os.environ.get(\"TRADIER_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"TRADIER_IS_PAPER\")\n    else True,\n}",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "TRADIER_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "TRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),\n    \"ACCOUNT_NUMBER\": os.environ.get(\"TRADIER_ACCOUNT_NUMBER\"),\n    \"PAPER\": os.environ.get(\"TRADIER_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"TRADIER_IS_PAPER\")\n    else True,\n}\nKRAKEN_CONFIG = {\n    # Add KRAKEN_API_KEY and KRAKEN_API_SECRET to your .env file or set them as secrets",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "KRAKEN_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "KRAKEN_CONFIG = {\n    # Add KRAKEN_API_KEY and KRAKEN_API_SECRET to your .env file or set them as secrets\n    \"exchange_id\": \"kraken\",\n    \"apiKey\": os.environ.get(\"KRAKEN_API_KEY\"),\n    \"secret\": os.environ.get(\"KRAKEN_API_SECRET\"),\n    \"margin\": True,\n    \"sandbox\": False,\n}\nCOINBASE_CONFIG = {\n    # Add COINBASE_API_KEY and COINBASE_API_SECRET to your .env file or set them as secrets",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "COINBASE_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "COINBASE_CONFIG = {\n    # Add COINBASE_API_KEY and COINBASE_API_SECRET to your .env file or set them as secrets\n    \"exchange_id\": \"coinbase\",\n    \"apiKey\": os.environ.get(\"COINBASE_API_KEY\"),\n    \"secret\": os.environ.get(\"COINBASE_API_SECRET\"),\n    \"margin\": False,\n    \"sandbox\": False,\n}\nINTERACTIVE_BROKERS_CONFIG = {\n    \"SOCKET_PORT\": int(os.environ.get(\"INTERACTIVE_BROKERS_PORT\")) if os.environ.get(\"INTERACTIVE_BROKERS_PORT\") else None,",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "INTERACTIVE_BROKERS_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "INTERACTIVE_BROKERS_CONFIG = {\n    \"SOCKET_PORT\": int(os.environ.get(\"INTERACTIVE_BROKERS_PORT\")) if os.environ.get(\"INTERACTIVE_BROKERS_PORT\") else None,\n    \"CLIENT_ID\": int(os.environ.get(\"INTERACTIVE_BROKERS_CLIENT_ID\")) if os.environ.get(\"INTERACTIVE_BROKERS_CLIENT_ID\") else None,\n    \"IP\": os.environ.get(\"INTERACTIVE_BROKERS_IP\", \"127.0.0.1\"),\n    \"IB_SUBACCOUNT\": os.environ.get(\"IB_SUBACCOUNT\", None)\n}\nINTERACTIVE_BROKERS_REST_CONFIG = {\n    \"IB_USERNAME\": os.environ.get(\"IB_USERNAME\"),\n    \"IB_PASSWORD\": os.environ.get(\"IB_PASSWORD\"),\n    \"ACCOUNT_ID\": os.environ.get(\"ACCOUNT_ID\"),",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "INTERACTIVE_BROKERS_REST_CONFIG",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "INTERACTIVE_BROKERS_REST_CONFIG = {\n    \"IB_USERNAME\": os.environ.get(\"IB_USERNAME\"),\n    \"IB_PASSWORD\": os.environ.get(\"IB_PASSWORD\"),\n    \"ACCOUNT_ID\": os.environ.get(\"ACCOUNT_ID\"),\n    \"API_URL\": os.environ.get(\"IB_API_URL\"),\n    \"RUNNING_ON_SERVER\": os.environ.get(\"RUNNING_ON_SERVER\")\n}\nLUMIWEALTH_API_KEY = os.environ.get(\"LUMIWEALTH_API_KEY\")\nif IS_BACKTESTING:\n    broker = None",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "LUMIWEALTH_API_KEY",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "LUMIWEALTH_API_KEY = os.environ.get(\"LUMIWEALTH_API_KEY\")\nif IS_BACKTESTING:\n    broker = None\nelse:\n    # If using Alpaca as a broker, set that as the broker\n    if ALPACA_CONFIG[\"API_KEY\"]:\n        broker = Alpaca(ALPACA_CONFIG)\n    # If using Tradier as a broker, set that as the broker\n    elif TRADIER_CONFIG[\"ACCESS_TOKEN\"]:\n        broker = Tradier(TRADIER_CONFIG)",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BROKER",
        "kind": 5,
        "importPath": "lumibot.credentials",
        "description": "lumibot.credentials",
        "peekOfCode": "BROKER = broker",
        "detail": "lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "get_sentiment_score",
        "kind": 2,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "def get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n    result = sentiment_analyzer(text)\n    sentiment = result[0]['label']\n    score = result[0]['score']\n    return sentiment, score\n# Step 2: Data Collection",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "collect_data",
        "kind": 2,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "def collect_data():\n    import pandas as pd\n    # Example dataset\n    data = {\n        'date': ['2023-10-01', '2023-10-02', '2023-10-03'],\n        'text': ['Great earnings report!', 'Market crash expected.', 'Stable growth predicted.']\n    }\n    df = pd.DataFrame(data)\n    # Apply sentiment analysis\n    df['sentiment'], df['score'] = zip(*df['text'].apply(get_sentiment_score))",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "kind": 2,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "def estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)\n        probability = result[torch.argmax(result)]\n        sentiment = labels[torch.argmax(result)]\n        return probability, sentiment",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "lumibot.finbert_utils",
        "description": "lumibot.finbert_utils",
        "peekOfCode": "labels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")",
        "detail": "lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.LumibotML.credentials",
        "description": "pages.TraderBot.lib.LumibotML.credentials",
        "peekOfCode": "class AlpacaConfig:\n    # Put your own Alpaca api key here:\n    # API_KEY = \"PK674RO5M858JZ217SPM\"\n    API_KEY = \"PKEJH4W0URAU56SHKQW3\"\n    # Put your own Alpaca secret here:\n    API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\n    # API_SECRET = \"uWm6opmroTTWuZ9Yr81XRTMsOMLNv8nvBmmLO4Dt\"\n    # If you want to go live, you must change this\n    ENDPOINT = \"https://paper-api.alpaca.markets\"\n    def __init__(self, load_from_secret_manager=True):",
        "detail": "pages.TraderBot.lib.LumibotML.credentials",
        "documentation": {}
    },
    {
        "label": "symbols",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "symbols = [\"VIX\", \"VXX\", \"XIV\", \"PBP\", \"SPXL\"]\ninterval = \"1min\"\napi_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):",
        "detail": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "interval",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "interval = \"1min\"\napi_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):",
        "detail": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "api_key = \"30WM6G3P2TVGCIWL\"\n################################################################################\nyears = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"",
        "detail": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "years",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "years = 2\nmonths = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"\n                url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval={interval}&slice={slice}&apikey={api_key}\"\n                df = pd.read_csv(url)",
        "detail": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "months",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "description": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "peekOfCode": "months = 12\nwith tqdm(total=months * years * len(symbols)) as pbar:\n    for symbol in symbols:\n        dfs = []\n        for y in range(years):\n            for m in range(months):\n                slice = f\"year{y+1}month{m+1}\"\n                url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval={interval}&slice={slice}&apikey={api_key}\"\n                df = pd.read_csv(url)\n                dfs.append(df)",
        "detail": "pages.TraderBot.lib.LumibotML.download_price_data_alpha_vantage",
        "documentation": {}
    },
    {
        "label": "MachineLearningCrypto",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.LumibotML.ml_strategy_crypto",
        "description": "pages.TraderBot.lib.LumibotML.ml_strategy_crypto",
        "peekOfCode": "class MachineLearningCrypto(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "pages.TraderBot.lib.LumibotML.ml_strategy_crypto",
        "documentation": {}
    },
    {
        "label": "MachineLearningStocks",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.LumibotML.ml_strategy_stocks",
        "description": "pages.TraderBot.lib.LumibotML.ml_strategy_stocks",
        "peekOfCode": "class MachineLearningStocks(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "pages.TraderBot.lib.LumibotML.ml_strategy_stocks",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "description": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "description": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "peekOfCode": "MODELS = {\n    \"ddpg\": AgentDDPG,\n    \"td3\": AgentTD3,\n    \"sac\": AgentSAC,\n    \"ppo\": AgentPPO,\n    \"a2c\": AgentA2C,\n}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}",
        "detail": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "description": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "description": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "pages.TraderBot.lib.rl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "PolicyGradient",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.algorithms",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.algorithms",
        "peekOfCode": "class PolicyGradient:\n    \"\"\"Class implementing policy gradient algorithm to train portfolio\n    optimization agents.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        train_env: Environment used to train the agent\n        train_policy: Policy used in training.",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.algorithms",
        "documentation": {}
    },
    {
        "label": "EIIE",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EIIE(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_size=3,\n        conv_mid_features=2,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",\n    ):",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "EI3",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EI3(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "GPM",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class GPM(nn.Module):\n    def __init__(\n        self,\n        edge_index,\n        edge_type,\n        nodes_to_select,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.models",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"\n    def __init__(self, env):",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.models",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.models",
        "peekOfCode": "MODELS = {\"pg\": PolicyGradient}\nclass DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "PVM",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class PVM:\n    def __init__(self, capacity, portfolio_size):\n        \"\"\"Initializes portfolio vector memory.\n        Args:\n          capacity: Max capacity of memory.\n          portfolio_size: Portfolio size.\n        \"\"\"\n        # initially, memory will have the same actions\n        self.capacity = capacity\n        self.portfolio_size = portfolio_size",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class ReplayBuffer:\n    def __init__(self, capacity):\n        \"\"\"Initializes replay buffer.\n        Args:\n          capacity: Max capacity of buffer.\n        \"\"\"\n        self.buffer = deque(maxlen=capacity)\n    def __len__(self):\n        \"\"\"Represents the size of the buffer\n        Returns:",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "RLDataset",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "class RLDataset(IterableDataset):\n    def __init__(self, buffer):\n        \"\"\"Initializes reinforcement learning dataset.\n        Args:\n            buffer: replay buffer to become iterable dataset.\n        Note:\n            It's a subclass of pytorch's IterableDataset,\n            check https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n        \"\"\"\n        self.buffer = buffer",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "apply_portfolio_noise",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "description": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "peekOfCode": "def apply_portfolio_noise(portfolio, epsilon=0.0):\n    \"\"\"Apply noise to portfolio distribution considering its constrains.\n    Arg:\n        portfolio: initial portfolio distribution.\n        epsilon: maximum rebalancing.\n    Returns:\n        New portolio distribution with noise applied.\n    \"\"\"\n    portfolio_size = portfolio.shape[0]\n    new_portfolio = portfolio.copy()",
        "detail": "pages.TraderBot.lib.rl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "DRLlibv2",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "description": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "class DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:\n        Training environment instance\n    train_env_name: str",
        "detail": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "psutil_memory_in_bytes",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "description": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "psutil_memory_in_bytes = psutil.virtual_memory().total\nray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter",
        "detail": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "ray._private.utils.get_system_memory",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "description": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "peekOfCode": "ray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:",
        "detail": "pages.TraderBot.lib.rl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.rllib.models",
        "description": "pages.TraderBot.lib.rl.agents.rllib.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data\n        tech_array: numpy array\n            techical data",
        "detail": "pages.TraderBot.lib.rl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.rllib.models",
        "description": "pages.TraderBot.lib.rl.agents.rllib.models",
        "peekOfCode": "MODELS = {\"a2c\": a2c, \"ddpg\": ddpg, \"td3\": td3, \"sac\": sac, \"ppo\": ppo}\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nclass DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data",
        "detail": "pages.TraderBot.lib.rl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "sample_ppo_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ppo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for PPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_trpo_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_trpo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TRPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_a2c_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_a2c_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for A2C hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    normalize_advantage = trial.suggest_categorical(",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_sac_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_sac_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for SAC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_td3_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_td3_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TD3 hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ddpg_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ddpg_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DDPG hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_dqn_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_dqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_her_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_her_params(\n    trial: optuna.Trial, hyperparams: dict[str, Any]\n) -> dict[str, Any]:\n    \"\"\"\n    Sampler for HerReplayBuffer hyperparams.\n    :param trial:\n    :parma hyperparams:\n    :return:\n    \"\"\"\n    her_kwargs = trial.her_kwargs.copy()",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_tqc_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_tqc_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TQC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is SAC + Distributional RL\n    hyperparams = sample_sac_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 50)\n    top_quantiles_to_drop_per_net = trial.suggest_int(",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_qrdqn_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_qrdqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for QR-DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is DQN + Distributional RL\n    hyperparams = sample_dqn_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 200)\n    hyperparams[\"policy_kwargs\"].update({\"n_quantiles\": n_quantiles})",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ars_params",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ars_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for ARS hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # n_eval_episodes = trial.suggest_categorical(\"n_eval_episodes\", [1, 2])\n    n_delta = trial.suggest_categorical(\"n_delta\", [4, 8, 6, 32, 64])\n    # learning_rate = trial.suggest_categorical(\"learning_rate\", [0.01, 0.02, 0.025, 0.03])\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "HYPERPARAMS_SAMPLER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "HYPERPARAMS_SAMPLER = {\n    \"a2c\": sample_a2c_params,\n    \"ars\": sample_ars_params,\n    \"ddpg\": sample_ddpg_params,\n    \"dqn\": sample_dqn_params,\n    \"qrdqn\": sample_qrdqn_params,\n    \"sac\": sample_sac_params,\n    \"tqc\": sample_tqc_params,\n    \"ppo\": sample_ppo_params,\n    \"td3\": sample_td3_params,",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "TensorboardCallback",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)\n    def _on_step(self) -> bool:\n        try:\n            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n        except BaseException as error:",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Provides implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLEnsembleAgent:\n    @staticmethod\n    def get_model(\n        model_name,\n        env,\n        policy=\"MlpPolicy\",\n        policy_kwargs=None,\n        model_kwargs=None,\n        seed=None,\n        verbose=1,",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\nMODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODEL_KWARGS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "NOISE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "peekOfCode": "NOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "LoggingCallback",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.tune_sb3",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class LoggingCallback:\n    def __init__(self, threshold: int, trial_number: int, patience: int):\n        \"\"\"\n        threshold:int tolerance for increase in sharpe ratio\n        trial_number: int Prune after minimum number of trials\n        patience: int patience for the threshold\n        \"\"\"\n        self.threshold = threshold\n        self.trial_number = trial_number\n        self.patience = patience",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "TuneSB3Optuna",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.agents.stablebaselines3.tune_sb3",
        "description": "pages.TraderBot.lib.rl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class TuneSB3Optuna:\n    \"\"\"\n    Hyperparameter tuning of SB3 agents using Optuna\n    Attributes\n    ----------\n      env_train: Training environment for SB3\n      model_name: str\n      env_trade: testing environment\n      logging_callback: callback for tuning\n      total_timesteps: int",
        "detail": "pages.TraderBot.lib.rl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "calc_stockname_from_filename",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_stockname_from_filename(filename):\n    return filename.split(\"/\")[-1].split(\".csv\")[0]\ndef calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)\n    return paths2\ndef calc_stocknames(path):",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_stocknames",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_stocknames(path):\n    filenames = calc_all_filenames(path)\n    res = []\n    for filename in filenames:\n        stockname = calc_stockname_from_filename(filename)\n        res.append(stockname)\n    return res\ndef remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:\n        os.system(\"rm -f \" + path_of_data + \"/*\")\n    dir_list = os.listdir(path_of_data)\n    for file in dir_list:\n        if \"~\" in file:\n            os.system(\"rm -f \" + path_of_data + \"/\" + file)\n    dir_list = os.listdir(path_of_data)\n    if remove == 1:",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def date2str(dat: datetime.date) -> str:\n    return datetime.date.strftime(dat, \"%Y-%m-%d\")\ndef str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_dates",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)\n        dates.append(d)\n        dat += delta\n    return dates",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_starts_ends_if_rolling(\n    init_train_dates: list[str], init_trade_dates: list[str], rolling_window_length: int\n) -> tuple[list[str], list[str], list[str], list[str]]:\n    trade_dates_length = len(init_trade_dates)\n    train_window_length = len(init_train_dates)\n    trade_window_length = min(rolling_window_length, trade_dates_length)\n    num_subsets_if_rolling = int(np.ceil(trade_dates_length / trade_window_length))\n    print(\"num_subsets_if_rolling: \", num_subsets_if_rolling)\n    dates = np.concatenate((init_train_dates, init_trade_dates), axis=0)\n    train_starts = []",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_data(\n    i: int,\n    train_starts: list[str],\n    train_ends: list[str],\n    trade_starts: list[str],\n    trade_ends: list[str],\n    init_train_data: pd.DataFrame(),\n    init_trade_data: pd.DataFrame(),\n    date_col: str,\n) -> tuple[pd.DataFrame(), pd.DataFrame()]:",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_alpaca",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_alpaca",
        "peekOfCode": "class AlpacaProcessor:\n    def __init__(self, API_KEY=None, API_SECRET=None, API_BASE_URL=None, api=None):\n        if api is None:\n            try:\n                self.api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, \"v2\")\n            except BaseException:\n                raise ValueError(\"Wrong Account Info!\")\n        else:\n            self.api = api\n    def _fetch_data_for_ticker(self, ticker, start_date, end_date, time_interval):",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "CCXTEngineer",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_ccxt",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_ccxt",
        "peekOfCode": "class CCXTEngineer:\n    def __init__(self):\n        self.binance = ccxt.binance()\n    def data_fetch(self, start, end, pair_list=[\"BTC/USDT\"], period=\"1m\"):\n        def min_ohlcv(dt, pair, limit):\n            since = calendar.timegm(dt.utctimetuple()) * 1000\n            ohlcv = self.binance.fetch_ohlcv(\n                symbol=pair, timeframe=\"1m\", since=since, limit=limit\n            )\n            return ohlcv",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_ccxt",
        "documentation": {}
    },
    {
        "label": "JoinQuantEngineer",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_joinquant",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_joinquant",
        "peekOfCode": "class JoinQuantEngineer:\n    def __init__(self):\n        pass\n    def auth(self, username, password):\n        jq.auth(username, password)\n    def data_fetch(self, stock_list, num, unit, end_dt):\n        df = jq.get_bars(\n            security=stock_list,\n            count=num,\n            unit=unit,",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_joinquant",
        "documentation": {}
    },
    {
        "label": "QuantConnectEngineer",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_quantconnect",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_quantconnect",
        "peekOfCode": "class QuantConnectEngineer:\n    def __init__(self):\n        pass\n    def data_fetch(start_time, end_time, stock_list, resolution=Resolution.Daily):\n        # resolution: Daily, Hour, Minute, Second\n        qb = QuantBook()\n        for stock in stock_list:\n            qb.AddEquity(stock)\n        history = qb.History(qb.Securities.Keys, start_time, end_time, resolution)\n        return history",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_quantconnect",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_wrds",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_wrds",
        "peekOfCode": "class WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,\n        time_interval,",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "pd.options.mode.chained_assignment",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_wrds",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_wrds",
        "peekOfCode": "pd.options.mode.chained_assignment = None\nclass WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processors.processor_yahoofinance",
        "description": "pages.TraderBot.lib.rl.meta.data_processors.processor_yahoofinance",
        "peekOfCode": "class YahooFinanceProcessor:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    \"\"\"\n    def __init__(self):\n        pass\n    \"\"\"\n    Param\n    ----------\n        start_date : str",
        "detail": "pages.TraderBot.lib.rl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "BitcoinEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "description": "pages.TraderBot.lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "peekOfCode": "class BitcoinEnv:  # custom env\n    def __init__(\n        self,\n        data_cwd=None,\n        price_ary=None,\n        tech_ary=None,\n        time_frequency=15,\n        start=None,\n        mid1=172197,\n        mid2=216837,",
        "detail": "pages.TraderBot.lib.rl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "documentation": {}
    },
    {
        "label": "CryptoEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "description": "pages.TraderBot.lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "peekOfCode": "class CryptoEnv:  # custom env\n    def __init__(\n        self,\n        config,\n        lookback=1,\n        initial_capital=1e6,\n        buy_cost_pct=1e-3,\n        sell_cost_pct=1e-3,\n        gamma=0.99,\n    ):",
        "detail": "pages.TraderBot.lib.rl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "documentation": {}
    },
    {
        "label": "StockPortfolioEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "description": "pages.TraderBot.lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "peekOfCode": "class StockPortfolioEnv(gym.Env):\n    \"\"\"A single stock trading environment for OpenAI gym\n    Attributes\n    ----------\n        df: DataFrame\n            input data\n        stock_dim : int\n            number of unique stocks\n        hmax : int\n            maximum number of shares to trade",
        "detail": "pages.TraderBot.lib.rl.meta.env_portfolio_allocation.env_portfolio",
        "documentation": {}
    },
    {
        "label": "PortfolioOptimizationEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "description": "pages.TraderBot.lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "peekOfCode": "class PortfolioOptimizationEnv(gym.Env):\n    \"\"\"A portfolio allocation environment for OpenAI gym.\n    This environment simulates the interactions between an agent and the financial market\n    based on data provided by a dataframe. The dataframe contains the time series of\n    features defined by the user (such as closing, high and low prices) and must have\n    a time and a tic column with a list of datetimes and ticker symbols respectively.\n    An example of dataframe is shown below::\n            date        high            low             close           tic\n        0   2020-12-23  0.157414        0.127420        0.136394        ADA-USD\n        1   2020-12-23  34.381519       30.074295       31.097898       BNB-USD",
        "detail": "pages.TraderBot.lib.rl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "StockEnvNAS100",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "peekOfCode": "class StockEnvNAS100:\n    def __init__(\n        self,\n        cwd=\"./data/nas100\",\n        price_ary=None,\n        tech_ary=None,\n        turbulence_ary=None,\n        gamma=0.999,\n        turbulence_thresh=30,\n        min_stock_rate=0.1,",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_nas100_wrds",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class AlpacaPaperTrading:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {\"render.modes\": [\"human\"]}\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        stock_dim: int,\n        hmax: int,\n        initial_amount: int,\n        num_stock_shares: list[int],",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvCashpenalty",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "peekOfCode": "class StockTradingEnvCashpenalty(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model for not maintaining a reserve of cash.\n    This enables the model to manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) - initial_cash - max(0, sum(cash, asset_value)*cash_penalty_proportion-cash))/(days_elapsed)\n        This reward function takes into account a liquidity requirement, as well as long-term accrued rewards.\n    Parameters:\n        df (pandas.DataFrame): Dataframe containing data",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    def __init__(\n        self,\n        config,\n        initial_account=1e6,\n        gamma=0.99,\n        turbulence_thresh=99,\n        min_stock_rate=0.1,\n        max_stock=1e2,\n        initial_capital=1e6,",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvStopLoss",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "description": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "peekOfCode": "class StockTradingEnvStopLoss(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model if excedeed the stop-loss threshold, selling assets with under expectation %profit, and also\n    for not maintaining a reserve of cash.\n    This enables the model to do trading with high confidence and manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) + additional_reward - total_penalty - initial_cash) / initial_cash / days_elapsed\n        , where total_penalty = cash_penalty + stop_loss_penalty + low_profit_penalty\n                cash_penalty = max(0, sum(cash, asset_value)*cash_penalty_proportion-cash)",
        "detail": "pages.TraderBot.lib.rl.meta.env_stock_trading.env_stocktrading_stoploss",
        "documentation": {}
    },
    {
        "label": "PaperTradingAlpaca",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.alpaca",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.alpaca",
        "peekOfCode": "class PaperTradingAlpaca:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.alpaca",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.alpaca",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(\n            torch.zeros((1, action_dim)), requires_grad=True\n        )  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {\n                \"env_name\": None,\n                \"state_dim\": None,\n                \"action_dim\": None,\n                \"if_discrete\": None,",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class AgentBase:\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.state_dim = state_dim",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.if_off_policy = False",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < \"0.18.0\" else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        \"\"\"the necessary env information when you design a custom env\"\"\"\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class Evaluator:\n    def __init__(\n        self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = \".\"\n    ):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = (",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {\"unwrapped\", \"observation_space\", \"action_space\", \"spec\"}.issubset(\n        dir(env)\n    ):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = (\n            state_shape[0] if len(state_shape) == 1 else state_shape\n        )  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in (\"env_name\", \"state_dim\", \"action_dim\", \"if_discrete\"):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(\n        args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args\n    )\n    agent.states = env.reset()[np.newaxis, :]\n    evaluator = Evaluator(\n        eval_env=build_env(args.env_class, args.env_args),\n        eval_per_step=args.eval_per_step,",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def render_agent(\n    env_class,\n    env_args: dict,\n    net_dims: [int],\n    agent_class,\n    actor_path: str,\n    render_times: int = 8,\n):\n    env = build_env(env_class, env_args)\n    state_dim = env_args[\"state_dim\"]",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_rewards_and_steps(\n    env, actor, if_render: bool = False\n) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(\n            state, dtype=torch.float32, device=device",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def get_trading_days(start, end):\n    nyse = tc.get_calendar(\"NYSE\")\n    df = nyse.sessions_in_range(\n        pd.Timestamp(start, tz=pytz.UTC), pd.Timestamp(end, tz=pytz.UTC)\n    )\n    trading_days = []\n    for day in df:\n        trading_days.append(str(day)[:10])\n    return trading_days\ndef alpaca_history(key, secret, url, start, end):",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, \"v2\")\n    trading_days = get_trading_days(start, end)\n    df = pd.DataFrame()\n    for day in trading_days:\n        df = df.append(\n            api.get_portfolio_history(date_start=day, timeframe=\"5Min\").df.iloc[:78]\n        )\n    equities = df.equity.values\n    cumu_returns = equities / equities[0]",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "def DIA_history(start):\n    data_df = yf.download([\"^DJI\"], start=start, interval=\"5m\")\n    data_df = data_df.iloc[:]\n    baseline_returns = data_df[\"Adj Close\"].values / data_df[\"Adj Close\"].values[0]\n    return data_df, baseline_returns\n# -----------------------------------------------------------------------------------------------------------------------------------------",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "description": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "pages.TraderBot.lib.rl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "GroupByScaler",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "class GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"\n    def __init__(self, by, scaler=MaxAbsScaler, columns=None, scaler_kwargs=None):\n        \"\"\"Initializes GoupBy scaler.\n        Args:\n            by: Name of column that will be used to group.",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "class FeatureEngineer:\n    \"\"\"Provides methods for preprocessing the stock price data\n    Attributes\n    ----------\n        use_technical_indicator : boolean\n            we technical indicator or not\n        tech_indicator_list : list\n            a list of technical indicator names (modified from neofinrl_config.py)\n        use_turbulence : boolean\n            use turbulence index or not",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def load_dataset(*, file_name: str) -> pd.DataFrame:\n    \"\"\"\n    load csv dataset from path\n    :return: (df) pandas dataframe\n    \"\"\"\n    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n    _data = pd.read_csv(file_name)\n    return _data\ndef data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"\n    split the dataset into training or testing using date\n    :param data: (df) pandas dataframe, start, end\n    :return: (df) pandas dataframe\n    \"\"\"\n    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n    data.index = data[target_date_col].factorize()[0]\n    return data",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "convert_to_datetime",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "peekOfCode": "def convert_to_datetime(time):\n    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n    if isinstance(time, str):\n        return datetime.datetime.strptime(time, time_fmt)\nclass GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "TushareDownloader",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.tusharedownloader",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.tusharedownloader",
        "peekOfCode": "class TushareDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    tushare API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from config.py)\n        end_date : str\n            end date of the data (modified from config.py)\n        ticker_list : list",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.tusharedownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.preprocessor.yahoodownloader",
        "description": "pages.TraderBot.lib.rl.meta.preprocessor.yahoodownloader",
        "peekOfCode": "class YahooDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from neofinrl_config.py)\n        end_date : str\n            end date of the data (modified from neofinrl_config.py)\n        ticker_list : list",
        "detail": "pages.TraderBot.lib.rl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processor",
        "description": "pages.TraderBot.lib.rl.meta.data_processor",
        "peekOfCode": "class DataProcessor:\n    def __init__(self, data_source, tech_indicator=None, vix=None, **kwargs):\n        if data_source == \"alpaca\":\n            try:\n                # API_KEY = kwargs.get(\"API_KEY\")\n                # API_SECRET = kwargs.get(\"API_SECRET\")\n                # API_BASE_URL = kwargs.get(\"API_BASE_URL\")\n                self.processor = Alpaca(ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL)\n                jprint(\"Alpaca successfully connected\")\n            except BaseException:",
        "detail": "pages.TraderBot.lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.data_processor",
        "description": "pages.TraderBot.lib.rl.meta.data_processor",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nclass DataProcessor:\n    def __init__(self, data_source, tech_indicator=None, vix=None, **kwargs):\n        if data_source == \"alpaca\":\n            try:\n                # API_KEY = kwargs.get(\"API_KEY\")\n                # API_SECRET = kwargs.get(\"API_SECRET\")\n                # API_BASE_URL = kwargs.get(\"API_BASE_URL\")\n                self.processor = Alpaca(ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL)\n                jprint(\"Alpaca successfully connected\")",
        "detail": "pages.TraderBot.lib.rl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "TRAIN_START_DATE = \"2019-01-01\"\nTRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "TRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "TEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "TEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "TRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "TRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "PATH_OF_DATA",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "PATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "READ_DATA_FROM_LOCAL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "READ_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]\nFAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "FAANG_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "FAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]\n# Dow 30 constituents at 2019/01\nDOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",\n    \"NKE\",\n    \"DIS\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.meta.meta_config",
        "description": "pages.TraderBot.lib.rl.meta.meta_config",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "pages.TraderBot.lib.rl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "OrderSide",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "class OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"\n    TRAILING_STOP = \"trailing_stop\"\nclass TimeInForce():",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "OrderType",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "class OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"\n    TRAILING_STOP = \"trailing_stop\"\nclass TimeInForce():\n    DAY = \"day\"\n    GTC = \"gtc\"\n    OPG = \"opg\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TimeInForce",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "class TimeInForce():\n    DAY = \"day\"\n    GTC = \"gtc\"\n    OPG = \"opg\"\n    CLS = \"cls\"\n    IOC = \"ioc\"\n    FOK = \"fok\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "now = datetime.datetime.now().strftime(\"%Y%m%d-%Hh%M\")\nst.write(\"Current Date and Time:\", now)\nMAIN_RESULTS_DIR = 'pages/data' + now\nDATA_SAVE_DIR       = MAIN_RESULTS_DIR + \"/datasets\"\nTRAINED_MODEL_DIR   = MAIN_RESULTS_DIR + \"/trained_models\"\nTENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "MAIN_RESULTS_DIR",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "MAIN_RESULTS_DIR = 'pages/data' + now\nDATA_SAVE_DIR       = MAIN_RESULTS_DIR + \"/datasets\"\nTRAINED_MODEL_DIR   = MAIN_RESULTS_DIR + \"/trained_models\"\nTENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TENSORBOARD_LOG_DIR = MAIN_RESULTS_DIR + \"/tensorboard_log\"\nRESULTS_DIR         = MAIN_RESULTS_DIR + \"/main_results\"\nDATA_FRAME_DIR      = MAIN_RESULTS_DIR + \"/data_frame\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\n# TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TEST_END_DATE = \"2021-10-01\"\n# TRADE_START_DATE = \"2021-11-01\"\n# TRADE_END_DATE = \"2021-12-01\"\nTRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TRADE_END_DATE = '2023-03-01'\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "A2C_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.0007}\nPPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "PPO_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "PPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "DDPG_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TD3_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "SAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "ERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": 512,\n    \"target_step\": 5000,\n    \"eval_gap\": 30,\n    \"eval_times\": 64,  # bug fix:KeyError: 'eval_times' line 68, in get_model model.eval_times = model_kwargs[\"eval_times\"]\n}",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "RLlib_PARAMS = {\"lr\": 5e-5, \"train_batch_size\": 500, \"gamma\": 0.99}\n# Possible time zones\nTIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SHANGHAI",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_USEASTERN",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_PARIS",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_BERLIN",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_JAKARTA",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "TIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "USE_TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "USE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "ALPACA_API_KEY = \"PKEJH4W0URAU56SHKQW3\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "ALPACA_API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config",
        "description": "pages.TraderBot.lib.rl.config",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\n# parameters for data sources\nclass OrderSide():\n    BUY = \"buy\"\n    SELL = \"sell\"\nclass OrderType():\n    MARKET = \"market\"\n    LIMIT = \"limit\"\n    STOP = \"stop\"\n    STOP_LIMIT = \"stop_limit\"",
        "detail": "pages.TraderBot.lib.rl.config",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_private",
        "description": "pages.TraderBot.lib.rl.config_private",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url\nGROQ_API_KEY= \"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\"\nALPACA_API_KEY = \"PKKR2EEEBE9Q3MLXWXFT\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"dJw28M9E5S4WujgUwPRBnfk4DLttQM66YCvhdC5X\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "pages.TraderBot.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_private",
        "description": "pages.TraderBot.lib.rl.config_private",
        "peekOfCode": "ALPACA_API_KEY = \"PKKR2EEEBE9Q3MLXWXFT\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"dJw28M9E5S4WujgUwPRBnfk4DLttQM66YCvhdC5X\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "pages.TraderBot.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_private",
        "description": "pages.TraderBot.lib.rl.config_private",
        "peekOfCode": "ALPACA_API_SECRET = \"dJw28M9E5S4WujgUwPRBnfk4DLttQM66YCvhdC5X\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "pages.TraderBot.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_private",
        "description": "pages.TraderBot.lib.rl.config_private",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets/v2\"  # alpaca url",
        "detail": "pages.TraderBot.lib.rl.config_private",
        "documentation": {}
    },
    {
        "label": "SINGLE_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "SINGLE_TICKER = [\"AAPL\"]\n# Dow 30 constituents in 2021/10\n# check https://wrds-www.wharton.upenn.edu/ for U.S. index constituents\nDOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",\n    \"CVX\",\n    \"GS\",\n    \"HD\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "HSI_50_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "HSI_50_TICKER = [\n    \"0011.HK\",\n    \"0005.HK\",\n    \"0012.HK\",\n    \"0006.HK\",\n    \"0003.HK\",\n    \"0016.HK\",\n    \"0019.HK\",\n    \"0002.HK\",\n    \"0001.HK\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SSE_50_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "SSE_50_TICKER = [\n    \"600000.XSHG\",\n    \"600036.XSHG\",\n    \"600104.XSHG\",\n    \"600030.XSHG\",\n    \"601628.XSHG\",\n    \"601166.XSHG\",\n    \"601318.XSHG\",\n    \"601328.XSHG\",\n    \"601088.XSHG\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CSI_300_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "CSI_300_TICKER = [\n    \"600000.XSHG\",\n    \"600004.XSHG\",\n    \"600009.XSHG\",\n    \"600010.XSHG\",\n    \"600011.XSHG\",\n    \"600015.XSHG\",\n    \"600016.XSHG\",\n    \"600018.XSHG\",\n    \"600019.XSHG\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CAC_40_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "CAC_40_TICKER = [\n    \"AC.PA\",\n    \"AI.PA\",\n    \"AIR.PA\",\n    \"MT.AS\",\n    \"ATO.PA\",\n    \"CS.PA\",\n    \"BNP.PA\",\n    \"EN.PA\",\n    \"CAP.PA\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DAX_30_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "DAX_30_TICKER = [\n    \"DHER.DE\",\n    \"RWE.DE\",\n    \"FRE.DE\",\n    \"MTX.DE\",\n    \"MRK.DE\",\n    \"LIN.DE\",\n    \"ALV.DE\",\n    \"VNA.DE\",\n    \"EOAN.DE\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "TECDAX_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "TECDAX_TICKER = [\n    \"ADV.DE\",\n    \"AFX.DE\",\n    \"AM3D.DE\",\n    \"BC8.DE\",\n    \"COK.DE\",\n    \"DLG.DE\",\n    \"DRI.DE\",\n    \"DRW3.DE\",\n    \"EVT.DE\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "MDAX_50_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "MDAX_50_TICKER = [\n    \"1COV.DE\",\n    \"AIR.DE\",\n    \"AOX.DE\",\n    \"ARL.DE\",\n    \"BNR.DE\",\n    \"BOSS.DE\",\n    \"DEQ.DE\",\n    \"DUE.DE\",\n    \"DWNI.DE\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SDAX_50_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "SDAX_50_TICKER = [\n    \"AAD.DE\",\n    \"ACX.DE\",\n    \"ADJ.DE\",\n    \"ADL.DE\",\n    \"BDT.DE\",\n    \"BIO3.DE\",\n    \"BVB.DE\",\n    \"BYW6.DE\",\n    \"CWC.DE\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "LQ45_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "LQ45_TICKER = [\n    \"ACES.JK\",\n    \"ADRO.JK\",\n    \"AKRA.JK\",\n    \"ANTM.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SRI_KEHATI_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "SRI_KEHATI_TICKER = [\n    \"AALI.JK\",\n    \"ADHI.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",\n    \"BMRI.JK\",\n    \"BSDE.JK\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "FX_TICKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "FX_TICKER = [\n    \"AUDCAD=X\",\n    \"AUDCHF=X\",\n    \"AUDJPY=X\",\n    \"AUDNZD=X\",\n    \"AUDSGD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "custom_index",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "custom_index = [\"MMM\", \"AXP\", \"BA\", \"CAT\", \"CSCO\"]\nsector_dict = {\n    \"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"META\", \"TSLA\"],\n    \"Healthcare\": [\"JNJ\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\"],\n    \"Finance\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"],\n    \"Consumer Discretionary\": [\"AMZN\", \"HD\", \"NKE\", \"MCD\", \"SBUX\"],\n    \"Energy\": [\"XOM\", \"CVX\", \"COP\", \"PSX\", \"VLO\"]\n}\nusa_dict = {\n    # usa_dict[S&P 500]",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "sector_dict",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "sector_dict = {\n    \"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"META\", \"TSLA\"],\n    \"Healthcare\": [\"JNJ\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\"],\n    \"Finance\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"],\n    \"Consumer Discretionary\": [\"AMZN\", \"HD\", \"NKE\", \"MCD\", \"SBUX\"],\n    \"Energy\": [\"XOM\", \"CVX\", \"COP\", \"PSX\", \"VLO\"]\n}\nusa_dict = {\n    # usa_dict[S&P 500]\n  \"NYSE\": SP_500_TICKER  ",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "usa_dict",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "usa_dict = {\n    # usa_dict[S&P 500]\n  \"NYSE\": SP_500_TICKER  \n}\nindex_dict = {\n    \"Dow 30\": DOW_30_TICKER,\n    \"Nasdaq 100\": NAS_100_TICKER,\n    \"S&P 500\": SP_500_TICKER,\n    \"Hang Seng Index\" : HSI_50_TICKER, \n    \"SSE 50\" :SSE_50_TICKER, ",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "index_dict",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.rl.config_tickers",
        "description": "pages.TraderBot.lib.rl.config_tickers",
        "peekOfCode": "index_dict = {\n    \"Dow 30\": DOW_30_TICKER,\n    \"Nasdaq 100\": NAS_100_TICKER,\n    \"S&P 500\": SP_500_TICKER,\n    \"Hang Seng Index\" : HSI_50_TICKER, \n    \"SSE 50\" :SSE_50_TICKER, \n    \"CSI 300\" : CSI_300_TICKER, \n    \"CAC 40\" : CAC_40_TICKER, \n    \"DAX 30\" : DAX_30_TICKER, \n    \"TecDAX\" : TECDAX_TICKER, ",
        "detail": "pages.TraderBot.lib.rl.config_tickers",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.main",
        "description": "pages.TraderBot.lib.rl.main",
        "peekOfCode": "def build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        dest=\"mode\",\n        help=\"start mode, train, download_data\" \" backtest\",\n        metavar=\"MODE\",\n        default=\"train\",\n    )\n    return parser",
        "detail": "pages.TraderBot.lib.rl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.main",
        "description": "pages.TraderBot.lib.rl.main",
        "peekOfCode": "def check_and_make_directories(directories: list[str]):\n    for directory in directories:\n        if not os.path.exists(\"./\" + directory):\n            os.makedirs(\"./\" + directory)\ndef main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )",
        "detail": "pages.TraderBot.lib.rl.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.main",
        "description": "pages.TraderBot.lib.rl.main",
        "peekOfCode": "def main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )\n    if options.mode == \"train\":\n        from lib.rl import train\n        env = StockTradingEnv\n        # demo for elegantrl",
        "detail": "pages.TraderBot.lib.rl.main",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def get_daily_return(df, value_col_name=\"account_value\"):\n    df = deepcopy(df)\n    df[\"daily_return\"] = df[value_col_name].pct_change(1)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    df.set_index(\"date\", inplace=True, drop=True)\n    df.index = df.index.tz_localize(\"UTC\")\n    return pd.Series(df[\"daily_return\"], index=df.index)\ndef convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "convert_daily_return_to_pyfolio_ts",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n    del strategy_ret[\"date\"]\n    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\ndef backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(\n        returns=dr_test,\n        positions=None,\n        transactions=None,\n        turnover_denom=\"AGB\",\n    )\n    # jprint(perf_stats_all)\n    st.table(perf_stats_all)",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def backtest_plot(\n    account_value,\n    baseline_start=config.TRADE_START_DATE,\n    baseline_end=config.TRADE_END_DATE,\n    baseline_ticker=\"^DJI\",\n    value_col_name=\"account_value\",\n):\n    df = deepcopy(account_value)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    test_returns = get_daily_return(df, value_col_name=value_col_name)",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def get_baseline(ticker, start, end):\n    return YahooDownloader(\n        start_date=start, end_date=end, ticker_list=[ticker]\n    ).fetch_data()\ndef trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "trx_plot",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):\n        df_trx_temp = df_trx.iloc[:, i]\n        df_trx_temp_sign = np.sign(df_trx_temp)\n        buying_signal = df_trx_temp_sign.apply(lambda x: x > 0)\n        selling_signal = df_trx_temp_sign.apply(lambda x: x < 0)",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "transfer_date",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def transfer_date(str_dat):\n    return datetime.datetime.strptime(str_dat, \"%Y-%m-%d\").date().strftime(\"%m/%d/%Y\")\ndef plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result_from_csv",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    result = pd.read_csv(csv_file)",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def plot_result(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    columns = result.columns",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "get_if_overlap",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def get_if_overlap(fig, ax):\n    fig.canvas.draw()\n    # \n    bboxes = [label.get_window_extent() for label in ax.get_xticklabels()]\n    # \n    distances = [bboxes[i + 1].x0 - bboxes[i].x1 for i in range(len(bboxes) - 1)]\n    # 0\n    if any(distance < 0 for distance in distances):\n        if_overlap = True\n    else:",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def plot_return(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return_from_csv",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.plot",
        "description": "pages.TraderBot.lib.rl.plot",
        "peekOfCode": "def plot_return_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "pages.TraderBot.lib.rl.plot",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.test",
        "description": "pages.TraderBot.lib.rl.test",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages.TraderBot.lib.rl.test",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.trade",
        "description": "pages.TraderBot.lib.rl.trade",
        "peekOfCode": "def trade(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages.TraderBot.lib.rl.trade",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.rl.train",
        "description": "pages.TraderBot.lib.rl.train",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages.TraderBot.lib.rl.train",
        "documentation": {}
    },
    {
        "label": "WorkflowScheduler",
        "kind": 6,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "class WorkflowScheduler:\n    def __init__(self):\n        # Define labels and date ranges for different workflow modes\n        self.labels = {\n            \"Train\": (TRAIN_START_DATE, TRAIN_END_DATE),\n            \"Test\": (TEST_START_DATE, TEST_END_DATE),\n            \"Trade\": (TRADE_START_DATE, TRADE_END_DATE),\n        }\n        self.train_start_date = self.labels[\"Train\"][0]\n        self.train_end_date = self.labels[\"Train\"][1]",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "setFirstPageTitle",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def setFirstPageTitle() : \n    custom_css = \"\"\"\n    <style>\n    body {\n    background-color: black; /* Background color (black) */\n    font-family: \"Times New Roman\", Times, serif; /* Font family (Times New Roman) */\n    color: white; /* Text color (white) */\n    line-height: 1.6; /* Line height for readability */\n    }\n    h1 {",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_inputs99",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def set_inputs99():\n    st.title(\"Dynamic Financial Reinforcement Learning\")\n    st.write(\"\"\"\n    This application simulates a dynamic dataset-driven financial reinforcement learning model, \n    which uses a rolling window technique to incrementally update the training and testing sets based on real-time market data.\n    The dataset is divided into training and testing segments, which adjust every W days to keep the model updated.\n    \"\"\")\nclass WorkflowScheduler:\n    def __init__(self):\n        # Define labels and date ranges for different workflow modes",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "get_full_path",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def get_full_path(fn):\n    file_path = os.path.join(DATA_FRAME_DIR, fn )\n    return file_path\ndef set_yahoo_data_frame(ticker_ls, wf) :\n  \"\"\"app.py: Waiting data collection From Yahoo downloader ...\"\"\"\n  df = YahooDownloader(start_date  = \n  wf.train_start_date,\n  end_date = wf.trade_end_date,\n  ticker_list = ticker_ls).fetch_data()\n  df.sort_values(['date','tic'],ignore_index=True).head()",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "set_yahoo_data_frame",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def set_yahoo_data_frame(ticker_ls, wf) :\n  \"\"\"app.py: Waiting data collection From Yahoo downloader ...\"\"\"\n  df = YahooDownloader(start_date  = \n  wf.train_start_date,\n  end_date = wf.trade_end_date,\n  ticker_list = ticker_ls).fetch_data()\n  df.sort_values(['date','tic'],ignore_index=True).head()\n  fe = FeatureEngineer(\n                    use_technical_indicator=True,\n                    tech_indicator_list = INDICATORS,",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def train_agent(agent, model_name = \"a2c\", total_timesteps=50000):\n    \"\"\"\n    Train a model with the provided agent and model_name and total_timesteps \n    \"\"\"\n    # Get the model for A2C if applicable\n    __cached__model_ = agent.get_model(model_name)\n    # Set up logger\n    _tmp_path = RESULTS_DIR + '/' + model_name\n    _new_logger = configure(_tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n    # Set the new logger",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "predict_with_models",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def predict_with_models(models, environment):\n      \"\"\"\n      Perform predictions using multiple trained models in the specified environment.\n      Parameters:\n      - models: A dictionary of trained models with names as keys.\n      - environment: The trading environment to be used for predictions.\n      Returns:\n      - results: A dictionary containing DataFrames of account values and actions for each model.\n      \"\"\"\n      results = {}",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "GetTickerList",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.inputs",
        "description": "pages.TraderBot.lib.utility.inputs",
        "peekOfCode": "def GetTickerList():\n    \"\"\"\n    Generate a list of tickers based on user selection (Index, Sector, or NYSE) in a Streamlit app.\n    Parameters:\n    - index_dict: Dictionary of indexes and their respective tickers.\n    - sector_dict: Dictionary of sectors and their respective tickers.\n    - usa_dict: Dictionary of NYSE-specific categories and tickers.\n    - SP_500_TICKER: List of tickers for the S&P 500.\n    Returns:\n    - final_ticker_list: List of selected tickers.",
        "detail": "pages.TraderBot.lib.utility.inputs",
        "documentation": {}
    },
    {
        "label": "jprint",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.jprint",
        "description": "pages.TraderBot.lib.utility.jprint",
        "peekOfCode": "def jprint(s1 = '', s2 = '' , s3 = '', s4 = \"\"):\n  a1 = str(s1) + str(s2) + str(s3) +str(s4)\n  print   (a1)\n  st.write(a1)\n# def jprint2(*args):\n#     # Convert all inputs to strings and handle lists/arrays\n#     result = []\n#     for arg in args:\n#         if isinstance(arg, (list, tuple)):  # Check if the argument is a list or tuple\n#             result.extend(map(str, arg))    # Convert each item in the list to a string",
        "detail": "pages.TraderBot.lib.utility.jprint",
        "documentation": {}
    },
    {
        "label": "get_ticker_start_end_date",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_ticker_start_end_date():\n    # Select Index Category\n    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])\n    with col1:\n        selected_index = st.selectbox(\" Select Index Category:\", list(index_dict.keys()))\n        TICKERS = index_dict[selected_index]  # Update TICKERS based on selection\n    with col2:\n        ticker = st.selectbox(\" Select a Stock Ticker:\", TICKERS)\n    with col3:\n        start_date = st.date_input(\" Start Date\", datetime.date(2025, 1, 1))",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_real_time_price",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_real_time_price(ticker):\n    try:\n        api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=\"https://paper-api.alpaca.markets\")\n        trade = api.get_latest_trade(ticker)\n        return trade.price  #  Return price if trade exists\n    except tradeapi.rest.APIError as e:\n        print(f\" Alpaca API Error: {e}\")  #  Log the error\n        return None  #  Return None if no trade is found\n# Original alpaca_hist (still used for stock universe)\ndef get_stock_client():",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\n# Initialize Alpaca Data Client\nstock_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\nimport pandas as pd\nfrom datetime import date, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom alpaca.data.historical import StockHistoricalDataClient\nfrom alpaca.data.requests import StockBarsRequest\nfrom alpaca.data.timeframe import TimeFrame",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_baseline2",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_baseline2(ticker: str, start: str, end: str) -> pd.DataFrame:\n    print(f\" Fetching baseline: {ticker} from {start} to {end}\")\n    # Replace ^DJI or unsupported indices with valid ETF tickers\n    if ticker in [\"^DJI\", \"^GSPC\", \"^NDX\"]:\n        print(f\" Replacing unsupported index ticker {ticker} with SPY\")\n        ticker = \"SPY\"\n    start_date = dt.strptime(start, \"%Y-%m-%d\").date()\n    end_date = dt.strptime(end, \"%Y-%m-%d\").date()\n    try:\n        request = StockBarsRequest(",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_stock_client",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_stock_client():\n    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\n@st.cache_data\ndef alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alpaca_hist",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def alpaca_hist(tickers, start_date, end_date):\n    print(f\"Fetching data from {start_date} to {end_date}\")\n    data_frames = []\n    for ticker in tickers:\n        print(f\"Fetching: {ticker}\")\n        try:\n            request_params = StockBarsRequest(\n                symbol_or_symbols=ticker,\n                timeframe=TimeFrame.Day,\n                start=start_date,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_stock_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def fetch_stock_data(ticker, start_date, end_date):\n    \"\"\"Fetch historical stock data from Alpaca.\"\"\"\n    try:\n        # client = get_stock_client()\n        # request_params = StockBarsRequest(symbol_or_symbols=[ticker], timeframe=TimeFrame.Day, start=start_date, end=end_date)\n        # return client.get_stock_bars(request_params)\n        if not ticker:\n            raise ValueError(\"Ticker is empty or None.\")\n        client = get_stock_client()\n        request_params = StockBarsRequest(",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "load_and_plot_stock_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def load_and_plot_stock_data(ticker, start_date, end_date):\n    from lib.utility.util import fetch_stock_data, convert_barSet_to_DataFrame\n    barset = fetch_stock_data(ticker, start_date, end_date)\n    df, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\n    return df, close_col\n#  Convert Alpaca Data to DataFrame\ndef convert_alpaca_data_to_df(stock_data):\n    \"\"\"Converts Alpaca BarSet to a Pandas DataFrame for visualization.\"\"\"\n    if isinstance(stock_data, BarSet):\n        data_list = []",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_alpaca_data_to_df",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def convert_alpaca_data_to_df(stock_data):\n    \"\"\"Converts Alpaca BarSet to a Pandas DataFrame for visualization.\"\"\"\n    if isinstance(stock_data, BarSet):\n        data_list = []\n        for symbol, bars in stock_data.data.items():\n            for bar in bars:\n                data_list.append({\n                    \"timestamp\": bar.timestamp,\n                    \"open\": bar.open,\n                    \"high\": bar.high,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_news_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def fetch_news_data(ticker):\n    \"\"\"Retrieve news headlines from Finviz and ensure date values exist.\"\"\"\n    try:\n        req = Request(url=FINVIZ_URL + ticker, headers={\"user-agent\": \"Mozilla/5.0\"})\n        html = BeautifulSoup(urlopen(req), \"html.parser\")\n        news_table = html.find(id=\"news-table\")\n        if not news_table:\n            st.warning(f\" No news data found for {ticker}.\")\n            return None\n        news_list = []",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def analyze_sentiment(news_list):\n    if not news_list:\n        return None\n    df_sentiment = pd.DataFrame(news_list)\n    df_sentiment[\"Date\"] = pd.to_datetime(df_sentiment[\"date\"], errors=\"coerce\").dt.date\n    df_sentiment[\"Compound Score\"] = df_sentiment[\"title\"].apply(lambda title: SentimentIntensityAnalyzer().polarity_scores(title)[\"compound\"])\n    return df_sentiment\n#  Display Sentiment Summary\ndef display_sentiment_summary(df_sentiment):\n    st.subheader(\" Sentiment Summary\")",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "display_sentiment_summary",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def display_sentiment_summary(df_sentiment):\n    st.subheader(\" Sentiment Summary\")\n    avg_score = df_sentiment[\"Compound Score\"].mean() * 100\n    sentiment_icon = \"\" if avg_score > 10 else \"\" if avg_score < -10 else \"\"\n    st.metric(label=f\" Average Sentiment Score {sentiment_icon}\", value=f\"{avg_score:.2f}%\")\n    summary = {\n        \" Positive\": f\"{(df_sentiment['Compound Score'] > 0).sum() / len(df_sentiment) * 100:.2f}%\",\n        \" Negative\": f\"{(df_sentiment['Compound Score'] < 0).sum() / len(df_sentiment) * 100:.2f}%\",\n        \" Neutral\": f\"{(df_sentiment['Compound Score'] == 0).sum() / len(df_sentiment) * 100:.2f}%\"\n    }",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "plot_stock_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def plot_stock_data(stock_data, ticker):\n    \"\"\"Processes stock data and plots it.\"\"\"\n    df_stock = convert_alpaca_data_to_df(stock_data)\n    if not df_stock.empty:\n        st.subheader(f\" {ticker} Stock Price Movements\")\n        st.line_chart(df_stock[[\"close\"]])\n    else:\n        st.warning(\" No valid stock data available.\")\n#  Compute Moving Averages\ndef compute_moving_averages(df_stock, close_col):",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def compute_moving_averages(df_stock, close_col):\n    \"\"\"Computes SMA & EMA indicators.\"\"\"\n    df_stock[\"SMA_50\"] = df_stock[close_col].rolling(window=50, min_periods=1).mean()\n    df_stock[\"EMA_20\"] = df_stock[close_col].ewm(span=20, adjust=False).mean()\n    return df_stock\n#  Generate Buy/Sell Signals\ndef generate_trade_signals(df_stock, df_news, close_col):\n    if df_stock is None or df_news is None or close_col not in df_stock.columns:\n        st.warning(\" Cannot generate trade signals due to missing price or sentiment data.\")\n        return pd.DataFrame()",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "generate_trade_signals",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def generate_trade_signals(df_stock, df_news, close_col):\n    if df_stock is None or df_news is None or close_col not in df_stock.columns:\n        st.warning(\" Cannot generate trade signals due to missing price or sentiment data.\")\n        return pd.DataFrame()\n    df_news = df_news.copy()\n    if \"Date\" not in df_news.columns and df_news.index.name == \"Date\":\n        df_news = df_news.reset_index()\n    df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"], errors=\"coerce\", utc=True)\n    df_news.set_index(\"Date\", inplace=True)\n    df_merged = df_stock.merge(",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "convert_barSet_to_DataFrame",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def convert_barSet_to_DataFrame(stock_data, _, ticker):\n    if isinstance(stock_data, BarSet):\n        data_list = []\n        for symbol, bars in stock_data.data.items():\n            for bar in bars:\n                data_list.append({\n                    \"timestamp\": bar.timestamp,\n                    \"open\": bar.open,\n                    \"high\": bar.high,\n                    \"low\": bar.low,",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_moving_averages",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def compute_moving_averages(df_stock_, ticker, df_news):\n        close_col = f\"{ticker}_close\" if f\"{ticker}_close\" in df_stock_.columns else None\n        if close_col:\n            #  Compute Moving Averages\n            df_stock_[\"SMA_50\"] = df_stock_[close_col].rolling(window=50, min_periods=1).mean()\n            df_stock_[\"EMA_20\"] = df_stock_[close_col].ewm(span=20, adjust=False).mean()\n            #  Convert df_news[\"Date\"] to datetime & set as index\n            df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"], errors=\"coerce\", utc=True)\n            df_news.set_index(\"Date\", inplace=True)\n            #  Merge Sentiment and Stock Data (Fixed: Ensure both indices are datetime64[ns, UTC])",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "collapsible_detailed_description",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def collapsible_detailed_description(s1,s2):          \n  with st.expander(s1):\n    st.markdown(s2)  \n@st.cache_data\ndef fetch_twitter_sentiment(ticker):\n    # Placeholder/mock: In real app, integrate Twitter API or snscrape\n    mock_data = [\n        {\"text\": f\"{ticker} is going to the moon! \", \"sentiment\": 0.8},\n        {\"text\": f\"I'm not sure about {ticker}, looks weak.\", \"sentiment\": -0.3},\n    ]",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_twitter_sentiment",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def fetch_twitter_sentiment(ticker):\n    # Placeholder/mock: In real app, integrate Twitter API or snscrape\n    mock_data = [\n        {\"text\": f\"{ticker} is going to the moon! \", \"sentiment\": 0.8},\n        {\"text\": f\"I'm not sure about {ticker}, looks weak.\", \"sentiment\": -0.3},\n    ]\n    df = pd.DataFrame(mock_data)\n    df[\"source\"] = \"Twitter\"\n    return df    \n@st.cache_data",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_reddit_sentiment",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def fetch_reddit_sentiment(ticker):\n    mock_data = [\n        {\"text\": f\"{ticker} YOLO play on r/wallstreetbets\", \"sentiment\": 0.7},\n        {\"text\": f\"{ticker} is overhyped.\", \"sentiment\": -0.2},\n    ]\n    df = pd.DataFrame(mock_data)\n    df[\"source\"] = \"Reddit\"\n    return df\n@st.cache_data\ndef fetch_google_trends(ticker):",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "fetch_google_trends",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def fetch_google_trends(ticker):\n    from pytrends.request import TrendReq\n    pytrends = TrendReq()\n    kw_list = [ticker]\n    pytrends.build_payload(kw_list, timeframe=\"now 7-d\")\n    interest = pytrends.interest_over_time()\n    if not interest.empty:\n        df = interest.reset_index()[[\"date\", ticker]]\n        df.rename(columns={ticker: \"interest\"}, inplace=True)\n        return df",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "alternative_data_source",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def alternative_data_source():\n    from pytrends.request import TrendReq\n    pytrends = TrendReq()\n    pytrends.build_payload([ticker], timeframe=\"now 7-d\", geo=\"US\")\n    trends_data = pytrends.interest_over_time()\n    st.subheader(\" Google Trends Interest\")\n    st.line_chart(trends_data)\n#  5. Portfolio Analysis\n#  Features Added:\n# Tracks multiple stocks.",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "calculate_portfolio_value",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def calculate_portfolio_value(portfolio):\n    portfolio = {\n    \"AAPL\": {\"quantity\": 5, \"buy_price\": 150},\n    \"TSLA\": {\"quantity\": 3, \"buy_price\": 700}\n    }\n    total_value = 0\n    for stock, details in portfolio.items():\n        current_price = get_real_time_price(stock)\n        total_value += details[\"quantity\"] * current_price\n    return total_value",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "place_trade",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def place_trade(order_type, ticker, qty):\n    import alpaca_trade_api as tradeapi\n    api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=\"https://paper-api.alpaca.markets\")\n    api.submit_order(\n        symbol=ticker,\n        qty=qty,\n        side=order_type,\n        type=\"market\",\n        time_in_force=\"gtc\"\n    )",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "stock_prediction",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def stock_prediction():\n    import tensorflow as tf\n    from keras.models import Sequential\n    from keras.layers import LSTM, Dense\n    model = Sequential([\n        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n        LSTM(50, return_sequences=False),\n        Dense(25),\n        Dense(1)\n    ])",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "daily_market_summary",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def daily_market_summary():\n    st.subheader(\" Market Summary\")\n    market_summary = {\n        \" Top Gainer\": \"NVDA (+12.5%)\",\n        \" Top Loser\": \"TSLA (-8.2%)\",\n        \" Market Trend\": \"Bullish \"\n    }\n    st.json(market_summary)\n# 3. AI-Based Sentiment Classification (GPT-4)\n#  Features Added:",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "get_sentiment_gpt4",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def get_sentiment_gpt4(news_headline):\n    import openai\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": f\"Analyze the sentiment of this stock-related news: {news_headline}\"}]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"]\ndef compute_price_features(df, close_col, short_window=50, long_window=100):\n    \"\"\"\n    Compute SMA, EMA, and percentage change on the closing price column.",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "compute_price_features",
        "kind": 2,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "def compute_price_features(df, close_col, short_window=50, long_window=100):\n    \"\"\"\n    Compute SMA, EMA, and percentage change on the closing price column.\n    Args:\n        df (pd.DataFrame): Stock price data.\n        close_col (str): Column name for close prices (e.g. 'AAPL_close').\n        short_window (int): Window for short-term SMA.\n        long_window (int): Window for long-term SMA.\n    Returns:\n        pd.DataFrame: DataFrame with new SMA, EMA, and % Change columns added.",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "FINVIZ_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "FINVIZ_URL = \"https://finviz.com/quote.ashx?t=\"\n#  Download NLTK dependencies\nnltk.download(\"vader_lexicon\")\n#  Fetch Real-Time Stock Price\nimport alpaca_trade_api as tradeapi\nfrom datetime import datetime as dt\ndef get_ticker_start_end_date():\n    # Select Index Category\n    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])\n    with col1:",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "stock_client",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "stock_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\nimport pandas as pd\nfrom datetime import date, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom alpaca.data.historical import StockHistoricalDataClient\nfrom alpaca.data.requests import StockBarsRequest\nfrom alpaca.data.timeframe import TimeFrame\nimport os\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\nfrom datetime import datetime as dt  #  alias to avoid conflicts",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "stock_client",
        "kind": 5,
        "importPath": "pages.TraderBot.lib.utility.util",
        "description": "pages.TraderBot.lib.utility.util",
        "peekOfCode": "stock_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\ndef get_baseline2(ticker: str, start: str, end: str) -> pd.DataFrame:\n    print(f\" Fetching baseline: {ticker} from {start} to {end}\")\n    # Replace ^DJI or unsupported indices with valid ETF tickers\n    if ticker in [\"^DJI\", \"^GSPC\", \"^NDX\"]:\n        print(f\" Replacing unsupported index ticker {ticker} with SPY\")\n        ticker = \"SPY\"\n    start_date = dt.strptime(start, \"%Y-%m-%d\").date()\n    end_date = dt.strptime(end, \"%Y-%m-%d\").date()\n    try:",
        "detail": "pages.TraderBot.lib.utility.util",
        "documentation": {}
    },
    {
        "label": "WorkingAlpacaBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting",
        "peekOfCode": "class WorkingAlpacaBacktesting(AlpacaData):\n    \"\"\"\n    Operational replacement for the non-working AlpacaBacktesting class\n    \"\"\"\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        # Initialize config\n        config = kwargs.pop('config', {}) or {}\n        config.update({\n            'datetime_start': datetime_start,\n            'datetime_end': datetime_end,",
        "detail": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "IS_BACKTESTING_BROKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting",
        "peekOfCode": "IS_BACKTESTING_BROKER = True\nclass WorkingAlpacaBacktesting(AlpacaData):\n    \"\"\"\n    Operational replacement for the non-working AlpacaBacktesting class\n    \"\"\"\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        # Initialize config\n        config = kwargs.pop('config', {}) or {}\n        config.update({\n            'datetime_start': datetime_start,",
        "detail": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "FixedAlpacaBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting1",
        "description": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting1",
        "peekOfCode": "class FixedAlpacaBacktesting(AlpacaData):\n    \"\"\"\n    Fully operational Alpaca backtesting class that properly integrates with Lumibot\n    \"\"\"\n    # Mark this as a backtesting broker\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        # Initialize config\n        config = kwargs.pop('config', {}) or {}\n        config.update({",
        "detail": "pages.TraderBot.lumibot.backtesting.alpaca_backtesting1",
        "documentation": {}
    },
    {
        "label": "AlphaVantageBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.alpha_vantage_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.alpha_vantage_backtesting",
        "peekOfCode": "class AlphaVantageBacktesting(DataSourceBacktesting, AlphaVantageData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        raise Exception(\"AlphaVantageBacktesting is not currently operational\")\n        AlphaVantageData.__init__(self, **kwargs)\n        DataSourceBacktesting.__init__(self, datetime_start, datetime_end)",
        "detail": "pages.TraderBot.lumibot.backtesting.alpha_vantage_backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.backtesting_broker",
        "description": "pages.TraderBot.lumibot.backtesting.backtesting_broker",
        "peekOfCode": "class BacktestingBroker(Broker):\n    # Metainfo\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, data_source, option_source=None, connect_stream=True, max_workers=20, config=None, **kwargs):\n        super().__init__(name=\"backtesting\", data_source=data_source,\n                         option_source=option_source, connect_stream=connect_stream, **kwargs)\n        # Calling init methods\n        self.max_workers = max_workers\n        self.market = \"NASDAQ\"\n        self.option_source = option_source",
        "detail": "pages.TraderBot.lumibot.backtesting.backtesting_broker",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.backtesting_broker",
        "description": "pages.TraderBot.lumibot.backtesting.backtesting_broker",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass BacktestingBroker(Broker):\n    # Metainfo\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, data_source, option_source=None, connect_stream=True, max_workers=20, config=None, **kwargs):\n        super().__init__(name=\"backtesting\", data_source=data_source,\n                         option_source=option_source, connect_stream=connect_stream, **kwargs)\n        # Calling init methods\n        self.max_workers = max_workers\n        self.market = \"NASDAQ\"",
        "detail": "pages.TraderBot.lumibot.backtesting.backtesting_broker",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.ccxt_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.ccxt_backtesting",
        "peekOfCode": "class CcxtBacktesting(CcxtBacktestingData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        CcxtBacktestingData.__init__(self, datetime_start, datetime_end, **kwargs)",
        "detail": "pages.TraderBot.lumibot.backtesting.ccxt_backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.pandas_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.pandas_backtesting",
        "peekOfCode": "class PandasDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of the PandasData class.  This class is just kept around for legacy purposes.\n    Please just use PandasData directly instead.\n    \"\"\"\n    def __init__(self, *args, pandas_data=None, **kwargs):\n        super().__init__(*args, pandas_data=pandas_data, **kwargs)",
        "detail": "pages.TraderBot.lumibot.backtesting.pandas_backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.polygon_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.polygon_backtesting",
        "peekOfCode": "class PolygonDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of Polygon\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,\n        api_key=None,",
        "detail": "pages.TraderBot.lumibot.backtesting.polygon_backtesting",
        "documentation": {}
    },
    {
        "label": "START_BUFFER",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.polygon_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.polygon_backtesting",
        "peekOfCode": "START_BUFFER = timedelta(days=5)\nclass PolygonDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of Polygon\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,",
        "detail": "pages.TraderBot.lumibot.backtesting.polygon_backtesting",
        "documentation": {}
    },
    {
        "label": "SimpleAlpacaStrategy",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.t1",
        "description": "pages.TraderBot.lumibot.backtesting.t1",
        "peekOfCode": "class SimpleAlpacaStrategy(Strategy):\n    def initialize(self):\n        self.symbol = \"SPY\"\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        # Get historical data\n        bars = self.get_historical_prices(self.symbol, 20, \"day\")\n        current_price = bars.df[\"close\"][-1]\n        # Simple buy and hold strategy\n        if not self.get_position(self.symbol):",
        "detail": "pages.TraderBot.lumibot.backtesting.t1",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.t1",
        "description": "pages.TraderBot.lumibot.backtesting.t1",
        "peekOfCode": "start_date = datetime(2023, 1, 1)\nend_date = datetime(2023, 12, 31)\n# Create data source\ndata_source = WorkingAlpacaBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    # Add these if you need real Alpaca data:\n    # API_KEY=\"YOUR_API_KEY\",\n    # API_SECRET=\"YOUR_API_SECRET\"\n)",
        "detail": "pages.TraderBot.lumibot.backtesting.t1",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.t1",
        "description": "pages.TraderBot.lumibot.backtesting.t1",
        "peekOfCode": "end_date = datetime(2023, 12, 31)\n# Create data source\ndata_source = WorkingAlpacaBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    # Add these if you need real Alpaca data:\n    # API_KEY=\"YOUR_API_KEY\",\n    # API_SECRET=\"YOUR_API_SECRET\"\n)\n# Run backtest",
        "detail": "pages.TraderBot.lumibot.backtesting.t1",
        "documentation": {}
    },
    {
        "label": "data_source",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.t1",
        "description": "pages.TraderBot.lumibot.backtesting.t1",
        "peekOfCode": "data_source = WorkingAlpacaBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    # Add these if you need real Alpaca data:\n    # API_KEY=\"YOUR_API_KEY\",\n    # API_SECRET=\"YOUR_API_SECRET\"\n)\n# Run backtest\nstrategy = SimpleAlpacaStrategy(\n    broker=data_source,",
        "detail": "pages.TraderBot.lumibot.backtesting.t1",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.t1",
        "description": "pages.TraderBot.lumibot.backtesting.t1",
        "peekOfCode": "strategy = SimpleAlpacaStrategy(\n    broker=data_source,\n    budget=100000\n)\nresults = strategy.backtest()\nprint(f\"Backtest results: {results}\")",
        "detail": "pages.TraderBot.lumibot.backtesting.t1",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.t1",
        "description": "pages.TraderBot.lumibot.backtesting.t1",
        "peekOfCode": "results = strategy.backtest()\nprint(f\"Backtest results: {results}\")",
        "detail": "pages.TraderBot.lumibot.backtesting.t1",
        "documentation": {}
    },
    {
        "label": "ThetaDataBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.thetadata_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.thetadata_backtesting",
        "peekOfCode": "class ThetaDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of ThetaData\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,\n        username=None,",
        "detail": "pages.TraderBot.lumibot.backtesting.thetadata_backtesting",
        "documentation": {}
    },
    {
        "label": "START_BUFFER",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.backtesting.thetadata_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.thetadata_backtesting",
        "peekOfCode": "START_BUFFER = timedelta(days=5)\nclass ThetaDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of ThetaData\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,",
        "detail": "pages.TraderBot.lumibot.backtesting.thetadata_backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.backtesting.yahoo_backtesting",
        "description": "pages.TraderBot.lumibot.backtesting.yahoo_backtesting",
        "peekOfCode": "class YahooDataBacktesting(YahooData):\n    \"\"\"\n    YahooDataBacktesting is a DataSourceBacktesting that uses YahooData as a\n    backtesting data source.\n    \"\"\"\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        YahooData.__init__(self, datetime_start, datetime_end, **kwargs)",
        "detail": "pages.TraderBot.lumibot.backtesting.yahoo_backtesting",
        "documentation": {}
    },
    {
        "label": "OrderData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.alpaca",
        "description": "pages.TraderBot.lumibot.brokers.alpaca",
        "peekOfCode": "class OrderData:\n    def __init__(self, **kwargs):\n        self.__dict__.update(kwargs)\n    def to_request_fields(self):\n        return self.__dict__\nclass Alpaca(Broker):\n    \"\"\"A broker class that connects to Alpaca\n    Attributes\n    ----------\n    api : tradeapi.REST",
        "detail": "pages.TraderBot.lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.alpaca",
        "description": "pages.TraderBot.lumibot.brokers.alpaca",
        "peekOfCode": "class Alpaca(Broker):\n    \"\"\"A broker class that connects to Alpaca\n    Attributes\n    ----------\n    api : tradeapi.REST\n        Alpaca API object\n    Methods\n    -------\n    get_timestamp()\n        Returns the current UNIX timestamp representation from Alpaca",
        "detail": "pages.TraderBot.lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "CustomLoggerAdapter",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.broker",
        "description": "pages.TraderBot.lumibot.brokers.broker",
        "peekOfCode": "class CustomLoggerAdapter(logging.LoggerAdapter):\n    def process(self, msg, kwargs):\n        # Check if the level is enabled to avoid formatting costs if not necessary\n        if self.logger.isEnabledFor(kwargs.get('level', logging.INFO)):\n            # Lazy formatting of the message\n            return f'[{self.extra[\"strategy_name\"]}] {msg}', kwargs\n        else:\n            return msg, kwargs\n    def update_strategy_name(self, new_strategy_name):\n        self.extra['strategy_name'] = new_strategy_name",
        "detail": "pages.TraderBot.lumibot.brokers.broker",
        "documentation": {}
    },
    {
        "label": "Broker",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.broker",
        "description": "pages.TraderBot.lumibot.brokers.broker",
        "peekOfCode": "class Broker(ABC):\n    # Metainfo\n    IS_BACKTESTING_BROKER = False\n    # Trading events flags\n    NEW_ORDER = \"new\"\n    CANCELED_ORDER = \"canceled\"\n    FILLED_ORDER = \"fill\"\n    PARTIALLY_FILLED_ORDER = \"partial_fill\"\n    CASH_SETTLED = \"cash_settled\"\n    ERROR_ORDER = \"error\"",
        "detail": "pages.TraderBot.lumibot.brokers.broker",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.ccxt",
        "description": "pages.TraderBot.lumibot.brokers.ccxt",
        "peekOfCode": "class Ccxt(Broker):\n    \"\"\"\n    Crypto broker using CCXT.\n    \"\"\"\n    def __init__(self, config, data_source: CcxtData = None, max_workers=20, chunk_size=100, **kwargs):\n        if data_source is None:\n            data_source = CcxtData(config, max_workers=max_workers, chunk_size=chunk_size)\n        super().__init__(name=\"ccxt\", config=config, data_source=data_source, max_workers=max_workers, **kwargs)\n        self.market = \"24/7\"\n        self.fetch_open_orders_last_request_time = None",
        "detail": "pages.TraderBot.lumibot.brokers.ccxt",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.example_broker",
        "description": "pages.TraderBot.lumibot.brokers.example_broker",
        "peekOfCode": "class ExampleBroker(Broker):\n    \"\"\"\n    Example broker that demonstrates how to connect to an API.\n    \"\"\"\n    NAME = \"ExampleBroker\"\n    def __init__(\n            self,\n            config=None,\n            data_source=None,\n    ):",
        "detail": "pages.TraderBot.lumibot.brokers.example_broker",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class InteractiveBrokers(Broker):\n    \"\"\"Inherit InteractiveBrokerData first and all the price market\n    methods than inherits broker\"\"\"\n    def __init__(self, config, max_workers=20, chunk_size=100, data_source=None, **kwargs):\n        if data_source is None:\n            data_source = InteractiveBrokersData(config, max_workers=max_workers, chunk_size=chunk_size)\n        super().__init__(\n            name=\"interactive_brokers\", \n            config=config, \n            data_source=data_source, ",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBWrapper",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBWrapper(EWrapper):\n    \"\"\"Listens and collects data from IB.\"\"\"\n    # Error handling code.\n    def init_error(self):\n        error_queue = queue.Queue()\n        self.my_errors_queue = error_queue\n    def is_error(self):\n        error_exist = not self.my_errors_queue.empty()\n        return error_exist\n    def get_error(self, timeout=6):",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBClient",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBClient(EClient):\n    \"\"\"Sends data to IB\"\"\"\n    def __init__(self, wrapper):\n        ## Set up with a wrapper inside\n        EClient.__init__(self, wrapper)\n        self.max_wait_time = 13\n        self.reqId = 10000\n    def get_reqid(self):\n        self.reqId += 1\n        return self.reqId",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBApp",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBApp(IBWrapper, IBClient):\n    def __init__(self, ip_address, socket_port, client_id, subaccount=None, ib_broker=None):\n        IBWrapper.__init__(self)\n        IBClient.__init__(self, wrapper=self)\n        self.ip_address = ip_address\n        self.socket_port = socket_port\n        self.client_id = client_id\n        self.ib_broker = ib_broker\n        self.subaccount = subaccount\n        self.reqAutoOpenOrders(True)",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nDATE_MAP = dict(\n    future=\"%Y%m%d\",",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "DATE_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "DATE_MAP = dict(\n    future=\"%Y%m%d\",\n    option=\"%Y%m%d\",\n)\nORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "ORDERTYPE_MAPPING",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "peekOfCode": "ORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",\n)\nclass InteractiveBrokers(Broker):\n    \"\"\"Inherit InteractiveBrokerData first and all the price market\n    methods than inherits broker\"\"\"",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "class InteractiveBrokersREST(Broker):\n    \"\"\"\n    Broker that connects to the Interactive Brokers REST API.\n    \"\"\"\n    NAME = \"InteractiveBrokersREST\"\n    def __init__(self, config, data_source=None):\n        if data_source is None:\n            data_source = InteractiveBrokersRESTData(config)\n        super().__init__(name=self.NAME, data_source=data_source, config=config)\n        self.market = \"NYSE\"  # The default market is NYSE.",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nDATE_MAP = dict(\n    future=\"%Y%m%d\",",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "DATE_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "DATE_MAP = dict(\n    future=\"%Y%m%d\",\n    option=\"%Y%m%d\",\n)\nORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "ORDERTYPE_MAPPING",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "ORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",\n)\nSPREAD_CONID_MAP = {\n    \"AUD\": 61227077,\n    \"CAD\": 61227082,",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "SPREAD_CONID_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "SPREAD_CONID_MAP = {\n    \"AUD\": 61227077,\n    \"CAD\": 61227082,\n    \"CHF\": 61227087,\n    \"CNH\": 136000441,\n    \"GBP\": 58666491,\n    \"HKD\": 61227072,\n    \"INR\": 136000444,\n    \"JPY\": 61227069,\n    \"KRW\": 136000424,",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "ASSET_CLASS_MAPPING",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "description": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "ASSET_CLASS_MAPPING = {\n    \"STK\": Asset.AssetType.STOCK,\n    \"OPT\": Asset.AssetType.OPTION,\n    \"FUT\": Asset.AssetType.FUTURE,\n    \"CASH\": Asset.AssetType.FOREX,\n}\nclass InteractiveBrokersREST(Broker):\n    \"\"\"\n    Broker that connects to the Interactive Brokers REST API.\n    \"\"\"",
        "detail": "pages.TraderBot.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.brokers.tradier",
        "description": "pages.TraderBot.lumibot.brokers.tradier",
        "peekOfCode": "class Tradier(Broker):\n    \"\"\"\n    Broker that connects to Tradier API to place orders and retrieve data. Tradier API only supports Order streaming\n    for live accounts, paper trading accounts must use a 'polling' method to retrieve order updates. This class will\n    still use a CustomStream object to process order updates (which can be confusing!), but this will more seamlessly\n    match what other LumiBrokers are doing without requiring changes to the stategy_executor. This\n    polling method will also work for Live accounts, so it will be used by default. However, future updates will be\n    made to natively support websocket streaming for Live accounts.\n    \"\"\"\n    POLL_EVENT = PollingStream.POLL_EVENT",
        "detail": "pages.TraderBot.lumibot.brokers.tradier",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.alpaca_data",
        "description": "pages.TraderBot.lumibot.data_sources.alpaca_data",
        "peekOfCode": "class AlpacaData(DataSource):\n    SOURCE = \"ALPACA\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"minute\",\n            \"representations\": [TimeFrame.Minute, \"minute\"],\n        },\n        {\n            \"timestep\": \"5 minutes\",",
        "detail": "pages.TraderBot.lumibot.data_sources.alpaca_data",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.alpha_vantage_data",
        "description": "pages.TraderBot.lumibot.data_sources.alpha_vantage_data",
        "peekOfCode": "class AlphaVantageData(DataSource):\n    SOURCE = \"ALPHA_VANTAGE\"\n    MIN_TIMESTEP = \"minute\"\n    DATA_STALE_AFTER = timedelta(days=1)\n    def __init__(self, config=None, auto_adjust=True, **kwargs):\n        self.name = \"alpha vantage\"\n        self.auto_adjust = auto_adjust\n        self._data_store = {}\n        self.config = config\n    def _append_data(self, asset, data):",
        "detail": "pages.TraderBot.lumibot.data_sources.alpha_vantage_data",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.ccxt_backtesting_data",
        "description": "pages.TraderBot.lumibot.data_sources.ccxt_backtesting_data",
        "peekOfCode": "class CcxtBacktestingData(DataSourceBacktesting):\n    \"\"\"Use CcxtCacheDB to download and cache data.\n    \"\"\"\n    # SOURCE must be `CCXT` for the DataSourceBacktesting to work\n    # `CCXT` is used in DataSource name\n    SOURCE = \"CCXT\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"minute\", \"representations\": [\"1m\"]},\n        {\"timestep\": \"day\", \"representations\": [\"1d\"]},",
        "detail": "pages.TraderBot.lumibot.data_sources.ccxt_backtesting_data",
        "documentation": {}
    },
    {
        "label": "CcxtData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.ccxt_data",
        "description": "pages.TraderBot.lumibot.data_sources.ccxt_data",
        "peekOfCode": "class CcxtData(DataSource):\n    SOURCE = \"CCXT\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"minute\", \"representations\": [\"1m\"]},\n        {\"timestep\": \"day\", \"representations\": [\"1d\"]},\n    ]\n    IS_BACKTESTING_DATA_SOURCE = False\n    \"\"\"Common base class for data_sources/ccxt and brokers/ccxt\"\"\"\n    @staticmethod",
        "detail": "pages.TraderBot.lumibot.data_sources.ccxt_data",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.data_source",
        "description": "pages.TraderBot.lumibot.data_sources.data_source",
        "peekOfCode": "class DataSource(ABC):\n    SOURCE = \"\"\n    IS_BACKTESTING_DATA_SOURCE = False\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = []\n    DEFAULT_TIMEZONE = LUMIBOT_DEFAULT_TIMEZONE\n    DEFAULT_PYTZ = LUMIBOT_DEFAULT_PYTZ\n    def __init__(self, api_key=None, delay=None):\n        \"\"\"\n        Parameters",
        "detail": "pages.TraderBot.lumibot.data_sources.data_source",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.data_source_backtesting",
        "description": "pages.TraderBot.lumibot.data_sources.data_source_backtesting",
        "peekOfCode": "class DataSourceBacktesting(DataSource, ABC):\n    \"\"\"\n    This class is the base class for all backtesting data sources.  It is also an abstract class and should not be\n    instantiated directly because it does not define all necessary methods. Instead, instantiate one of the\n    child classes like PandasData.\n    \"\"\"\n    IS_BACKTESTING_DATA_SOURCE = True\n    def __init__(\n        self,\n        datetime_start,",
        "detail": "pages.TraderBot.lumibot.data_sources.data_source_backtesting",
        "documentation": {}
    },
    {
        "label": "ExampleBrokerData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.example_broker_data",
        "description": "pages.TraderBot.lumibot.data_sources.example_broker_data",
        "peekOfCode": "class ExampleBrokerData(DataSource):\n    \"\"\"\n    Data source that connects to the Example Broker API.\n    \"\"\"\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"ExampleBroker\"\n    def __init__(self):\n        super().__init__()\n    # Method stubs with logging for not yet implemented methods\n    def get_chains(self, asset: Asset, quote: Asset = None) -> dict:",
        "detail": "pages.TraderBot.lumibot.data_sources.example_broker_data",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.exceptions",
        "description": "pages.TraderBot.lumibot.data_sources.exceptions",
        "peekOfCode": "class NoDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoDataFound, self).__init__(message)\nclass UnavailabeTimestep(Exception):\n    def __init__(self, source, timestep):\n        message = \"%s data source does not have data with %r timestep\" % (",
        "detail": "pages.TraderBot.lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "UnavailabeTimestep",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.exceptions",
        "description": "pages.TraderBot.lumibot.data_sources.exceptions",
        "peekOfCode": "class UnavailabeTimestep(Exception):\n    def __init__(self, source, timestep):\n        message = \"%s data source does not have data with %r timestep\" % (\n            source,\n            timestep,\n        )\n        super(UnavailabeTimestep, self).__init__(message)",
        "detail": "pages.TraderBot.lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.interactive_brokers_data",
        "description": "pages.TraderBot.lumibot.data_sources.interactive_brokers_data",
        "peekOfCode": "class InteractiveBrokersData(DataSource):\n    \"\"\"Make Interactive Brokers connection and gets data.\n    Create connection to Interactive Brokers market through either Gateway or TWS\n    which must be running locally for connection to be made.\n    \"\"\"\n    SOURCE = \"InteractiveBrokers\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"second\",",
        "detail": "pages.TraderBot.lumibot.data_sources.interactive_brokers_data",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.data_sources.interactive_brokers_data",
        "description": "pages.TraderBot.lumibot.data_sources.interactive_brokers_data",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nclass InteractiveBrokersData(DataSource):\n    \"\"\"Make Interactive Brokers connection and gets data.",
        "detail": "pages.TraderBot.lumibot.data_sources.interactive_brokers_data",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersRESTData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.interactive_brokers_rest_data",
        "description": "pages.TraderBot.lumibot.data_sources.interactive_brokers_rest_data",
        "peekOfCode": "class InteractiveBrokersRESTData(DataSource):\n    \"\"\"\n    Data source that connects to the Interactive Brokers REST API.\n    \"\"\"\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"InteractiveBrokersREST\"\n    def __init__(self, config):\n        if config[\"API_URL\"] is None:\n            self.port = \"4234\"\n            self.base_url = f\"https://localhost:{self.port}/v1/api\"",
        "detail": "pages.TraderBot.lumibot.data_sources.interactive_brokers_rest_data",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.data_sources.interactive_brokers_rest_data",
        "description": "pages.TraderBot.lumibot.data_sources.interactive_brokers_rest_data",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nclass InteractiveBrokersRESTData(DataSource):\n    \"\"\"",
        "detail": "pages.TraderBot.lumibot.data_sources.interactive_brokers_rest_data",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.pandas_data",
        "description": "pages.TraderBot.lumibot.data_sources.pandas_data",
        "peekOfCode": "class PandasData(DataSourceBacktesting):\n    \"\"\"\n    PandasData is a Backtesting-only DataSource that uses a Pandas DataFrame (read from CSV) as the source of\n    data for a backtest run. It is not possible to use this class to run a live trading strategy.\n    \"\"\"\n    SOURCE = \"PANDAS\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1D\", \"day\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1M\", \"minute\"]},\n    ]",
        "detail": "pages.TraderBot.lumibot.data_sources.pandas_data",
        "documentation": {}
    },
    {
        "label": "TradierAPIError",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.tradier_data",
        "description": "pages.TraderBot.lumibot.data_sources.tradier_data",
        "peekOfCode": "class TradierAPIError(Exception):\n    pass\nclass TradierData(DataSource):\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"Tradier\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"tick\",\n            \"representations\": [\n                \"tick\",",
        "detail": "pages.TraderBot.lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "TradierData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.tradier_data",
        "description": "pages.TraderBot.lumibot.data_sources.tradier_data",
        "peekOfCode": "class TradierData(DataSource):\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"Tradier\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"tick\",\n            \"representations\": [\n                \"tick\",\n            ],\n        },",
        "detail": "pages.TraderBot.lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "YahooData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.data_sources.yahoo_data",
        "description": "pages.TraderBot.lumibot.data_sources.yahoo_data",
        "peekOfCode": "class YahooData(DataSourceBacktesting):\n    SOURCE = \"YAHOO\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1d\", \"day\"]},\n        {\"timestep\": \"15 minutes\", \"representations\": [\"15m\", \"15 minutes\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1m\", \"1 minute\"]},\n    ]\n    def __init__(self, *args, auto_adjust=True, **kwargs):\n        super().__init__(*args, **kwargs)",
        "detail": "pages.TraderBot.lumibot.data_sources.yahoo_data",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.data_sources.yahoo_data",
        "description": "pages.TraderBot.lumibot.data_sources.yahoo_data",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass YahooData(DataSourceBacktesting):\n    SOURCE = \"YAHOO\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1d\", \"day\"]},\n        {\"timestep\": \"15 minutes\", \"representations\": [\"15m\", \"15 minutes\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1m\", \"1 minute\"]},\n    ]\n    def __init__(self, *args, auto_adjust=True, **kwargs):",
        "detail": "pages.TraderBot.lumibot.data_sources.yahoo_data",
        "documentation": {}
    },
    {
        "label": "Asset",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.asset",
        "description": "pages.TraderBot.lumibot.entities.asset",
        "peekOfCode": "class Asset:\n    \"\"\"\n    This is a base class for Assets including stocks, futures, options,\n    forex, and crypto.\n    Parameters\n    ----------\n    symbol : str\n        Symbol of the stock or underlying in case of futures/options.\n    asset_type : str\n        Type of the asset. Asset types are only 'stock', 'option', 'future', 'forex', 'crypto'",
        "detail": "pages.TraderBot.lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.asset",
        "description": "pages.TraderBot.lumibot.entities.asset",
        "peekOfCode": "class AssetsMapping(UserDict):\n    def __init__(self, mapping):\n        UserDict.__init__(self, mapping)\n        symbols_mapping = {k.symbol: v for k, v in mapping.items()}\n        self._symbols_mapping = symbols_mapping\n    def __missing__(self, key):\n        if isinstance(key, str):\n            if key in self._symbols_mapping:\n                return self._symbols_mapping[key]\n        raise KeyError(key)",
        "detail": "pages.TraderBot.lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Bar",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.bar",
        "description": "pages.TraderBot.lumibot.entities.bar",
        "peekOfCode": "class Bar(ComparaisonMixin):\n    \"\"\"\n    The Bar class represents a single bar (OHLC) of data.\n    Attributes\n    ----------\n    timestamp : datetime.datetime\n        The timestamp of the bar.\n    open : float\n        The opening price of the bar.\n    high : float",
        "detail": "pages.TraderBot.lumibot.entities.bar",
        "documentation": {}
    },
    {
        "label": "Bars",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.bars",
        "description": "pages.TraderBot.lumibot.entities.bars",
        "peekOfCode": "class Bars:\n    \"\"\"Pricing and financial data for given Symbol.\n    The OHLCV, and if available, dividends, stock splits for a given\n    financial instrument. Price change, dividend yield and return\n    are calculated if appropriate.\n    Parameters\n    ----------\n    df : Pandas Dataframe\n        Dataframe with:\n            datetime.datetime index time zone aware.",
        "detail": "pages.TraderBot.lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "NoBarDataFound",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.bars",
        "description": "pages.TraderBot.lumibot.entities.bars",
        "peekOfCode": "class NoBarDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoBarDataFound, self).__init__(message)\n    def aggregate_bars(self, frequency):\n        \"\"\"\n        Will convert a set of bars to a different timeframe (eg. 1 min to 15 min)",
        "detail": "pages.TraderBot.lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "NoBarDataFound",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.bars",
        "description": "pages.TraderBot.lumibot.entities.bars",
        "peekOfCode": "class NoBarDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoBarDataFound, self).__init__(message)",
        "detail": "pages.TraderBot.lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "Data",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.data",
        "description": "pages.TraderBot.lumibot.entities.data",
        "peekOfCode": "class Data:\n    \"\"\"Input and manage Pandas dataframes for backtesting.\n    Parameters\n    ----------\n    asset : Asset Object\n        Asset to which this data is attached.\n    df : dataframe\n        Pandas dataframe containing OHLCV etc. trade data. Loaded by user\n        from csv.\n        Index is date and must be pandas datetime64.",
        "detail": "pages.TraderBot.lumibot.entities.data",
        "documentation": {}
    },
    {
        "label": "Dataline",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.dataline",
        "description": "pages.TraderBot.lumibot.entities.dataline",
        "peekOfCode": "class Dataline:\n    def __init__(self, asset, name, dataline, dtype):\n        self.asset = asset\n        self.name = name\n        self.dataline = dataline\n        self.dtype = dtype",
        "detail": "pages.TraderBot.lumibot.entities.dataline",
        "documentation": {}
    },
    {
        "label": "Order",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.order",
        "description": "pages.TraderBot.lumibot.entities.order",
        "peekOfCode": "class Order:\n    Transaction = namedtuple(\"Transaction\", [\"quantity\", \"price\"])\n    class OrderClass:\n        BRACKET = \"bracket\"\n        OCO = \"oco\"\n        OTO = \"oto\"\n        MULTILEG = \"multileg\"\n    class OrderType:\n        MARKET = \"market\"\n        LIMIT = \"limit\"",
        "detail": "pages.TraderBot.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "SELL",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.entities.order",
        "description": "pages.TraderBot.lumibot.entities.order",
        "peekOfCode": "SELL = \"sell\"\nBUY = \"buy\"\nVALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status",
        "detail": "pages.TraderBot.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "BUY",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.entities.order",
        "description": "pages.TraderBot.lumibot.entities.order",
        "peekOfCode": "BUY = \"buy\"\nVALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status",
        "detail": "pages.TraderBot.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "VALID_STATUS",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.entities.order",
        "description": "pages.TraderBot.lumibot.entities.order",
        "peekOfCode": "VALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status\n    \"presubmitted\": \"new\",  # IBKR status",
        "detail": "pages.TraderBot.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "STATUS_ALIAS_MAP",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.entities.order",
        "description": "pages.TraderBot.lumibot.entities.order",
        "peekOfCode": "STATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status\n    \"presubmitted\": \"new\",  # IBKR status\n    \"rejected\": \"error\",  # Tradier status",
        "detail": "pages.TraderBot.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "Position",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.position",
        "description": "pages.TraderBot.lumibot.entities.position",
        "peekOfCode": "class Position:\n    \"\"\"\n    This is a Position object. It is used to keep track of the quantity of an asset owned in a strategy.\n    Position objects are retreived from the broker using the get_positions() or get_position() methods.\n    Attributes\n    ----------\n    strategy : str\n        The strategy that owns this position.\n    asset : Asset\n        The asset that this position is for.",
        "detail": "pages.TraderBot.lumibot.entities.position",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.entities.trading_fee",
        "description": "pages.TraderBot.lumibot.entities.trading_fee",
        "peekOfCode": "class TradingFee:\n    \"\"\"TradingFee class. Used to define the trading fees for a broker in a strategy/backtesting.\"\"\"\n    def __init__(self, flat_fee=0.0, percent_fee=0.0, maker=True, taker=True):\n        \"\"\"\n        Parameters\n        ----------\n        flat_fee : Decimal, float, or None\n            Flat fee to pay for each order. This is a fixed fee that is paid for each order in the quote currency.\n        percent_fee : Decimal, float, or None\n            Percentage fee to pay for each order. This is a percentage of the order value that is paid for each order in the quote currency.",
        "detail": "pages.TraderBot.lumibot.entities.trading_fee",
        "documentation": {}
    },
    {
        "label": "Developing_Momentum_Trading_Strategy",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "class Developing_Momentum_Trading_Strategy:\n    # https://github.com/mjmacarty/alphavantage/blob/main/3-momentum_algorithmic.ipynb\n    # Many services for this, some paid some free\n    # Yahoo Finance API\n    # Typically trading \"systems\" involve a number of securities\n    # For this demonstration we are just going to look at GLD --> the gold ETF\n    import numpy as np\n    import pandas as pd\n    import pandas_datareader as pdr\n    import matplotlib.pyplot as plt   ",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "FastTrading",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "class FastTrading(Strategy):\n    # =========over loading life cycle methods\n    def initialize(self, momentum_length = 2, max_assets = 4):\n        self.momentum_length =  momentum_length # in minutes\n        self.sleeptime = 1\n         # set symbols tht we want to be monitoring\n        self.symbols = ['TSLA', 'SPY', 'GLD', 'TLT', 'MSFT', 'MCHI', 'SPXL', 'SPXS']\n        # Initialise our variables  \n        self.assets_quantity = {symbol:0 for symbol in self.symbols}\n        self.max_assets = min(max_assets, len(self.symbols))",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass Developing_Momentum_Trading_Strategy:\n    # https://github.com/mjmacarty/alphavantage/blob/main/3-momentum_algorithmic.ipynb\n    # Many services for this, some paid some free\n    # Yahoo Finance API\n    # Typically trading \"systems\" involve a number of securities\n    # For this demonstration we are just going to look at GLD --> the gold ETF\n    import numpy as np\n    import pandas as pd\n    import pandas_datareader as pdr",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "FastTrading",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.fasttrading_2",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.fasttrading_2",
        "peekOfCode": "class FastTrading(Strategy):\n    IS_BACKTESTING = False\n    # ===== Overloading Lifecycle Methods =====\n    def initialize(self, momentum_length=2, max_assets=4):\n        # Set symbols we want to monitor\n        self.symbols = ['TSLA', 'SPY', 'GLD', 'TLT', 'MSFT', 'MCHI', 'SPXL', 'SPXS']\n        self.momentum_length = momentum_length  # in minutes\n        self.sleeptime = 1  # Optional: For slowing down execution\n        self.frequency = \"minute\"  # For minute-level trading\n        self.max_assets = min(max_assets, len(self.symbols))  # Limit max assets to trade",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.fasttrading_2",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "AlpacaConfig = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}  \nlogfile = \"logs/test.log\"\ntrader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "logfile",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "logfile = \"logs/test.log\"\ntrader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" ",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "trader",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "trader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "broker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "strategy_name",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "strategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:\n    ###\n    # 1. Backtest the strtegy\n    ###\nbacktesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:\n    ###\n    # 1. Backtest the strtegy\n    ###\nbacktesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)\ndatestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "backtesting_start",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "backtesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)\ndatestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")\nstats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "datestring",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "datestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")\nstats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,\n    stats_file=stats_file\n) ",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "stats_file",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "description": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "stats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,\n    stats_file=stats_file\n) \n###",
        "detail": "pages.TraderBot.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingExampleStrategy",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.ccxt_backtesting_example",
        "description": "pages.TraderBot.lumibot.example_strategies.ccxt_backtesting_example",
        "peekOfCode": "class CcxtBacktestingExampleStrategy(Strategy):\n    def initialize(self, asset:tuple[Asset,Asset] = None,\n                   cash_at_risk:float=.25,window:int=21):\n        if asset is None:\n            raise ValueError(\"You must provide a valid asset pair\")\n        # for crypto, market is 24/7\n        self.set_market(\"24/7\")\n        self.sleeptime = \"1D\"\n        self.asset = asset\n        self.base, self.quote = asset",
        "detail": "pages.TraderBot.lumibot.example_strategies.ccxt_backtesting_example",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.crypto_important_functions",
        "description": "pages.TraderBot.lumibot.example_strategies.crypto_important_functions",
        "peekOfCode": "class ImportantFunctions(Strategy):\n    def initialize(self):\n        # Set the time between trading iterations\n        self.sleeptime = \"30S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n    def on_trading_iteration(self):\n        ###########################\n        # Placing an Order\n        ###########################",
        "detail": "pages.TraderBot.lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "description": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class DriftRebalancer(Strategy):\n    \"\"\"The DriftRebalancer strategy rebalances a portfolio based on drift from target weights.\n    The strategy calculates the drift of each asset in the portfolio and triggers a rebalance if the drift exceeds\n    the drift_threshold. The strategy will sell assets that have drifted above the threshold and\n    buy assets that have drifted below the threshold.\n    The current version of the DriftRebalancer strategy only supports limit orders and whole share quantities.\n    Submit an issue if you need market orders or fractional shares. It should be pretty easy to add.\n    Example parameters:\n    parameters = {\n        ### Standard lumibot strategy parameters",
        "detail": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftCalculationLogic",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "description": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class DriftCalculationLogic:\n    def __init__(self, target_weights: Dict[str, Decimal]) -> None:\n        self.df = pd.DataFrame({\n            \"symbol\": target_weights.keys(),\n            \"is_quote_asset\": False,\n            \"current_quantity\": Decimal(0),\n            \"current_value\": Decimal(0),\n            \"current_weight\": Decimal(0),\n            \"target_weight\": [Decimal(weight) for weight in target_weights.values()],\n            \"target_value\": Decimal(0),",
        "detail": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LimitOrderRebalanceLogic",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "description": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class LimitOrderRebalanceLogic:\n    def __init__(\n            self,\n            *,\n            strategy: Strategy,\n            df: pd.DataFrame,\n            fill_sleeptime: int = 15,\n            acceptable_slippage: Decimal = Decimal(\"0.005\"),\n            shorting: bool = False\n    ) -> None:",
        "detail": "pages.TraderBot.lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LifecycleLogger",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.lifecycle_logger",
        "description": "pages.TraderBot.lumibot.example_strategies.lifecycle_logger",
        "peekOfCode": "class LifecycleLogger(Strategy):\n    parameters = {\n        \"sleeptime\": \"10s\",\n        \"market\": \"24/7\",\n    }\n    def initialize(self, symbol=\"\"):\n        self.sleeptime = self.parameters[\"sleeptime\"]\n        self.set_market(self.parameters[\"market\"])\n    def before_market_opens(self):\n        dt = self.get_datetime()",
        "detail": "pages.TraderBot.lumibot.example_strategies.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.lifecycle_logger",
        "description": "pages.TraderBot.lumibot.example_strategies.lifecycle_logger",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LifecycleLogger(Strategy):\n    parameters = {\n        \"sleeptime\": \"10s\",\n        \"market\": \"24/7\",\n    }\n    def initialize(self, symbol=\"\"):\n        self.sleeptime = self.parameters[\"sleeptime\"]\n        self.set_market(self.parameters[\"market\"])\n    def before_market_opens(self):",
        "detail": "pages.TraderBot.lumibot.example_strategies.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "OptionsHoldToExpiry",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.options_hold_to_expiry",
        "description": "pages.TraderBot.lumibot.example_strategies.options_hold_to_expiry",
        "peekOfCode": "class OptionsHoldToExpiry(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"expiry\": datetime(2023, 10, 20),\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants\n        # Built in Variables\n        self.sleeptime = \"1D\"",
        "detail": "pages.TraderBot.lumibot.example_strategies.options_hold_to_expiry",
        "documentation": {}
    },
    {
        "label": "MyStrategy",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.simple_start_single_file",
        "description": "pages.TraderBot.lumibot.example_strategies.simple_start_single_file",
        "peekOfCode": "class MyStrategy(Strategy):\n    def initialize(self, symbol=\"\"):\n        # Will make on_trading_iteration() run every 180 minutes\n        self.sleeptime = 180\n        # Custom parameters\n        self.symbol = symbol\n        self.quantity = 1\n        self.side = \"buy\"\n    def on_trading_iteration(self):\n        self.order = self.create_order(self.symbol, self.quantity, self.side)",
        "detail": "pages.TraderBot.lumibot.example_strategies.simple_start_single_file",
        "documentation": {}
    },
    {
        "label": "StockBracket",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_bracket",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_bracket",
        "peekOfCode": "class StockBracket(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_bracket",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_buy_and_hold",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_buy_and_hold",
        "peekOfCode": "class BuyAndHold(Strategy):\n    parameters = {\n        \"buy_symbol\": \"QQQ\",\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the sleep time to one day (the strategy will run once per day)\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        \"\"\"Buys the self.buy_symbol once, then never again\"\"\"",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_buy_and_hold",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_diversified_leverage",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_diversified_leverage",
        "peekOfCode": "class DiversifiedLeverage(Strategy):\n    # =====Overloading lifecycle methods=============\n    parameters = {\n        \"portfolio\": [\n            {\n                \"symbol\": \"TQQQ\",  # 3x Leveraged Nasdaq\n                \"weight\": 0.20,\n            },\n            {\n                \"symbol\": \"UPRO\",  # 3x Leveraged S&P 500",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "LimitAndTrailingStop",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_limit_and_trailing_stops",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_limit_and_trailing_stops",
        "peekOfCode": "class LimitAndTrailingStop(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"limit_buy_price\": 403,\n        \"limit_sell_price\": 407,\n        \"trail_percent\": 0.02,\n        \"trail_price\": 7,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_limit_and_trailing_stops",
        "documentation": {}
    },
    {
        "label": "Momentum",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_momentum",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_momentum",
        "peekOfCode": "class Momentum(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self, symbols=None):\n        # Setting the waiting period (in days)\n        self.period = 2\n        # The counter for the number of days we have been holding the current asset\n        self.counter = 0\n        # There is only one trading operation per day\n        # No need to sleep between iterations\n        self.sleeptime = 0",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_momentum",
        "documentation": {}
    },
    {
        "label": "StockOco",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_oco",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_oco",
        "peekOfCode": "class StockOco(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_oco",
        "documentation": {}
    },
    {
        "label": "StockSentiment",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_sentiment",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_sentiment",
        "peekOfCode": "class StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],\n            base_url=BASE_URL",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.example_strategies.stock_sentiment",
        "description": "pages.TraderBot.lumibot.example_strategies.stock_sentiment",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nclass StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],",
        "detail": "pages.TraderBot.lumibot.example_strategies.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "Strangle",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.strangle",
        "description": "pages.TraderBot.lumibot.example_strategies.strangle",
        "peekOfCode": "class Strangle(Strategy):\n    \"\"\"Strategy Description: Strangle\n    In a long stranglethe more common strategythe investor simultaneously buys an\n    out-of-the-money call and an out-of-the-money put option. The call option's strike\n    price is higher than the underlying asset's current market price, while the put has a\n    strike price that is lower than the asset's market price. This strategy has large profit\n    potential since the call option has theoretically unlimited upside if the underlying\n    asset rises in price, while the put option can profit if the underlying asset falls.\n    The risk on the trade is limited to the premium paid for the two options.\n    Place the strangle two weeks before earnings announcement.",
        "detail": "pages.TraderBot.lumibot.example_strategies.strangle",
        "documentation": {}
    },
    {
        "label": "BrokerTest",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.example_strategies.test_broker_functions",
        "description": "pages.TraderBot.lumibot.example_strategies.test_broker_functions",
        "peekOfCode": "class BrokerTest(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the time between trading iterations\n        # strategy runs every 20 seconds.\n        self.sleeptime = \"20S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n        # Record the last trade time\n        self.last_trade_time = None",
        "detail": "pages.TraderBot.lumibot.example_strategies.test_broker_functions",
        "documentation": {}
    },
    {
        "label": "CustomLoggerAdapter",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.strategies._strategy",
        "description": "pages.TraderBot.lumibot.strategies._strategy",
        "peekOfCode": "class CustomLoggerAdapter(logging.LoggerAdapter):\n    def __init__(self, logger, extra):\n        super().__init__(logger, extra)\n        self.prefix = f'[{self.extra[\"strategy_name\"]}] '\n    def process(self, msg, kwargs):\n        try:\n            return self.prefix + msg, kwargs\n        except Exception as e:\n            return msg, kwargs\nclass Vars:",
        "detail": "pages.TraderBot.lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "Vars",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.strategies._strategy",
        "description": "pages.TraderBot.lumibot.strategies._strategy",
        "peekOfCode": "class Vars:\n    def __init__(self):\n        super().__setattr__('_vars_dict', {})\n    def __getattr__(self, name):\n        try:\n            return self._vars_dict[name]\n        except KeyError:\n            raise AttributeError(f\"'Vars' object has no attribute '{name}'\")\n    def __setattr__(self, name, value):\n        self._vars_dict[name] = value",
        "detail": "pages.TraderBot.lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "_Strategy",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.strategies._strategy",
        "description": "pages.TraderBot.lumibot.strategies._strategy",
        "peekOfCode": "class _Strategy:\n    IS_BACKTESTABLE = True\n    _trader = None\n    def __init__(\n        self,\n        broker=None,\n        minutes_before_closing=1,\n        minutes_before_opening=60,\n        minutes_after_closing=0,\n        sleeptime=\"1M\",",
        "detail": "pages.TraderBot.lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.strategies.strategy",
        "description": "pages.TraderBot.lumibot.strategies.strategy",
        "peekOfCode": "class Strategy(_Strategy):\n    @property\n    def name(self):\n        \"\"\"Returns the name of the strategy.\n        Returns:\n            str: The name of the strategy.\n        Example\n        -------\n        >>> self.log_message(f'Strategy name: {self.name}')\n        \"\"\"",
        "detail": "pages.TraderBot.lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "STATS_TABLE_NAME",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.strategies.strategy",
        "description": "pages.TraderBot.lumibot.strategies.strategy",
        "peekOfCode": "STATS_TABLE_NAME = \"strategy_tracker\"\nclass Strategy(_Strategy):\n    @property\n    def name(self):\n        \"\"\"Returns the name of the strategy.\n        Returns:\n            str: The name of the strategy.\n        Example\n        -------\n        >>> self.log_message(f'Strategy name: {self.name}')",
        "detail": "pages.TraderBot.lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "StrategyExecutor",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.strategies.strategy_executor",
        "description": "pages.TraderBot.lumibot.strategies.strategy_executor",
        "peekOfCode": "class StrategyExecutor(Thread):\n    # Trading events flags\n    NEW_ORDER = \"new\"\n    CANCELED_ORDER = \"canceled\"\n    FILLED_ORDER = \"fill\"\n    PARTIALLY_FILLED_ORDER = \"partial_fill\"\n    def __init__(self, strategy):\n        super(StrategyExecutor, self).__init__()\n        self.daemon = True\n        self.stop_event = Event()",
        "detail": "pages.TraderBot.lumibot.strategies.strategy_executor",
        "documentation": {}
    },
    {
        "label": "GK",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "class GK:\n    \"\"\"Garman-Kohlhagen\n\tUsed for pricing European options on currencies\n\tGK([underlyingPrice, strikePrice, domesticRate, foreignRate, \\\n\t\t\tdaysToExpiration], volatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "BS",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "class BS:\n    \"\"\"Black-Scholes\n\tUsed for pricing European options on stocks without dividends\n\tBS([underlyingPrice, strikePrice, interestRate, daysToExpiration], \\\n\t\t\tvolatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "Me",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "class Me:\n    \"\"\"Merton\n\tUsed for pricing European options on stocks with dividends\n\tMe([underlyingPrice, strikePrice, interestRate, annualDividends, \\\n\t\t\tdaysToExpiration], volatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.Me([52, 50, 1, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "impliedVolatility",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "def impliedVolatility(className, args, callPrice=None, putPrice=None, high=500.0, low=0.0):\n    \"\"\"Returns the estimated implied volatility\"\"\"\n    if callPrice:\n        target = callPrice\n        restimate = eval(className)(args, volatility=high, performance=True).callPrice\n        if restimate < target:\n            return high\n        if args[0] > args[1] + callPrice:\n            return 0.001\n    if putPrice:",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRhoD\t\t\t\t# Returns the call domestic rho",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], putPrice=0.03)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], putPrice=0.03)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.domesticRate = float(args[2]) / 100\n        self.foreignRate = float(args[3]) / 100",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.domesticRate = float(args[2]) / 100\n        self.foreignRate = float(args[3]) / 100\n        self.daysToExpiration = float(args[4]) / 365\n        for i in [",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRho\t\t\t\t# Returns the call rho",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.daysToExpiration = float(args[3]) / 365",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.daysToExpiration = float(args[3]) / 365\n        for i in [\n            \"callPrice\",",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRho\t\t\t\t# Returns the call rho",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.dividend = float(args[3])",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.black_scholes",
        "description": "pages.TraderBot.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.dividend = float(args[3])\n        self.dividendYield = self.dividend / self.underlyingPrice\n        self.daysToExpiration = float(args[4]) / 365",
        "detail": "pages.TraderBot.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "CcxtCacheDB",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.ccxt_data_store",
        "description": "pages.TraderBot.lumibot.tools.ccxt_data_store",
        "peekOfCode": "class CcxtCacheDB:\n    \"\"\"A ccxt data cache class using duckdb.\n    The data being cached is OHLCV data and is stored in UTC.\n    After importing the data, you'll need to change the timezone if necessary.\n    Create an exchange_id folder in the cache folder, and create a symbol_timeframe.duckdb file under it.\n    ex) Create a BTC_USDT_1m.duckdb file in the binance folder.\n    If there is an existing cache file, it will use it to fetch the data, otherwise it will use ccxt to fetch the data.\n    If a cache file exists, but the requested data range is not in the cache file, the data will be fetched using ccxt.\n    For example, if the cache file contains data from 2023-01-01 to 2023-01-10, and you request data from 2023-01-05 to 2023-01-15,\n    the data from 2023-01-05 to 2023-01-10 will be fetched from the cache file, and the data from 2023-01-11 to 2023-01-15 will be fetched using ccxt.",
        "detail": "pages.TraderBot.lumibot.tools.ccxt_data_store",
        "documentation": {}
    },
    {
        "label": "PerfCounters",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.debugers",
        "description": "pages.TraderBot.lumibot.tools.debugers",
        "peekOfCode": "class PerfCounters:\n    def __init__(self):\n        self.counters = {}\n    def add_counter(self, name):\n        self.counters[name] = [0, 0]\n    def tic_counter(self, name):\n        self.counters[name][1] = perf_counter()\n    def toc_counter(self, name):\n        toc = perf_counter()\n        counter = self.counters[name]",
        "detail": "pages.TraderBot.lumibot.tools.debugers",
        "documentation": {}
    },
    {
        "label": "perf_counters",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.debugers",
        "description": "pages.TraderBot.lumibot.tools.debugers",
        "peekOfCode": "perf_counters = PerfCounters()",
        "detail": "pages.TraderBot.lumibot.tools.debugers",
        "documentation": {}
    },
    {
        "label": "staticdecorator",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.decorators",
        "description": "pages.TraderBot.lumibot.tools.decorators",
        "peekOfCode": "def staticdecorator(func):\n    \"\"\"Makes a function decorated with staticmethod executable\"\"\"\n    return func.__get__(\"\")\ndef call_function_get_frame(func, *args, **kwargs):\n    \"\"\"\n    Calls the function *func* with the specified arguments and keyword\n    arguments and snatches its local frame before it actually executes.\n    \"\"\"\n    frame = None\n    trace = sys.gettrace()",
        "detail": "pages.TraderBot.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "call_function_get_frame",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.decorators",
        "description": "pages.TraderBot.lumibot.tools.decorators",
        "peekOfCode": "def call_function_get_frame(func, *args, **kwargs):\n    \"\"\"\n    Calls the function *func* with the specified arguments and keyword\n    arguments and snatches its local frame before it actually executes.\n    \"\"\"\n    frame = None\n    trace = sys.gettrace()\n    def snatch_locals(_frame, name, arg):\n        nonlocal frame\n        if frame is None and name == \"call\":",
        "detail": "pages.TraderBot.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "snatch_locals",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.decorators",
        "description": "pages.TraderBot.lumibot.tools.decorators",
        "peekOfCode": "def snatch_locals(store):\n    \"\"\"Snatch a function local variables\n    and store them in store variable\"\"\"\n    def wrapper(func_input):\n        @wraps(func_input)\n        def func_output(*args, **kwargs):\n            global store\n            frame, result = call_function_get_frame(func_input, *args, **kwargs)\n            store = frame.f_locals\n            return result",
        "detail": "pages.TraderBot.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "append_locals",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.decorators",
        "description": "pages.TraderBot.lumibot.tools.decorators",
        "peekOfCode": "def append_locals(func_input):\n    \"\"\"Snatch a function local variables\n    and store them in store variable\"\"\"\n    @wraps(func_input)\n    def func_output(*args, **kwargs):\n        frame, result = call_function_get_frame(func_input, *args, **kwargs)\n        if frame is not None:\n            func_output.locals = frame.f_locals\n        else:\n            func_output.locals = None",
        "detail": "pages.TraderBot.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "execute_after",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.decorators",
        "description": "pages.TraderBot.lumibot.tools.decorators",
        "peekOfCode": "def execute_after(actions):\n    def decorator_func(input_func):\n        @wraps(input_func)\n        def output_func(*args, **kwargs):\n            input_func(*args, **kwargs)\n            for action in actions:\n                action()\n        return output_func\n    return decorator_func",
        "detail": "pages.TraderBot.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "ComparaisonMixin",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "class ComparaisonMixin:\n    COMPARAISON_PROP = \"timestamp\"\n    def __eq__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) == getattr(other, self.COMPARAISON_PROP)\n    def __ne__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) != getattr(other, self.COMPARAISON_PROP)\n    def __gt__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) > getattr(other, self.COMPARAISON_PROP)\n    def __ge__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) >= getattr(other, self.COMPARAISON_PROP)",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_chunks",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def get_chunks(l, chunk_size):\n    chunks = []\n    for i in range(0, len(l), chunk_size):\n        chunks.append(l[i: i + chunk_size])\n    return chunks\ndef deduplicate_sequence(seq, key=\"\"):\n    seen = set()\n    pos = 0\n    if key:\n        get_ref = lambda item: getattr(item, key)",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "deduplicate_sequence",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def deduplicate_sequence(seq, key=\"\"):\n    seen = set()\n    pos = 0\n    if key:\n        get_ref = lambda item: getattr(item, key)\n    else:\n        get_ref = lambda item: item\n    for item in seq:\n        ref = get_ref(item)\n        if ref not in seen:",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def get_trading_days(market=\"NYSE\", start_date=\"1950-01-01\", end_date=None):\n    format_datetime = lambda dt: dt.to_pydatetime().astimezone(LUMIBOT_DEFAULT_PYTZ)\n    start_date = to_datetime_aware(pd.to_datetime(start_date))\n    today = get_lumibot_datetime()\n    # macl's \"24/7\" calendar doesn't return consecutive days, so need to be generated manually.\n    if market == \"24/7\":\n        market_open = pd.date_range(\n            start=start_date, end=end_date or today).to_frame(index=False,name=\"market_open\")\n        market_close = pd.date_range(\n            start=start_date.replace(hour=23,minute=59,second=59,microsecond=999999), ",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "print_progress_bar",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def print_progress_bar(\n    value,\n    start_value,\n    end_value,\n    backtesting_started,\n    file=sys.stdout,\n    length=None,\n    prefix=\"Progress\",\n    suffix=\"\",\n    decimals=2,",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_lumibot_datetime",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def get_lumibot_datetime():\n    return dt.datetime.now().astimezone(LUMIBOT_DEFAULT_PYTZ)\ndef to_datetime_aware(dt_in):\n    \"\"\"Convert naive time to datetime aware on default timezone.\"\"\"\n    if not dt_in:\n        return dt_in\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo is None):\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo.utcoffset(dt_in) is None):\n        # TODO: This will fail because an exception is thrown if tzinfo is not None.",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def to_datetime_aware(dt_in):\n    \"\"\"Convert naive time to datetime aware on default timezone.\"\"\"\n    if not dt_in:\n        return dt_in\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo is None):\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo.utcoffset(dt_in) is None):\n        # TODO: This will fail because an exception is thrown if tzinfo is not None.\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    else:",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_symbol",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def parse_symbol(symbol):\n    \"\"\"\n    Parse the given symbol and determine if it's an option or a stock.\n    For options, extract and return the stock symbol, expiration date (as a datetime.date object),\n    type (call or put), and strike price.\n    For stocks, simply return the stock symbol.\n    TODO: Crypto and Forex support\n    \"\"\"\n    # Check that the symbol is a string\n    if not isinstance(symbol, str):",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def create_options_symbol(stock_symbol, expiration_date, option_type, strike_price):\n    \"\"\"\n    Create an option symbol string from its components.\n    Parameters\n    ----------\n    stock_symbol : str\n        The stock symbol, e.g., 'AAPL'.\n    expiration_date : dt.date or dt.datetime\n        The expiration date of the option.\n    option_type : str",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.helpers",
        "description": "pages.TraderBot.lumibot.tools.helpers",
        "peekOfCode": "def parse_timestep_qty_and_unit(timestep):\n    \"\"\"\n    Parse the timestep string and return the quantity and unit.\n    Parameters\n    ----------\n    timestep : str\n        The timestep string to parse.\n    Returns\n    -------\n    tuple",
        "detail": "pages.TraderBot.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "total_return",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def total_return(_df):\n    \"\"\"Calculate the cumulative return in a dataframe\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    df = df.sort_index(ascending=True)\n    df[\"cum_return\"] = (1 + df[\"return\"]).cumprod()\n    total_ret = df[\"cum_return\"].iloc[-1] - 1\n    return total_ret",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "cagr",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def cagr(_df):\n    \"\"\"Calculate the Compound Annual Growth Rate\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    Example:\n    >>> df = pd.DataFrame({\"return\": [0.1, 0.2, 0.3, 0.4, 0.5]})\n    >>> cagr(df)\n    0.3125\n    \"\"\"\n    df = _df.copy()",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "volatility",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def volatility(_df):\n    \"\"\"Calculate the volatility (standard deviation)\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    start = datetime.fromtimestamp(df.index.values[0].astype(\"O\") / 1e9, pytz.UTC)\n    end = datetime.fromtimestamp(df.index.values[-1].astype(\"O\") / 1e9, pytz.UTC)\n    period_years = (end - start).days / 365.25\n    if period_years == 0:",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "sharpe",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def sharpe(_df, risk_free_rate):\n    \"\"\"Calculate the Sharpe Rate, or (CAGR - risk_free_rate) / volatility\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily).\n    risk_free_rate should be either LIBOR, or the shortest possible US Treasury Rate\n    \"\"\"\n    ret = cagr(_df)\n    vol = volatility(_df)\n    if vol == 0:\n        return 0",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "max_drawdown",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def max_drawdown(_df):\n    \"\"\"Calculate the Max Drawdown, or the biggest percentage drop\n    from peak to trough.\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    if _df.shape[0] == 1:\n        return {\"drawdown\": 0, \"date\": _df.index[0]}\n    df = _df.copy()\n    df = df.sort_index(ascending=True)",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "romad",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def romad(_df):\n    \"\"\"Calculate the Return Over Maximum Drawdown (RoMaD)\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    ret = cagr(_df)\n    mdd = max_drawdown(_df)\n    if mdd[\"drawdown\"] == 0:\n        return 0\n    romad = ret / mdd[\"drawdown\"]",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "stats_summary",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def stats_summary(_df, risk_free_rate):\n    return {\n        \"cagr\": cagr(_df),\n        \"volatility\": volatility(_df),\n        \"sharpe\": sharpe(_df, risk_free_rate),\n        \"max_drawdown\": max_drawdown(_df),\n        \"romad\": romad(_df),\n        \"total_return\": total_return(_df),\n    }\ndef performance(_df, risk_free, prefix=\"\"):",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "performance",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def performance(_df, risk_free, prefix=\"\"):\n    \"\"\"Calculate and print out all of our performance indicators\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    cagr_adj = cagr(_df)\n    vol_adj = volatility(_df)\n    sharpe_adj = sharpe(_df, risk_free)\n    maxdown_adj = max_drawdown(_df)\n    romad_adj = romad(_df)",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def get_symbol_returns(symbol, start=datetime(1900, 1, 1), end=datetime.now()):\n    \"\"\"Get the returns for a symbol between two dates\n    Parameters\n    ----------\n    symbol : str\n        The symbol to get the returns for\n    start : datetime, optional\n        The start date, by default datetime(1900, 1, 1)\n    end : datetime, optional\n        The end date, by default datetime.now()",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "calculate_returns",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def calculate_returns(symbol, start=datetime(1900, 1, 1), end=datetime.now()):\n    start = to_datetime_aware(start)\n    end = to_datetime_aware(end)\n    benchmark_df = get_symbol_returns(symbol, start, end)\n    risk_free_rate = get_risk_free_rate()\n    performance(benchmark_df, risk_free_rate, symbol)\ndef plot_indicators(\n    plot_file_html=\"indicators.html\",\n    chart_markers_df=None,\n    chart_lines_df=None,",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "plot_indicators",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def plot_indicators(\n    plot_file_html=\"indicators.html\",\n    chart_markers_df=None,\n    chart_lines_df=None,\n    strategy_name=None,\n    show_indicators=True,\n):\n    # If show plot is False, then we don't want to open the plot in the browser\n    if not show_indicators:\n        logger.debug(\"show_indicators is False, not creating the plot file.\")",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "plot_returns",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def plot_returns(\n    strategy_df,\n    strategy_name,\n    benchmark_df,\n    benchmark_name,\n    plot_file_html=\"backtest_result.html\",\n    trades_df=None,\n    show_plot=True,\n    initial_budget=1,\n    # chart_markers_df=None,",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "create_tearsheet",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def create_tearsheet(\n    # =========BY DOV========\n    strategy_df: pd.DataFrame.to_numpy,\n    strat_name: str,\n    tearsheet_file: str,\n    benchmark_df: pd.DataFrame.to_numpy,\n    benchmark_asset,  # This is causing a circular import: Asset,\n    show_tearsheet: bool,\n    save_tearsheet: bool,\n    risk_free_rate: float,",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "get_risk_free_rate",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "def get_risk_free_rate(dt: datetime = None):\n    try:\n        result = yh.get_risk_free_rate(dt=dt)\n    except Exception as e:\n        logging.error(f\"Error getting the risk free rate: {e}\")\n        result = 0\n    return result",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.indicators",
        "description": "pages.TraderBot.lumibot.tools.indicators",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef total_return(_df):\n    \"\"\"Calculate the cumulative return in a dataframe\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    df = df.sort_index(ascending=True)\n    df[\"cum_return\"] = (1 + df[\"return\"]).cumprod()\n    total_ret = df[\"cum_return\"].iloc[-1] - 1",
        "detail": "pages.TraderBot.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "warning_time_sleep",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.lumibot_time",
        "description": "pages.TraderBot.lumibot.tools.lumibot_time",
        "peekOfCode": "def warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):\n            warned_against_calling_time_sleep = True\n            # TODO: Look into this warning being handled more gracefully. Right now it",
        "detail": "pages.TraderBot.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "default_time_sleep",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.lumibot_time",
        "description": "pages.TraderBot.lumibot.tools.lumibot_time",
        "peekOfCode": "default_time_sleep = time.sleep\nwarned_against_calling_time_sleep = False\ndef warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):",
        "detail": "pages.TraderBot.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "warned_against_calling_time_sleep",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.lumibot_time",
        "description": "pages.TraderBot.lumibot.tools.lumibot_time",
        "peekOfCode": "warned_against_calling_time_sleep = False\ndef warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):\n            warned_against_calling_time_sleep = True",
        "detail": "pages.TraderBot.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "time.sleep",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.lumibot_time",
        "description": "pages.TraderBot.lumibot.tools.lumibot_time",
        "peekOfCode": "time.sleep = warning_time_sleep",
        "detail": "pages.TraderBot.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "day_deduplicate",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.pandas",
        "description": "pages.TraderBot.lumibot.tools.pandas",
        "peekOfCode": "def day_deduplicate(df_):\n    df_copy = df_.copy()\n    df_copy = df_copy.groupby(level=0).head(1)\n    return df_copy\ndef is_daily_data(df_):\n    times = pd.Series(df_.index).apply(lambda x: x.time()).unique()\n    if len(times) == 1 and times[0] == time(0, 0):\n        return True\n    return False\ndef fill_void(df_, interval, end):",
        "detail": "pages.TraderBot.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "is_daily_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.pandas",
        "description": "pages.TraderBot.lumibot.tools.pandas",
        "peekOfCode": "def is_daily_data(df_):\n    times = pd.Series(df_.index).apply(lambda x: x.time()).unique()\n    if len(times) == 1 and times[0] == time(0, 0):\n        return True\n    return False\ndef fill_void(df_, interval, end):\n    n_rows = len(df_.index)\n    missing_lines = pd.DataFrame()\n    for index, row in df_.iterrows():\n        position = df_.index.get_loc(index)",
        "detail": "pages.TraderBot.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "fill_void",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.pandas",
        "description": "pages.TraderBot.lumibot.tools.pandas",
        "peekOfCode": "def fill_void(df_, interval, end):\n    n_rows = len(df_.index)\n    missing_lines = pd.DataFrame()\n    for index, row in df_.iterrows():\n        position = df_.index.get_loc(index)\n        if position + 1 == n_rows:\n            if index < end:\n                n_missing = (end - index) // interval\n                missing_days = [index + (i + 1) * interval for i in range(n_missing)]\n                missing_lines = pd.concat(",
        "detail": "pages.TraderBot.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "print_full_pandas_dataframes",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.pandas",
        "description": "pages.TraderBot.lumibot.tools.pandas",
        "peekOfCode": "def print_full_pandas_dataframes():\n    \"\"\"\n    Show the whole dataframe when printing pandas dataframes\n    \"\"\"\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_colwidth', None)\n    pd.set_option('display.max_rows', None)\n    pd.set_option('display.width', 1000)\ndef set_pandas_float_precision(precision: int = 5):\n    format_str = '{:.' + str(precision) + 'f}'",
        "detail": "pages.TraderBot.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "set_pandas_float_precision",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.pandas",
        "description": "pages.TraderBot.lumibot.tools.pandas",
        "peekOfCode": "def set_pandas_float_precision(precision: int = 5):\n    format_str = '{:.' + str(precision) + 'f}'\n    pd.set_option('display.float_format', format_str.format)\ndef prettify_dataframe_with_decimals(df: pd.DataFrame, decimal_places: int = 5) -> str:\n    def decimal_formatter(x):\n        if isinstance(x, Decimal):\n            return f\"{x:.{decimal_places}f}\"\n        return x\n    return df.to_string(formatters={col: decimal_formatter for col in df.columns})",
        "detail": "pages.TraderBot.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "prettify_dataframe_with_decimals",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.pandas",
        "description": "pages.TraderBot.lumibot.tools.pandas",
        "peekOfCode": "def prettify_dataframe_with_decimals(df: pd.DataFrame, decimal_places: int = 5) -> str:\n    def decimal_formatter(x):\n        if isinstance(x, Decimal):\n            return f\"{x:.{decimal_places}f}\"\n        return x\n    return df.to_string(formatters={col: decimal_formatter for col in df.columns})",
        "detail": "pages.TraderBot.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "PolygonClient",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "class PolygonClient(RESTClient):\n    ''' Rate Limited RESTClient with factory method '''\n    WAIT_SECONDS_RETRY = 60\n    @classmethod\n    def create(cls, *args, **kwargs) -> RESTClient:\n        \"\"\"\n        Factory method to create a RESTClient or PolygonClient instance.\n        The method uses environment variables to determine default values for the API key \n        and subscription type. If the `api_key` is not provided in `kwargs`, it defaults \n        to the value of the `POLYGON_API_KEY` environment variable.",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_cached_schedule",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache\n    if cache_key in schedule_cache:\n        return schedule_cache[cache_key]",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_price_data_from_polygon",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_price_data_from_polygon(\n    api_key: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    force_cache_update: bool = False,\n):\n    \"\"\"",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "validate_cache",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def validate_cache(force_cache_update: bool, asset: Asset, cache_file: Path, api_key: str):\n    \"\"\"\n    If the list of splits for a stock have changed then we need to invalidate its cache\n    because all of the prices will have changed (because we're using split adjusted prices).\n    Get the splits data from Polygon only once per day per stock.\n    Use the timestamp on the splits feather file to determine if we need to get the splits again.\n    When invalidating we delete the cache file and return force_cache_update=True too.\n    \"\"\"\n    if asset.asset_type not in [Asset.AssetType.STOCK, Asset.AssetType.OPTION]:\n        return force_cache_update",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_trading_dates",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_trading_dates(asset: Asset, start: datetime, end: datetime):\n    \"\"\"\n    Get a list of trading days for the asset between the start and end dates\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    start : datetime\n        Start date for the data requested\n    end : datetime",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_polygon_symbol",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_polygon_symbol(asset, polygon_client, quote_asset=None):\n    \"\"\"\n    Get the symbol for the asset in a format that Polygon will understand\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    polygon_client : RESTClient\n        The RESTClient connection for Polygon Stock-Equity API\n    quote_asset : Asset",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "build_cache_filename",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def build_cache_filename(asset: Asset, timespan: str):\n    \"\"\"Helper function to create the cache filename for a given asset and timespan\"\"\"\n    lumibot_polygon_cache_folder = Path(LUMIBOT_CACHE_FOLDER) / \"polygon\"\n    # If It's an option then also add the expiration date, strike price and right to the filename\n    if asset.asset_type == \"option\":\n        if asset.expiration is None:\n            raise ValueError(f\"Expiration date is required for option {asset} but it is None\")\n        # Make asset.expiration datetime into a string like \"YYMMDD\"\n        expiry_string = asset.expiration.strftime(\"%y%m%d\")\n        uniq_str = f\"{asset.symbol}_{expiry_string}_{asset.strike}_{asset.right}\"",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_missing_dates",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_missing_dates(df_all, asset, start, end):\n    \"\"\"\n    Check if we have data for the full range\n    Later Query to Polygon will pad an extra full day to start/end dates so that there should never\n    be any gap with intraday data missing.\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        Data loaded from the cache file\n    asset : Asset",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def load_cache(cache_file):\n    \"\"\"Load the data from the cache file and return a DataFrame with a DateTimeIndex\"\"\"\n    df_feather = pd.read_feather(cache_file)\n    # Set the 'datetime' column as the index of the DataFrame\n    df_feather.set_index(\"datetime\", inplace=True)\n    df_feather.index = pd.to_datetime(\n        df_feather.index\n    )  # TODO: Is there some way to speed this up? It takes several times longer than just reading the feather file\n    df_feather = df_feather.sort_index()\n    # Check if the index is already timezone aware",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "update_cache",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def update_cache(cache_file, df_all, missing_dates=None):\n    \"\"\"Update the cache file with the new data.  Missing dates are added as empty (all NaN) \n    rows before it is saved to the cache file.\n    Parameters\n    ----------\n    cache_file : Path\n        The path to the cache file\n    df_all : pd.DataFrame\n        The DataFrame with the data we want to cache\n    missing_dates : list[datetime.date]",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "update_polygon_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "def update_polygon_data(df_all, result):\n    \"\"\"\n    Update the DataFrame with the new data from Polygon\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        A DataFrame with the data we already have\n    result : list\n        A List of dictionaries with the new data from Polygon\n        Format: [{'o': 1.0, 'h': 2.0, 'l': 3.0, 'c': 4.0, 'v': 5.0, 't': 116120000000}]",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "MAX_POLYGON_DAYS",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "MAX_POLYGON_DAYS = 30\n# Define a cache dictionary to store schedules and a global dictionary for buffered schedules\nschedule_cache = {}\nbuffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "schedule_cache",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "schedule_cache = {}\nbuffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "buffered_schedules",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.polygon_helper",
        "description": "pages.TraderBot.lumibot.tools.polygon_helper",
        "peekOfCode": "buffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache\n    if cache_key in schedule_cache:",
        "detail": "pages.TraderBot.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_price_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    dt=None,\n    datastyle: str = \"ohlc\"",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_trading_dates",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_trading_dates(asset: Asset, start: datetime, end: datetime):\n    \"\"\"\n    Get a list of trading days for the asset between the start and end dates\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    start : datetime\n        Start date for the data requested\n    end : datetime",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "build_cache_filename",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def build_cache_filename(asset: Asset, timespan: str, datastyle: str = \"ohlc\"):\n    \"\"\"Helper function to create the cache filename for a given asset and timespan\"\"\"\n    lumibot_cache_folder = Path(LUMIBOT_CACHE_FOLDER) / CACHE_SUBFOLDER\n    # If It's an option then also add the expiration date, strike price and right to the filename\n    if asset.asset_type == \"option\":\n        if asset.expiration is None:\n            raise ValueError(f\"Expiration date is required for option {asset} but it is None\")\n        # Make asset.expiration datetime into a string like \"YYMMDD\"\n        expiry_string = asset.expiration.strftime(\"%y%m%d\")\n        uniq_str = f\"{asset.symbol}_{expiry_string}_{asset.strike}_{asset.right}\"",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_missing_dates",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_missing_dates(df_all, asset, start, end):\n    \"\"\"\n    Check if we have data for the full range\n    Later Query to Polygon will pad an extra full day to start/end dates so that there should never\n    be any gap with intraday data missing.\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        Data loaded from the cache file\n    asset : Asset",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def load_cache(cache_file):\n    \"\"\"Load the data from the cache file and return a DataFrame with a DateTimeIndex\"\"\"\n    df_feather = pd.read_feather(cache_file)\n    # Set the 'datetime' column as the index of the DataFrame\n    df_feather.set_index(\"datetime\", inplace=True)\n    df_feather.index = pd.to_datetime(\n        df_feather.index\n    )  # TODO: Is there some way to speed this up? It takes several times longer than just reading the feather file\n    df_feather = df_feather.sort_index()\n    # Check if the index is already timezone aware",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "update_cache",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def update_cache(cache_file, df_all, df_feather):\n    \"\"\"Update the cache file with the new data\"\"\"\n    # Check if df_all is different from df_feather (if df_feather exists)\n    if df_all is not None and len(df_all) > 0:\n        # Check if the dataframes are the same\n        if df_all.equals(df_feather):\n            return\n        # Create the directory if it doesn't exist\n        cache_file.parent.mkdir(parents=True, exist_ok=True)\n        # Reset the index to convert DatetimeIndex to a regular column",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "update_df",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def update_df(df_all, result):\n    \"\"\"\n    Update the DataFrame with the new data from ThetaData\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        A DataFrame with the data we already have\n    result : pandas DataFrame\n        A List of dictionaries with the new data from Polygon\n        Format:",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "start_theta_data_client",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def start_theta_data_client(username: str, password: str):\n    # First try shutting down any existing connection\n    try:\n        requests.get(f\"{BASE_URL}/v2/system/terminal/shutdown\")\n    except Exception:\n        pass\n    client = ThetaClient(username=username, passwd=password)\n    time.sleep(1)\n    return client\ndef check_connection(username: str, password: str):",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "check_connection",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def check_connection(username: str, password: str):\n    # Do endless while loop and check if connected every 100 milliseconds\n    MAX_RETRIES = 15\n    counter = 0\n    client = None\n    connected = False\n    while True:\n        try:\n            time.sleep(0.5)\n            res = requests.get(f\"{BASE_URL}/v2/system/mdds/status\", timeout=1)",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_request",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_request(url: str, headers: dict, querystring: dict, username: str, password: str):\n    counter = 0\n    while True:\n        try:\n            response = requests.get(url, headers=headers, params=querystring)\n            # If status code is not 200, then we are not connected\n            if response.status_code != 200:\n                check_connection(username=username, password=password)\n            else:\n                json_resp = response.json()",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_historical_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_historical_data(asset: Asset, start_dt: datetime, end_dt: datetime, ivl: int, username: str, password: str, datastyle:str = \"ohlc\"):\n    \"\"\"\n    Get data from ThetaData\n    Parameters\n    ----------\n    asset : Asset\n        The asset we are getting data for\n    start_dt : datetime\n        The start date/time for the data we want\n    end_dt : datetime",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_expirations",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_expirations(username: str, password: str, ticker: str, after_date: date):\n    \"\"\"\n    Get a list of expiration dates for the given ticker\n    Parameters\n    ----------\n    username : str\n        Your ThetaData username\n    password : str\n        Your ThetaData password\n    ticker : str",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_strikes",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_strikes(username: str, password: str, ticker: str, expiration: datetime):\n    \"\"\"\n    Get a list of strike prices for the given ticker and expiration date\n    Parameters\n    ----------\n    username : str\n        Your ThetaData username\n    password : str\n        Your ThetaData password\n    ticker : str",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "WAIT_TIME",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "WAIT_TIME = 60\nMAX_DAYS = 30\nCACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "MAX_DAYS",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "MAX_DAYS = 30\nCACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "CACHE_SUBFOLDER",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "CACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "description": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "peekOfCode": "BASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    dt=None,",
        "detail": "pages.TraderBot.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "check_numeric",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.types",
        "description": "pages.TraderBot.lumibot.tools.types",
        "peekOfCode": "def check_numeric(\n    input, type, error_message, positive=True, strict=False, nullable=False, ratio=False, allow_negative=True\n):\n    if nullable and input is None:\n        return None\n    error = ValueError(error_message)\n    if isinstance(input, str) or (type == Decimal and not isinstance(input, Decimal)):\n        try:\n            input = type(input)\n        except:",
        "detail": "pages.TraderBot.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_positive",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.types",
        "description": "pages.TraderBot.lumibot.tools.types",
        "peekOfCode": "def check_positive(input, type, custom_message=\"\", strict=False):\n    if strict:\n        error_message = \"%r is not a strictly positive value.\" % input\n    else:\n        error_message = \"%r is not a positive value.\" % input\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    result = check_numeric(\n        input,\n        type,",
        "detail": "pages.TraderBot.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_quantity",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.types",
        "description": "pages.TraderBot.lumibot.tools.types",
        "peekOfCode": "def check_quantity(quantity, custom_message=\"\"):\n    error_message = \"%r is not a positive Decimal.\" % quantity\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    quantity = Decimal(quantity)\n    result = check_numeric(\n        quantity,\n        Decimal,\n        error_message,\n        strict=True,",
        "detail": "pages.TraderBot.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_price",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.tools.types",
        "description": "pages.TraderBot.lumibot.tools.types",
        "peekOfCode": "def check_price(price, custom_message=\"\", nullable=True, allow_negative=True):\n    error_message = \"%r is not a valid price.\" % price\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    result = check_numeric(price, float, error_message, strict=True, nullable=nullable, allow_negative=allow_negative)\n    return result",
        "detail": "pages.TraderBot.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "_YahooData",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "description": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "peekOfCode": "class _YahooData:\n    def __init__(self, symbol, type, data):\n        self.symbol = symbol\n        self.type = type.lower()\n        self.data = data\n        self.file_name = f\"{symbol}_{type.lower()}.pickle\"\n    def is_up_to_date(self, last_needed_datetime=None):\n        if last_needed_datetime is None:\n            last_needed_datetime = get_lumibot_datetime()\n        if self.type == '1d':",
        "detail": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "YahooHelper",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "description": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "peekOfCode": "class YahooHelper:\n    # =========Internal initialization parameters and methods============\n    CACHING_ENABLED = False\n    LUMIBOT_YAHOO_CACHE_FOLDER = os.path.join(LUMIBOT_CACHE_FOLDER, \"yahoo\")\n    if not os.path.exists(LUMIBOT_YAHOO_CACHE_FOLDER):\n        try:\n            os.makedirs(LUMIBOT_YAHOO_CACHE_FOLDER)\n            CACHING_ENABLED = True\n        except Exception as e:\n            pass",
        "detail": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "INFO_DATA",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "description": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "peekOfCode": "INFO_DATA = \"info\"\nclass _YahooData:\n    def __init__(self, symbol, type, data):\n        self.symbol = symbol\n        self.type = type.lower()\n        self.data = data\n        self.file_name = f\"{symbol}_{type.lower()}.pickle\"\n    def is_up_to_date(self, last_needed_datetime=None):\n        if last_needed_datetime is None:\n            last_needed_datetime = get_lumibot_datetime()",
        "detail": "pages.TraderBot.lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "DebugLogTrader",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.traders.debug_log_trader",
        "description": "pages.TraderBot.lumibot.traders.debug_log_trader",
        "peekOfCode": "class DebugLogTrader(Trader):\n    \"\"\"I'm just a trader instance with debug turned on by default\"\"\"\n    def __init__(self, logfile=\"\", backtest=False, debug=True, strategies=None, quiet_logs=False):\n        super().__init__(logfile=logfile, backtest=backtest, debug=debug, strategies=strategies, quiet_logs=quiet_logs)",
        "detail": "pages.TraderBot.lumibot.traders.debug_log_trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.traders.trader",
        "description": "pages.TraderBot.lumibot.traders.trader",
        "peekOfCode": "class Trader:\n    def __init__(self, logfile=\"\", backtest=False, debug=False, strategies=None, quiet_logs=False):\n        \"\"\"\n        Parameters\n        ----------\n        logfile: str\n            The path to the logfile. If not specified, the logfile will be saved in the user's log directory.\n        backtest: bool\n            Whether to run the strategies in backtest mode or not. This is used as a safety check to make sure you\n            don't mix backtesting and live strategies.",
        "detail": "pages.TraderBot.lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.traders.trader",
        "description": "pages.TraderBot.lumibot.traders.trader",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# import streamlit as st\nclass Trader:\n    def __init__(self, logfile=\"\", backtest=False, debug=False, strategies=None, quiet_logs=False):\n        \"\"\"\n        Parameters\n        ----------\n        logfile: str\n            The path to the logfile. If not specified, the logfile will be saved in the user's log directory.\n        backtest: bool",
        "detail": "pages.TraderBot.lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "CustomStream",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.trading_builtins.custom_stream",
        "description": "pages.TraderBot.lumibot.trading_builtins.custom_stream",
        "peekOfCode": "class CustomStream:\n    def __init__(self):\n        self._queue = Queue(100)\n        self._actions_mapping = {}\n    def dispatch(self, event, wait_until_complete=False, **payload):\n        self._queue.put((event, payload), block=False)\n        # Primarily used for backtesting. If wait_until_complete is True, the function will block until the queue is\n        # empty. This is useful for ensuring that all events have been processed before moving on to the next step.\n        if wait_until_complete:\n            self._queue.join()",
        "detail": "pages.TraderBot.lumibot.trading_builtins.custom_stream",
        "documentation": {}
    },
    {
        "label": "PollingStream",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.trading_builtins.custom_stream",
        "description": "pages.TraderBot.lumibot.trading_builtins.custom_stream",
        "peekOfCode": "class PollingStream(CustomStream):\n    \"\"\"\n    A stream that polls an API endpoint at a regular interval and dispatches events based on the response. It is\n    required that a polling action is registered with the stream using add_action(). The polling action should make a\n    request to the API and dispatch events based on the response. A user can also dispatch events to the stream manually\n    using dispatch(), including the poll event to force an off-cycle poll action to occur.\n    \"\"\"\n    POLL_EVENT = \"poll\"\n    def __init__(self, polling_interval=5.0):\n        \"\"\"",
        "detail": "pages.TraderBot.lumibot.trading_builtins.custom_stream",
        "documentation": {}
    },
    {
        "label": "SafeList",
        "kind": 6,
        "importPath": "pages.TraderBot.lumibot.trading_builtins.safe_list",
        "description": "pages.TraderBot.lumibot.trading_builtins.safe_list",
        "peekOfCode": "class SafeList:\n    def __init__(self, lock, initial=None):\n        if not isinstance(lock, rlock_type):\n            raise ValueError(\"lock must be a threading.RLock\")\n        if initial is None:\n            initial = []\n        self.__lock = lock\n        self.__items = initial\n    def __repr__(self):\n        return repr(self.__items)",
        "detail": "pages.TraderBot.lumibot.trading_builtins.safe_list",
        "documentation": {}
    },
    {
        "label": "find_and_load_dotenv",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "def find_and_load_dotenv(base_dir) -> bool:\n    for root, dirs, files in os.walk(base_dir):\n        logger.debug(f\"Checking {root} for .env file\")\n        if '.env' in files:\n            dotenv_path = os.path.join(root, '.env')\n            load_dotenv(dotenv_path)\n            # Create a colored message for the log using termcolor\n            colored_message = termcolor.colored(f\".env file loaded from: {dotenv_path}\", \"green\")\n            logger.info(colored_message)\n            return True",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef find_and_load_dotenv(base_dir) -> bool:\n    for root, dirs, files in os.walk(base_dir):\n        logger.debug(f\"Checking {root} for .env file\")\n        if '.env' in files:\n            dotenv_path = os.path.join(root, '.env')\n            load_dotenv(dotenv_path)\n            # Create a colored message for the log using termcolor\n            colored_message = termcolor.colored(f\".env file loaded from: {dotenv_path}\", \"green\")\n            logger.info(colored_message)",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "script_dir",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\nlogger.debug(f\"script_dir: {script_dir}\")\nfound_dotenv = find_and_load_dotenv(script_dir)\nif not found_dotenv:\n    # Get the root directory of the project\n    cwd_dir = os.getcwd()\n    logger.debug(f\"cwd_dir: {cwd_dir}\")\n    found_dotenv = find_and_load_dotenv(cwd_dir)\n# If no .env file was found, print a warning message\nif not found_dotenv:",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "found_dotenv",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "found_dotenv = find_and_load_dotenv(script_dir)\nif not found_dotenv:\n    # Get the root directory of the project\n    cwd_dir = os.getcwd()\n    logger.debug(f\"cwd_dir: {cwd_dir}\")\n    found_dotenv = find_and_load_dotenv(cwd_dir)\n# If no .env file was found, print a warning message\nif not found_dotenv:\n    # Create a colored message for the log using termcolor\n    colored_message = termcolor.colored(\"No .env file found. This is ok if you are using environment variables or secrets (like on Replit, AWS, etc), but if you are not, please create a .env file in the root directory of the project.\", \"yellow\")",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "is_backtesting",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "is_backtesting = os.environ.get(\"IS_BACKTESTING\")\nif not is_backtesting or is_backtesting.lower() == \"false\":\n    IS_BACKTESTING = False\nelif is_backtesting.lower() == \"true\":\n    IS_BACKTESTING = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"IS_BACKTESTING must be set to 'true' or 'false'. Got '{is_backtesting}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    IS_BACKTESTING = False",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "hide_trades",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "hide_trades = os.environ.get(\"HIDE_TRADES\")\nif not hide_trades or hide_trades.lower() == \"false\":\n    HIDE_TRADES = False\nelif hide_trades.lower() == \"true\":\n    HIDE_TRADES = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"HIDE_TRADES must be set to 'true' or 'false'. Got '{hide_trades}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    HIDE_TRADES = False",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "hide_positions",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "hide_positions = os.environ.get(\"HIDE_POSITIONS\")\nif not hide_positions or hide_positions.lower() == \"false\":\n    HIDE_POSITIONS = False\nelif hide_positions.lower() == \"true\":\n    HIDE_POSITIONS = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"HIDE_POSITIONS must be set to 'true' or 'false'. Got '{hide_positions}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    HIDE_POSITIONS = False",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "STRATEGY_NAME",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "STRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")\n# Market to be traded\nMARKET = os.environ.get(\"MARKET\")\n# Live trading configuration (if applicable)\nLIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "MARKET",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "MARKET = os.environ.get(\"MARKET\")\n# Live trading configuration (if applicable)\nLIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "LIVE_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "LIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DISCORD_WEBHOOK_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "DISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_PLOT",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "SHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_INDICATORS",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "SHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_TEARSHEET",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "SHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):\n    DB_CONNECTION_STR = os.environ.get(\"DB_CONNECTION_STR\")",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DB_CONNECTION_STR",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "DB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):\n    DB_CONNECTION_STR = os.environ.get(\"DB_CONNECTION_STR\")\n# Name for the strategy to be used in the database\nSTRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "STRATEGY_NAME",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "STRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")\n# Set a hard limit on the memory polygon uses\nPOLYGON_MAX_MEMORY_BYTES = os.environ.get(\"POLYGON_MAX_MEMORY_BYTES\")\nPOLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_MAX_MEMORY_BYTES",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "POLYGON_MAX_MEMORY_BYTES = os.environ.get(\"POLYGON_MAX_MEMORY_BYTES\")\nPOLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,\n}\n# Polygon API Key",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "POLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,\n}\n# Polygon API Key\nPOLYGON_API_KEY = POLYGON_CONFIG['API_KEY']",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_API_KEY",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "POLYGON_API_KEY = POLYGON_CONFIG['API_KEY']\n# Thetadata Configuration\nTHETADATA_CONFIG = {\n    # Get the ThetaData API key from the .env file or secrets\n    \"THETADATA_USERNAME\": os.environ.get(\"THETADATA_USERNAME\"),\n    \"THETADATA_PASSWORD\": os.environ.get(\"THETADATA_PASSWORD\")\n}\n# Alpaca Configuration\nALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "THETADATA_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "THETADATA_CONFIG = {\n    # Get the ThetaData API key from the .env file or secrets\n    \"THETADATA_USERNAME\": os.environ.get(\"THETADATA_USERNAME\"),\n    \"THETADATA_PASSWORD\": os.environ.get(\"THETADATA_PASSWORD\")\n}\n# Alpaca Configuration\nALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"ALPACA_API_KEY\"),\n    \"API_SECRET\": os.environ.get(\"ALPACA_API_SECRET\"),",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "ALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"ALPACA_API_KEY\"),\n    \"API_SECRET\": os.environ.get(\"ALPACA_API_SECRET\"),\n    \"PAPER\": os.environ.get(\"ALPACA_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"ALPACA_IS_PAPER\")\n    else True,\n}\nALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", ",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", \n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\", \n    \"PAPER\": True\n}\nBASE_URL = \"https://paper-api.alpaca.markets\"\n# Tradier Configuration\nTRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\n# Tradier Configuration\nTRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),\n    \"ACCOUNT_NUMBER\": os.environ.get(\"TRADIER_ACCOUNT_NUMBER\"),\n    \"PAPER\": os.environ.get(\"TRADIER_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"TRADIER_IS_PAPER\")\n    else True,\n}",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "TRADIER_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "TRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),\n    \"ACCOUNT_NUMBER\": os.environ.get(\"TRADIER_ACCOUNT_NUMBER\"),\n    \"PAPER\": os.environ.get(\"TRADIER_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"TRADIER_IS_PAPER\")\n    else True,\n}\nKRAKEN_CONFIG = {\n    # Add KRAKEN_API_KEY and KRAKEN_API_SECRET to your .env file or set them as secrets",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "KRAKEN_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "KRAKEN_CONFIG = {\n    # Add KRAKEN_API_KEY and KRAKEN_API_SECRET to your .env file or set them as secrets\n    \"exchange_id\": \"kraken\",\n    \"apiKey\": os.environ.get(\"KRAKEN_API_KEY\"),\n    \"secret\": os.environ.get(\"KRAKEN_API_SECRET\"),\n    \"margin\": True,\n    \"sandbox\": False,\n}\nCOINBASE_CONFIG = {\n    # Add COINBASE_API_KEY and COINBASE_API_SECRET to your .env file or set them as secrets",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "COINBASE_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "COINBASE_CONFIG = {\n    # Add COINBASE_API_KEY and COINBASE_API_SECRET to your .env file or set them as secrets\n    \"exchange_id\": \"coinbase\",\n    \"apiKey\": os.environ.get(\"COINBASE_API_KEY\"),\n    \"secret\": os.environ.get(\"COINBASE_API_SECRET\"),\n    \"margin\": False,\n    \"sandbox\": False,\n}\nINTERACTIVE_BROKERS_CONFIG = {\n    \"SOCKET_PORT\": int(os.environ.get(\"INTERACTIVE_BROKERS_PORT\")) if os.environ.get(\"INTERACTIVE_BROKERS_PORT\") else None,",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "INTERACTIVE_BROKERS_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "INTERACTIVE_BROKERS_CONFIG = {\n    \"SOCKET_PORT\": int(os.environ.get(\"INTERACTIVE_BROKERS_PORT\")) if os.environ.get(\"INTERACTIVE_BROKERS_PORT\") else None,\n    \"CLIENT_ID\": int(os.environ.get(\"INTERACTIVE_BROKERS_CLIENT_ID\")) if os.environ.get(\"INTERACTIVE_BROKERS_CLIENT_ID\") else None,\n    \"IP\": os.environ.get(\"INTERACTIVE_BROKERS_IP\", \"127.0.0.1\"),\n    \"IB_SUBACCOUNT\": os.environ.get(\"IB_SUBACCOUNT\", None)\n}\nINTERACTIVE_BROKERS_REST_CONFIG = {\n    \"IB_USERNAME\": os.environ.get(\"IB_USERNAME\"),\n    \"IB_PASSWORD\": os.environ.get(\"IB_PASSWORD\"),\n    \"ACCOUNT_ID\": os.environ.get(\"ACCOUNT_ID\"),",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "INTERACTIVE_BROKERS_REST_CONFIG",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "INTERACTIVE_BROKERS_REST_CONFIG = {\n    \"IB_USERNAME\": os.environ.get(\"IB_USERNAME\"),\n    \"IB_PASSWORD\": os.environ.get(\"IB_PASSWORD\"),\n    \"ACCOUNT_ID\": os.environ.get(\"ACCOUNT_ID\"),\n    \"API_URL\": os.environ.get(\"IB_API_URL\"),\n    \"RUNNING_ON_SERVER\": os.environ.get(\"RUNNING_ON_SERVER\")\n}\nLUMIWEALTH_API_KEY = os.environ.get(\"LUMIWEALTH_API_KEY\")\nif IS_BACKTESTING:\n    broker = None",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "LUMIWEALTH_API_KEY",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "LUMIWEALTH_API_KEY = os.environ.get(\"LUMIWEALTH_API_KEY\")\nif IS_BACKTESTING:\n    broker = None\nelse:\n    # If using Alpaca as a broker, set that as the broker\n    if ALPACA_CONFIG[\"API_KEY\"]:\n        broker = Alpaca(ALPACA_CONFIG)\n    # If using Tradier as a broker, set that as the broker\n    elif TRADIER_CONFIG[\"ACCESS_TOKEN\"]:\n        broker = Tradier(TRADIER_CONFIG)",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BROKER",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.credentials",
        "description": "pages.TraderBot.lumibot.credentials",
        "peekOfCode": "BROKER = broker",
        "detail": "pages.TraderBot.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "get_sentiment_score",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "def get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n    result = sentiment_analyzer(text)\n    sentiment = result[0]['label']\n    score = result[0]['score']\n    return sentiment, score\n# Step 2: Data Collection",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "collect_data",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "def collect_data():\n    import pandas as pd\n    # Example dataset\n    data = {\n        'date': ['2023-10-01', '2023-10-02', '2023-10-03'],\n        'text': ['Great earnings report!', 'Market crash expected.', 'Stable growth predicted.']\n    }\n    df = pd.DataFrame(data)\n    # Apply sentiment analysis\n    df['sentiment'], df['score'] = zip(*df['text'].apply(get_sentiment_score))",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "kind": 2,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "def estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)\n        probability = result[torch.argmax(result)]\n        sentiment = labels[torch.argmax(result)]\n        return probability, sentiment",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pages.TraderBot.lumibot.finbert_utils",
        "description": "pages.TraderBot.lumibot.finbert_utils",
        "peekOfCode": "labels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")",
        "detail": "pages.TraderBot.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "kind": 2,
        "importPath": "pages.TraderBot.finbert_utils",
        "description": "pages.TraderBot.finbert_utils",
        "peekOfCode": "def estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)\n        probability = result[torch.argmax(result)]\n        sentiment = labels[torch.argmax(result)]\n        return probability, sentiment",
        "detail": "pages.TraderBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pages.TraderBot.finbert_utils",
        "description": "pages.TraderBot.finbert_utils",
        "peekOfCode": "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\ndef estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]",
        "detail": "pages.TraderBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "pages.TraderBot.finbert_utils",
        "description": "pages.TraderBot.finbert_utils",
        "peekOfCode": "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\ndef estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)",
        "detail": "pages.TraderBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pages.TraderBot.finbert_utils",
        "description": "pages.TraderBot.finbert_utils",
        "peekOfCode": "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\ndef estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)\n        probability = result[torch.argmax(result)]",
        "detail": "pages.TraderBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pages.TraderBot.finbert_utils",
        "description": "pages.TraderBot.finbert_utils",
        "peekOfCode": "labels = [\"positive\", \"negative\", \"neutral\"]\ndef estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)\n        probability = result[torch.argmax(result)]\n        sentiment = labels[torch.argmax(result)]",
        "detail": "pages.TraderBot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "class MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(base_url=BASE_URL, key_id=ALPACA_CREDS[\"API_KEY\"], secret_key=ALPACA_CREDS[\"API_SECRET\"])\n    def position_sizing(self): \n        cash = self.get_cash() \n        last_price = self.get_last_price(self.symbol)",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nclass MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" ",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nclass MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None ",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "start_date = datetime(2020,1,1)\nend_date = datetime(2023,12,31) \nfrom lumibot.backtesting.alpaca_backtesting import AlpacaDataBacktesting\nfrom lumibot.backtesting import BacktestingBroker\n# Create data source\ndata_source = AlpacaDataBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    API_KEY=ALPACA_CREDS[\"API_KEY\"],  # Optional for pure backtesting\n    API_SECRET=ALPACA_CREDS[\"API_SECRET\"]  # Optional for pure backtesting",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "end_date = datetime(2023,12,31) \nfrom lumibot.backtesting.alpaca_backtesting import AlpacaDataBacktesting\nfrom lumibot.backtesting import BacktestingBroker\n# Create data source\ndata_source = AlpacaDataBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    API_KEY=ALPACA_CREDS[\"API_KEY\"],  # Optional for pure backtesting\n    API_SECRET=ALPACA_CREDS[\"API_SECRET\"]  # Optional for pure backtesting\n)",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "data_source",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "data_source = AlpacaDataBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    API_KEY=ALPACA_CREDS[\"API_KEY\"],  # Optional for pure backtesting\n    API_SECRET=ALPACA_CREDS[\"API_SECRET\"]  # Optional for pure backtesting\n)\n# Create broker\nbroker = BacktestingBroker(data_source)\n# Create strategy\nstrategy = MLTrader(",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "broker = BacktestingBroker(data_source)\n# Create strategy\nstrategy = MLTrader(\n    name='mlstrat',\n    broker=broker,\n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":0.5}\n)\n# Run backtest\nstrategy.backtest()",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot",
        "description": "pages.TraderBot.tradingbot",
        "peekOfCode": "strategy = MLTrader(\n    name='mlstrat',\n    broker=broker,\n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":0.5}\n)\n# Run backtest\nstrategy.backtest()",
        "detail": "pages.TraderBot.tradingbot",
        "documentation": {}
    },
    {
        "label": "SimpleAlpacaStrategy",
        "kind": 6,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "class SimpleAlpacaStrategy(Strategy):\n    def initialize(self):\n        self.symbol = \"SPY\"\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        # Get historical data\n        bars = self.get_historical_prices(self.symbol, 20, \"day\")\n        current_price = bars.df[\"close\"][-1]\n        # Simple buy and hold strategy\n        if not self.get_position(self.symbol):",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nBASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, ",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nBASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nfrom lumibot.strategies import Strategy\nfrom datetime import datetime\nfrom lumibot.backtesting.alpaca_backtesting import WorkingAlpacaBacktesting\nclass SimpleAlpacaStrategy(Strategy):",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nfrom lumibot.strategies import Strategy\nfrom datetime import datetime\nfrom lumibot.backtesting.alpaca_backtesting import WorkingAlpacaBacktesting\nclass SimpleAlpacaStrategy(Strategy):\n    def initialize(self):",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "start_date = datetime(2023, 1, 1)\nend_date = datetime(2023, 12, 31)\nfrom lumibot.backtesting.alpaca_backtesting import WorkingAlpacaBacktesting\nfrom lumibot.backtesting import BacktestingBroker\n# Create data source\ndata_source = WorkingAlpacaBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,   # Add these if you need real Alpaca data:\n    API_KEY=ALPACA_API_KEY,\n    API_SECRET=ALPACA_API_SECRET",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "end_date = datetime(2023, 12, 31)\nfrom lumibot.backtesting.alpaca_backtesting import WorkingAlpacaBacktesting\nfrom lumibot.backtesting import BacktestingBroker\n# Create data source\ndata_source = WorkingAlpacaBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,   # Add these if you need real Alpaca data:\n    API_KEY=ALPACA_API_KEY,\n    API_SECRET=ALPACA_API_SECRET\n)",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "data_source",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "data_source = WorkingAlpacaBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,   # Add these if you need real Alpaca data:\n    API_KEY=ALPACA_API_KEY,\n    API_SECRET=ALPACA_API_SECRET\n)\n# Run backtest\nstrategy = SimpleAlpacaStrategy(\n    broker=data_source,\n    budget=100000",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "strategy = SimpleAlpacaStrategy(\n    broker=data_source,\n    budget=100000\n)\nresults = strategy.backtest()\nprint(f\"Backtest results: {results}\")",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "pages.TraderBot.tradingbot1",
        "description": "pages.TraderBot.tradingbot1",
        "peekOfCode": "results = strategy.backtest()\nprint(f\"Backtest results: {results}\")",
        "detail": "pages.TraderBot.tradingbot1",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "class MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(base_url=BASE_URL, key_id=ALPACA_CREDS[\"API_KEY\"], secret_key=ALPACA_CREDS[\"API_SECRET\"])\n    def position_sizing(self): \n        cash = self.get_cash() \n        last_price = self.get_last_price(self.symbol)",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nclass MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" ",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\":ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nclass MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None ",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "start_date = datetime(2020,1,1)\nend_date = datetime(2023,12,31) \nfrom lumibot.backtesting.alpaca_backtesting import AlpacaDataBacktesting\nfrom lumibot.backtesting import BacktestingBroker\n# Create data source\ndata_source = AlpacaDataBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    API_KEY=ALPACA_CREDS[\"API_KEY\"],  # Optional for pure backtesting\n    API_SECRET=ALPACA_CREDS[\"API_SECRET\"]  # Optional for pure backtesting",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "end_date = datetime(2023,12,31) \nfrom lumibot.backtesting.alpaca_backtesting import AlpacaDataBacktesting\nfrom lumibot.backtesting import BacktestingBroker\n# Create data source\ndata_source = AlpacaDataBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    API_KEY=ALPACA_CREDS[\"API_KEY\"],  # Optional for pure backtesting\n    API_SECRET=ALPACA_CREDS[\"API_SECRET\"]  # Optional for pure backtesting\n)",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "data_source",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "data_source = AlpacaDataBacktesting(\n    datetime_start=start_date,\n    datetime_end=end_date,\n    API_KEY=ALPACA_CREDS[\"API_KEY\"],  # Optional for pure backtesting\n    API_SECRET=ALPACA_CREDS[\"API_SECRET\"]  # Optional for pure backtesting\n)\n# Create broker\nbroker = BacktestingBroker(data_source)\n# Create strategy\nstrategy = MLTrader(",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "broker = BacktestingBroker(data_source)\n# Create strategy\nstrategy = MLTrader(\n    name='mlstrat',\n    broker=broker,\n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":0.5}\n)\n# Run backtest\nstrategy.backtest()",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages.tradingbot",
        "description": "pages.tradingbot",
        "peekOfCode": "strategy = MLTrader(\n    name='mlstrat',\n    broker=broker,\n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":0.5}\n)\n# Run backtest\nstrategy.backtest()",
        "detail": "pages.tradingbot",
        "documentation": {}
    },
    {
        "label": "EmbeddingClient",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.bce.embedding_client",
        "description": "pages2.FinRAG.app.core.bce.embedding_client",
        "peekOfCode": "class EmbeddingClient:\n    def __init__(self, model_name_or_path) -> None:\n        self.model = EmbeddingModel(\n            model_name_or_path=model_name_or_path, \n            device=DEVICE,\n            trust_remote_code=True,\n        )\n    def get_embedding(self, sentences):\n        embeddings = self.model.encode(sentences)\n        return embeddings",
        "detail": "pages2.FinRAG.app.core.bce.embedding_client",
        "documentation": {}
    },
    {
        "label": "RerankClient",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.bce.rerank_client",
        "description": "pages2.FinRAG.app.core.bce.rerank_client",
        "peekOfCode": "class RerankClient:\n    def __init__(self,rerank_model) -> None:\n        self.model = RerankerModel(rerank_model,\n                                   trust_remote_code=True,)\n    def rerank(self,query,massages):\n        sentence_pairs = [[query, massage] for massage in massages]\n        #scores = self.model.compute_score(sentence_pairs)\n        rerank_results = self.model.rerank(query, massages)\n        return rerank_results",
        "detail": "pages2.FinRAG.app.core.bce.rerank_client",
        "documentation": {}
    },
    {
        "label": "OpenChat",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.chat.open_chat",
        "description": "pages2.FinRAG.app.core.chat.open_chat",
        "peekOfCode": "class OpenChat:\n    def __init__(self) -> None:\n        self.client = OpenAI(\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"), # API Key\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # DashScope SDKbase_url\n    )\n    def chat(self,messages):\n        logger.info(str(messages))\n        completion = self.client.chat.completions.create(\n        model=\"qwen-plus\",",
        "detail": "pages2.FinRAG.app.core.chat.open_chat",
        "documentation": {}
    },
    {
        "label": "RAGChat",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.chat.rag_chat",
        "description": "pages2.FinRAG.app.core.chat.rag_chat",
        "peekOfCode": "class RAGChat:\n    def __init__(self) -> None:\n        self.client = OpenAI(\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"), # API Key\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # DashScope SDKbase_url\n    )\n    def chat(self,messages):\n        query = messages[-1].get(\"content\")\n        query_emb = ''\n        completion = self.client.chat.completions.create(",
        "detail": "pages2.FinRAG.app.core.chat.rag_chat",
        "documentation": {}
    },
    {
        "label": "UnstructuredPaddlePDFLoader",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.loader.pdf_loader",
        "description": "pages2.FinRAG.app.core.loader.pdf_loader",
        "peekOfCode": "class UnstructuredPaddlePDFLoader(UnstructuredFileLoader):\n    \"\"\"Loader that uses unstructured to load image files, such as PNGs and JPGs.\"\"\"\n    def __init__(\n        self,\n        file_path: Union[str, List[str]],\n        # ocr_engine: Callable,\n        mode: str = \"single\",\n        **unstructured_kwargs: Any,\n    ):\n        \"\"\"Initialize with file path.\"\"\"",
        "detail": "pages2.FinRAG.app.core.loader.pdf_loader",
        "documentation": {}
    },
    {
        "label": "ocr_engine",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.loader.pdf_loader",
        "description": "pages2.FinRAG.app.core.loader.pdf_loader",
        "peekOfCode": "ocr_engine = PaddleOCR(use_angle_cls=True, lang=\"ch\", use_gpu=True, show_log=False)\nclass UnstructuredPaddlePDFLoader(UnstructuredFileLoader):\n    \"\"\"Loader that uses unstructured to load image files, such as PNGs and JPGs.\"\"\"\n    def __init__(\n        self,\n        file_path: Union[str, List[str]],\n        # ocr_engine: Callable,\n        mode: str = \"single\",\n        **unstructured_kwargs: Any,\n    ):",
        "detail": "pages2.FinRAG.app.core.loader.pdf_loader",
        "documentation": {}
    },
    {
        "label": "FileProcesser",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.preprocessor.file_processor",
        "description": "pages2.FinRAG.app.core.preprocessor.file_processor",
        "peekOfCode": "class FileProcesser:\n    def __init__(self):\n        logger.info(f\"Success init file processor\")\n    def split_file_to_docs(self,\n                           file_path,\n                           sentence_size=config.SENTENCE_SIZE):\n        logger.info(\",,,...\")\n        file_type = file_path.split('.')[-1].lower()\n        if file_type == \"txt\":\n            loader = TextLoader(file_path, autodetect_encoding=True)",
        "detail": "pages2.FinRAG.app.core.preprocessor.file_processor",
        "documentation": {}
    },
    {
        "label": "text_splitter",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.preprocessor.file_processor",
        "description": "pages2.FinRAG.app.core.preprocessor.file_processor",
        "peekOfCode": "text_splitter = RecursiveCharacterTextSplitter(\n    separators=[\n        \"\\n\",\n        \".\",\n        \"\",\n        \"!\",\n        \"\",\n        \"?\",\n        \"\",\n        \"\",",
        "detail": "pages2.FinRAG.app.core.preprocessor.file_processor",
        "documentation": {}
    },
    {
        "label": "ChineseTextSplitter",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.splitter.chinese_text_splitter",
        "description": "pages2.FinRAG.app.core.splitter.chinese_text_splitter",
        "peekOfCode": "class ChineseTextSplitter(CharacterTextSplitter):\n    def __init__(self, pdf: bool = False, sentence_size: int = 200, **kwargs):\n        super().__init__(**kwargs)\n        self.pdf = pdf\n        self.sentence_size = sentence_size\n    def split_text1(self, text: str) -> List[str]:\n        if self.pdf:\n            text = re.sub(r\"\\n{3,}\", \"\\n\", text)\n            text = re.sub('\\s', ' ', text)\n            text = text.replace(\"\\n\\n\", \"\")",
        "detail": "pages2.FinRAG.app.core.splitter.chinese_text_splitter",
        "documentation": {}
    },
    {
        "label": "under_non_alpha_ratio",
        "kind": 2,
        "importPath": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "description": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "peekOfCode": "def under_non_alpha_ratio(text: str, threshold: float = 0.5):\n    \"\"\"Checks if the proportion of non-alpha characters in the text snippet exceeds a given\n    threshold. This helps prevent text like \"-----------BREAK---------\" from being tagged\n    as a title or narrative text. The ratio does not count spaces.\n    Parameters\n    ----------\n    text\n        The input string to test\n    threshold\n        If the proportion of non-alpha characters exceeds this threshold, the function",
        "detail": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "documentation": {}
    },
    {
        "label": "is_possible_title",
        "kind": 2,
        "importPath": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "description": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "peekOfCode": "def is_possible_title(\n        text: str,\n        title_max_word_length: int = 20,\n        non_alpha_threshold: float = 0.5,\n) -> bool:\n    \"\"\"Checks to see if the text passes all of the checks for a valid title.\n    Parameters\n    ----------\n    text\n        The input text to check",
        "detail": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "documentation": {}
    },
    {
        "label": "zh_title_enhance",
        "kind": 2,
        "importPath": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "description": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "peekOfCode": "def zh_title_enhance(docs: List[Document]) -> List[Document]:\n    title = None\n    if len(docs) > 0:\n        for doc in docs:\n            if is_possible_title(doc.page_content):\n                doc.metadata['category'] = 'cn_Title'\n                title = doc.page_content\n            elif title:\n                doc.page_content = f\"({title}){doc.page_content}\"\n        return docs",
        "detail": "pages2.FinRAG.app.core.splitter.zh_title_enhance",
        "documentation": {}
    },
    {
        "label": "CustomerMilvusClient",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "class CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(\n        #     uri=config.milvus_uri\n        # )\n        connections.connect(uri=MILVUS_URI)\n        self.collection_name = COLLECTION_NAME\n        self.collection = self.init()\n        self.collection.load()\n    def init(self):",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "embedding_client",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "embedding_client = EmbeddingClient(EMBEDDING_MODEL)\nrerank_client = RerankClient(RERANK_MODEL)\noss_downloader = Downloader()\nfile_processer = FileProcesser()\nopen_chat = OpenChat()\n_dim = 768\nfrom utils import logger\nclass CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "rerank_client",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "rerank_client = RerankClient(RERANK_MODEL)\noss_downloader = Downloader()\nfile_processer = FileProcesser()\nopen_chat = OpenChat()\n_dim = 768\nfrom utils import logger\nclass CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(\n        #     uri=config.milvus_uri",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "oss_downloader",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "oss_downloader = Downloader()\nfile_processer = FileProcesser()\nopen_chat = OpenChat()\n_dim = 768\nfrom utils import logger\nclass CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(\n        #     uri=config.milvus_uri\n        # )",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "file_processer",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "file_processer = FileProcesser()\nopen_chat = OpenChat()\n_dim = 768\nfrom utils import logger\nclass CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(\n        #     uri=config.milvus_uri\n        # )\n        connections.connect(uri=MILVUS_URI)",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "open_chat",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "open_chat = OpenChat()\n_dim = 768\nfrom utils import logger\nclass CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(\n        #     uri=config.milvus_uri\n        # )\n        connections.connect(uri=MILVUS_URI)\n        self.collection_name = COLLECTION_NAME",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "_dim",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "description": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "peekOfCode": "_dim = 768\nfrom utils import logger\nclass CustomerMilvusClient:\n    def __init__(self):\n        # self.client = MilvusClient(\n        #     uri=config.milvus_uri\n        # )\n        connections.connect(uri=MILVUS_URI)\n        self.collection_name = COLLECTION_NAME\n        self.collection = self.init()",
        "detail": "pages2.FinRAG.app.core.vectorstore.customer_milvus_client",
        "documentation": {}
    },
    {
        "label": "DialogRequest",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.models.dialog",
        "description": "pages2.FinRAG.app.models.dialog",
        "peekOfCode": "class DialogRequest:\n    request_id = \"\"\n    query = \"\"\n    session_id = \"\"\n    user_id = \"\"\n    session = []\n    stream = False\nclass DialogResponse:\n    status = Status\n    answer = \"\"",
        "detail": "pages2.FinRAG.app.models.dialog",
        "documentation": {}
    },
    {
        "label": "DialogResponse",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.models.dialog",
        "description": "pages2.FinRAG.app.models.dialog",
        "peekOfCode": "class DialogResponse:\n    status = Status\n    answer = \"\"\n    title = \"\"\n    recommend_topic = \"\"\n    chunks = \"\"",
        "detail": "pages2.FinRAG.app.models.dialog",
        "documentation": {}
    },
    {
        "label": "ErrorMsg",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.models.status",
        "description": "pages2.FinRAG.app.models.status",
        "peekOfCode": "class ErrorMsg:\n    code = \"xxxxxx\"\n    data = None\n    message= \"\"\n    success= False\n    @classmethod\n    def to_dict(cls):\n        return {\n            'code': cls.code,\n            'data': cls.data,",
        "detail": "pages2.FinRAG.app.models.status",
        "documentation": {}
    },
    {
        "label": "SuccessMsg",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.models.status",
        "description": "pages2.FinRAG.app.models.status",
        "peekOfCode": "class SuccessMsg():\n    code = \"000000\"\n    data = None\n    message= \"\"\n    success= True\n    @classmethod\n    def to_dict(cls):\n        return {\n            'code': cls.code,\n            'data': cls.data,",
        "detail": "pages2.FinRAG.app.models.status",
        "documentation": {}
    },
    {
        "label": "Downloader",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.oss.download_file",
        "description": "pages2.FinRAG.app.oss.download_file",
        "peekOfCode": "class Downloader:\n    def __init__(self) -> None:\n        auth = oss2.ProviderAuth(EnvironmentVariableCredentialsProvider())\n        self.bucket = oss2.Bucket(auth, endpoint, bucket_name)\n    def get_file(self, remote, local):\n        if STORAGE_TYPE=='local':\n            return self.get_local_file(remote, local)\n        else:\n            return self.get_oss_file(remote, local)\n    def get_local_file(self,remote,local):",
        "detail": "pages2.FinRAG.app.oss.download_file",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.oss.download_file",
        "description": "pages2.FinRAG.app.oss.download_file",
        "peekOfCode": "endpoint = os.getenv(\"END_POINT\")\nbucket_name = os.getenv(\"BUCKET_NAME\")\nclass Downloader:\n    def __init__(self) -> None:\n        auth = oss2.ProviderAuth(EnvironmentVariableCredentialsProvider())\n        self.bucket = oss2.Bucket(auth, endpoint, bucket_name)\n    def get_file(self, remote, local):\n        if STORAGE_TYPE=='local':\n            return self.get_local_file(remote, local)\n        else:",
        "detail": "pages2.FinRAG.app.oss.download_file",
        "documentation": {}
    },
    {
        "label": "bucket_name",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.oss.download_file",
        "description": "pages2.FinRAG.app.oss.download_file",
        "peekOfCode": "bucket_name = os.getenv(\"BUCKET_NAME\")\nclass Downloader:\n    def __init__(self) -> None:\n        auth = oss2.ProviderAuth(EnvironmentVariableCredentialsProvider())\n        self.bucket = oss2.Bucket(auth, endpoint, bucket_name)\n    def get_file(self, remote, local):\n        if STORAGE_TYPE=='local':\n            return self.get_local_file(remote, local)\n        else:\n            return self.get_oss_file(remote, local)",
        "detail": "pages2.FinRAG.app.oss.download_file",
        "documentation": {}
    },
    {
        "label": "Item",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "class Item(BaseModel):\n    syncId: Any\n    sysCategory: Any\nclass Query(BaseModel):\n    chatId: Any\n    ownerId: Any\n    chatName: Any\n    initInputs: Dict\n    initOpening: Any\n    chatMessages: Any",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "Query",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "class Query(BaseModel):\n    chatId: Any\n    ownerId: Any\n    chatName: Any\n    initInputs: Dict\n    initOpening: Any\n    chatMessages: Any\nclass Notify(BaseModel):\n    syncId: Any\n    status: Any",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "Notify",
        "kind": 6,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "class Notify(BaseModel):\n    syncId: Any\n    status: Any\ndef notify_another(notify_msg: Notify):\n    logger.info(\"Embedding\")\n    data = {\"syncId\": notify_msg.syncId, \"status\": notify_msg.status}\n    response = requests.post(config.NOTIFY_URL, \n                            headers={'content-type':'application/json'},\n                            data=json.dumps(data))\n    # ",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "notify_another",
        "kind": 2,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "def notify_another(notify_msg: Notify):\n    logger.info(\"Embedding\")\n    data = {\"syncId\": notify_msg.syncId, \"status\": notify_msg.status}\n    response = requests.post(config.NOTIFY_URL, \n                            headers={'content-type':'application/json'},\n                            data=json.dumps(data))\n    # \n    print('Status Code:', response.status_code)\n    if response.status_code==200:\n        logger.info(\"!\")",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "cmc",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "cmc = CustomerMilvusClient()\nopen_chat = OpenChat()\nclass Item(BaseModel):\n    syncId: Any\n    sysCategory: Any\nclass Query(BaseModel):\n    chatId: Any\n    ownerId: Any\n    chatName: Any\n    initInputs: Dict",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "open_chat",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "open_chat = OpenChat()\nclass Item(BaseModel):\n    syncId: Any\n    sysCategory: Any\nclass Query(BaseModel):\n    chatId: Any\n    ownerId: Any\n    chatName: Any\n    initInputs: Dict\n    initOpening: Any",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "pages2.FinRAG.app.finrag_server",
        "description": "pages2.FinRAG.app.finrag_server",
        "peekOfCode": "app = FastAPI()\n@app.post(\"/chat\")\nasync def chat(query: Query):\n    logger.info(\"Chat\")\n    # logger.info(\"query:\"+str(query.to_dict()))\n    chatId = query.chatId\n    ownerId = query.ownerId\n    chatName = query.chatName\n    initInputs = query.initInputs\n    initOpening = query.initOpening",
        "detail": "pages2.FinRAG.app.finrag_server",
        "documentation": {}
    },
    {
        "label": "COLLECTION_NAME",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "COLLECTION_NAME = \"FIN_RAG\"  # Name of the vector database\nSENTENCE_SIZE = 500  # Length of the split text\nDEVICE = \"cuda\"  # Whether to use CPU or GPU\nEMBEDDING_MODEL = \"/data/WoLLM/bce-embedding-base_v1\"  # Local path of the embedding model\nRERANK_MODEL = \"/data/WoLLM/bce-reranker-base_v1\"  # Local path of the rerank model\nMILVUS_URI = \"http://localhost:19530\"  # URI for Milvus\nNOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "SENTENCE_SIZE",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "SENTENCE_SIZE = 500  # Length of the split text\nDEVICE = \"cuda\"  # Whether to use CPU or GPU\nEMBEDDING_MODEL = \"/data/WoLLM/bce-embedding-base_v1\"  # Local path of the embedding model\nRERANK_MODEL = \"/data/WoLLM/bce-reranker-base_v1\"  # Local path of the rerank model\nMILVUS_URI = \"http://localhost:19530\"  # URI for Milvus\nNOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "DEVICE = \"cuda\"  # Whether to use CPU or GPU\nEMBEDDING_MODEL = \"/data/WoLLM/bce-embedding-base_v1\"  # Local path of the embedding model\nRERANK_MODEL = \"/data/WoLLM/bce-reranker-base_v1\"  # Local path of the rerank model\nMILVUS_URI = \"http://localhost:19530\"  # URI for Milvus\nNOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "EMBEDDING_MODEL",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "EMBEDDING_MODEL = \"/data/WoLLM/bce-embedding-base_v1\"  # Local path of the embedding model\nRERANK_MODEL = \"/data/WoLLM/bce-reranker-base_v1\"  # Local path of the rerank model\nMILVUS_URI = \"http://localhost:19530\"  # URI for Milvus\nNOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "RERANK_MODEL",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "RERANK_MODEL = \"/data/WoLLM/bce-reranker-base_v1\"  # Local path of the rerank model\nMILVUS_URI = \"http://localhost:19530\"  # URI for Milvus\nNOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title\nDIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "MILVUS_URI",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "MILVUS_URI = \"http://localhost:19530\"  # URI for Milvus\nNOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title\nDIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content\n{context}",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "NOTIFY_URL",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "NOTIFY_URL = \"http://39.96.174.204/api/medical-assistant/knowledge/file/vector/complete\"  # URL to send a message to the backend after vector update completion\nCACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title\nDIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content\n{context}\nPlease limit it to within 20 characters",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "CACHE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "CACHE_DIR = \".cache\"  # Local cache path for downloading OSS files\nSTORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title\nDIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content\n{context}\nPlease limit it to within 20 characters\nYour response:\"\"\"",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "STORAGE_TYPE",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "STORAGE_TYPE = \"local\"  # Use local or OSS [new feature]\nSTORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title\nDIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content\n{context}\nPlease limit it to within 20 characters\nYour response:\"\"\"\n# Core prompt for RAG",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "STORAGE_DIR = \"/data/storage/\"  # Local file [new feature]\nif not os.path.exists(CACHE_DIR):\n    os.mkdir(CACHE_DIR)\n# Prompt for summarizing dialogue content into a title\nDIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content\n{context}\nPlease limit it to within 20 characters\nYour response:\"\"\"\n# Core prompt for RAG\nRAG_PROMPT = \"\"\"Reference information:",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "DIALOGUE_SUMMARY",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "DIALOGUE_SUMMARY = \"\"\"Summarize a title for the following dialogue content\n{context}\nPlease limit it to within 20 characters\nYour response:\"\"\"\n# Core prompt for RAG\nRAG_PROMPT = \"\"\"Reference information:\n{context}\n---\nMy question or instruction:\n{question}",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "RAG_PROMPT",
        "kind": 5,
        "importPath": "pages2.FinRAG.conf.config",
        "description": "pages2.FinRAG.conf.config",
        "peekOfCode": "RAG_PROMPT = \"\"\"Reference information:\n{context}\n---\nMy question or instruction:\n{question}\n---\nPlease answer my question or respond to my instruction based on the reference information above.\n- If my question or instruction is in a specific language, reply in that language.\n- The reference information may or may not be useful, please make your own judgment.\n- If the reference information is relevant to the question, select the most relevant information from the given reference to support your answer.",
        "detail": "pages2.FinRAG.conf.config",
        "documentation": {}
    },
    {
        "label": "embedding_client",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "embedding_client = EmbeddingClient(\"/data/WoLLM/bce-embedding-base_v1\")\n# txt\nf = open(\"test.txt\", \"r\", encoding=\"utf-8\")\ndoc = f.read().splitlines()\nembeddings = embedding_client.get_embedding(doc)\nfields = [\n    FieldSchema(\n        name=\"id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n    ),\n    FieldSchema(name=\"kb_name\", dtype=DataType.VARCHAR, max_length=100),",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "f = open(\"test.txt\", \"r\", encoding=\"utf-8\")\ndoc = f.read().splitlines()\nembeddings = embedding_client.get_embedding(doc)\nfields = [\n    FieldSchema(\n        name=\"id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n    ),\n    FieldSchema(name=\"kb_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"file_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"chunk_id\", dtype=DataType.INT64),",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "doc = f.read().splitlines()\nembeddings = embedding_client.get_embedding(doc)\nfields = [\n    FieldSchema(\n        name=\"id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n    ),\n    FieldSchema(name=\"kb_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"file_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"chunk_id\", dtype=DataType.INT64),\n    FieldSchema(name=\"chunk_content\", dtype=DataType.VARCHAR, max_length=100),",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "embeddings = embedding_client.get_embedding(doc)\nfields = [\n    FieldSchema(\n        name=\"id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n    ),\n    FieldSchema(name=\"kb_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"file_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"chunk_id\", dtype=DataType.INT64),\n    FieldSchema(name=\"chunk_content\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768),  # ",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "fields",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "fields = [\n    FieldSchema(\n        name=\"id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n    ),\n    FieldSchema(name=\"kb_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"file_name\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"chunk_id\", dtype=DataType.INT64),\n    FieldSchema(name=\"chunk_content\", dtype=DataType.VARCHAR, max_length=100),\n    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768),  # \n]",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "schema",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "schema = CollectionSchema(fields=fields)\n#  collection\n# print(\"client is connected:\", client.is_connected())\ncollection = Collection(\"test_collection3\", schema=schema)\n# \nindex_params = {\n    \"metric_type\": \"L2\",\n    \"index_type\": \"IVF_FLAT\",\n    \"params\": {\"nlist\": 128},\n}",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "collection",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "collection = Collection(\"test_collection3\", schema=schema)\n# \nindex_params = {\n    \"metric_type\": \"L2\",\n    \"index_type\": \"IVF_FLAT\",\n    \"params\": {\"nlist\": 128},\n}\n#  filmVector \ncollection.create_index(\"embedding\", index_params)\nentities = [[\"test_kb\"] * len(doc), doc, range(len(doc)), doc, embeddings]",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "index_params",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "index_params = {\n    \"metric_type\": \"L2\",\n    \"index_type\": \"IVF_FLAT\",\n    \"params\": {\"nlist\": 128},\n}\n#  filmVector \ncollection.create_index(\"embedding\", index_params)\nentities = [[\"test_kb\"] * len(doc), doc, range(len(doc)), doc, embeddings]\ncollection.insert(entities)\n#  flush ",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "entities",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test",
        "description": "pages2.FinRAG.test.test",
        "peekOfCode": "entities = [[\"test_kb\"] * len(doc), doc, range(len(doc)), doc, embeddings]\ncollection.insert(entities)\n#  flush \ncollection.flush()\nprint(collection)\ncollection.load()",
        "detail": "pages2.FinRAG.test.test",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "pages2.FinRAG.test.test_async",
        "description": "pages2.FinRAG.test.test_async",
        "peekOfCode": "app = FastAPI()\nasync def print_hello_world():\n    #  I/O\n    # await asyncio.sleep(1)\n    print(\"Hello, World!\")\n@app.get(\"/async-endpoint\")\nasync def root():\n    #  I/O I/O \n    asyncio.create_task(print_hello_world())\n    return {\"message\": \"Task started\"}",
        "detail": "pages2.FinRAG.test.test_async",
        "documentation": {}
    },
    {
        "label": "Logger",
        "kind": 6,
        "importPath": "pages2.FinRAG.utils",
        "description": "pages2.FinRAG.utils",
        "peekOfCode": "class Logger:\n    @classmethod\n    def get_logger(self):\n        folder_ = \"logs/\"\n        prefix_ = \"mylog-\"\n        rotation_ = \"10 MB\"\n        retention_ = \"30 days\"\n        encoding_ = \"utf-8\"\n        backtrace_ = True\n        diagnose_ = True",
        "detail": "pages2.FinRAG.utils",
        "documentation": {}
    },
    {
        "label": "timeit",
        "kind": 2,
        "importPath": "pages2.FinRAG.utils",
        "description": "pages2.FinRAG.utils",
        "peekOfCode": "def timeit(func):\n    def wrapper(*args, **kw):\n        start_time = time.time()\n        result = func(*args, **kw)\n        cost_time = time.time() - start_time\n        print(\"==\" * 25)\n        print(\"Current Function [%s] run time is %s s\" %\n              (func.__name__, cost_time))\n        print(\"==\" * 25)\n        return result",
        "detail": "pages2.FinRAG.utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.FinRAG.utils",
        "description": "pages2.FinRAG.utils",
        "peekOfCode": "logger = Logger.get_logger()\n# ,\ncurrent_time = datetime.now()\ncurrent_date = current_time.strftime(\"%Y-%m-%d\")\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n# \ndef timeit(func):\n    def wrapper(*args, **kw):\n        start_time = time.time()\n        result = func(*args, **kw)",
        "detail": "pages2.FinRAG.utils",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "pages2.FinRAG.utils",
        "description": "pages2.FinRAG.utils",
        "peekOfCode": "current_time = datetime.now()\ncurrent_date = current_time.strftime(\"%Y-%m-%d\")\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n# \ndef timeit(func):\n    def wrapper(*args, **kw):\n        start_time = time.time()\n        result = func(*args, **kw)\n        cost_time = time.time() - start_time\n        print(\"==\" * 25)",
        "detail": "pages2.FinRAG.utils",
        "documentation": {}
    },
    {
        "label": "current_date",
        "kind": 5,
        "importPath": "pages2.FinRAG.utils",
        "description": "pages2.FinRAG.utils",
        "peekOfCode": "current_date = current_time.strftime(\"%Y-%m-%d\")\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n# \ndef timeit(func):\n    def wrapper(*args, **kw):\n        start_time = time.time()\n        result = func(*args, **kw)\n        cost_time = time.time() - start_time\n        print(\"==\" * 25)\n        print(\"Current Function [%s] run time is %s s\" %",
        "detail": "pages2.FinRAG.utils",
        "documentation": {}
    },
    {
        "label": "formatted_time",
        "kind": 5,
        "importPath": "pages2.FinRAG.utils",
        "description": "pages2.FinRAG.utils",
        "peekOfCode": "formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n# \ndef timeit(func):\n    def wrapper(*args, **kw):\n        start_time = time.time()\n        result = func(*args, **kw)\n        cost_time = time.time() - start_time\n        print(\"==\" * 25)\n        print(\"Current Function [%s] run time is %s s\" %\n              (func.__name__, cost_time))",
        "detail": "pages2.FinRAG.utils",
        "documentation": {}
    },
    {
        "label": "group_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.investment_group",
        "description": "pages2.FinRobot.experiments.investment_group",
        "peekOfCode": "group_config = {\n    \"CIO\": {\n        \"title\": \"Chief Investment Officer\",\n        \"responsibilities\": [\n            \"Oversee the entire investment analysis process.\",\n            \"Integrate insights from various groups.\",\n            \"Make the final decision on portfolio composition and adjustments.\",\n        ],\n    },\n    \"groups\": {",
        "detail": "pages2.FinRobot.experiments.investment_group",
        "documentation": {}
    },
    {
        "label": "order_trigger",
        "kind": 2,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "def order_trigger(pattern, sender):\n    # print(pattern)\n    # print(sender.last_message()['content'])\n    return pattern in sender.last_message()[\"content\"]\ndef order_message(pattern, recipient, messages, sender, config):\n    full_order = recipient.chat_messages_for_summary(sender)[-1][\"content\"]\n    pattern = rf\"\\[{pattern}\\](?::)?\\s*(.+?)(?=\\n\\[|$)\"\n    match = re.search(pattern, full_order, re.DOTALL)\n    if match:\n        order = match.group(1).strip()",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "order_message",
        "kind": 2,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "def order_message(pattern, recipient, messages, sender, config):\n    full_order = recipient.chat_messages_for_summary(sender)[-1][\"content\"]\n    pattern = rf\"\\[{pattern}\\](?::)?\\s*(.+?)(?=\\n\\[|$)\"\n    match = re.search(pattern, full_order, re.DOTALL)\n    if match:\n        order = match.group(1).strip()\n    else:\n        order = full_order\n    return f\"\"\"\n    Follow leader's order and complete the following task: {order}.",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "config_list_gpt4",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "config_list_gpt4 = autogen.config_list_from_json(\n    \"OAI_CONFIG_LIST\",\n    filter_dict={\n        \"model\": [\"gpt-4-0125-preview\"],\n    },\n)\nllm_config = {\n    \"config_list\": config_list_gpt4,\n    \"cache_seed\": 42,\n    \"temperature\": 0,",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "llm_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "llm_config = {\n    \"config_list\": config_list_gpt4,\n    \"cache_seed\": 42,\n    \"temperature\": 0,\n}\nquant_group_config = json.load(open(\"quantitative_investment_group_config.json\"))\n# user_proxy = autogen.UserProxyAgent(\n#     name=\"User\",\n#     # human_input_mode=\"ALWAYS\",\n#     human_input_mode=\"NEVER\",",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "quant_group_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "quant_group_config = json.load(open(\"quantitative_investment_group_config.json\"))\n# user_proxy = autogen.UserProxyAgent(\n#     name=\"User\",\n#     # human_input_mode=\"ALWAYS\",\n#     human_input_mode=\"NEVER\",\n#     code_execution_config=False\n# )\ngroup_descs = \"\\n\\n\".join(\n    [\n        \"Name: {} \\nResponsibility: {}\".format(c[\"name\"], c[\"profile\"])",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "group_descs",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "group_descs = \"\\n\\n\".join(\n    [\n        \"Name: {} \\nResponsibility: {}\".format(c[\"name\"], c[\"profile\"])\n        for c in quant_group_config\n    ]\n)\ngroup_leader = autogen.AssistantAgent(\n    name=\"Group_Leader\",\n    system_message=\"\"\"\n    As a group leader, you are responsible for coordinating the team's efforts to achieve the project's objectives. ",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "group_leader",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "group_leader = autogen.AssistantAgent(\n    name=\"Group_Leader\",\n    system_message=\"\"\"\n    As a group leader, you are responsible for coordinating the team's efforts to achieve the project's objectives. \n    You must ensure that the team is working together effectively and efficiently. \n    Summarize the status of the whole project progess every time you respond, and assign task to one of the group members to progress the project. \n    Orders should follow the format: \\\"[<name of staff>] <order>\\\" and appear at the end of your response.\n    After receiving feedback from the team members, check the progress of the task, and make sure the task is well completed before proceding to th next order.\n    If the task is not well completed, your order should be to provide assistance and guidance for the team members to complete it again.\n    Reply TERMINATE only when the whole project is done. Your team members are as follows:\\n\\n",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "executor",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "executor = autogen.UserProxyAgent(\n    name=\"Executor\",\n    human_input_mode=\"NEVER\",\n    # human_input_mode=\"ALWAYS\",\n    is_termination_msg=lambda x: x.get(\"content\", \"\")\n    and \"TERMINATE\" in x.get(\"content\", \"\"),\n    # max_consecutive_auto_reply=3,\n    code_execution_config={\n        \"last_n_messages\": 3,\n        \"work_dir\": \"quant\",",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "quant_group",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "quant_group = {\n    c[\"name\"]: autogen.agentchat.AssistantAgent(\n        name=c[\"name\"],\n        system_message=c[\"profile\"],\n        llm_config=llm_config,\n    )\n    for c in quant_group_config\n}\ndef order_trigger(pattern, sender):\n    # print(pattern)",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "quant_task",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.multi_factor_agents",
        "description": "pages2.FinRobot.experiments.multi_factor_agents",
        "peekOfCode": "quant_task = \"Develop and test the feasibility of a quantitative investment strategy focusing on the Dow Jones 30 stocks, utilizing your multi-factor analysis expertise to identify potential investment opportunities and optimize the portfolio's performance. Ensure the strategy is robust, data-driven, and aligns with our risk management principles.\"\nwith Cache.disk() as cache:\n    executor.initiate_chat(group_leader, message=quant_task, cache=cache)",
        "detail": "pages2.FinRobot.experiments.multi_factor_agents",
        "documentation": {}
    },
    {
        "label": "llm_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "llm_config = {\n    \"config_list\": autogen.config_list_from_json(\n        \"../OAI_CONFIG_LIST\",\n        filter_dict={\n            \"model\": [\"gpt-4-0125-preview\"],\n        },\n    ),\n    \"cache_seed\": 42,\n    \"temperature\": 0,\n}",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "user_proxy",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "user_proxy = autogen.UserProxyAgent(\n    name=\"User\",\n    # human_input_mode=\"ALWAYS\",\n    human_input_mode=\"NEVER\",\n    is_termination_msg=lambda x: x.get(\"content\", \"\")\n    and \"TERMINATE\" in x.get(\"content\", \"\"),\n    code_execution_config={\n        \"last_n_messages\": 3,\n        \"work_dir\": \"quant\",\n        \"use_docker\": False,",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "rag_func",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "rag_func = get_rag_function(\n    retrieve_config={\n        \"task\": \"qa\",\n        \"docs_path\": \"https://www.sec.gov/Archives/edgar/data/1737806/000110465923049927/pdd-20221231x20f.htm\",\n        \"chunk_token_size\": 1000,\n        \"collection_name\": \"pdd2022\",\n        \"get_or_create\": True,\n    },\n)\nwith_leader_config = {",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "with_leader_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "with_leader_config = {\n    \"Market Sentiment Analysts\": True,\n    \"Risk Assessment Analysts\": True,\n    \"Fundamental Analysts\": True,\n}\nrepresentatives = []\nfor group_name, single_group_config in group_config[\"groups\"].items():\n    with_leader = with_leader_config.get(group_name)\n    if with_leader:\n        group_members = single_group_config[\"with_leader\"]",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "representatives",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "representatives = []\nfor group_name, single_group_config in group_config[\"groups\"].items():\n    with_leader = with_leader_config.get(group_name)\n    if with_leader:\n        group_members = single_group_config[\"with_leader\"]\n        group_members[\"agents\"] = group_members.pop(\"employees\")\n        group = MultiAssistantWithLeader(\n            group_members, llm_config=llm_config, user_proxy=user_proxy\n        )\n    else:",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "cio_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "cio_config = group_config[\"CIO\"]\nmain_group_config = {\"leader\": cio_config, \"agents\": representatives}\nmain_group = MultiAssistantWithLeader(\n    main_group_config, llm_config=llm_config, user_proxy=user_proxy\n)\ntask = dedent(\n    \"\"\"\n    Subject: Evaluate Investment Potential and Determine 6-Month Target Price for Pinduoduo (PDD)\n    Task Description:\n    Today is 2023-04-26. As the Chief Investment Officer, your task is to evaluate the potential investment in Pinduoduo (PDD) based on the newly released 2022 annual report and recent market news. You will need to coordinate with the Market Sentiment Analysts, Risk Assessment Analysts, and Fundamental Analysts to gather and analyze the relevant information. Your final deliverable should include a comprehensive evaluation, a 6-month target price for PDD's stock, and a recommendation on whether to invest in Pinduoduo. ",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "main_group_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "main_group_config = {\"leader\": cio_config, \"agents\": representatives}\nmain_group = MultiAssistantWithLeader(\n    main_group_config, llm_config=llm_config, user_proxy=user_proxy\n)\ntask = dedent(\n    \"\"\"\n    Subject: Evaluate Investment Potential and Determine 6-Month Target Price for Pinduoduo (PDD)\n    Task Description:\n    Today is 2023-04-26. As the Chief Investment Officer, your task is to evaluate the potential investment in Pinduoduo (PDD) based on the newly released 2022 annual report and recent market news. You will need to coordinate with the Market Sentiment Analysts, Risk Assessment Analysts, and Fundamental Analysts to gather and analyze the relevant information. Your final deliverable should include a comprehensive evaluation, a 6-month target price for PDD's stock, and a recommendation on whether to invest in Pinduoduo. \n    Notes:",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "main_group",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "main_group = MultiAssistantWithLeader(\n    main_group_config, llm_config=llm_config, user_proxy=user_proxy\n)\ntask = dedent(\n    \"\"\"\n    Subject: Evaluate Investment Potential and Determine 6-Month Target Price for Pinduoduo (PDD)\n    Task Description:\n    Today is 2023-04-26. As the Chief Investment Officer, your task is to evaluate the potential investment in Pinduoduo (PDD) based on the newly released 2022 annual report and recent market news. You will need to coordinate with the Market Sentiment Analysts, Risk Assessment Analysts, and Fundamental Analysts to gather and analyze the relevant information. Your final deliverable should include a comprehensive evaluation, a 6-month target price for PDD's stock, and a recommendation on whether to invest in Pinduoduo. \n    Notes:\n    All members in your group should be informed:",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "task",
        "kind": 5,
        "importPath": "pages2.FinRobot.experiments.portfolio_optimization",
        "description": "pages2.FinRobot.experiments.portfolio_optimization",
        "peekOfCode": "task = dedent(\n    \"\"\"\n    Subject: Evaluate Investment Potential and Determine 6-Month Target Price for Pinduoduo (PDD)\n    Task Description:\n    Today is 2023-04-26. As the Chief Investment Officer, your task is to evaluate the potential investment in Pinduoduo (PDD) based on the newly released 2022 annual report and recent market news. You will need to coordinate with the Market Sentiment Analysts, Risk Assessment Analysts, and Fundamental Analysts to gather and analyze the relevant information. Your final deliverable should include a comprehensive evaluation, a 6-month target price for PDD's stock, and a recommendation on whether to invest in Pinduoduo. \n    Notes:\n    All members in your group should be informed:\n    - Do not use any data after 2023-04-26, which is cheating.\n    Specific Instructions:\n    [Coordinate with Market Sentiment Analysts]:",
        "detail": "pages2.FinRobot.experiments.portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "library",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.agents.agent_library",
        "description": "pages2.FinRobot.finrobot.agents.agent_library",
        "peekOfCode": "library = [\n    {\n        \"name\": \"Software_Developer\",\n        \"profile\": \"As a Software Developer for this position, you must be able to work collaboratively in a group chat environment to complete tasks assigned by a leader or colleague, primarily using Python programming expertise, excluding the need for code interpretation skills.\",\n    },\n    {\n        \"name\": \"Data_Analyst\",\n        \"profile\": \"As a Data Analyst for this position, you must be adept at analyzing data using Python, completing tasks assigned by leaders or colleagues, and collaboratively solving problems in a group chat setting with professionals of various roles. Reply 'TERMINATE' when everything is done.\",\n    },\n    {",
        "detail": "pages2.FinRobot.finrobot.agents.agent_library",
        "documentation": {}
    },
    {
        "label": "library",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.agents.agent_library",
        "description": "pages2.FinRobot.finrobot.agents.agent_library",
        "peekOfCode": "library = {d[\"name\"]: d for d in library}",
        "detail": "pages2.FinRobot.finrobot.agents.agent_library",
        "documentation": {}
    },
    {
        "label": "leader_system_message",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.agents.prompts",
        "description": "pages2.FinRobot.finrobot.agents.prompts",
        "peekOfCode": "leader_system_message = dedent(\n    \"\"\"\n    You are the leader of the following group members:\n    {group_desc}\n    As a group leader, you are responsible for coordinating the team's efforts to achieve the project's objectives. You must ensure that the team is working together effectively and efficiently. \n    - Summarize the status of the whole project progess each time you respond.\n    - End your response with an order to one of your team members to progress the project, if the objective has not been achieved yet.\n    - Orders should be follow the format: \\\"[<name of staff>] <order>\\\".\n    - Orders need to be detailed, including necessary time period information, stock information or instruction from higher level leaders. \n    - Make only one order at a time.",
        "detail": "pages2.FinRobot.finrobot.agents.prompts",
        "documentation": {}
    },
    {
        "label": "role_system_message",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.agents.prompts",
        "description": "pages2.FinRobot.finrobot.agents.prompts",
        "peekOfCode": "role_system_message = dedent(\n    \"\"\"\n    As a {title}, your reponsibilities are as follows:\n    {responsibilities}\n    Reply \"TERMINATE\" in the end when everything is done.\n    \"\"\"\n)\norder_template = dedent(\n    \"\"\"\n    Follow leader's order and complete the following task with your group members:",
        "detail": "pages2.FinRobot.finrobot.agents.prompts",
        "documentation": {}
    },
    {
        "label": "order_template",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.agents.prompts",
        "description": "pages2.FinRobot.finrobot.agents.prompts",
        "peekOfCode": "order_template = dedent(\n    \"\"\"\n    Follow leader's order and complete the following task with your group members:\n    {order}\n    For coding tasks, provide python scripts and executor will run it for you.\n    Save your results or any intermediate data locally and let group leader know how to read them.\n    DO NOT include \"TERMINATE\" in your response until you have received the results from the execution of the Python scripts.\n    If the task cannot be done currently or need assistance from other members, report the reasons or requirements to group leader ended with TERMINATE. \n\"\"\"\n)",
        "detail": "pages2.FinRobot.finrobot.agents.prompts",
        "documentation": {}
    },
    {
        "label": "instruction_trigger",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.agents.utils",
        "description": "pages2.FinRobot.finrobot.agents.utils",
        "peekOfCode": "def instruction_trigger(sender):\n    # Check if the last message contains the path to the instruction text file\n    return \"instruction & resources saved to\" in sender.last_message()[\"content\"]\ndef instruction_message(recipient, messages, sender, config):\n    # Extract the path to the instruction text file from the last message\n    full_order = recipient.chat_messages_for_summary(sender)[-1][\"content\"]\n    txt_path = full_order.replace(\"instruction & resources saved to \", \"\").strip()\n    with open(txt_path, \"r\") as f:\n        instruction = f.read() + \"\\n\\nReply TERMINATE at the end of your response.\"\n    return instruction",
        "detail": "pages2.FinRobot.finrobot.agents.utils",
        "documentation": {}
    },
    {
        "label": "instruction_message",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.agents.utils",
        "description": "pages2.FinRobot.finrobot.agents.utils",
        "peekOfCode": "def instruction_message(recipient, messages, sender, config):\n    # Extract the path to the instruction text file from the last message\n    full_order = recipient.chat_messages_for_summary(sender)[-1][\"content\"]\n    txt_path = full_order.replace(\"instruction & resources saved to \", \"\").strip()\n    with open(txt_path, \"r\") as f:\n        instruction = f.read() + \"\\n\\nReply TERMINATE at the end of your response.\"\n    return instruction\ndef order_trigger(sender, name, pattern):\n    # print(pattern)\n    # print(sender.name)",
        "detail": "pages2.FinRobot.finrobot.agents.utils",
        "documentation": {}
    },
    {
        "label": "order_trigger",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.agents.utils",
        "description": "pages2.FinRobot.finrobot.agents.utils",
        "peekOfCode": "def order_trigger(sender, name, pattern):\n    # print(pattern)\n    # print(sender.name)\n    return sender.name == name and pattern in sender.last_message()[\"content\"]\ndef order_message(pattern, recipient, messages, sender, config):\n    full_order = recipient.chat_messages_for_summary(sender)[-1][\"content\"]\n    pattern = rf\"\\[{pattern}\\](?::)?\\s*(.+?)(?=\\n\\[|$)\"\n    match = re.search(pattern, full_order, re.DOTALL)\n    if match:\n        order = match.group(1).strip()",
        "detail": "pages2.FinRobot.finrobot.agents.utils",
        "documentation": {}
    },
    {
        "label": "order_message",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.agents.utils",
        "description": "pages2.FinRobot.finrobot.agents.utils",
        "peekOfCode": "def order_message(pattern, recipient, messages, sender, config):\n    full_order = recipient.chat_messages_for_summary(sender)[-1][\"content\"]\n    pattern = rf\"\\[{pattern}\\](?::)?\\s*(.+?)(?=\\n\\[|$)\"\n    match = re.search(pattern, full_order, re.DOTALL)\n    if match:\n        order = match.group(1).strip()\n    else:\n        order = full_order\n    return order_template.format(order=order)",
        "detail": "pages2.FinRobot.finrobot.agents.utils",
        "documentation": {}
    },
    {
        "label": "FinRobot",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class FinRobot(AssistantAgent):\n    def __init__(\n        self,\n        agent_config: str | Dict[str, Any],\n        system_message: str | None = None,  # overwrites previous config\n        toolkits: List[Callable | dict | type] = [],  # overwrites previous config\n        proxy: UserProxyAgent | None = None,\n        **kwargs,\n    ):\n        orig_name = \"\"",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "SingleAssistantBase",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class SingleAssistantBase(ABC):\n    def __init__(\n        self,\n        agent_config: str | Dict[str, Any],\n        llm_config: Dict[str, Any] = {},\n    ):\n        self.assistant = FinRobot(\n            agent_config=agent_config,\n            llm_config=llm_config,\n            proxy=None,",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "SingleAssistant",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class SingleAssistant(SingleAssistantBase):\n    def __init__(\n        self,\n        agent_config: str | Dict[str, Any],\n        llm_config: Dict[str, Any] = {},\n        is_termination_msg=lambda x: x.get(\"content\", \"\")\n        and x.get(\"content\", \"\").endswith(\"TERMINATE\"),\n        human_input_mode=\"NEVER\",\n        max_consecutive_auto_reply=10,\n        code_execution_config={",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "SingleAssistantRAG",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class SingleAssistantRAG(SingleAssistant):\n    def __init__(\n        self,\n        agent_config: str | Dict[str, Any],\n        llm_config: Dict[str, Any] = {},\n        is_termination_msg=lambda x: x.get(\"content\", \"\")\n        and x.get(\"content\", \"\").endswith(\"TERMINATE\"),\n        human_input_mode=\"NEVER\",\n        max_consecutive_auto_reply=10,\n        code_execution_config={",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "SingleAssistantShadow",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class SingleAssistantShadow(SingleAssistant):\n    def __init__(\n        self,\n        agent_config: str | Dict[str, Any],\n        llm_config: Dict[str, Any] = {},\n        is_termination_msg=lambda x: x.get(\"content\", \"\")\n        and x.get(\"content\", \"\").endswith(\"TERMINATE\"),\n        human_input_mode=\"NEVER\",\n        max_consecutive_auto_reply=10,\n        code_execution_config={",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "MultiAssistantBase",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class MultiAssistantBase(ABC):\n    def __init__(\n        self,\n        group_config: str | dict,\n        agent_configs: List[\n            Dict[str, Any] | str | ConversableAgent\n        ] = [],  # overwrites previous config\n        llm_config: Dict[str, Any] = {},\n        user_proxy: UserProxyAgent | None = None,\n        is_termination_msg=lambda x: x.get(\"content\", \"\")",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "MultiAssistant",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class MultiAssistant(MultiAssistantBase):\n    \"\"\"\n    Group Chat Workflow with multiple agents.\n    \"\"\"\n    def _get_representative(self):\n        def custom_speaker_selection_func(\n            last_speaker: autogen.Agent, groupchat: autogen.GroupChat\n        ):\n            \"\"\"Define a customized speaker selection function.\n            A recommended way is to define a transition for each speaker in the groupchat.",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "MultiAssistantWithLeader",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.agents.workflow",
        "description": "pages2.FinRobot.finrobot.agents.workflow",
        "peekOfCode": "class MultiAssistantWithLeader(MultiAssistantBase):\n    \"\"\"\n    Leader based Workflow with multiple agents connected to a leader agent through nested chats.\n    Group config has to follow the following structure:\n    {\n        \"leader\": {\n            \"title\": \"Leader Title\",\n            \"responsibilities\": [\"responsibility 1\", \"responsibility 2\"]\n        },\n        \"agents\": [",
        "detail": "pages2.FinRobot.finrobot.agents.workflow",
        "documentation": {}
    },
    {
        "label": "correct_date",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "description": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "peekOfCode": "def correct_date(yr, dt):\n    \"\"\"Some transcripts have incorrect date, correcting it\n    Args:\n        yr (int): actual\n        dt (datetime): given date\n    Returns:\n        datetime: corrected date\n    \"\"\"\n    dt = datetime.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n    if dt.year != yr:",
        "detail": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "documentation": {}
    },
    {
        "label": "extract_speakers",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "description": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "peekOfCode": "def extract_speakers(cont: str) -> List[str]:\n    \"\"\"Extract the list of speakers\n    Args:\n        cont (str): transcript content\n    Returns:\n        List[str]: list of speakers\n    \"\"\"\n    pattern = re.compile(r\"\\n(.*?):\")\n    matches = pattern.findall(cont)\n    return list(set(matches))",
        "detail": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "documentation": {}
    },
    {
        "label": "get_earnings_transcript",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "description": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "peekOfCode": "def get_earnings_transcript(quarter: str, ticker: str, year: int):\n    \"\"\"Get the earnings transcripts\n    Args:\n        quarter (str)\n        ticker (str)\n        year (int)\n    \"\"\"\n    response = requests.get(\n        f\"https://discountingcashflows.com/api/transcript/{ticker}/{quarter}/{year}/\",\n        auth=(\"user\", \"pass\"),",
        "detail": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.earningsData",
        "documentation": {}
    },
    {
        "label": "clean_speakers",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "description": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "peekOfCode": "def clean_speakers(speaker):\n    speaker = re.sub(\"\\n\", \"\", speaker)\n    speaker = re.sub(\":\", \"\", speaker)\n    return speaker\ndef get_earnings_all_quarters_data(quarter: str, ticker: str, year: int):\n    docs = []\n    resp_dict = get_earnings_transcript(quarter, ticker, year)\n    content = resp_dict[\"content\"]\n    pattern = re.compile(r\"\\n(.*?):\")\n    matches = pattern.finditer(content)",
        "detail": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "documentation": {}
    },
    {
        "label": "get_earnings_all_quarters_data",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "description": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "peekOfCode": "def get_earnings_all_quarters_data(quarter: str, ticker: str, year: int):\n    docs = []\n    resp_dict = get_earnings_transcript(quarter, ticker, year)\n    content = resp_dict[\"content\"]\n    pattern = re.compile(r\"\\n(.*?):\")\n    matches = pattern.finditer(content)\n    speakers_list = []\n    ranges = []\n    for match_ in matches:\n        # print(match.span())",
        "detail": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "documentation": {}
    },
    {
        "label": "get_earnings_all_docs",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "description": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "peekOfCode": "def get_earnings_all_docs(ticker: str, year: int):\n    earnings_docs = []\n    earnings_call_quarter_vals = []\n    print(\"Earnings Call Q1\")\n    try:\n        docs, speakers_list_1 = get_earnings_all_quarters_data(\"Q1\", ticker, year)\n        earnings_call_quarter_vals.append(\"Q1\")\n        earnings_docs.extend(docs)\n    except RetryError:\n        print(f\"Don't have the data for Q1\")",
        "detail": "pages2.FinRobot.finrobot.data_source.earnings_calls_src.main_earningsData",
        "documentation": {}
    },
    {
        "label": "HealthCheckFilter",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "peekOfCode": "class HealthCheckFilter(logging.Filter):\n    def filter(self, record: logging.LogRecord) -> bool:\n        return record.getMessage().find(\"/healthcheck\") == -1\nlogging.getLogger(\"uvicorn.access\").addFilter(HealthCheckFilter())\n@app.get(\"/healthcheck\", status_code=status.HTTP_200_OK, include_in_schema=False)\ndef healthcheck(request: Request):\n    return {\"healthcheck\": \"HEALTHCHECK STATUS: EVERYTHING OK!\"}",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "documentation": {}
    },
    {
        "label": "healthcheck",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "peekOfCode": "def healthcheck(request: Request):\n    return {\"healthcheck\": \"HEALTHCHECK STATUS: EVERYTHING OK!\"}",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "peekOfCode": "app = FastAPI(\n    title=\"Unstructured Pipeline API\",\n    description=\"\"\"\"\"\",\n    version=\"1.0.0\",\n    docs_url=\"/sec-filings/docs\",\n    openapi_url=\"/sec-filings/openapi.json\",\n)\nallowed_origins = os.environ.get(\"ALLOWED_ORIGINS\", None)\nif allowed_origins:\n    from fastapi.middleware.cors import CORSMiddleware",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "documentation": {}
    },
    {
        "label": "allowed_origins",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "peekOfCode": "allowed_origins = os.environ.get(\"ALLOWED_ORIGINS\", None)\nif allowed_origins:\n    from fastapi.middleware.cors import CORSMiddleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=allowed_origins.split(\",\"),\n        allow_methods=[\"OPTIONS\", \"POST\"],\n        allow_headers=[\"Content-Type\"],\n    )\napp.include_router(section_router)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.app",
        "documentation": {}
    },
    {
        "label": "timeout",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "class timeout:\n    def __init__(self, seconds=1, error_message=\"Timeout\"):\n        self.seconds = seconds\n        self.error_message = error_message\n    def handle_timeout(self, signum, frame):\n        raise TimeoutError(self.error_message)\n    def __enter__(self):\n        try:\n            signal.signal(signal.SIGALRM, self.handle_timeout)\n            signal.alarm(self.seconds)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "MultipartMixedResponse",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "class MultipartMixedResponse(StreamingResponse):\n    CRLF = b\"\\r\\n\"\n    def __init__(self, *args, content_type: str = None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.content_type = content_type\n    def init_headers(self, headers: Optional[Mapping[str, str]] = None) -> None:\n        super().init_headers(headers)\n        self.boundary_value = secrets.token_hex(16)\n        content_type = f'multipart/mixed; boundary=\"{self.boundary_value}\"'\n        self.raw_headers.append((b\"content-type\", content_type.encode(\"latin-1\")))",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "is_expected_response_type",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def is_expected_response_type(media_type, response_type):\n    if media_type == \"application/json\" and response_type not in [dict, list]:\n        return True\n    elif media_type == \"text/csv\" and response_type != str:\n        return True\n    else:\n        return False\n# pipeline-api\nclass timeout:\n    def __init__(self, seconds=1, error_message=\"Timeout\"):",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "get_regex_enum",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def get_regex_enum(section_regex):\n    class CustomSECSection(Enum):\n        CUSTOM = re.compile(section_regex)\n        @property\n        def pattern(self):\n            return self.value\n    return CustomSECSection.CUSTOM\ndef convert_to_isd_csv(results: dict) -> str:\n    \"\"\"\n    Returns the representation of document elements as an Initial Structured Document (ISD)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "convert_to_isd_csv",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def convert_to_isd_csv(results: dict) -> str:\n    \"\"\"\n    Returns the representation of document elements as an Initial Structured Document (ISD)\n    in CSV Format.\n    \"\"\"\n    csv_fieldnames: List[str] = [\"section\", \"element_type\", \"text\"]\n    new_rows = []\n    for section, section_narrative in results.items():\n        rows: List[Dict[str, str]] = convert_to_isd(section_narrative)\n        for row in rows:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "pipeline_api",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def pipeline_api(\n    text,\n    response_type=\"application/json\",\n    response_schema=\"isd\",\n    m_section=[],\n    m_section_regex=[],\n):\n    \"\"\"Many supported sections including: RISK_FACTORS, MANAGEMENT_DISCUSSION, and many more\"\"\"\n    validate_section_names(m_section)\n    sec_document = SECDocument.from_string(text)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "get_validated_mimetype",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def get_validated_mimetype(file):\n    \"\"\"\n    Return a file's mimetype, either via the file.content_type or the mimetypes lib if that's too\n    generic. If the user has set UNSTRUCTURED_ALLOWED_MIMETYPES, validate against this list and\n    return HTTP 400 for an invalid type.\n    \"\"\"\n    content_type = file.content_type\n    if not content_type or content_type == \"application/octet-stream\":\n        content_type = mimetypes.guess_type(str(file.filename))[0]\n        # Some filetypes missing for this library, just hardcode them for now",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "ungz_file",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def ungz_file(file: UploadFile, gz_uncompressed_content_type=None) -> UploadFile:\n    def return_content_type(filename):\n        if gz_uncompressed_content_type:\n            return gz_uncompressed_content_type\n        else:\n            return str(mimetypes.guess_type(filename)[0])\n    filename = str(file.filename) if file.filename else \"\"\n    if filename.endswith(\".gz\"):\n        filename = filename[:-3]\n    gzip_file = gzip.open(file.file).read()",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "pipeline_1",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "def pipeline_1(\n    request: Request,\n    gz_uncompressed_content_type: Optional[str] = Form(default=None),\n    text_files: Union[List[UploadFile], None] = File(default=None),\n    output_format: Union[str, None] = Form(default=None),\n    output_schema: str = Form(default=None),\n    section: List[str] = Form(default=[]),\n    section_regex: List[str] = Form(default=[]),\n):\n    if text_files:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "app = FastAPI()\nrouter = APIRouter()\ndef is_expected_response_type(media_type, response_type):\n    if media_type == \"application/json\" and response_type not in [dict, list]:\n        return True\n    elif media_type == \"text/csv\" and response_type != str:\n        return True\n    else:\n        return False\n# pipeline-api",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "router = APIRouter()\ndef is_expected_response_type(media_type, response_type):\n    if media_type == \"application/json\" and response_type not in [dict, list]:\n        return True\n    elif media_type == \"text/csv\" and response_type != str:\n        return True\n    else:\n        return False\n# pipeline-api\nclass timeout:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "LABELSTUDIO",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "LABELSTUDIO = \"labelstudio\"\nISD = \"isd\"\ndef pipeline_api(\n    text,\n    response_type=\"application/json\",\n    response_schema=\"isd\",\n    m_section=[],\n    m_section_regex=[],\n):\n    \"\"\"Many supported sections including: RISK_FACTORS, MANAGEMENT_DISCUSSION, and many more\"\"\"",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "ISD",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "peekOfCode": "ISD = \"isd\"\ndef pipeline_api(\n    text,\n    response_type=\"application/json\",\n    response_schema=\"isd\",\n    m_section=[],\n    m_section_regex=[],\n):\n    \"\"\"Many supported sections including: RISK_FACTORS, MANAGEMENT_DISCUSSION, and many more\"\"\"\n    validate_section_names(m_section)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.api.section",
        "documentation": {}
    },
    {
        "label": "get_filing",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_filing(\n    accession_number: Union[str, int], cik: Union[str, int], company: str, email: str\n) -> str:\n    \"\"\"Fetches the specified filing from the SEC EDGAR Archives. Conforms to the rate\n    limits specified on the SEC website.\n    ref: https://www.sec.gov/os/accessing-edgar-data\"\"\"\n    session = _get_session(company, email)\n    return _get_filing(session, cik, accession_number)\n@sleep_and_retry\n@limits(calls=10, period=1)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_cik_by_ticker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_cik_by_ticker(ticker: str) -> str:\n    \"\"\"Gets a CIK number from a stock ticker by running a search on the SEC website.\"\"\"\n    cik_re = re.compile(r\".*CIK=(\\d{10}).*\")\n    url = _search_url(ticker)\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n    }\n    # headers =  {\n    # 'authority': 'www.google.com',\n    # 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_forms_by_cik",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_forms_by_cik(session: requests.Session, cik: Union[str, int]) -> dict:\n    \"\"\"Gets retrieves dict of recent SEC form filings for a given cik number.\"\"\"\n    json_name = f\"CIK{cik}.json\"\n    response = session.get(f\"{SEC_SUBMISSIONS_URL}/{json_name}\")\n    response.raise_for_status()\n    content = json.loads(response.content)\n    recent_forms = content[\"filings\"][\"recent\"]\n    form_types = {\n        k: v for k, v in zip(recent_forms[\"accessionNumber\"], recent_forms[\"form\"])\n    }",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_recent_acc_by_cik",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_recent_acc_by_cik(\n    cik: str,\n    form_type: str,\n    company: Optional[str] = None,\n    email: Optional[str] = None,\n) -> Tuple[str, str]:\n    \"\"\"Returns (accession_number, retrieved_form_type) for the given cik and form_type.\n    The retrieved_form_type may be an amended version of requested form_type, e.g. 10-Q/A for 10-Q.\n    \"\"\"\n    session = _get_session(company, email)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_recent_cik_and_acc_by_ticker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_recent_cik_and_acc_by_ticker(\n    ticker: str,\n    form_type: str,\n    company: Optional[str] = None,\n    email: Optional[str] = None,\n) -> Tuple[str, str, str]:\n    \"\"\"Returns (cik, accession_number, retrieved_form_type) for the given ticker and form_type.\n    The retrieved_form_type may be an amended version of requested form_type, e.g. 10-Q/A for 10-Q.\n    \"\"\"\n    session = _get_session(company, email)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_form_by_ticker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_form_by_ticker(\n    ticker: str,\n    form_type: str,\n    allow_amended_filing: Optional[bool] = True,\n    company: Optional[str] = None,\n    email: Optional[str] = None,\n) -> str:\n    \"\"\"For a given ticker, gets the most recent form of a given form_type.\"\"\"\n    session = _get_session(company, email)\n    cik = get_cik_by_ticker(session, ticker)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "get_form_by_cik",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def get_form_by_cik(\n    cik: str,\n    form_type: str,\n    allow_amended_filing: Optional[bool] = True,\n    company: Optional[str] = None,\n    email: Optional[str] = None,\n) -> str:\n    \"\"\"For a given CIK, returns the most recent form of a given form_type. By default\n    an amended version of the form_type may be retrieved (allow_amended_filing=True).\n    E.g., if form_type is \"10-Q\", the retrived form could be a 10-Q or 10-Q/A.",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "open_form",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def open_form(cik, acc_num):\n    \"\"\"For a given cik and accession number, opens the index page in default browser for the\n    associated SEC form\"\"\"\n    acc_num = _drop_dashes(acc_num)\n    webbrowser.open_new_tab(\n        f\"{SEC_ARCHIVE_URL}/{cik}/{acc_num}/{_add_dashes(acc_num)}-index.html\"\n    )\ndef open_form_by_ticker(\n    ticker: str,\n    form_type: str,",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "open_form_by_ticker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def open_form_by_ticker(\n    ticker: str,\n    form_type: str,\n    allow_amended_filing: Optional[bool] = True,\n    company: Optional[str] = None,\n    email: Optional[str] = None,\n):\n    \"\"\"For a given ticker, opens the index page in default browser for the most recent form of a\n    given form_type.\"\"\"\n    session = _get_session(company, email)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "archive_url",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "def archive_url(cik: Union[str, int], accession_number: Union[str, int]) -> str:\n    \"\"\"Builds the archive URL for the SEC accession number. Looks for the .txt file for the\n    filing, while follows a {accession_number}.txt format.\"\"\"\n    filename = f\"{_add_dashes(accession_number)}.txt\"\n    accession_number = _drop_dashes(accession_number)\n    return f\"{SEC_ARCHIVE_URL}/{cik}/{accession_number}/{filename}\"\ndef _search_url(cik: Union[str, int]) -> str:\n    search_string = f\"CIK={cik}&Find=Search&owner=exclude&action=getcompany\"\n    url = f\"{SEC_SEARCH_URL}?{search_string}\"\n    return url",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "SEC_SUBMISSIONS_URL",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "peekOfCode": "SEC_SUBMISSIONS_URL = \"https://data.sec.gov/submissions\"\ndef get_filing(\n    accession_number: Union[str, int], cik: Union[str, int], company: str, email: str\n) -> str:\n    \"\"\"Fetches the specified filing from the SEC EDGAR Archives. Conforms to the rate\n    limits specified on the SEC website.\n    ref: https://www.sec.gov/os/accessing-edgar-data\"\"\"\n    session = _get_session(company, email)\n    return _get_filing(session, cik, accession_number)\n@sleep_and_retry",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.fetch",
        "documentation": {}
    },
    {
        "label": "SECDocument",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "class SECDocument(HTMLDocument):\n    filing_type = None\n    def _filter_table_of_contents(self, elements: List[Text]) -> List[Text]:\n        \"\"\"Filter out unnecessary elements in the table of contents using keyword search.\"\"\"\n        if self.filing_type in REPORT_TYPES:\n            # NOTE(yuming): Narrow TOC as all elements within\n            # the first two titles that contain the keyword 'part i\\b'.\n            start, end = None, None\n            for i, element in enumerate(elements):\n                if bool(re.match(r\"(?i)part i\\b\", clean_sec_text(element.text))):",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "get_narrative_texts",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def get_narrative_texts(\n    doc: HTMLDocument, up_to_next_title: Optional[bool] = False\n) -> List[Text]:\n    \"\"\"Returns a list of NarrativeText or ListItem from document,\n    with option to return narrative texts only up to next Title element.\"\"\"\n    if up_to_next_title:\n        narrative_texts = []\n        for el in doc.elements:\n            if isinstance(el, NarrativeText) or isinstance(el, ListItem):\n                narrative_texts.append(el)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_section_elem",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_section_elem(\n    section: SECSection, elem: Text, filing_type: Optional[str]\n) -> bool:\n    \"\"\"Checks to see if a text element matches the section title for a given filing type\"\"\"\n    _raise_for_invalid_filing_type(filing_type)\n    if section is SECSection.RISK_FACTORS:\n        return is_risk_title(elem.text, filing_type=filing_type)\n    else:\n        def _is_matching_section_pattern(text):\n            return bool(",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_item_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_item_title(title: str, filing_type: Optional[str]) -> bool:\n    \"\"\"Determines if a title corresponds to an item heading.\"\"\"\n    if filing_type in REPORT_TYPES:\n        return is_10k_item_title(title)\n    elif filing_type in S1_TYPES:\n        return is_s1_section_title(title)\n    return False\ndef is_risk_title(title: str, filing_type: Optional[str]) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    if filing_type in REPORT_TYPES:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_risk_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_risk_title(title: str, filing_type: Optional[str]) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    if filing_type in REPORT_TYPES:\n        return is_10k_risk_title(clean_sec_text(title, lowercase=True))\n    elif filing_type in S1_TYPES:\n        return is_s1_risk_title(clean_sec_text(title, lowercase=True))\n    return False\ndef is_toc_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the table of contents.\"\"\"\n    clean_title = clean_sec_text(title, lowercase=True)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_toc_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_toc_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the table of contents.\"\"\"\n    clean_title = clean_sec_text(title, lowercase=True)\n    return (clean_title == \"table of contents\") or (clean_title == \"index\")\ndef is_10k_item_title(title: str) -> bool:\n    \"\"\"Determines if a title corresponds to a 10-K item heading.\"\"\"\n    return ITEM_TITLE_RE.match(clean_sec_text(title, lowercase=True)) is not None\ndef is_10k_risk_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    return (\"1a\" in title.lower() or \"risk factors\" in title.lower()) and not (",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_10k_item_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_10k_item_title(title: str) -> bool:\n    \"\"\"Determines if a title corresponds to a 10-K item heading.\"\"\"\n    return ITEM_TITLE_RE.match(clean_sec_text(title, lowercase=True)) is not None\ndef is_10k_risk_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    return (\"1a\" in title.lower() or \"risk factors\" in title.lower()) and not (\n        \"summary\" in title.lower()\n    )\ndef is_s1_section_title(title: str) -> bool:\n    \"\"\"Detemines if a title corresponds to a section title.\"\"\"",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_10k_risk_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_10k_risk_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    return (\"1a\" in title.lower() or \"risk factors\" in title.lower()) and not (\n        \"summary\" in title.lower()\n    )\ndef is_s1_section_title(title: str) -> bool:\n    \"\"\"Detemines if a title corresponds to a section title.\"\"\"\n    return title.strip().isupper()\ndef is_s1_risk_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_s1_section_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_s1_section_title(title: str) -> bool:\n    \"\"\"Detemines if a title corresponds to a section title.\"\"\"\n    return title.strip().isupper()\ndef is_s1_risk_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    return title.strip().lower() == \"risk factors\"\ndef to_sklearn_format(elements: List[Element]) -> npt.NDArray[np.float32]:\n    \"\"\"The input to clustering needs to be locations in euclidean space, so we need to interpret\n    the locations of Titles within the sequence of elements as locations in 1d space\n    \"\"\"",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "is_s1_risk_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def is_s1_risk_title(title: str) -> bool:\n    \"\"\"Checks to see if the title matches the pattern for the risk heading.\"\"\"\n    return title.strip().lower() == \"risk factors\"\ndef to_sklearn_format(elements: List[Element]) -> npt.NDArray[np.float32]:\n    \"\"\"The input to clustering needs to be locations in euclidean space, so we need to interpret\n    the locations of Titles within the sequence of elements as locations in 1d space\n    \"\"\"\n    is_title: npt.NDArray[np.bool_] = np.array(\n        [is_possible_title(el.text) for el in elements][: len(elements)], dtype=bool\n    )",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "to_sklearn_format",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def to_sklearn_format(elements: List[Element]) -> npt.NDArray[np.float32]:\n    \"\"\"The input to clustering needs to be locations in euclidean space, so we need to interpret\n    the locations of Titles within the sequence of elements as locations in 1d space\n    \"\"\"\n    is_title: npt.NDArray[np.bool_] = np.array(\n        [is_possible_title(el.text) for el in elements][: len(elements)], dtype=bool\n    )\n    title_locs = np.arange(len(is_title)).astype(np.float32)[is_title].reshape(-1, 1)\n    return title_locs\ndef cluster_num_to_indices(",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "cluster_num_to_indices",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def cluster_num_to_indices(\n    num: int, elem_idxs: npt.NDArray[np.float32], res: npt.NDArray[np.int_]\n) -> List[int]:\n    \"\"\"Keeping in mind the input to clustering was indices in a list of elements interpreted as\n    location in 1-d space, this function gives back the original indices of elements that are\n    members of the cluster with the given number.\n    \"\"\"\n    idxs = elem_idxs[res == num].astype(int).flatten().tolist()\n    return idxs\ndef first(it: Iterable) -> Any:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "first",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def first(it: Iterable) -> Any:\n    \"\"\"Grabs the first item in an iterator.\"\"\"\n    try:\n        out = next(iter(it))\n    except StopIteration:\n        out = None\n    return out\ndef match_s1_toc_title_to_section(text: str, title: str) -> bool:\n    \"\"\"Matches an S-1 style title from the table of contents to the associated title in the document\n    body\"\"\"",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "match_s1_toc_title_to_section",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def match_s1_toc_title_to_section(text: str, title: str) -> bool:\n    \"\"\"Matches an S-1 style title from the table of contents to the associated title in the document\n    body\"\"\"\n    return text == title\ndef match_10k_toc_title_to_section(text: str, title: str) -> bool:\n    \"\"\"Matches a 10-K style title from the table of contents to the associated title in the document\n    body\"\"\"\n    if re.match(ITEM_TITLE_RE, title):\n        return text.startswith(title)\n    else:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "match_10k_toc_title_to_section",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def match_10k_toc_title_to_section(text: str, title: str) -> bool:\n    \"\"\"Matches a 10-K style title from the table of contents to the associated title in the document\n    body\"\"\"\n    if re.match(ITEM_TITLE_RE, title):\n        return text.startswith(title)\n    else:\n        text = remove_item_from_section_text(text)\n        return text.startswith(title)\ndef remove_item_from_section_text(text: str) -> str:\n    \"\"\"Removes 'item' heading from section text for 10-K/Q forms as preparation for other matching",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "remove_item_from_section_text",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def remove_item_from_section_text(text: str) -> str:\n    \"\"\"Removes 'item' heading from section text for 10-K/Q forms as preparation for other matching\n    techniques\"\"\"\n    return re.sub(ITEM_TITLE_RE, \"\", text).strip()\ndef get_element_by_title(\n    elements: Iterator[Element],\n    title: str,\n    filing_type: Optional[str],\n) -> Optional[Element]:\n    \"\"\"Get element from Element list whose text approximately matches title\"\"\"",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "get_element_by_title",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "def get_element_by_title(\n    elements: Iterator[Element],\n    title: str,\n    filing_type: Optional[str],\n) -> Optional[Element]:\n    \"\"\"Get element from Element list whose text approximately matches title\"\"\"\n    _raise_for_invalid_filing_type(filing_type)\n    if filing_type in REPORT_TYPES:\n        match = match_10k_toc_title_to_section\n    elif filing_type in S1_TYPES:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "ITEM_TITLE_RE",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "ITEM_TITLE_RE = re.compile(r\"(?i)item \\d{1,3}(?:[a-z]|\\([a-z]\\))?(?:\\.)?(?::)?\")\n# NOTE(yuming): clean_sec_text is a partial cleaner from clean,\n# and is used for cleaning a section of text from a SEC filing.\nclean_sec_text = partial(\n    clean, extra_whitespace=True, dashes=True, trailing_punctuation=True\n)\ndef _raise_for_invalid_filing_type(filing_type: Optional[str]):\n    if not filing_type:\n        raise ValueError(\"Filing type is empty.\")\n    elif filing_type not in VALID_FILING_TYPES:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "clean_sec_text",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "peekOfCode": "clean_sec_text = partial(\n    clean, extra_whitespace=True, dashes=True, trailing_punctuation=True\n)\ndef _raise_for_invalid_filing_type(filing_type: Optional[str]):\n    if not filing_type:\n        raise ValueError(\"Filing type is empty.\")\n    elif filing_type not in VALID_FILING_TYPES:\n        raise ValueError(\n            f\"Filing type was {filing_type}. Expected: {VALID_FILING_TYPES}\"\n        )",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sec_document",
        "documentation": {}
    },
    {
        "label": "SECSection",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "class SECSection(Enum):\n    PROSPECTUS_SUMMARY = re.compile(r\"^(?:prospectus )?summary$\")\n    ABOUT_PROSPECTUS = re.compile(r\"about this prospectus\")\n    FORWARD_LOOKING_STATEMENTS = re.compile(r\"forward[ -]looking statements\")\n    RISK_FACTORS = re.compile(r\"risk factors\")\n    USE_OF_PROCEEDS = re.compile(r\"use of proceeds\")\n    DIVIDEND_POLICY = re.compile(r\"^dividend policy\")\n    CAPITALIZATION = re.compile(r\"^capitalization$\")\n    DILUTION = re.compile(r\"^dilution$\")\n    MANAGEMENT_DISCUSSION = re.compile(r\"^management(?:[\\u2019']s)? discussion\")",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "validate_section_names",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "def validate_section_names(section_names: List[str]):\n    \"\"\"Return section names that don't correspond to a defined enum.\"\"\"\n    if len(section_names) == 1 and section_names[0] == ALL_SECTIONS:\n        return None\n    elif len(section_names) > 1 and ALL_SECTIONS in section_names:\n        raise ValueError(f\"{ALL_SECTIONS} may not be specified with other sections\")\n    invalid_names = [\n        name for name in section_names if name not in section_string_to_enum\n    ]\n    if invalid_names:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "ALL_SECTIONS",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "ALL_SECTIONS = \"_ALL\"\nsection_string_to_enum = {enum.name: enum for enum in SECSection}\n# NOTE(robinson) - Sections are listed in the following document from SEC\n# ref: https://www.sec.gov/files/form10-k.pdf\nSECTIONS_10K = (\n    SECSection.BUSINESS,  # ITEM 1\n    SECSection.RISK_FACTORS,  # ITEM 1A\n    SECSection.UNRESOLVED_STAFF_COMMENTS,  # ITEM 1B\n    SECSection.PROPERTIES,  # ITEM 2\n    SECSection.LEGAL_PROCEEDINGS,  # ITEM 3",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "section_string_to_enum",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "section_string_to_enum = {enum.name: enum for enum in SECSection}\n# NOTE(robinson) - Sections are listed in the following document from SEC\n# ref: https://www.sec.gov/files/form10-k.pdf\nSECTIONS_10K = (\n    SECSection.BUSINESS,  # ITEM 1\n    SECSection.RISK_FACTORS,  # ITEM 1A\n    SECSection.UNRESOLVED_STAFF_COMMENTS,  # ITEM 1B\n    SECSection.PROPERTIES,  # ITEM 2\n    SECSection.LEGAL_PROCEEDINGS,  # ITEM 3\n    SECSection.MINE_SAFETY,  # ITEM 4",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10K",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "SECTIONS_10K = (\n    SECSection.BUSINESS,  # ITEM 1\n    SECSection.RISK_FACTORS,  # ITEM 1A\n    SECSection.UNRESOLVED_STAFF_COMMENTS,  # ITEM 1B\n    SECSection.PROPERTIES,  # ITEM 2\n    SECSection.LEGAL_PROCEEDINGS,  # ITEM 3\n    SECSection.MINE_SAFETY,  # ITEM 4\n    SECSection.MARKET_FOR_REGISTRANT_COMMON_EQUITY,  # ITEM 5\n    # NOTE(robinson) - ITEM 6 is \"RESERVED\"\n    SECSection.MANAGEMENT_DISCUSSION,  # ITEM 7",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10Q",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "SECTIONS_10Q = (\n    # Part I - Financial information\n    SECSection.FINANCIAL_STATEMENTS,  # ITEM 1\n    SECSection.MANAGEMENT_DISCUSSION,  # ITEM 2\n    SECSection.MARKET_RISK_DISCLOSURES,  # ITEM 3\n    SECSection.CONTROLS_AND_PROCEDURES,  # ITEM 4\n    # Part II - Other information\n    SECSection.LEGAL_PROCEEDINGS,  # ITEM 1\n    SECSection.RISK_FACTORS,  # ITEM 1A\n    SECSection.USE_OF_PROCEEDS,  # ITEM 2",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "SECTIONS_S1",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "peekOfCode": "SECTIONS_S1 = (\n    SECSection.PROSPECTUS_SUMMARY,\n    SECSection.ABOUT_PROSPECTUS,\n    SECSection.FORWARD_LOOKING_STATEMENTS,\n    SECSection.RISK_FACTORS,\n    SECSection.USE_OF_PROCEEDS,\n    SECSection.DIVIDEND_POLICY,\n    SECSection.CAPITALIZATION,\n    SECSection.DILUTION,\n    SECSection.MANAGEMENT_DISCUSSION,",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.prepline_sec_filings.sections",
        "documentation": {}
    },
    {
        "label": "sec_main",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.secData",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.secData",
        "peekOfCode": "def sec_main(\n    ticker: str,\n    year: str,\n    filing_types: List[str] = [\"10-K\", \"10-Q\"],\n    include_amends=True,\n):\n    cik = get_cik_by_ticker(ticker)\n    rgld_cik = int(cik.lstrip(\"0\"))\n    forms = []\n    if include_amends:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.secData",
        "documentation": {}
    },
    {
        "label": "timeout",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "peekOfCode": "class timeout:\n    def __init__(self, seconds=1, error_message=\"Timeout\"):\n        self.seconds = seconds\n        self.error_message = error_message\n    def handle_timeout(self, signum, frame):\n        raise TimeoutError(self.error_message)\n    def __enter__(self):\n        try:\n            signal.signal(signal.SIGALRM, self.handle_timeout)\n            signal.alarm(self.seconds)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "SECExtractor",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "peekOfCode": "class SECExtractor:\n    def __init__(self, ticker: str, sections: List[str] = [\"_ALL\"]):\n        \"\"\"_summary_\n        Args:\n            tickers (List[str]): list of ticker\n            amount (int): amount of documenteds\n            filing_type (str): 10-K or 10-Q\n            start_date (str, optional): start date of getting files. Defaults to DEFAULT_AFTER_DATE.\n            end_date (str, optional): end date of getting files. Defaults to DEFAULT_BEFORE_DATE.\n            sections (List[str], optional): sections required, check sections names. Defaults to [\"_ALL\"].",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "get_regex_enum",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "peekOfCode": "def get_regex_enum(section_regex):\n    \"\"\"Get sections using regular expression\n    Args:\n        section_regex (str): regular expression for the section name\n    Returns:\n        CustomSECSection.CUSTOM: Custom regex section name\n    \"\"\"\n    class CustomSECSection(Enum):\n        CUSTOM = re.compile(section_regex)\n        @property",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT_TOKENS",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "peekOfCode": "DATE_FORMAT_TOKENS = \"%Y-%m-%d\"\nDEFAULT_BEFORE_DATE = date.today().strftime(DATE_FORMAT_TOKENS)\nDEFAULT_AFTER_DATE = date(2000, 1, 1).strftime(DATE_FORMAT_TOKENS)\nclass timeout:\n    def __init__(self, seconds=1, error_message=\"Timeout\"):\n        self.seconds = seconds\n        self.error_message = error_message\n    def handle_timeout(self, signum, frame):\n        raise TimeoutError(self.error_message)\n    def __enter__(self):",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_BEFORE_DATE",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "peekOfCode": "DEFAULT_BEFORE_DATE = date.today().strftime(DATE_FORMAT_TOKENS)\nDEFAULT_AFTER_DATE = date(2000, 1, 1).strftime(DATE_FORMAT_TOKENS)\nclass timeout:\n    def __init__(self, seconds=1, error_message=\"Timeout\"):\n        self.seconds = seconds\n        self.error_message = error_message\n    def handle_timeout(self, signum, frame):\n        raise TimeoutError(self.error_message)\n    def __enter__(self):\n        try:",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_AFTER_DATE",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "peekOfCode": "DEFAULT_AFTER_DATE = date(2000, 1, 1).strftime(DATE_FORMAT_TOKENS)\nclass timeout:\n    def __init__(self, seconds=1, error_message=\"Timeout\"):\n        self.seconds = seconds\n        self.error_message = error_message\n    def handle_timeout(self, signum, frame):\n        raise TimeoutError(self.error_message)\n    def __enter__(self):\n        try:\n            signal.signal(signal.SIGALRM, self.handle_timeout)",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.sec_filings",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10K",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "peekOfCode": "SECTIONS_10K = (\n    \"BUSINESS\",  # ITEM 1\n    \"RISK_FACTORS\",  # ITEM 1A\n    \"UNRESOLVED_STAFF_COMMENTS\",  # ITEM 1B\n    \"PROPERTIES\",  # ITEM 2\n    \"LEGAL_PROCEEDINGS\",  # ITEM 3\n    \"MINE_SAFETY\",  # ITEM 4\n    \"MARKET_FOR_REGISTRANT_COMMON_EQUITY\",  # ITEM 5\n    # NOTE(robinson) - ITEM 6 is \"RESERVED\"\n    \"MANAGEMENT_DISCUSSION\",  # ITEM 7",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "documentation": {}
    },
    {
        "label": "SECTIONS_10Q",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "peekOfCode": "SECTIONS_10Q = (\n    # Part I - Financial information\n    \"FINANCIAL_STATEMENTS\",  # ITEM 1\n    \"MANAGEMENT_DISCUSSION\",  # ITEM 2\n    \"MARKET_RISK_DISCLOSURES\",  # ITEM 3\n    \"CONTROLS_AND_PROCEDURES\",  # ITEM 4\n    # Part II - Other information\n    \"LEGAL_PROCEEDINGS\",  # ITEM 1\n    \"RISK_FACTORS\",  # ITEM 1A\n    \"USE_OF_PROCEEDS\",  # ITEM 2",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "documentation": {}
    },
    {
        "label": "SECTIONS_S1",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "description": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "peekOfCode": "SECTIONS_S1 = [\n    \"PROSPECTUS_SUMMARY\",\n    \"ABOUT_PROSPECTUS\",\n    \"FORWARD_LOOKING_STATEMENTS\",\n    \"RISK_FACTORS\",\n    \"USE_OF_PROCEEDS\",\n    \"DIVIDEND_POLICY\",\n    \"CAPITALIZATION\",\n    \"DILUTION\",\n    \"MANAGEMENT_DISCUSSION\",",
        "detail": "pages2.FinRobot.finrobot.data_source.filings_src.section_names",
        "documentation": {}
    },
    {
        "label": "run_marker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md",
        "peekOfCode": "def run_marker(\n    input_ticker_year_path: str, output_ticker_year_path:str,batch_multiplier: int = 2\n):\n    # subprocess.run([\"marker\", input_ticker_year_path,output_ticker_year_path,  \"--workers\", str(workers), \"--num_chunks\",str(num_chunks),\"--max\", str(max_workers) ,\"--metadata_file\", path_to_metadata])\n    # return\n    model_lst = load_all_models()\n    for input_path in os.listdir(input_ticker_year_path):\n        if not input_path.endswith(\".pdf\"):\n            continue\n        input_path = os.path.join(input_ticker_year_path, input_path)",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md",
        "peekOfCode": "SAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\n# def run_marker(input_ticker_year_path:str,ticker:str,year:str,workers:int=4,max_workers:int=8,num_chunks:int=1):\ndef run_marker(\n    input_ticker_year_path: str, output_ticker_year_path:str,batch_multiplier: int = 2\n):\n    # subprocess.run([\"marker\", input_ticker_year_path,output_ticker_year_path,  \"--workers\", str(workers), \"--num_chunks\",str(num_chunks),\"--max\", str(max_workers) ,\"--metadata_file\", path_to_metadata])\n    # return\n    model_lst = load_all_models()\n    for input_path in os.listdir(input_ticker_year_path):\n        if not input_path.endswith(\".pdf\"):",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md",
        "documentation": {}
    },
    {
        "label": "worker_init",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "def worker_init(shared_model):\n    global model_refs\n    model_refs = shared_model\ndef worker_exit():\n    global model_refs\n    del model_refs\ndef process_single_pdf(args):\n    filepath, out_folder, metadata, min_length = args\n    fname = os.path.basename(filepath)\n    if markdown_exists(out_folder, fname):",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "worker_exit",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "def worker_exit():\n    global model_refs\n    del model_refs\ndef process_single_pdf(args):\n    filepath, out_folder, metadata, min_length = args\n    fname = os.path.basename(filepath)\n    if markdown_exists(out_folder, fname):\n        return\n    if not filepath.endswith(\"pdf\"): \n        return",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "process_single_pdf",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "def process_single_pdf(args):\n    filepath, out_folder, metadata, min_length = args\n    fname = os.path.basename(filepath)\n    if markdown_exists(out_folder, fname):\n        return\n    if not filepath.endswith(\"pdf\"): \n        return\n    try:\n        # Skip trying to convert files that don't have a lot of embedded text\n        # This can indicate that they were scanned, and not OCRed properly",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "run_marker_mp",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "def run_marker_mp(\n    in_folder,\n    out_folder,\n    chunk_idx=0,\n    num_chunks=1,\n    max_files=None,\n    workers=5,\n    metadata_file=None,\n    min_length=None,\n    inference_ram: Optional[int] = None,",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "os.environ[\"IN_STREAMLIT\"]",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "os.environ[\"IN_STREAMLIT\"] = \"true\"  # Avoid multiprocessing inside surya\nos.environ[\"PDFTEXT_CPU_WORKERS\"] = \"1\"  # Avoid multiprocessing inside pdftext\nSAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\nimport pypdfium2  # Needs to be at the top to avoid warnings\nfrom typing import Optional\nimport torch.multiprocessing as mp\nfrom tqdm import tqdm\nimport math\nfrom marker.convert import convert_single_pdf\nfrom marker.output import markdown_exists, save_markdown",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PDFTEXT_CPU_WORKERS\"]",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "os.environ[\"PDFTEXT_CPU_WORKERS\"] = \"1\"  # Avoid multiprocessing inside pdftext\nSAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\nimport pypdfium2  # Needs to be at the top to avoid warnings\nfrom typing import Optional\nimport torch.multiprocessing as mp\nfrom tqdm import tqdm\nimport math\nfrom marker.convert import convert_single_pdf\nfrom marker.output import markdown_exists, save_markdown\nfrom marker.pdf.utils import find_filetype",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "SAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\nimport pypdfium2  # Needs to be at the top to avoid warnings\nfrom typing import Optional\nimport torch.multiprocessing as mp\nfrom tqdm import tqdm\nimport math\nfrom marker.convert import convert_single_pdf\nfrom marker.output import markdown_exists, save_markdown\nfrom marker.pdf.utils import find_filetype\nfrom marker.pdf.extract_text import get_length_of_text",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "peekOfCode": "SAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\ndef worker_init(shared_model):\n    global model_refs\n    model_refs = shared_model\ndef worker_exit():\n    global model_refs\n    del model_refs\ndef process_single_pdf(args):\n    filepath, out_folder, metadata, min_length = args\n    fname = os.path.basename(filepath)",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.pdf_to_md_parallel",
        "documentation": {}
    },
    {
        "label": "get_cik_by_ticker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "peekOfCode": "def get_cik_by_ticker(ticker: str) -> str:\n    \"\"\"Gets a CIK number from a stock ticker by running a search on the SEC website.\"\"\"\n    cik_re = re.compile(r\".*CIK=(\\d{10}).*\")\n    url = _search_url(ticker)\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n    }\n    # headers =  {\n    # 'authority': 'www.google.com',\n    # 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "documentation": {}
    },
    {
        "label": "sec_save_pdfs",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "peekOfCode": "def sec_save_pdfs(\n    ticker: str,\n    year: str,\n    filing_types: List[str] = [\"10-K\", \"10-Q\"],\n    include_amends=True,\n):\n    cik = get_cik_by_ticker(ticker)\n    rgld_cik = int(cik.lstrip(\"0\"))\n    ticker_year_path = os.path.join(BASE_DIR, f\"{ticker}-{year}\")\n    os.makedirs(ticker_year_path, exist_ok=True)",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "documentation": {}
    },
    {
        "label": "SEC_EDGAR_URL",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "peekOfCode": "SEC_EDGAR_URL = \"https://www.sec.gov/Archives/edgar/data\"\nBASE_DIR = \"output/SEC_EDGAR_FILINGS\"\nos.makedirs(BASE_DIR, exist_ok=True)\ndef sec_save_pdfs(\n    ticker: str,\n    year: str,\n    filing_types: List[str] = [\"10-K\", \"10-Q\"],\n    include_amends=True,\n):\n    cik = get_cik_by_ticker(ticker)",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "description": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "peekOfCode": "BASE_DIR = \"output/SEC_EDGAR_FILINGS\"\nos.makedirs(BASE_DIR, exist_ok=True)\ndef sec_save_pdfs(\n    ticker: str,\n    year: str,\n    filing_types: List[str] = [\"10-K\", \"10-Q\"],\n    include_amends=True,\n):\n    cik = get_cik_by_ticker(ticker)\n    rgld_cik = int(cik.lstrip(\"0\"))",
        "detail": "pages2.FinRobot.finrobot.data_source.marker_sec_src.sec_filings_to_pdf",
        "documentation": {}
    },
    {
        "label": "get_data",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.finance_data",
        "description": "pages2.FinRobot.finrobot.data_source.finance_data",
        "peekOfCode": "def get_data(\n        ticker:str,\n        year:str,\n        filing_types:List[str] = [\"10-K\", \"10-Q\"],\n        data_source:str = 'unstructured',\n        include_amends=True,\n        batch_processing:bool=False,\n        batch_multiplier:Optional[int]=None,\n        workers:Optional[int] = None,\n        inference_ram:Optional[int] = None,",
        "detail": "pages2.FinRobot.finrobot.data_source.finance_data",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.finance_data",
        "description": "pages2.FinRobot.finrobot.data_source.finance_data",
        "peekOfCode": "SAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\ndef get_data(\n        ticker:str,\n        year:str,\n        filing_types:List[str] = [\"10-K\", \"10-Q\"],\n        data_source:str = 'unstructured',\n        include_amends=True,\n        batch_processing:bool=False,\n        batch_multiplier:Optional[int]=None,\n        workers:Optional[int] = None,",
        "detail": "pages2.FinRobot.finrobot.data_source.finance_data",
        "documentation": {}
    },
    {
        "label": "FinnHubUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnhub_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnhub_utils",
        "peekOfCode": "class FinnHubUtils:\n    def get_company_profile(symbol: Annotated[str, \"ticker symbol\"]) -> str:\n        \"\"\"\n        get a company's profile information\n        \"\"\"\n        profile = finnhub_client.company_profile2(symbol=symbol)\n        if not profile:\n            return f\"Failed to find company profile for symbol {symbol} from finnhub!\"\n        formatted_str = (\n            \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. \"",
        "detail": "pages2.FinRobot.finrobot.data_source.finnhub_utils",
        "documentation": {}
    },
    {
        "label": "init_finnhub_client",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnhub_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnhub_utils",
        "peekOfCode": "def init_finnhub_client(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global finnhub_client\n        if os.environ.get(\"FINNHUB_API_KEY\") is None:\n            print(\n                \"Please set the environment variable FINNHUB_API_KEY to use the Finnhub API.\"\n            )\n            return None\n        else:",
        "detail": "pages2.FinRobot.finrobot.data_source.finnhub_utils",
        "documentation": {}
    },
    {
        "label": "FinNLPUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "peekOfCode": "class FinNLPUtils:\n    \"\"\"\n    Streaming News Download\n    \"\"\"\n    def cnbc_news_download(\n            keyword: Annotated[str, \"Keyword to search in news stream\"],\n            rounds: Annotated[int, \"Number of rounds to search. Default to 1\"] = 1,\n            selected_columns: Annotated[list[str], \"List of column names of news to return, should be chosen from 'description', 'cn:lastPubDate', 'dateModified', 'cn:dateline', 'cn:branding', 'section', 'cn:type', 'author', 'cn:source', 'cn:subtype', 'duration', 'summary', 'expires', 'cn:sectionSubType', 'cn:contentClassification', 'pubdateunix', 'url', 'datePublished', 'cn:promoImage', 'cn:title', 'cn:keyword', 'cn:liveURL', 'brand', 'hint', 'hint_detail'. Default to ['author', 'datePublished', 'description' ,'section', 'cn:title', 'summary']\"] = [\"author\", \"datePublished\", \"description\" ,\"section\", \"cn:title\", \"summary\"],\n            save_path: SavePathType = None\n        ) -> DataFrame:",
        "detail": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "documentation": {}
    },
    {
        "label": "streaming_download",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "peekOfCode": "def streaming_download(streaming, config, tag, keyword, rounds, selected_columns, save_path):\n    downloader = streaming(config)\n    if hasattr(downloader, 'download_streaming_search'):\n        downloader.download_streaming_search(keyword, rounds)\n    elif hasattr(downloader, 'download_streaming_stock'):\n        downloader.download_streaming_stock(keyword, rounds)\n    else:\n        downloader.download_streaming_all(rounds)\n    # print(downloader.dataframe.columns)\n    selected = downloader.dataframe[selected_columns]",
        "detail": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "documentation": {}
    },
    {
        "label": "date_range_download",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "peekOfCode": "def date_range_download(date_range, config, tag, start_date, end_date, stock, selected_columns, save_path):\n    downloader = date_range(config)\n    if hasattr(downloader, 'download_date_range_stock'):\n        downloader.download_date_range_stock(start_date, end_date, stock)\n    else:\n        downloader.download_date_range_all(start_date, end_date)\n    if hasattr(downloader, 'gather_content'):\n        downloader.gather_content()\n    # print(downloader.dataframe.columns)\n    selected_news = downloader.dataframe[selected_columns]",
        "detail": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "documentation": {}
    },
    {
        "label": "US_Proxy",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "peekOfCode": "US_Proxy = {\n    \"use_proxy\": \"us_free\",\n    \"max_retry\": 5,\n    \"proxy_pages\": 5,\n}\nCN_Proxy = {\n    \"use_proxy\": \"china_free\",\n    \"max_retry\": 5,\n    \"proxy_pages\": 5,\n}",
        "detail": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "documentation": {}
    },
    {
        "label": "CN_Proxy",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "peekOfCode": "CN_Proxy = {\n    \"use_proxy\": \"china_free\",\n    \"max_retry\": 5,\n    \"proxy_pages\": 5,\n}\ndef streaming_download(streaming, config, tag, keyword, rounds, selected_columns, save_path):\n    downloader = streaming(config)\n    if hasattr(downloader, 'download_streaming_search'):\n        downloader.download_streaming_search(keyword, rounds)\n    elif hasattr(downloader, 'download_streaming_stock'):",
        "detail": "pages2.FinRobot.finrobot.data_source.finnlp_utils",
        "documentation": {}
    },
    {
        "label": "FMPUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.fmp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.fmp_utils",
        "peekOfCode": "class FMPUtils:\n    def get_target_price(\n        ticker_symbol: Annotated[str, \"ticker symbol\"],\n        date: Annotated[str, \"date of the target price, should be 'yyyy-mm-dd'\"],\n    ) -> str:\n        \"\"\"Get the target price for a given stock on a given date\"\"\"\n        # API URL\n        url = f\"https://financialmodelingprep.com/api/v4/price-target?symbol={ticker_symbol}&apikey={fmp_api_key}\"\n        # GET\n        price_target = \"Not Given\"",
        "detail": "pages2.FinRobot.finrobot.data_source.fmp_utils",
        "documentation": {}
    },
    {
        "label": "init_fmp_api",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.fmp_utils",
        "description": "pages2.FinRobot.finrobot.data_source.fmp_utils",
        "peekOfCode": "def init_fmp_api(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global fmp_api_key\n        if os.environ.get(\"FMP_API_KEY\") is None:\n            print(\"Please set the environment variable FMP_API_KEY to use the FMP API.\")\n            return None\n        else:\n            fmp_api_key = os.environ[\"FMP_API_KEY\"]\n            print(\"FMP api key found successfully.\")",
        "detail": "pages2.FinRobot.finrobot.data_source.fmp_utils",
        "documentation": {}
    },
    {
        "label": "RedditUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.reddit_utils",
        "description": "pages2.FinRobot.finrobot.data_source.reddit_utils",
        "peekOfCode": "class RedditUtils:\n    def get_reddit_posts(\n        query: Annotated[\n            str, \"Search query, e.g. 'AAPL OR Apple Inc OR #AAPL OR (Apple AND stock)'\"\n        ],\n        start_date: Annotated[str, \"Start date in yyyy-mm-dd format\"],\n        end_date: Annotated[str, \"End date in yyyy-mm-dd format\"],\n        limit: Annotated[\n            int, \"Maximum number of posts to fetch, default to 1000\"\n        ] = 1000,",
        "detail": "pages2.FinRobot.finrobot.data_source.reddit_utils",
        "documentation": {}
    },
    {
        "label": "init_reddit_client",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.reddit_utils",
        "description": "pages2.FinRobot.finrobot.data_source.reddit_utils",
        "peekOfCode": "def init_reddit_client(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global reddit_client\n        if not all(\n            [os.environ.get(\"REDDIT_CLIENT_ID\"), os.environ.get(\"REDDIT_CLIENT_SECRET\")]\n        ):\n            print(\"Please set the environment variables for Reddit API credentials.\")\n            return None\n        else:",
        "detail": "pages2.FinRobot.finrobot.data_source.reddit_utils",
        "documentation": {}
    },
    {
        "label": "SECUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "description": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "peekOfCode": "class SECUtils:\n    def get_10k_metadata(\n        ticker: Annotated[str, \"ticker symbol\"],\n        start_date: Annotated[\n            str, \"start date of the 10-k file search range, in yyyy-mm-dd format\"\n        ],\n        end_date: Annotated[\n            str, \"end date of the 10-k file search range, in yyyy-mm-dd format\"\n        ],\n    ):",
        "detail": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "documentation": {}
    },
    {
        "label": "init_sec_api",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "description": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "peekOfCode": "def init_sec_api(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global extractor_api, query_api, render_api\n        if os.environ.get(\"SEC_API_KEY\") is None:\n            print(\"Please set the environment variable SEC_API_KEY to use sec_api.\")\n            return None\n        else:\n            extractor_api = ExtractorApi(os.environ[\"SEC_API_KEY\"])\n            query_api = QueryApi(os.environ[\"SEC_API_KEY\"])",
        "detail": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "documentation": {}
    },
    {
        "label": "CACHE_PATH",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "description": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "peekOfCode": "CACHE_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \".cache\")\nPDF_GENERATOR_API = \"https://api.sec-api.io/filing-reader\"\ndef init_sec_api(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global extractor_api, query_api, render_api\n        if os.environ.get(\"SEC_API_KEY\") is None:\n            print(\"Please set the environment variable SEC_API_KEY to use sec_api.\")\n            return None\n        else:",
        "detail": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "documentation": {}
    },
    {
        "label": "PDF_GENERATOR_API",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "description": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "peekOfCode": "PDF_GENERATOR_API = \"https://api.sec-api.io/filing-reader\"\ndef init_sec_api(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global extractor_api, query_api, render_api\n        if os.environ.get(\"SEC_API_KEY\") is None:\n            print(\"Please set the environment variable SEC_API_KEY to use sec_api.\")\n            return None\n        else:\n            extractor_api = ExtractorApi(os.environ[\"SEC_API_KEY\"])",
        "detail": "pages2.FinRobot.finrobot.data_source.sec_utils",
        "documentation": {}
    },
    {
        "label": "YFinanceUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.data_source.yfinance_utils",
        "description": "pages2.FinRobot.finrobot.data_source.yfinance_utils",
        "peekOfCode": "class YFinanceUtils:\n    def get_stock_data(\n        symbol: Annotated[str, \"ticker symbol\"],\n        start_date: Annotated[\n            str, \"start date for retrieving stock price data, YYYY-mm-dd\"\n        ],\n        end_date: Annotated[\n            str, \"end date for retrieving stock price data, YYYY-mm-dd\"\n        ],\n        save_path: SavePathType = None,",
        "detail": "pages2.FinRobot.finrobot.data_source.yfinance_utils",
        "documentation": {}
    },
    {
        "label": "init_ticker",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.data_source.yfinance_utils",
        "description": "pages2.FinRobot.finrobot.data_source.yfinance_utils",
        "peekOfCode": "def init_ticker(func: Callable) -> Callable:\n    \"\"\"Decorator to initialize yf.Ticker and pass it to the function.\"\"\"\n    @wraps(func)\n    def wrapper(symbol: Annotated[str, \"ticker symbol\"], *args, **kwargs) -> Any:\n        ticker = yf.Ticker(symbol)\n        return func(ticker, *args, **kwargs)\n    return wrapper\n@decorate_all_methods(init_ticker)\nclass YFinanceUtils:\n    def get_stock_data(",
        "detail": "pages2.FinRobot.finrobot.data_source.yfinance_utils",
        "documentation": {}
    },
    {
        "label": "ReportAnalysisUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.analyzer",
        "description": "pages2.FinRobot.finrobot.functional.analyzer",
        "peekOfCode": "class ReportAnalysisUtils:\n    def analyze_income_stmt(\n        ticker_symbol: Annotated[str, \"ticker symbol\"],\n        fyear: Annotated[str, \"fiscal year of the 10-K report\"],\n        save_path: Annotated[str, \"txt file path, to which the returned instruction & resources are written.\"]\n    ) -> str:\n        \"\"\"\n        Retrieve the income statement for the given ticker symbol with the related section of its 10-K report.\n        Then return with an instruction on how to analyze the income statement.\n        \"\"\"",
        "detail": "pages2.FinRobot.finrobot.functional.analyzer",
        "documentation": {}
    },
    {
        "label": "combine_prompt",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.functional.analyzer",
        "description": "pages2.FinRobot.finrobot.functional.analyzer",
        "peekOfCode": "def combine_prompt(instruction, resource, table_str=None):\n    if table_str:\n        prompt = f\"{table_str}\\n\\nResource: {resource}\\n\\nInstruction: {instruction}\"\n    else:\n        prompt = f\"Resource: {resource}\\n\\nInstruction: {instruction}\"\n    return prompt\ndef save_to_file(data: str, file_path: str):\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    with open(file_path, \"w\") as f:\n        f.write(data)",
        "detail": "pages2.FinRobot.finrobot.functional.analyzer",
        "documentation": {}
    },
    {
        "label": "save_to_file",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.functional.analyzer",
        "description": "pages2.FinRobot.finrobot.functional.analyzer",
        "peekOfCode": "def save_to_file(data: str, file_path: str):\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    with open(file_path, \"w\") as f:\n        f.write(data)\nclass ReportAnalysisUtils:\n    def analyze_income_stmt(\n        ticker_symbol: Annotated[str, \"ticker symbol\"],\n        fyear: Annotated[str, \"fiscal year of the 10-K report\"],\n        save_path: Annotated[str, \"txt file path, to which the returned instruction & resources are written.\"]\n    ) -> str:",
        "detail": "pages2.FinRobot.finrobot.functional.analyzer",
        "documentation": {}
    },
    {
        "label": "MplFinanceUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.charting",
        "description": "pages2.FinRobot.finrobot.functional.charting",
        "peekOfCode": "class MplFinanceUtils:\n    def plot_stock_price_chart(\n        ticker_symbol: Annotated[\n            str, \"Ticker symbol of the stock (e.g., 'AAPL' for Apple)\"\n        ],\n        start_date: Annotated[\n            str, \"Start date of the historical data in 'YYYY-MM-DD' format\"\n        ],\n        end_date: Annotated[\n            str, \"End date of the historical data in 'YYYY-MM-DD' format\"",
        "detail": "pages2.FinRobot.finrobot.functional.charting",
        "documentation": {}
    },
    {
        "label": "ReportChartUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.charting",
        "description": "pages2.FinRobot.finrobot.functional.charting",
        "peekOfCode": "class ReportChartUtils:\n    def get_share_performance(\n        ticker_symbol: Annotated[\n            str, \"Ticker symbol of the stock (e.g., 'AAPL' for Apple)\"\n        ],\n        filing_date: Annotated[str | datetime, \"filing date in 'YYYY-MM-DD' format\"],\n        save_path: Annotated[str, \"File path where the plot should be saved\"],\n    ) -> str:\n        \"\"\"Plot the stock performance of a company compared to the S&P 500 over the past year.\"\"\"\n        if isinstance(filing_date, str):",
        "detail": "pages2.FinRobot.finrobot.functional.charting",
        "documentation": {}
    },
    {
        "label": "IPythonUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.coding",
        "description": "pages2.FinRobot.finrobot.functional.coding",
        "peekOfCode": "class IPythonUtils:\n    def exec_python(cell: Annotated[str, \"Valid Python cell to execute.\"]) -> str:\n        \"\"\"\n        run cell in ipython and return the execution result.\n        \"\"\"\n        ipython = get_ipython()\n        result = ipython.run_cell(cell)\n        log = str(result.result)\n        if result.error_before_exec is not None:\n            log += f\"\\n{result.error_before_exec}\"",
        "detail": "pages2.FinRobot.finrobot.functional.coding",
        "documentation": {}
    },
    {
        "label": "CodingUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.coding",
        "description": "pages2.FinRobot.finrobot.functional.coding",
        "peekOfCode": "class CodingUtils:  # Borrowed from https://microsoft.github.io/autogen/docs/notebooks/agentchat_function_call_code_writing\n    def list_dir(directory: Annotated[str, \"Directory to check.\"]) -> str:\n        \"\"\"\n        List files in choosen directory.\n        \"\"\"\n        files = os.listdir(default_path + directory)\n        return str(files)\n    def see_file(filename: Annotated[str, \"Name and path of file to check.\"]) -> str:\n        \"\"\"\n        Check the contents of a chosen file.",
        "detail": "pages2.FinRobot.finrobot.functional.coding",
        "documentation": {}
    },
    {
        "label": "default_path",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.functional.coding",
        "description": "pages2.FinRobot.finrobot.functional.coding",
        "peekOfCode": "default_path = \"coding/\"\nclass IPythonUtils:\n    def exec_python(cell: Annotated[str, \"Valid Python cell to execute.\"]) -> str:\n        \"\"\"\n        run cell in ipython and return the execution result.\n        \"\"\"\n        ipython = get_ipython()\n        result = ipython.run_cell(cell)\n        log = str(result.result)\n        if result.error_before_exec is not None:",
        "detail": "pages2.FinRobot.finrobot.functional.coding",
        "documentation": {}
    },
    {
        "label": "DeployedCapitalAnalyzer",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.quantitative",
        "description": "pages2.FinRobot.finrobot.functional.quantitative",
        "peekOfCode": "class DeployedCapitalAnalyzer(bt.Analyzer):\n    def start(self):\n        self.deployed_capital = []\n        self.initial_cash = self.strategy.broker.get_cash()  # Initial cash in account\n    def notify_order(self, order):\n        if order.status in [order.Completed]:\n            if order.isbuy():\n                self.deployed_capital.append(order.executed.price * order.executed.size)\n            elif order.issell():\n                self.deployed_capital.append(order.executed.price * order.executed.size)",
        "detail": "pages2.FinRobot.finrobot.functional.quantitative",
        "documentation": {}
    },
    {
        "label": "BackTraderUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.quantitative",
        "description": "pages2.FinRobot.finrobot.functional.quantitative",
        "peekOfCode": "class BackTraderUtils:\n    def back_test(\n        ticker_symbol: Annotated[\n            str, \"Ticker symbol of the stock (e.g., 'AAPL' for Apple)\"\n        ],\n        start_date: Annotated[\n            str, \"Start date of the historical data in 'YYYY-MM-DD' format\"\n        ],\n        end_date: Annotated[\n            str, \"End date of the historical data in 'YYYY-MM-DD' format\"",
        "detail": "pages2.FinRobot.finrobot.functional.quantitative",
        "documentation": {}
    },
    {
        "label": "get_rag_function",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.functional.rag",
        "description": "pages2.FinRobot.finrobot.functional.rag",
        "peekOfCode": "def get_rag_function(retrieve_config, description=\"\"):\n    def termination_msg(x):\n        return (\n            isinstance(x, dict)\n            and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n        )\n    if \"customized_prompt\" not in retrieve_config:\n        retrieve_config[\"customized_prompt\"] = PROMPT_RAG_FUNC\n    rag_assitant = RetrieveUserProxyAgent(\n        name=\"RAG_Assistant\",",
        "detail": "pages2.FinRobot.finrobot.functional.rag",
        "documentation": {}
    },
    {
        "label": "PROMPT_RAG_FUNC",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.functional.rag",
        "description": "pages2.FinRobot.finrobot.functional.rag",
        "peekOfCode": "PROMPT_RAG_FUNC = \"\"\"Below is the context retrieved from the required file based on your query.\nIf you can't answer the question with or without the current context, you should try using a more refined search query according to your requirements, or ask for more contexts.\nYour current query is: {input_question}\nRetrieved context is: {input_context}\n\"\"\"\ndef get_rag_function(retrieve_config, description=\"\"):\n    def termination_msg(x):\n        return (\n            isinstance(x, dict)\n            and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()",
        "detail": "pages2.FinRobot.finrobot.functional.rag",
        "documentation": {}
    },
    {
        "label": "rag_database_earnings_call",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.functional.ragquery",
        "description": "pages2.FinRobot.finrobot.functional.ragquery",
        "peekOfCode": "def rag_database_earnings_call(\n        ticker: str,\n        year: str)->str:\n        #assert quarter in earnings_call_quarter_vals, \"The quarter should be from Q1, Q2, Q3, Q4\"\n        earnings_docs, earnings_call_quarter_vals, speakers_list_1, speakers_list_2, speakers_list_3, speakers_list_4 = get_data(ticker=ticker,year=year,data_source='earnings_calls')\n        emb_fn = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n        text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1024,\n        chunk_overlap=100,\n        length_function=len,)",
        "detail": "pages2.FinRobot.finrobot.functional.ragquery",
        "documentation": {}
    },
    {
        "label": "rag_database_sec",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.functional.ragquery",
        "description": "pages2.FinRobot.finrobot.functional.ragquery",
        "peekOfCode": "def rag_database_sec(\n        ticker: str,\n        year: str,\n        FROM_MARKDOWN = False,\n        filing_types = ['10-K','10-Q'])->str:\n    if not FROM_MARKDOWN:\n        sec_data,sec_form_names = get_data(ticker=ticker, year=year,data_source='unstructured',include_amends=True,filing_types=filing_types)\n        emb_fn = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n        text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1024,",
        "detail": "pages2.FinRobot.finrobot.functional.ragquery",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.functional.ragquery",
        "description": "pages2.FinRobot.finrobot.functional.ragquery",
        "peekOfCode": "SAVE_DIR = \"output/SEC_EDGAR_FILINGS_MD\"\ndef rag_database_earnings_call(\n        ticker: str,\n        year: str)->str:\n        #assert quarter in earnings_call_quarter_vals, \"The quarter should be from Q1, Q2, Q3, Q4\"\n        earnings_docs, earnings_call_quarter_vals, speakers_list_1, speakers_list_2, speakers_list_3, speakers_list_4 = get_data(ticker=ticker,year=year,data_source='earnings_calls')\n        emb_fn = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n        text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1024,\n        chunk_overlap=100,",
        "detail": "pages2.FinRobot.finrobot.functional.ragquery",
        "documentation": {}
    },
    {
        "label": "ReportLabUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.reportlab",
        "description": "pages2.FinRobot.finrobot.functional.reportlab",
        "peekOfCode": "class ReportLabUtils:\n    def build_annual_report(\n        ticker_symbol: Annotated[str, \"ticker symbol\"],\n        save_path: Annotated[str, \"path to save the annual report pdf\"],\n        operating_results: Annotated[\n            str,\n            \"a paragraph of text: the company's income summarization from its financial report\",\n        ],\n        market_position: Annotated[\n            str,",
        "detail": "pages2.FinRobot.finrobot.functional.reportlab",
        "documentation": {}
    },
    {
        "label": "TextUtils",
        "kind": 6,
        "importPath": "pages2.FinRobot.finrobot.functional.text",
        "description": "pages2.FinRobot.finrobot.functional.text",
        "peekOfCode": "class TextUtils:\n    def check_text_length(\n        text: Annotated[str, \"text to check\"],\n        min_length: Annotated[int, \"minimum length of the text, default to 0\"] = 0,\n        max_length: Annotated[int, \"maximum length of the text, default to 100000\"] = 100000,\n    ) -> str:\n        \"\"\"\n        Check if the length of the text is exceeds than the maximum length.\n        \"\"\"\n        length = len(text.split())",
        "detail": "pages2.FinRobot.finrobot.functional.text",
        "documentation": {}
    },
    {
        "label": "stringify_output",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.toolkits",
        "description": "pages2.FinRobot.finrobot.toolkits",
        "peekOfCode": "def stringify_output(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        result = func(*args, **kwargs)\n        if isinstance(result, DataFrame):\n            return result.to_string()\n        else:\n            return str(result)\n    return wrapper\ndef register_toolkits(",
        "detail": "pages2.FinRobot.finrobot.toolkits",
        "documentation": {}
    },
    {
        "label": "register_toolkits",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.toolkits",
        "description": "pages2.FinRobot.finrobot.toolkits",
        "peekOfCode": "def register_toolkits(\n    config: List[dict | Callable | type],\n    caller: ConversableAgent,\n    executor: ConversableAgent,\n    **kwargs\n):\n    \"\"\"Register tools from a configuration list.\"\"\"\n    for tool in config:\n        if isinstance(tool, type):\n            register_tookits_from_cls(caller, executor, tool, **kwargs)",
        "detail": "pages2.FinRobot.finrobot.toolkits",
        "documentation": {}
    },
    {
        "label": "register_code_writing",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.toolkits",
        "description": "pages2.FinRobot.finrobot.toolkits",
        "peekOfCode": "def register_code_writing(caller: ConversableAgent, executor: ConversableAgent):\n    \"\"\"Register code writing tools.\"\"\"\n    register_toolkits(\n        [\n            {\n                \"function\": CodingUtils.list_dir,\n                \"name\": \"list_files\",\n                \"description\": \"List files in a directory.\",\n            },\n            {",
        "detail": "pages2.FinRobot.finrobot.toolkits",
        "documentation": {}
    },
    {
        "label": "register_tookits_from_cls",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.toolkits",
        "description": "pages2.FinRobot.finrobot.toolkits",
        "peekOfCode": "def register_tookits_from_cls(\n    caller: ConversableAgent,\n    executor: ConversableAgent,\n    cls: type,\n    include_private: bool = False,\n):\n    \"\"\"Register all methods of a class as tools.\"\"\"\n    if include_private:\n        funcs = [\n            func",
        "detail": "pages2.FinRobot.finrobot.toolkits",
        "documentation": {}
    },
    {
        "label": "save_output",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.utils",
        "description": "pages2.FinRobot.finrobot.utils",
        "peekOfCode": "def save_output(data: pd.DataFrame, tag: str, save_path: SavePathType = None) -> None:\n    if save_path:\n        data.to_csv(save_path)\n        print(f\"{tag} saved to {save_path}\")\ndef get_current_date():\n    return date.today().strftime(\"%Y-%m-%d\")\ndef register_keys_from_json(file_path):\n    with open(file_path, \"r\") as f:\n        keys = json.load(f)\n    for key, value in keys.items():",
        "detail": "pages2.FinRobot.finrobot.utils",
        "documentation": {}
    },
    {
        "label": "get_current_date",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.utils",
        "description": "pages2.FinRobot.finrobot.utils",
        "peekOfCode": "def get_current_date():\n    return date.today().strftime(\"%Y-%m-%d\")\ndef register_keys_from_json(file_path):\n    with open(file_path, \"r\") as f:\n        keys = json.load(f)\n    for key, value in keys.items():\n        os.environ[key] = value\ndef decorate_all_methods(decorator):\n    def class_decorator(cls):\n        for attr_name, attr_value in cls.__dict__.items():",
        "detail": "pages2.FinRobot.finrobot.utils",
        "documentation": {}
    },
    {
        "label": "register_keys_from_json",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.utils",
        "description": "pages2.FinRobot.finrobot.utils",
        "peekOfCode": "def register_keys_from_json(file_path):\n    with open(file_path, \"r\") as f:\n        keys = json.load(f)\n    for key, value in keys.items():\n        os.environ[key] = value\ndef decorate_all_methods(decorator):\n    def class_decorator(cls):\n        for attr_name, attr_value in cls.__dict__.items():\n            if callable(attr_value):\n                setattr(cls, attr_name, decorator(attr_value))",
        "detail": "pages2.FinRobot.finrobot.utils",
        "documentation": {}
    },
    {
        "label": "decorate_all_methods",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.utils",
        "description": "pages2.FinRobot.finrobot.utils",
        "peekOfCode": "def decorate_all_methods(decorator):\n    def class_decorator(cls):\n        for attr_name, attr_value in cls.__dict__.items():\n            if callable(attr_value):\n                setattr(cls, attr_name, decorator(attr_value))\n        return cls\n    return class_decorator\ndef get_next_weekday(date):\n    if not isinstance(date, datetime):\n        date = datetime.strptime(date, \"%Y-%m-%d\")",
        "detail": "pages2.FinRobot.finrobot.utils",
        "documentation": {}
    },
    {
        "label": "get_next_weekday",
        "kind": 2,
        "importPath": "pages2.FinRobot.finrobot.utils",
        "description": "pages2.FinRobot.finrobot.utils",
        "peekOfCode": "def get_next_weekday(date):\n    if not isinstance(date, datetime):\n        date = datetime.strptime(date, \"%Y-%m-%d\")\n    if date.weekday() >= 5:\n        days_to_add = 7 - date.weekday()\n        next_weekday = date + timedelta(days=days_to_add)\n        return next_weekday\n    else:\n        return date\n# def create_inner_assistant(",
        "detail": "pages2.FinRobot.finrobot.utils",
        "documentation": {}
    },
    {
        "label": "SavePathType",
        "kind": 5,
        "importPath": "pages2.FinRobot.finrobot.utils",
        "description": "pages2.FinRobot.finrobot.utils",
        "peekOfCode": "SavePathType = Annotated[str, \"File path to save data. If None, data is not saved.\"]\n# def process_output(data: pd.DataFrame, tag: str, verbose: VerboseType = True, save_path: SavePathType = None) -> None:\n#     if verbose:\n#         print(data.to_string())\n#     if save_path:\n#         data.to_csv(save_path)\n#         print(f\"{tag} saved to {save_path}\")\ndef save_output(data: pd.DataFrame, tag: str, save_path: SavePathType = None) -> None:\n    if save_path:\n        data.to_csv(save_path)",
        "detail": "pages2.FinRobot.finrobot.utils",
        "documentation": {}
    },
    {
        "label": "config_file_or_env",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "config_file_or_env = \"OAI_CONFIG_LIST\"\nllm_config = {\"temperature\": 0}\nbuilder = AgentBuilder(\n    config_file_or_env=config_file_or_env,\n    builder_model=\"gpt-4-0125-preview\",\n    agent_model=\"gpt-4-0125-preview\",\n)\nconfig_list = autogen.config_list_from_json(\n    config_file_or_env, filter_dict={\"model\": [\"gpt-4-0125-preview\"]}\n)",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "llm_config",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "llm_config = {\"temperature\": 0}\nbuilder = AgentBuilder(\n    config_file_or_env=config_file_or_env,\n    builder_model=\"gpt-4-0125-preview\",\n    agent_model=\"gpt-4-0125-preview\",\n)\nconfig_list = autogen.config_list_from_json(\n    config_file_or_env, filter_dict={\"model\": [\"gpt-4-0125-preview\"]}\n)\nbuilding_task = \"Gather information like company profile, recent stock price fluctuations, market news, and financial basics of a specified company (e.g. AAPL) by programming and analyze its current positive developments and potential concerns. Based on all the information, come up with a rough estimate (e.g. up by 2-3%) and give a summary of the reasons for next week's stock price. Each python program should execute on its own, and avoid plotting any chart.\"",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "builder",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "builder = AgentBuilder(\n    config_file_or_env=config_file_or_env,\n    builder_model=\"gpt-4-0125-preview\",\n    agent_model=\"gpt-4-0125-preview\",\n)\nconfig_list = autogen.config_list_from_json(\n    config_file_or_env, filter_dict={\"model\": [\"gpt-4-0125-preview\"]}\n)\nbuilding_task = \"Gather information like company profile, recent stock price fluctuations, market news, and financial basics of a specified company (e.g. AAPL) by programming and analyze its current positive developments and potential concerns. Based on all the information, come up with a rough estimate (e.g. up by 2-3%) and give a summary of the reasons for next week's stock price. Each python program should execute on its own, and avoid plotting any chart.\"\nconfig_path = \"configs/save_config_forecaster.json\"",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "config_list",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "config_list = autogen.config_list_from_json(\n    config_file_or_env, filter_dict={\"model\": [\"gpt-4-0125-preview\"]}\n)\nbuilding_task = \"Gather information like company profile, recent stock price fluctuations, market news, and financial basics of a specified company (e.g. AAPL) by programming and analyze its current positive developments and potential concerns. Based on all the information, come up with a rough estimate (e.g. up by 2-3%) and give a summary of the reasons for next week's stock price. Each python program should execute on its own, and avoid plotting any chart.\"\nconfig_path = \"configs/save_config_forecaster.json\"\nif os.path.exists(config_path):\n    agent_list, agent_config = builder.load(config_path)\nelse:\n    agent_list, agent_configs = builder.build(\n        building_task,",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "building_task",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "building_task = \"Gather information like company profile, recent stock price fluctuations, market news, and financial basics of a specified company (e.g. AAPL) by programming and analyze its current positive developments and potential concerns. Based on all the information, come up with a rough estimate (e.g. up by 2-3%) and give a summary of the reasons for next week's stock price. Each python program should execute on its own, and avoid plotting any chart.\"\nconfig_path = \"configs/save_config_forecaster.json\"\nif os.path.exists(config_path):\n    agent_list, agent_config = builder.load(config_path)\nelse:\n    agent_list, agent_configs = builder.build(\n        building_task,\n        llm_config,\n        coding=True,\n        code_execution_config={",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "config_path",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "config_path = \"configs/save_config_forecaster.json\"\nif os.path.exists(config_path):\n    agent_list, agent_config = builder.load(config_path)\nelse:\n    agent_list, agent_configs = builder.build(\n        building_task,\n        llm_config,\n        coding=True,\n        code_execution_config={\n            \"work_dir\": \"coding\",",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "group_chat",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "group_chat = autogen.GroupChat(agents=agent_list, messages=[], max_round=20)\nmanager = autogen.GroupChatManager(\n    groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config}\n)\nagent_list[0].initiate_chat(\n    manager,\n    message=f\"Today is {get_current_date()}, predict next week's stock price for Nvidia with its recent market news and stock price movements.\",\n)",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "manager",
        "kind": 5,
        "importPath": "pages2.FinRobot.agent_builder_demo",
        "description": "pages2.FinRobot.agent_builder_demo",
        "peekOfCode": "manager = autogen.GroupChatManager(\n    groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config}\n)\nagent_list[0].initiate_chat(\n    manager,\n    message=f\"Today is {get_current_date()}, predict next week's stock price for Nvidia with its recent market news and stock price movements.\",\n)",
        "detail": "pages2.FinRobot.agent_builder_demo",
        "documentation": {}
    },
    {
        "label": "TestStrategy",
        "kind": 6,
        "importPath": "pages2.FinRobot.test_module",
        "description": "pages2.FinRobot.test_module",
        "peekOfCode": "class TestStrategy(bt.Strategy):\n    params = ((\"exitbars\", 5),)\n    def log(self, txt, dt=None):\n        \"\"\"Logging function fot this strategy\"\"\"\n        dt = dt or self.datas[0].datetime.date(0)\n        print(\"%s, %s\" % (dt.isoformat(), txt))\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n        # To keep track of pending orders and buy price/commission",
        "detail": "pages2.FinRobot.test_module",
        "documentation": {}
    },
    {
        "label": "Tweet",
        "kind": 6,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.Tweet",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.Tweet",
        "peekOfCode": "class Tweet(object):\n    def __init__(self, content, polarity):\n        self.content = content\n        self.polarity = polarity",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.Tweet",
        "documentation": {}
    },
    {
        "label": "num_of_tweets",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.constants",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.constants",
        "peekOfCode": "num_of_tweets = int(300)",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.constants",
        "documentation": {}
    },
    {
        "label": "add_header",
        "kind": 2,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "peekOfCode": "def add_header(response):\n    response.headers['Pragma'] = 'no-cache'\n    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'\n    response.headers['Expires'] = '0'\n    return response\n@app.route('/')\ndef index():\n   return render_template('index.html')\n@app.route('/insertintotable',methods = ['POST'])\ndef insertintotable():",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "peekOfCode": "def index():\n   return render_template('index.html')\n@app.route('/insertintotable',methods = ['POST'])\ndef insertintotable():\n    nm = request.form['nm']\n    #**************** FUNCTIONS TO FETCH DATA ***************************\n    def get_historical(quote):\n        end = datetime.now()\n        start = datetime(end.year-2,end.month,end.day)\n        data = yf.download(quote, start=start, end=end)",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "documentation": {}
    },
    {
        "label": "insertintotable",
        "kind": 2,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "peekOfCode": "def insertintotable():\n    nm = request.form['nm']\n    #**************** FUNCTIONS TO FETCH DATA ***************************\n    def get_historical(quote):\n        end = datetime.now()\n        start = datetime(end.year-2,end.month,end.day)\n        data = yf.download(quote, start=start, end=end)\n        df = pd.DataFrame(data=data)\n        df.to_csv(''+quote+'.csv')\n        if(df.empty):",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "documentation": {}
    },
    {
        "label": "os.environ['TF_CPP_MIN_LOG_LEVEL']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "peekOfCode": "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n#***************** FLASK *****************************\napp = Flask(__name__)\n#To control caching so as to save and retrieve plot figs on client side\n@app.after_request\ndef add_header(response):\n    response.headers['Pragma'] = 'no-cache'\n    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'\n    response.headers['Expires'] = '0'\n    return response",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "peekOfCode": "app = Flask(__name__)\n#To control caching so as to save and retrieve plot figs on client side\n@app.after_request\ndef add_header(response):\n    response.headers['Pragma'] = 'no-cache'\n    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'\n    response.headers['Expires'] = '0'\n    return response\n@app.route('/')\ndef index():",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "documentation": {}
    },
    {
        "label": "@app.route('/insertintotable',methods",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "description": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "peekOfCode": "@app.route('/insertintotable',methods = ['POST'])\ndef insertintotable():\n    nm = request.form['nm']\n    #**************** FUNCTIONS TO FETCH DATA ***************************\n    def get_historical(quote):\n        end = datetime.now()\n        start = datetime(end.year-2,end.month,end.day)\n        data = yf.download(quote, start=start, end=end)\n        df = pd.DataFrame(data=data)\n        df.to_csv(''+quote+'.csv')",
        "detail": "pages2.Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis.main",
        "documentation": {}
    },
    {
        "label": "Preprocess_Tweets",
        "kind": 2,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "def Preprocess_Tweets(data):\n\tdata['Text_Cleaned'] = data['Text'].str.lower()\n\t## FIX HYPERLINKS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'https?:\\/\\/.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'www.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('https', '', regex=False)\n\t## FIX INDIVIDUAL SYMBOLS \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text'].str.lower()\n\t## FIX HYPERLINKS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'https?:\\/\\/.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'www.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('https', '', regex=False)\n\t## FIX INDIVIDUAL SYMBOLS \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'https?:\\/\\/.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'www.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('https', '', regex=False)\n\t## FIX INDIVIDUAL SYMBOLS \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'www.*[\\r\\n]*', ' ',regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('https', '', regex=False)\n\t## FIX INDIVIDUAL SYMBOLS \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('https', '', regex=False)\n\t## FIX INDIVIDUAL SYMBOLS \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(': ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(', ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('. ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[;\\n~]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(\"[]'*|]\", '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[[()!?\"]', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('_', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('w/', ' with ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('f/', ' for ', regex=False)\n\t## FIX EMOJIS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':-(', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('0_o', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(';)', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=^.^=', '', regex=False)\n\t## FIX % SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('%', ' percent ', regex=False)\n\t## FIX & SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' & ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&amp', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&gt', ' greater than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup&handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c&h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('head&shoulders', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h&s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('point&figure', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p&f', 'point and figure', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    ",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('s&p', 'SP500', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('q&a', 'question and answer', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('&', ' and ', regex=False)\n\t## FIX USER TAGS AND HASTAGS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#[a-z0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('@', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('#', '', regex=False)\n\t## FIX EMBEDDED COMMAS AND PERIODS    \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) ",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]),([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]),([0-9])', r'\\1\\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])[+]+', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(',', '', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('u.s.', ' us ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('\\.{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('pdating', 'updating', regex=False) \n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])\\.', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'\\.([a-z])', r' \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' . ', ' ', regex=False)\n\t## FIX + SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'[+]([0-9])', r'positive \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('c+h', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('h+s', 'head and shoulders', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('cup+handle', 'cup and handle', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' + ', ' and ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+ ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[+]([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('+', '', regex=False)\n\t## FIX - SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])[-]+([a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z]) - ([a-z])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) -([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r' [-]([0-9])', r' negative \\1', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])-([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]) - ([0-9\\.])', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9a-z])-([0-9a-z])', r'\\1 \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[-]+[>]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [-]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('-', ' ', regex=False)\n\t## FIX $ SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[$][0-9\\.]', ' dollars ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('$', '', regex=False)\n\t## FIX = SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('=', ' equals ', regex=False)\n\t## FIX / SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/c', ' because ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/out', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('b/o', ' break out ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('p/e', ' pe ratio ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [/]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/2 ', ' .5 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/4 ', ' .25 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3/4 ', ' .75 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1/3 ', ' .3 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2/3 ', ' .6 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[/]{2,}', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([a-z])/([a-z])', r'\\1 and \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+/[0-9]+/[0-9]+', '', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{3,})/([0-9\\.]{2,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]{2,})/([0-9\\.]{3,})', r'\\1 to \\2', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[a-z0-9]+/[a-z0-9]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('/', '', regex=False)\n\t## FIX < > SYMBOLS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[<]+ ', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('<', ' less than ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' [>]+', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('>', ' greater than ', regex=False)\n\t## FIX : SYMBOL\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]+am', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('[0-9]+:[0-9]', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(':', ' ', regex=False)\n\t## FIX UNITS\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('user ', ' ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)dma', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'dma([0-9]+)', r'\\1 displaced moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)sma', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'sma([0-9]+)', r'\\1 simple moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ema', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ema([0-9]+)', r'\\1 expontential moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9]+)ma', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'ma([0-9]+)', r'\\1 moving average ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mos', r'\\1 months ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minute', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])minutes', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])min', r'\\1 minute ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mins', r'\\1 minutes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])day', r'\\1 day ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])days', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wk', r'\\1 week ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wk ', ' week ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' wknd ', ' weekend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])wks', r'\\1 weeks ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hours', r'\\1 hours ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])hour', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yr', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])yrs', r'\\1 years ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' yr', ' year ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])am', r'\\1 am ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])pm', r'\\1 pm ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])est', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])ish', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9 ])pts', r'\\1 points ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])x', r'\\1 times ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])th', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])rd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])st', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])nd', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('mrkt', 'market', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' vol ', ' volume ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ptrend', ' positive trend ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' ppl', ' people ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pts', ' points ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' pt', ' point ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' l(ol){1,}', ' laugh ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('imho', ' in my opinion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace('prev ', 'previous ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 1q', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 2q', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 3q', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 4q', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q1', ' first quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q2', ' second quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q3', ' third quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' q4', ' fourth quarter ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' 10q ', ' form 10 ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])million', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])mil', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' mil ', ' million ', regex=False)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])billion', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])cents', r'\\1 cents ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])3d', r'\\1 3 dimensional ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])gb', r'\\1 3 gigabytes ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])c', r'\\1 calls ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])y', r'\\1 year ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])p', r'\\1 puts ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])d', r'\\1 days ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])h', r'\\1 hour ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])s', r'\\1 ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k1', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])k', r'\\1 thousand ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])m', r'\\1 million ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])b', r'\\1 billion ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].replace(r'([0-9])([a-z])', r'\\1 \\2', regex=True)\n\t## FIX EXTRA SPACES AND ENDING PUNCTUATION\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.replace(' +', ' ', regex=True)\n\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "\tdata['Text_Cleaned']",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "peekOfCode": "\tdata['Text_Cleaned'] = data['Text_Cleaned'].str.strip(' .!?,)(:-')\n\treturn data",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.preprocess",
        "documentation": {}
    },
    {
        "label": "ticker",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "ticker = st.sidebar.text_input('Ticker')\nstart_date = st.sidebar.date_input('Start Date')\nend_date = st.sidebar.date_input('End Date')\n# Check if the ticker and start date are provided\nif ticker and start_date:\n    # Fetch historical stock data\n    data = yf.download(ticker, start=start_date, end=end_date)\n    # Check if data is available\n    if not data.empty:\n        # Display the fetched data in a line chart",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "start_date = st.sidebar.date_input('Start Date')\nend_date = st.sidebar.date_input('End Date')\n# Check if the ticker and start date are provided\nif ticker and start_date:\n    # Fetch historical stock data\n    data = yf.download(ticker, start=start_date, end=end_date)\n    # Check if data is available\n    if not data.empty:\n        # Display the fetched data in a line chart\n        fig = px.line(data, x=data.index, y='Close', title=f'{ticker} Stock Price')",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "end_date = st.sidebar.date_input('End Date')\n# Check if the ticker and start date are provided\nif ticker and start_date:\n    # Fetch historical stock data\n    data = yf.download(ticker, start=start_date, end=end_date)\n    # Check if data is available\n    if not data.empty:\n        # Display the fetched data in a line chart\n        fig = px.line(data, x=data.index, y='Close', title=f'{ticker} Stock Price')\n        st.plotly_chart(fig)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "start = \"2011-02-01\"\nend = \"2019-12-31\"\nuser_input = st.text_input(\"Enter Stock Ticker\", \"AAPL\")\ndf = yf.download(user_input, start=start, end=end)\ndf = df.reset_index()\ndf = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "end",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "end = \"2019-12-31\"\nuser_input = st.text_input(\"Enter Stock Ticker\", \"AAPL\")\ndf = yf.download(user_input, start=start, end=end)\ndf = df.reset_index()\ndf = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "user_input",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "user_input = st.text_input(\"Enter Stock Ticker\", \"AAPL\")\ndf = yf.download(user_input, start=start, end=end)\ndf = df.reset_index()\ndf = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization\nst.subheader(\"Closing Price vs Time Chart\")",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "df = yf.download(user_input, start=start, end=end)\ndf = df.reset_index()\ndf = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization\nst.subheader(\"Closing Price vs Time Chart\")\nfig = plt.figure(figsize=(12, 6))",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "df = df.reset_index()\ndf = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization\nst.subheader(\"Closing Price vs Time Chart\")\nfig = plt.figure(figsize=(12, 6))\nplt.plot(df.Close)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "df = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization\nst.subheader(\"Closing Price vs Time Chart\")\nfig = plt.figure(figsize=(12, 6))\nplt.plot(df.Close)\nst.pyplot(fig)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "fig = plt.figure(figsize=(12, 6))\nplt.plot(df.Close)\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA\")\nma100 = df.Close.rolling(100).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100)\nplt.plot(df.Close)\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA and 200MA\")",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "ma100",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "ma100 = df.Close.rolling(100).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100)\nplt.plot(df.Close)\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA and 200MA\")\nma100 = df.Close.rolling(100).mean()\nma200 = df.Close.rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "fig = plt.figure(figsize=(12, 6))\nplt.plot(ma100)\nplt.plot(df.Close)\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA and 200MA\")\nma100 = df.Close.rolling(100).mean()\nma200 = df.Close.rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "ma100",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "ma100 = df.Close.rolling(100).mean()\nma200 = df.Close.rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")\nplt.plot(df.Close)\nst.pyplot(fig)\ndata_training = pd.DataFrame(df[\"Close\"][0:int(len(df) * 0.70)])\ndata_testing = pd.DataFrame(df[\"Close\"][int(len(df) * 0.70):int(len(df))])\nif len(data_testing) > 0:",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "ma200",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "ma200 = df.Close.rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")\nplt.plot(df.Close)\nst.pyplot(fig)\ndata_training = pd.DataFrame(df[\"Close\"][0:int(len(df) * 0.70)])\ndata_testing = pd.DataFrame(df[\"Close\"][int(len(df) * 0.70):int(len(df))])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "fig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")\nplt.plot(df.Close)\nst.pyplot(fig)\ndata_training = pd.DataFrame(df[\"Close\"][0:int(len(df) * 0.70)])\ndata_testing = pd.DataFrame(df[\"Close\"][int(len(df) * 0.70):int(len(df))])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_training_array = scaler.fit_transform(data_training)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "data_training",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "data_training = pd.DataFrame(df[\"Close\"][0:int(len(df) * 0.70)])\ndata_testing = pd.DataFrame(df[\"Close\"][int(len(df) * 0.70):int(len(df))])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_training_array = scaler.fit_transform(data_training)\n    model = load_model(\"stock_sentiment_model.pt.h5\")\n    # Feeding model with past 100 days of data\n    # Testing part\n    past_100_days = data_training.tail(100)\n    final_df = past_100_days.append(data_testing, ignore_index=True)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "data_testing",
        "kind": 5,
        "importPath": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "description": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "peekOfCode": "data_testing = pd.DataFrame(df[\"Close\"][int(len(df) * 0.70):int(len(df))])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_training_array = scaler.fit_transform(data_training)\n    model = load_model(\"stock_sentiment_model.pt.h5\")\n    # Feeding model with past 100 days of data\n    # Testing part\n    past_100_days = data_training.tail(100)\n    final_df = past_100_days.append(data_testing, ignore_index=True)\n    input_data = scaler.transform(final_df)",
        "detail": "pages2.Stock-Market-Trend-Prediction-Using-Sentiment-Analysis.streamlit_app",
        "documentation": {}
    },
    {
        "label": "aapl_model",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.demos.PredictionDemo_AAPL",
        "description": "pages2.Stock-Prediction.demos.PredictionDemo_AAPL",
        "peekOfCode": "aapl_model = StockModel('AAPL')\naapl_model.loadStock()\nmodel, history = aapl_model.train()\nrmse = aapl_model.validate(model)\naapl_model.plotOneDayCurve(model)\naapl_model.plotFutureCurves(model)\naapl_model.plotBuySellPoints(model)\naapl_model.plotPortfolioReturn(model)",
        "detail": "pages2.Stock-Prediction.demos.PredictionDemo_AAPL",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.demos.PredictionDemo_AAPL",
        "description": "pages2.Stock-Prediction.demos.PredictionDemo_AAPL",
        "peekOfCode": "rmse = aapl_model.validate(model)\naapl_model.plotOneDayCurve(model)\naapl_model.plotFutureCurves(model)\naapl_model.plotBuySellPoints(model)\naapl_model.plotPortfolioReturn(model)",
        "detail": "pages2.Stock-Prediction.demos.PredictionDemo_AAPL",
        "documentation": {}
    },
    {
        "label": "aapl_model",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "aapl_model = StockModel('AAPL')\n# optimize lookback ==> 7\nprint \"...tuning lookback\"\nlookback_range = [7, 14, 21, 28, 35]\nlookback_rmse = []\nfor e,lookback in enumerate(lookback_range):\n    aapl_model.loadStock(lookback=lookback, validation_split=True)\n    model, history = aapl_model.train(lstm_dim1=128, lstm_dim2=128, dropout=0.2, dense_dim1=None, epochs=50)\n    rmse = aapl_model.validate(model)\n    lookback_rmse.append(rmse)",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "lookback_range",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "lookback_range = [7, 14, 21, 28, 35]\nlookback_rmse = []\nfor e,lookback in enumerate(lookback_range):\n    aapl_model.loadStock(lookback=lookback, validation_split=True)\n    model, history = aapl_model.train(lstm_dim1=128, lstm_dim2=128, dropout=0.2, dense_dim1=None, epochs=50)\n    rmse = aapl_model.validate(model)\n    lookback_rmse.append(rmse)\n    print \"%i/%i lookback tunings complete.\" % (e+1,len(lookback_range))\nplotHyperparameterTuning(lookback_range, lookback_rmse, 'lookback')\n# optimize lstm_dim1 ==> 512",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "lookback_rmse",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "lookback_rmse = []\nfor e,lookback in enumerate(lookback_range):\n    aapl_model.loadStock(lookback=lookback, validation_split=True)\n    model, history = aapl_model.train(lstm_dim1=128, lstm_dim2=128, dropout=0.2, dense_dim1=None, epochs=50)\n    rmse = aapl_model.validate(model)\n    lookback_rmse.append(rmse)\n    print \"%i/%i lookback tunings complete.\" % (e+1,len(lookback_range))\nplotHyperparameterTuning(lookback_range, lookback_rmse, 'lookback')\n# optimize lstm_dim1 ==> 512\nprint \"...tuning lstm_dim1\"",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "lstm_dim1_range",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "lstm_dim1_range = [16, 32, 64, 128, 256, 512, 1024]\nlstm_dim1_rmse = []\nfor e,lstm_dim1 in enumerate(lstm_dim1_range):\n    model, history = aapl_model.train(lstm_dim1=lstm_dim1, lstm_dim2=128, dropout=0.2, dense_dim1=None, epochs=100)\n    rmse = aapl_model.validate(model)\n    lstm_dim1_rmse.append(rmse)\n    print \"%i/%i lstm_dim1 tunings complete.\" % (e+1,len(lstm_dim1_range))\nplotHyperparameterTuning(lstm_dim1_range, lstm_dim1_rmse, 'lstm_dim1')\n# optimize lstm_dim2 ==> 256\nprint \"...tuning lstm_dim2\"",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "lstm_dim1_rmse",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "lstm_dim1_rmse = []\nfor e,lstm_dim1 in enumerate(lstm_dim1_range):\n    model, history = aapl_model.train(lstm_dim1=lstm_dim1, lstm_dim2=128, dropout=0.2, dense_dim1=None, epochs=100)\n    rmse = aapl_model.validate(model)\n    lstm_dim1_rmse.append(rmse)\n    print \"%i/%i lstm_dim1 tunings complete.\" % (e+1,len(lstm_dim1_range))\nplotHyperparameterTuning(lstm_dim1_range, lstm_dim1_rmse, 'lstm_dim1')\n# optimize lstm_dim2 ==> 256\nprint \"...tuning lstm_dim2\"\nlstm_dim2_range = [16, 32, 64, 128, 256, 512, 1024]",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "lstm_dim2_range",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "lstm_dim2_range = [16, 32, 64, 128, 256, 512, 1024]\nlstm_dim2_rmse = []\nfor e,lstm_dim2 in enumerate(lstm_dim2_range):\n    model, history = aapl_model.train(lstm_dim1=512, lstm_dim2=lstm_dim2, dropout=0.2, dense_dim1=None, epochs=100)\n    rmse = aapl_model.validate(model)\n    lstm_dim2_rmse.append(rmse)\n    print \"%i/%i lstm_dim2 tunings complete.\" % (e+1,len(lstm_dim2_range))\nplotHyperparameterTuning(lstm_dim2_range, lstm_dim2_rmse, 'lstm_dim2')\n# optimize dropout ==> 0.3\nprint \"...tuning dropout\"",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "lstm_dim2_rmse",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "lstm_dim2_rmse = []\nfor e,lstm_dim2 in enumerate(lstm_dim2_range):\n    model, history = aapl_model.train(lstm_dim1=512, lstm_dim2=lstm_dim2, dropout=0.2, dense_dim1=None, epochs=100)\n    rmse = aapl_model.validate(model)\n    lstm_dim2_rmse.append(rmse)\n    print \"%i/%i lstm_dim2 tunings complete.\" % (e+1,len(lstm_dim2_range))\nplotHyperparameterTuning(lstm_dim2_range, lstm_dim2_rmse, 'lstm_dim2')\n# optimize dropout ==> 0.3\nprint \"...tuning dropout\"\ndropout_range = [0, .1, .2, .3, .4]",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "dropout_range",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "dropout_range = [0, .1, .2, .3, .4]\ndropout_rmse = []\nfor e,dropout in enumerate(dropout_range):\n    model, history = aapl_model.train(lstm_dim1=512, lstm_dim2=256, dropout=dropout, dense_dim1=None, epochs=100)\n    rmse = aapl_model.validate(model)\n    dropout_rmse.append(rmse)\n    print \"%i/%i dropout tunings complete.\" % (e+1,len(dropout_range))\nplotHyperparameterTuning(dropout_range, dropout_rmse, 'dropout')\n# optimize dense_dim1 ==> 16\nprint \"...tuning dense_dim1\"",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "dropout_rmse",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "dropout_rmse = []\nfor e,dropout in enumerate(dropout_range):\n    model, history = aapl_model.train(lstm_dim1=512, lstm_dim2=256, dropout=dropout, dense_dim1=None, epochs=100)\n    rmse = aapl_model.validate(model)\n    dropout_rmse.append(rmse)\n    print \"%i/%i dropout tunings complete.\" % (e+1,len(dropout_range))\nplotHyperparameterTuning(dropout_range, dropout_rmse, 'dropout')\n# optimize dense_dim1 ==> 16\nprint \"...tuning dense_dim1\"\ndense_dim1_range = [0, 4, 8, 16, 32]",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "dense_dim1_range",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "dense_dim1_range = [0, 4, 8, 16, 32]\ndense_dim1_rmse = []\nfor e,dense_dim1 in enumerate(dense_dim1_range):\n    if dense_dim1 == 0:\n        dense_dim1 = None\n    model, history = aapl_model.train(lstm_dim1=512, lstm_dim2=256, dropout=0.3, dense_dim1=dense_dim1, epochs=100)\n    rmse = aapl_model.validate(model)\n    dense_dim1_rmse.append(rmse)\n    print \"%i/%i dense_dim1 tunings complete.\" % (e+1,len(dense_dim1_range))\nplotHyperparameterTuning(dense_dim1_range, dense_dim1_rmse, 'dense_dim1')",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "dense_dim1_rmse",
        "kind": 5,
        "importPath": "pages2.Stock-Prediction.hyperparameters.tuning",
        "description": "pages2.Stock-Prediction.hyperparameters.tuning",
        "peekOfCode": "dense_dim1_rmse = []\nfor e,dense_dim1 in enumerate(dense_dim1_range):\n    if dense_dim1 == 0:\n        dense_dim1 = None\n    model, history = aapl_model.train(lstm_dim1=512, lstm_dim2=256, dropout=0.3, dense_dim1=dense_dim1, epochs=100)\n    rmse = aapl_model.validate(model)\n    dense_dim1_rmse.append(rmse)\n    print \"%i/%i dense_dim1 tunings complete.\" % (e+1,len(dense_dim1_range))\nplotHyperparameterTuning(dense_dim1_range, dense_dim1_rmse, 'dense_dim1')",
        "detail": "pages2.Stock-Prediction.hyperparameters.tuning",
        "documentation": {}
    },
    {
        "label": "MomentumAgent",
        "kind": 6,
        "importPath": "pages2.Stock-Prediction.models.momentum",
        "description": "pages2.Stock-Prediction.models.momentum",
        "peekOfCode": "class MomentumAgent(StockModel):\n    def _decideBuySell(self, startpoint, days_topredict, model, return_threshold):\n        '''\n        predict future prices and return a market decision\n        - returns True: \"buy long\"\n        - returns False: \"sell short\"\n        - returns None: \"do nothing\"\n        '''\n        if self.y_test[startpoint-1] > self.y_test[startpoint-2]:\n            return True",
        "detail": "pages2.Stock-Prediction.models.momentum",
        "documentation": {}
    },
    {
        "label": "prettify_ax",
        "kind": 2,
        "importPath": "pages2.Stock-Prediction.helpers",
        "description": "pages2.Stock-Prediction.helpers",
        "peekOfCode": "def prettify_ax(ax):\n    ''' make an axis pretty '''\n    for spine in ax.spines.itervalues():\n        spine.set_visible(False)\n    ax.set_frameon=True\n    ax.patch.set_facecolor('#eeeeef')\n    ax.grid('on', color='w', linestyle='-', linewidth=1)\n    ax.tick_params(direction='out')\n    ax.set_axisbelow(True)\ndef simple_ax(figsize=(6,4), **kwargs):",
        "detail": "pages2.Stock-Prediction.helpers",
        "documentation": {}
    },
    {
        "label": "simple_ax",
        "kind": 2,
        "importPath": "pages2.Stock-Prediction.helpers",
        "description": "pages2.Stock-Prediction.helpers",
        "peekOfCode": "def simple_ax(figsize=(6,4), **kwargs):\n    ''' single prettified axis '''\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111, **kwargs)\n    prettify_ax(ax)\n    return fig, ax\ndef earliest_date_after(query_date, date_list):\n    ''' find the earliest date after a query date from ordered list of dates '''\n    for i in range(len(date_list)):\n        if query_date < date_list[i].date():",
        "detail": "pages2.Stock-Prediction.helpers",
        "documentation": {}
    },
    {
        "label": "earliest_date_after",
        "kind": 2,
        "importPath": "pages2.Stock-Prediction.helpers",
        "description": "pages2.Stock-Prediction.helpers",
        "peekOfCode": "def earliest_date_after(query_date, date_list):\n    ''' find the earliest date after a query date from ordered list of dates '''\n    for i in range(len(date_list)):\n        if query_date < date_list[i].date():\n            return date_list[i].date()\n    print '\\nQUERY DATE ERROR WITH:', query_date, '\\n'\n    raise Exception('No values after query date')\ndef latest_date_before(query_date, date_list):\n    ''' find the latest date before a query date from ordered list of dates '''\n    for i in range(len(date_list)):",
        "detail": "pages2.Stock-Prediction.helpers",
        "documentation": {}
    },
    {
        "label": "latest_date_before",
        "kind": 2,
        "importPath": "pages2.Stock-Prediction.helpers",
        "description": "pages2.Stock-Prediction.helpers",
        "peekOfCode": "def latest_date_before(query_date, date_list):\n    ''' find the latest date before a query date from ordered list of dates '''\n    for i in range(len(date_list)):\n        if query_date < date_list[i].date():\n            if i==0:\n                print '\\nQUERY DATE ERROR WITH:', query_date, '\\n'\n                raise Exception('No values before query date in list')\n            return date_list[i-1].date()\n    print '\\nQUERY DATE ERROR WITH:', query_date, '\\n'\n    raise Exception('No values after query date in list; this could densensitize model')",
        "detail": "pages2.Stock-Prediction.helpers",
        "documentation": {}
    },
    {
        "label": "inv_price_transform",
        "kind": 2,
        "importPath": "pages2.Stock-Prediction.helpers",
        "description": "pages2.Stock-Prediction.helpers",
        "peekOfCode": "def inv_price_transform(normalized_data, scaler):\n    ''' inverse from normalized price to raw price '''\n    m = scaler.mean_[0]\n    s = scaler.scale_[0]\n    return s*np.array(normalized_data)+m\ndef plotHyperparameterTuning(x, y, param_name):\n    ''' plot a hyperparameter tuning curve '''\n    f,a = simple_ax(figsize=(10,6))\n    a.plot(x,y)\n    a.set_xlabel(param_name)",
        "detail": "pages2.Stock-Prediction.helpers",
        "documentation": {}
    },
    {
        "label": "plotHyperparameterTuning",
        "kind": 2,
        "importPath": "pages2.Stock-Prediction.helpers",
        "description": "pages2.Stock-Prediction.helpers",
        "peekOfCode": "def plotHyperparameterTuning(x, y, param_name):\n    ''' plot a hyperparameter tuning curve '''\n    f,a = simple_ax(figsize=(10,6))\n    a.plot(x,y)\n    a.set_xlabel(param_name)\n    a.set_ylabel('RMSE')\n    a.set_title('RMSE vs %s on Validation Set' % param_name)\n    plt.savefig('hyperparameters/curves/%s.png' % param_name)\n    print \"%s tuning complete and curve saved to /hyperparameters/curves/\\n\\n\" % param_name",
        "detail": "pages2.Stock-Prediction.helpers",
        "documentation": {}
    },
    {
        "label": "StockModel",
        "kind": 6,
        "importPath": "pages2.Stock-Prediction.lstm",
        "description": "pages2.Stock-Prediction.lstm",
        "peekOfCode": "class StockModel():\n    def __init__(self, \\\n                 ticker, \\\n                 stock_file = 'data/stock/prices-split-adjusted.csv', \\\n                 news_directory = 'data/news/', \\\n                 econ_file = 'data/market/economic_indicators.csv', \\\n                 reddit_file = 'data/market/reddit_sentiments.csv'):\n        self.ticker = ticker\n        self.__stockFile = stock_file\n        self.__newsDirectory = news_directory",
        "detail": "pages2.Stock-Prediction.lstm",
        "documentation": {}
    },
    {
        "label": "AlpacaBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.alpaca_backtesting",
        "description": "pages2.lumibot.backtesting.alpaca_backtesting",
        "peekOfCode": "class AlpacaBacktesting(DataSourceBacktesting, AlpacaData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        # raise Exception(\"AlpacaBacktesting is not currently operational\")\n        AlpacaData.__init__(self, **kwargs)\n        DataSourceBacktesting.__init__(self, datetime_start, datetime_end)\n# from lumibot.data_sources import AlpacaData\n# class AlpacaDataBacktesting(AlpacaData):\n#     \"\"\"\n#     AlpacaDataBacktesting is a DataSourceBacktesting that uses AlpacaData as a\n#     backtesting data source.",
        "detail": "pages2.lumibot.backtesting.alpaca_backtesting",
        "documentation": {}
    },
    {
        "label": "AlphaVantageBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.alpha_vantage_backtesting",
        "description": "pages2.lumibot.backtesting.alpha_vantage_backtesting",
        "peekOfCode": "class AlphaVantageBacktesting(DataSourceBacktesting, AlphaVantageData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        raise Exception(\"AlphaVantageBacktesting is not currently operational\")\n        AlphaVantageData.__init__(self, **kwargs)\n        DataSourceBacktesting.__init__(self, datetime_start, datetime_end)",
        "detail": "pages2.lumibot.backtesting.alpha_vantage_backtesting",
        "documentation": {}
    },
    {
        "label": "BacktestingBroker",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.backtesting_broker",
        "description": "pages2.lumibot.backtesting.backtesting_broker",
        "peekOfCode": "class BacktestingBroker(Broker):\n    # Metainfo\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, data_source, option_source=None, connect_stream=True, max_workers=20, config=None, **kwargs):\n        super().__init__(name=\"backtesting\", data_source=data_source,\n                         option_source=option_source, connect_stream=connect_stream, **kwargs)\n        # Calling init methods\n        self.max_workers = max_workers\n        self.market = \"NASDAQ\"\n        self.option_source = option_source",
        "detail": "pages2.lumibot.backtesting.backtesting_broker",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.backtesting.backtesting_broker",
        "description": "pages2.lumibot.backtesting.backtesting_broker",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass BacktestingBroker(Broker):\n    # Metainfo\n    IS_BACKTESTING_BROKER = True\n    def __init__(self, data_source, option_source=None, connect_stream=True, max_workers=20, config=None, **kwargs):\n        super().__init__(name=\"backtesting\", data_source=data_source,\n                         option_source=option_source, connect_stream=connect_stream, **kwargs)\n        # Calling init methods\n        self.max_workers = max_workers\n        self.market = \"NASDAQ\"",
        "detail": "pages2.lumibot.backtesting.backtesting_broker",
        "documentation": {}
    },
    {
        "label": "CcxtBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.ccxt_backtesting",
        "description": "pages2.lumibot.backtesting.ccxt_backtesting",
        "peekOfCode": "class CcxtBacktesting(CcxtBacktestingData):\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        CcxtBacktestingData.__init__(self, datetime_start, datetime_end, **kwargs)",
        "detail": "pages2.lumibot.backtesting.ccxt_backtesting",
        "documentation": {}
    },
    {
        "label": "PandasDataBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.pandas_backtesting",
        "description": "pages2.lumibot.backtesting.pandas_backtesting",
        "peekOfCode": "class PandasDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of the PandasData class.  This class is just kept around for legacy purposes.\n    Please just use PandasData directly instead.\n    \"\"\"\n    def __init__(self, *args, pandas_data=None, **kwargs):\n        super().__init__(*args, pandas_data=pandas_data, **kwargs)",
        "detail": "pages2.lumibot.backtesting.pandas_backtesting",
        "documentation": {}
    },
    {
        "label": "PolygonDataBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.polygon_backtesting",
        "description": "pages2.lumibot.backtesting.polygon_backtesting",
        "peekOfCode": "class PolygonDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of Polygon\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,\n        api_key=None,",
        "detail": "pages2.lumibot.backtesting.polygon_backtesting",
        "documentation": {}
    },
    {
        "label": "START_BUFFER",
        "kind": 5,
        "importPath": "pages2.lumibot.backtesting.polygon_backtesting",
        "description": "pages2.lumibot.backtesting.polygon_backtesting",
        "peekOfCode": "START_BUFFER = timedelta(days=5)\nclass PolygonDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of Polygon\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,",
        "detail": "pages2.lumibot.backtesting.polygon_backtesting",
        "documentation": {}
    },
    {
        "label": "ThetaDataBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.thetadata_backtesting",
        "description": "pages2.lumibot.backtesting.thetadata_backtesting",
        "peekOfCode": "class ThetaDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of ThetaData\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,\n        username=None,",
        "detail": "pages2.lumibot.backtesting.thetadata_backtesting",
        "documentation": {}
    },
    {
        "label": "START_BUFFER",
        "kind": 5,
        "importPath": "pages2.lumibot.backtesting.thetadata_backtesting",
        "description": "pages2.lumibot.backtesting.thetadata_backtesting",
        "peekOfCode": "START_BUFFER = timedelta(days=5)\nclass ThetaDataBacktesting(PandasData):\n    \"\"\"\n    Backtesting implementation of ThetaData\n    \"\"\"\n    def __init__(\n        self,\n        datetime_start,\n        datetime_end,\n        pandas_data=None,",
        "detail": "pages2.lumibot.backtesting.thetadata_backtesting",
        "documentation": {}
    },
    {
        "label": "YahooDataBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.backtesting.yahoo_backtesting",
        "description": "pages2.lumibot.backtesting.yahoo_backtesting",
        "peekOfCode": "class YahooDataBacktesting(YahooData):\n    \"\"\"\n    YahooDataBacktesting is a DataSourceBacktesting that uses YahooData as a\n    backtesting data source.\n    \"\"\"\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        YahooData.__init__(self, datetime_start, datetime_end, **kwargs)",
        "detail": "pages2.lumibot.backtesting.yahoo_backtesting",
        "documentation": {}
    },
    {
        "label": "OrderData",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.alpaca",
        "description": "pages2.lumibot.brokers.alpaca",
        "peekOfCode": "class OrderData:\n    def __init__(self, **kwargs):\n        self.__dict__.update(kwargs)\n    def to_request_fields(self):\n        return self.__dict__\nclass Alpaca(Broker):\n    \"\"\"A broker class that connects to Alpaca\n    Attributes\n    ----------\n    api : tradeapi.REST",
        "detail": "pages2.lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "Alpaca",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.alpaca",
        "description": "pages2.lumibot.brokers.alpaca",
        "peekOfCode": "class Alpaca(Broker):\n    \"\"\"A broker class that connects to Alpaca\n    Attributes\n    ----------\n    api : tradeapi.REST\n        Alpaca API object\n    Methods\n    -------\n    get_timestamp()\n        Returns the current UNIX timestamp representation from Alpaca",
        "detail": "pages2.lumibot.brokers.alpaca",
        "documentation": {}
    },
    {
        "label": "CustomLoggerAdapter",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.broker",
        "description": "pages2.lumibot.brokers.broker",
        "peekOfCode": "class CustomLoggerAdapter(logging.LoggerAdapter):\n    def process(self, msg, kwargs):\n        # Check if the level is enabled to avoid formatting costs if not necessary\n        if self.logger.isEnabledFor(kwargs.get('level', logging.INFO)):\n            # Lazy formatting of the message\n            return f'[{self.extra[\"strategy_name\"]}] {msg}', kwargs\n        else:\n            return msg, kwargs\n    def update_strategy_name(self, new_strategy_name):\n        self.extra['strategy_name'] = new_strategy_name",
        "detail": "pages2.lumibot.brokers.broker",
        "documentation": {}
    },
    {
        "label": "Broker",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.broker",
        "description": "pages2.lumibot.brokers.broker",
        "peekOfCode": "class Broker(ABC):\n    # Metainfo\n    IS_BACKTESTING_BROKER = False\n    # Trading events flags\n    NEW_ORDER = \"new\"\n    CANCELED_ORDER = \"canceled\"\n    FILLED_ORDER = \"fill\"\n    PARTIALLY_FILLED_ORDER = \"partial_fill\"\n    CASH_SETTLED = \"cash_settled\"\n    ERROR_ORDER = \"error\"",
        "detail": "pages2.lumibot.brokers.broker",
        "documentation": {}
    },
    {
        "label": "Ccxt",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.ccxt",
        "description": "pages2.lumibot.brokers.ccxt",
        "peekOfCode": "class Ccxt(Broker):\n    \"\"\"\n    Crypto broker using CCXT.\n    \"\"\"\n    def __init__(self, config, data_source: CcxtData = None, max_workers=20, chunk_size=100, **kwargs):\n        if data_source is None:\n            data_source = CcxtData(config, max_workers=max_workers, chunk_size=chunk_size)\n        super().__init__(name=\"ccxt\", config=config, data_source=data_source, max_workers=max_workers, **kwargs)\n        self.market = \"24/7\"\n        self.fetch_open_orders_last_request_time = None",
        "detail": "pages2.lumibot.brokers.ccxt",
        "documentation": {}
    },
    {
        "label": "ExampleBroker",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.example_broker",
        "description": "pages2.lumibot.brokers.example_broker",
        "peekOfCode": "class ExampleBroker(Broker):\n    \"\"\"\n    Example broker that demonstrates how to connect to an API.\n    \"\"\"\n    NAME = \"ExampleBroker\"\n    def __init__(\n            self,\n            config=None,\n            data_source=None,\n    ):",
        "detail": "pages2.lumibot.brokers.example_broker",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokers",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class InteractiveBrokers(Broker):\n    \"\"\"Inherit InteractiveBrokerData first and all the price market\n    methods than inherits broker\"\"\"\n    def __init__(self, config, max_workers=20, chunk_size=100, data_source=None, **kwargs):\n        if data_source is None:\n            data_source = InteractiveBrokersData(config, max_workers=max_workers, chunk_size=chunk_size)\n        super().__init__(\n            name=\"interactive_brokers\", \n            config=config, \n            data_source=data_source, ",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBWrapper",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBWrapper(EWrapper):\n    \"\"\"Listens and collects data from IB.\"\"\"\n    # Error handling code.\n    def init_error(self):\n        error_queue = queue.Queue()\n        self.my_errors_queue = error_queue\n    def is_error(self):\n        error_exist = not self.my_errors_queue.empty()\n        return error_exist\n    def get_error(self, timeout=6):",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBClient",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBClient(EClient):\n    \"\"\"Sends data to IB\"\"\"\n    def __init__(self, wrapper):\n        ## Set up with a wrapper inside\n        EClient.__init__(self, wrapper)\n        self.max_wait_time = 13\n        self.reqId = 10000\n    def get_reqid(self):\n        self.reqId += 1\n        return self.reqId",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "IBApp",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "class IBApp(IBWrapper, IBClient):\n    def __init__(self, ip_address, socket_port, client_id, subaccount=None, ib_broker=None):\n        IBWrapper.__init__(self)\n        IBClient.__init__(self, wrapper=self)\n        self.ip_address = ip_address\n        self.socket_port = socket_port\n        self.client_id = client_id\n        self.ib_broker = ib_broker\n        self.subaccount = subaccount\n        self.reqAutoOpenOrders(True)",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nDATE_MAP = dict(\n    future=\"%Y%m%d\",",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "DATE_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "DATE_MAP = dict(\n    future=\"%Y%m%d\",\n    option=\"%Y%m%d\",\n)\nORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "ORDERTYPE_MAPPING",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers",
        "description": "pages2.lumibot.brokers.interactive_brokers",
        "peekOfCode": "ORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",\n)\nclass InteractiveBrokers(Broker):\n    \"\"\"Inherit InteractiveBrokerData first and all the price market\n    methods than inherits broker\"\"\"",
        "detail": "pages2.lumibot.brokers.interactive_brokers",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersREST",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.interactive_brokers_rest",
        "description": "pages2.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "class InteractiveBrokersREST(Broker):\n    \"\"\"\n    Broker that connects to the Interactive Brokers REST API.\n    \"\"\"\n    NAME = \"InteractiveBrokersREST\"\n    def __init__(self, config, data_source=None):\n        if data_source is None:\n            data_source = InteractiveBrokersRESTData(config)\n        super().__init__(name=self.NAME, data_source=data_source, config=config)\n        self.market = \"NYSE\"  # The default market is NYSE.",
        "detail": "pages2.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers_rest",
        "description": "pages2.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nDATE_MAP = dict(\n    future=\"%Y%m%d\",",
        "detail": "pages2.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "DATE_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers_rest",
        "description": "pages2.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "DATE_MAP = dict(\n    future=\"%Y%m%d\",\n    option=\"%Y%m%d\",\n)\nORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",",
        "detail": "pages2.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "ORDERTYPE_MAPPING",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers_rest",
        "description": "pages2.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "ORDERTYPE_MAPPING = dict(\n    market=\"MKT\",\n    limit=\"LMT\",\n    stop=\"STP\",\n    stop_limit=\"STP LMT\",\n    trailing_stop=\"TRAIL\",\n)\nSPREAD_CONID_MAP = {\n    \"AUD\": 61227077,\n    \"CAD\": 61227082,",
        "detail": "pages2.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "SPREAD_CONID_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers_rest",
        "description": "pages2.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "SPREAD_CONID_MAP = {\n    \"AUD\": 61227077,\n    \"CAD\": 61227082,\n    \"CHF\": 61227087,\n    \"CNH\": 136000441,\n    \"GBP\": 58666491,\n    \"HKD\": 61227072,\n    \"INR\": 136000444,\n    \"JPY\": 61227069,\n    \"KRW\": 136000424,",
        "detail": "pages2.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "ASSET_CLASS_MAPPING",
        "kind": 5,
        "importPath": "pages2.lumibot.brokers.interactive_brokers_rest",
        "description": "pages2.lumibot.brokers.interactive_brokers_rest",
        "peekOfCode": "ASSET_CLASS_MAPPING = {\n    \"STK\": Asset.AssetType.STOCK,\n    \"OPT\": Asset.AssetType.OPTION,\n    \"FUT\": Asset.AssetType.FUTURE,\n    \"CASH\": Asset.AssetType.FOREX,\n}\nclass InteractiveBrokersREST(Broker):\n    \"\"\"\n    Broker that connects to the Interactive Brokers REST API.\n    \"\"\"",
        "detail": "pages2.lumibot.brokers.interactive_brokers_rest",
        "documentation": {}
    },
    {
        "label": "Tradier",
        "kind": 6,
        "importPath": "pages2.lumibot.brokers.tradier",
        "description": "pages2.lumibot.brokers.tradier",
        "peekOfCode": "class Tradier(Broker):\n    \"\"\"\n    Broker that connects to Tradier API to place orders and retrieve data. Tradier API only supports Order streaming\n    for live accounts, paper trading accounts must use a 'polling' method to retrieve order updates. This class will\n    still use a CustomStream object to process order updates (which can be confusing!), but this will more seamlessly\n    match what other LumiBrokers are doing without requiring changes to the stategy_executor. This\n    polling method will also work for Live accounts, so it will be used by default. However, future updates will be\n    made to natively support websocket streaming for Live accounts.\n    \"\"\"\n    POLL_EVENT = PollingStream.POLL_EVENT",
        "detail": "pages2.lumibot.brokers.tradier",
        "documentation": {}
    },
    {
        "label": "AlpacaData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.alpaca_data",
        "description": "pages2.lumibot.data_sources.alpaca_data",
        "peekOfCode": "class AlpacaData(DataSource):\n    SOURCE = \"ALPACA\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"minute\",\n            \"representations\": [TimeFrame.Minute, \"minute\"],\n        },\n        {\n            \"timestep\": \"5 minutes\",",
        "detail": "pages2.lumibot.data_sources.alpaca_data",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.alpha_vantage_data",
        "description": "pages2.lumibot.data_sources.alpha_vantage_data",
        "peekOfCode": "class AlphaVantageData(DataSource):\n    SOURCE = \"ALPHA_VANTAGE\"\n    MIN_TIMESTEP = \"minute\"\n    DATA_STALE_AFTER = timedelta(days=1)\n    def __init__(self, config=None, auto_adjust=True, **kwargs):\n        self.name = \"alpha vantage\"\n        self.auto_adjust = auto_adjust\n        self._data_store = {}\n        self.config = config\n    def _append_data(self, asset, data):",
        "detail": "pages2.lumibot.data_sources.alpha_vantage_data",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.ccxt_backtesting_data",
        "description": "pages2.lumibot.data_sources.ccxt_backtesting_data",
        "peekOfCode": "class CcxtBacktestingData(DataSourceBacktesting):\n    \"\"\"Use CcxtCacheDB to download and cache data.\n    \"\"\"\n    # SOURCE must be `CCXT` for the DataSourceBacktesting to work\n    # `CCXT` is used in DataSource name\n    SOURCE = \"CCXT\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"minute\", \"representations\": [\"1m\"]},\n        {\"timestep\": \"day\", \"representations\": [\"1d\"]},",
        "detail": "pages2.lumibot.data_sources.ccxt_backtesting_data",
        "documentation": {}
    },
    {
        "label": "CcxtData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.ccxt_data",
        "description": "pages2.lumibot.data_sources.ccxt_data",
        "peekOfCode": "class CcxtData(DataSource):\n    SOURCE = \"CCXT\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"minute\", \"representations\": [\"1m\"]},\n        {\"timestep\": \"day\", \"representations\": [\"1d\"]},\n    ]\n    IS_BACKTESTING_DATA_SOURCE = False\n    \"\"\"Common base class for data_sources/ccxt and brokers/ccxt\"\"\"\n    @staticmethod",
        "detail": "pages2.lumibot.data_sources.ccxt_data",
        "documentation": {}
    },
    {
        "label": "DataSource",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.data_source",
        "description": "pages2.lumibot.data_sources.data_source",
        "peekOfCode": "class DataSource(ABC):\n    SOURCE = \"\"\n    IS_BACKTESTING_DATA_SOURCE = False\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = []\n    DEFAULT_TIMEZONE = LUMIBOT_DEFAULT_TIMEZONE\n    DEFAULT_PYTZ = LUMIBOT_DEFAULT_PYTZ\n    def __init__(self, api_key=None, delay=None):\n        \"\"\"\n        Parameters",
        "detail": "pages2.lumibot.data_sources.data_source",
        "documentation": {}
    },
    {
        "label": "DataSourceBacktesting",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.data_source_backtesting",
        "description": "pages2.lumibot.data_sources.data_source_backtesting",
        "peekOfCode": "class DataSourceBacktesting(DataSource, ABC):\n    \"\"\"\n    This class is the base class for all backtesting data sources.  It is also an abstract class and should not be\n    instantiated directly because it does not define all necessary methods. Instead, instantiate one of the\n    child classes like PandasData.\n    \"\"\"\n    IS_BACKTESTING_DATA_SOURCE = True\n    def __init__(\n        self,\n        datetime_start,",
        "detail": "pages2.lumibot.data_sources.data_source_backtesting",
        "documentation": {}
    },
    {
        "label": "ExampleBrokerData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.example_broker_data",
        "description": "pages2.lumibot.data_sources.example_broker_data",
        "peekOfCode": "class ExampleBrokerData(DataSource):\n    \"\"\"\n    Data source that connects to the Example Broker API.\n    \"\"\"\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"ExampleBroker\"\n    def __init__(self):\n        super().__init__()\n    # Method stubs with logging for not yet implemented methods\n    def get_chains(self, asset: Asset, quote: Asset = None) -> dict:",
        "detail": "pages2.lumibot.data_sources.example_broker_data",
        "documentation": {}
    },
    {
        "label": "NoDataFound",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.exceptions",
        "description": "pages2.lumibot.data_sources.exceptions",
        "peekOfCode": "class NoDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoDataFound, self).__init__(message)\nclass UnavailabeTimestep(Exception):\n    def __init__(self, source, timestep):\n        message = \"%s data source does not have data with %r timestep\" % (",
        "detail": "pages2.lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "UnavailabeTimestep",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.exceptions",
        "description": "pages2.lumibot.data_sources.exceptions",
        "peekOfCode": "class UnavailabeTimestep(Exception):\n    def __init__(self, source, timestep):\n        message = \"%s data source does not have data with %r timestep\" % (\n            source,\n            timestep,\n        )\n        super(UnavailabeTimestep, self).__init__(message)",
        "detail": "pages2.lumibot.data_sources.exceptions",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.interactive_brokers_data",
        "description": "pages2.lumibot.data_sources.interactive_brokers_data",
        "peekOfCode": "class InteractiveBrokersData(DataSource):\n    \"\"\"Make Interactive Brokers connection and gets data.\n    Create connection to Interactive Brokers market through either Gateway or TWS\n    which must be running locally for connection to be made.\n    \"\"\"\n    SOURCE = \"InteractiveBrokers\"\n    MIN_TIMESTEP = \"minute\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"second\",",
        "detail": "pages2.lumibot.data_sources.interactive_brokers_data",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.data_sources.interactive_brokers_data",
        "description": "pages2.lumibot.data_sources.interactive_brokers_data",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nclass InteractiveBrokersData(DataSource):\n    \"\"\"Make Interactive Brokers connection and gets data.",
        "detail": "pages2.lumibot.data_sources.interactive_brokers_data",
        "documentation": {}
    },
    {
        "label": "InteractiveBrokersRESTData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.interactive_brokers_rest_data",
        "description": "pages2.lumibot.data_sources.interactive_brokers_rest_data",
        "peekOfCode": "class InteractiveBrokersRESTData(DataSource):\n    \"\"\"\n    Data source that connects to the Interactive Brokers REST API.\n    \"\"\"\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"InteractiveBrokersREST\"\n    def __init__(self, config):\n        if config[\"API_URL\"] is None:\n            self.port = \"4234\"\n            self.base_url = f\"https://localhost:{self.port}/v1/api\"",
        "detail": "pages2.lumibot.data_sources.interactive_brokers_rest_data",
        "documentation": {}
    },
    {
        "label": "TYPE_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.data_sources.interactive_brokers_rest_data",
        "description": "pages2.lumibot.data_sources.interactive_brokers_rest_data",
        "peekOfCode": "TYPE_MAP = dict(\n    stock=\"STK\",\n    option=\"OPT\",\n    future=\"FUT\",\n    forex=\"CASH\",\n    index=\"IND\",\n    multileg=\"BAG\",\n)\nclass InteractiveBrokersRESTData(DataSource):\n    \"\"\"",
        "detail": "pages2.lumibot.data_sources.interactive_brokers_rest_data",
        "documentation": {}
    },
    {
        "label": "PandasData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.pandas_data",
        "description": "pages2.lumibot.data_sources.pandas_data",
        "peekOfCode": "class PandasData(DataSourceBacktesting):\n    \"\"\"\n    PandasData is a Backtesting-only DataSource that uses a Pandas DataFrame (read from CSV) as the source of\n    data for a backtest run. It is not possible to use this class to run a live trading strategy.\n    \"\"\"\n    SOURCE = \"PANDAS\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1D\", \"day\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1M\", \"minute\"]},\n    ]",
        "detail": "pages2.lumibot.data_sources.pandas_data",
        "documentation": {}
    },
    {
        "label": "TradierAPIError",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.tradier_data",
        "description": "pages2.lumibot.data_sources.tradier_data",
        "peekOfCode": "class TradierAPIError(Exception):\n    pass\nclass TradierData(DataSource):\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"Tradier\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"tick\",\n            \"representations\": [\n                \"tick\",",
        "detail": "pages2.lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "TradierData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.tradier_data",
        "description": "pages2.lumibot.data_sources.tradier_data",
        "peekOfCode": "class TradierData(DataSource):\n    MIN_TIMESTEP = \"minute\"\n    SOURCE = \"Tradier\"\n    TIMESTEP_MAPPING = [\n        {\n            \"timestep\": \"tick\",\n            \"representations\": [\n                \"tick\",\n            ],\n        },",
        "detail": "pages2.lumibot.data_sources.tradier_data",
        "documentation": {}
    },
    {
        "label": "YahooData",
        "kind": 6,
        "importPath": "pages2.lumibot.data_sources.yahoo_data",
        "description": "pages2.lumibot.data_sources.yahoo_data",
        "peekOfCode": "class YahooData(DataSourceBacktesting):\n    SOURCE = \"YAHOO\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1d\", \"day\"]},\n        {\"timestep\": \"15 minutes\", \"representations\": [\"15m\", \"15 minutes\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1m\", \"1 minute\"]},\n    ]\n    def __init__(self, *args, auto_adjust=True, **kwargs):\n        super().__init__(*args, **kwargs)",
        "detail": "pages2.lumibot.data_sources.yahoo_data",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.data_sources.yahoo_data",
        "description": "pages2.lumibot.data_sources.yahoo_data",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass YahooData(DataSourceBacktesting):\n    SOURCE = \"YAHOO\"\n    MIN_TIMESTEP = \"day\"\n    TIMESTEP_MAPPING = [\n        {\"timestep\": \"day\", \"representations\": [\"1d\", \"day\"]},\n        {\"timestep\": \"15 minutes\", \"representations\": [\"15m\", \"15 minutes\"]},\n        {\"timestep\": \"minute\", \"representations\": [\"1m\", \"1 minute\"]},\n    ]\n    def __init__(self, *args, auto_adjust=True, **kwargs):",
        "detail": "pages2.lumibot.data_sources.yahoo_data",
        "documentation": {}
    },
    {
        "label": "Asset",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.asset",
        "description": "pages2.lumibot.entities.asset",
        "peekOfCode": "class Asset:\n    \"\"\"\n    This is a base class for Assets including stocks, futures, options,\n    forex, and crypto.\n    Parameters\n    ----------\n    symbol : str\n        Symbol of the stock or underlying in case of futures/options.\n    asset_type : str\n        Type of the asset. Asset types are only 'stock', 'option', 'future', 'forex', 'crypto'",
        "detail": "pages2.lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "AssetsMapping",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.asset",
        "description": "pages2.lumibot.entities.asset",
        "peekOfCode": "class AssetsMapping(UserDict):\n    def __init__(self, mapping):\n        UserDict.__init__(self, mapping)\n        symbols_mapping = {k.symbol: v for k, v in mapping.items()}\n        self._symbols_mapping = symbols_mapping\n    def __missing__(self, key):\n        if isinstance(key, str):\n            if key in self._symbols_mapping:\n                return self._symbols_mapping[key]\n        raise KeyError(key)",
        "detail": "pages2.lumibot.entities.asset",
        "documentation": {}
    },
    {
        "label": "Bar",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.bar",
        "description": "pages2.lumibot.entities.bar",
        "peekOfCode": "class Bar(ComparaisonMixin):\n    \"\"\"\n    The Bar class represents a single bar (OHLC) of data.\n    Attributes\n    ----------\n    timestamp : datetime.datetime\n        The timestamp of the bar.\n    open : float\n        The opening price of the bar.\n    high : float",
        "detail": "pages2.lumibot.entities.bar",
        "documentation": {}
    },
    {
        "label": "Bars",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.bars",
        "description": "pages2.lumibot.entities.bars",
        "peekOfCode": "class Bars:\n    \"\"\"Pricing and financial data for given Symbol.\n    The OHLCV, and if available, dividends, stock splits for a given\n    financial instrument. Price change, dividend yield and return\n    are calculated if appropriate.\n    Parameters\n    ----------\n    df : Pandas Dataframe\n        Dataframe with:\n            datetime.datetime index time zone aware.",
        "detail": "pages2.lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "NoBarDataFound",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.bars",
        "description": "pages2.lumibot.entities.bars",
        "peekOfCode": "class NoBarDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoBarDataFound, self).__init__(message)\n    def aggregate_bars(self, frequency):\n        \"\"\"\n        Will convert a set of bars to a different timeframe (eg. 1 min to 15 min)",
        "detail": "pages2.lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "NoBarDataFound",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.bars",
        "description": "pages2.lumibot.entities.bars",
        "peekOfCode": "class NoBarDataFound(Exception):\n    def __init__(self, source, asset):\n        message = (\n            f\"{source} did not return data for symbol {asset}. \"\n            f\"Make sure there is no symbol typo or use another data source\"\n        )\n        super(NoBarDataFound, self).__init__(message)",
        "detail": "pages2.lumibot.entities.bars",
        "documentation": {}
    },
    {
        "label": "Data",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.data",
        "description": "pages2.lumibot.entities.data",
        "peekOfCode": "class Data:\n    \"\"\"Input and manage Pandas dataframes for backtesting.\n    Parameters\n    ----------\n    asset : Asset Object\n        Asset to which this data is attached.\n    df : dataframe\n        Pandas dataframe containing OHLCV etc. trade data. Loaded by user\n        from csv.\n        Index is date and must be pandas datetime64.",
        "detail": "pages2.lumibot.entities.data",
        "documentation": {}
    },
    {
        "label": "Dataline",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.dataline",
        "description": "pages2.lumibot.entities.dataline",
        "peekOfCode": "class Dataline:\n    def __init__(self, asset, name, dataline, dtype):\n        self.asset = asset\n        self.name = name\n        self.dataline = dataline\n        self.dtype = dtype",
        "detail": "pages2.lumibot.entities.dataline",
        "documentation": {}
    },
    {
        "label": "Order",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.order",
        "description": "pages2.lumibot.entities.order",
        "peekOfCode": "class Order:\n    Transaction = namedtuple(\"Transaction\", [\"quantity\", \"price\"])\n    class OrderClass:\n        BRACKET = \"bracket\"\n        OCO = \"oco\"\n        OTO = \"oto\"\n        MULTILEG = \"multileg\"\n    class OrderType:\n        MARKET = \"market\"\n        LIMIT = \"limit\"",
        "detail": "pages2.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "SELL",
        "kind": 5,
        "importPath": "pages2.lumibot.entities.order",
        "description": "pages2.lumibot.entities.order",
        "peekOfCode": "SELL = \"sell\"\nBUY = \"buy\"\nVALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status",
        "detail": "pages2.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "BUY",
        "kind": 5,
        "importPath": "pages2.lumibot.entities.order",
        "description": "pages2.lumibot.entities.order",
        "peekOfCode": "BUY = \"buy\"\nVALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status",
        "detail": "pages2.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "VALID_STATUS",
        "kind": 5,
        "importPath": "pages2.lumibot.entities.order",
        "description": "pages2.lumibot.entities.order",
        "peekOfCode": "VALID_STATUS = [\"unprocessed\", \"new\", \"open\", \"submitted\", \"fill\", \"partial_fill\", \"cancelling\", \"canceled\", \"error\", \"cash_settled\"]\nSTATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status\n    \"presubmitted\": \"new\",  # IBKR status",
        "detail": "pages2.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "STATUS_ALIAS_MAP",
        "kind": 5,
        "importPath": "pages2.lumibot.entities.order",
        "description": "pages2.lumibot.entities.order",
        "peekOfCode": "STATUS_ALIAS_MAP = {\n    \"cancelled\": \"canceled\",\n    \"cancel\": \"canceled\",\n    \"cash\": \"cash_settled\",\n    \"expired\": \"canceled\",  # Alpaca/Tradier status\n    \"filled\": \"fill\",  # Alpaca/Tradier status\n    \"partially_filled\": \"partial_filled\",  # Alpaca/Tradier status\n    \"pending\": \"open\",  # Tradier status\n    \"presubmitted\": \"new\",  # IBKR status\n    \"rejected\": \"error\",  # Tradier status",
        "detail": "pages2.lumibot.entities.order",
        "documentation": {}
    },
    {
        "label": "Position",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.position",
        "description": "pages2.lumibot.entities.position",
        "peekOfCode": "class Position:\n    \"\"\"\n    This is a Position object. It is used to keep track of the quantity of an asset owned in a strategy.\n    Position objects are retreived from the broker using the get_positions() or get_position() methods.\n    Attributes\n    ----------\n    strategy : str\n        The strategy that owns this position.\n    asset : Asset\n        The asset that this position is for.",
        "detail": "pages2.lumibot.entities.position",
        "documentation": {}
    },
    {
        "label": "TradingFee",
        "kind": 6,
        "importPath": "pages2.lumibot.entities.trading_fee",
        "description": "pages2.lumibot.entities.trading_fee",
        "peekOfCode": "class TradingFee:\n    \"\"\"TradingFee class. Used to define the trading fees for a broker in a strategy/backtesting.\"\"\"\n    def __init__(self, flat_fee=0.0, percent_fee=0.0, maker=True, taker=True):\n        \"\"\"\n        Parameters\n        ----------\n        flat_fee : Decimal, float, or None\n            Flat fee to pay for each order. This is a fixed fee that is paid for each order in the quote currency.\n        percent_fee : Decimal, float, or None\n            Percentage fee to pay for each order. This is a percentage of the order value that is paid for each order in the quote currency.",
        "detail": "pages2.lumibot.entities.trading_fee",
        "documentation": {}
    },
    {
        "label": "Developing_Momentum_Trading_Strategy",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "class Developing_Momentum_Trading_Strategy:\n    # https://github.com/mjmacarty/alphavantage/blob/main/3-momentum_algorithmic.ipynb\n    # Many services for this, some paid some free\n    # Yahoo Finance API\n    # Typically trading \"systems\" involve a number of securities\n    # For this demonstration we are just going to look at GLD --> the gold ETF\n    import numpy as np\n    import pandas as pd\n    import pandas_datareader as pdr\n    import matplotlib.pyplot as plt   ",
        "detail": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "FastTrading",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "class FastTrading(Strategy):\n    # =========over loading life cycle methods\n    def initialize(self, momentum_length = 2, max_assets = 4):\n        self.momentum_length =  momentum_length # in minutes\n        self.sleeptime = 1\n         # set symbols tht we want to be monitoring\n        self.symbols = ['TSLA', 'SPY', 'GLD', 'TLT', 'MSFT', 'MCHI', 'SPXL', 'SPXS']\n        # Initialise our variables  \n        self.assets_quantity = {symbol:0 for symbol in self.symbols}\n        self.max_assets = min(max_assets, len(self.symbols))",
        "detail": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "description": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass Developing_Momentum_Trading_Strategy:\n    # https://github.com/mjmacarty/alphavantage/blob/main/3-momentum_algorithmic.ipynb\n    # Many services for this, some paid some free\n    # Yahoo Finance API\n    # Typically trading \"systems\" involve a number of securities\n    # For this demonstration we are just going to look at GLD --> the gold ETF\n    import numpy as np\n    import pandas as pd\n    import pandas_datareader as pdr",
        "detail": "pages2.lumibot.example_strategies.FastTrading.FastTrading_1",
        "documentation": {}
    },
    {
        "label": "FastTrading",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.fasttrading_2",
        "description": "pages2.lumibot.example_strategies.FastTrading.fasttrading_2",
        "peekOfCode": "class FastTrading(Strategy):\n    IS_BACKTESTING = False\n    # ===== Overloading Lifecycle Methods =====\n    def initialize(self, momentum_length=2, max_assets=4):\n        # Set symbols we want to monitor\n        self.symbols = ['TSLA', 'SPY', 'GLD', 'TLT', 'MSFT', 'MCHI', 'SPXL', 'SPXS']\n        self.momentum_length = momentum_length  # in minutes\n        self.sleeptime = 1  # Optional: For slowing down execution\n        self.frequency = \"minute\"  # For minute-level trading\n        self.max_assets = min(max_assets, len(self.symbols))  # Limit max assets to trade",
        "detail": "pages2.lumibot.example_strategies.FastTrading.fasttrading_2",
        "documentation": {}
    },
    {
        "label": "AlpacaConfig",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "AlpacaConfig = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}  \nlogfile = \"logs/test.log\"\ntrader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "logfile",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "logfile = \"logs/test.log\"\ntrader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" ",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "trader",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "trader = Trader(logfile=logfile)\nbroker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "broker = Alpaca(AlpacaConfig)\n# strategy_name = \"RedditSentiment\" \n# strategy = RedditSentiment(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"DebtTrading\" \n# strategy = DebtTrading(name=strategy_name, budget=budget, broker= broker)\nstrategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "strategy_name",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "strategy_name = \"FastTrading\" \nstrategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:\n    ###\n    # 1. Backtest the strtegy\n    ###\nbacktesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# strategy_name = \"My Strategy\" \n# strategy = FastTrading(name=strategy_name, budget=budget, broker= broker)\n# if type(strategy) != IntrdayMomentum and type(strategy) != FastTrading:\n    ###\n    # 1. Backtest the strtegy\n    ###\nbacktesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)\ndatestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "backtesting_start",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "backtesting_start = datetime(2012, 1, 1)\nbacktesting_end   = datetime(2021, 1, 1)\ndatestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")\nstats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "datestring",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "datestring = datetime.now.strftime(\"%Y-%m-%d %H:%M:%S\")\nstats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,\n    stats_file=stats_file\n) ",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "stats_file",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.FastTrading.main",
        "description": "pages2.lumibot.example_strategies.FastTrading.main",
        "peekOfCode": "stats_file = f\"logs/{strategy_name}_{datestring}.csv\"\n# Run the actual backtest\nprint(f\"Starting Backtest...\")\nstrategy.backtest(\n    YahooDataBacktesting, \n    backtesting_start, \n    backtesting_end,\n    stats_file=stats_file\n) \n###",
        "detail": "pages2.lumibot.example_strategies.FastTrading.main",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingExampleStrategy",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.ccxt_backtesting_example",
        "description": "pages2.lumibot.example_strategies.ccxt_backtesting_example",
        "peekOfCode": "class CcxtBacktestingExampleStrategy(Strategy):\n    def initialize(self, asset:tuple[Asset,Asset] = None,\n                   cash_at_risk:float=.25,window:int=21):\n        if asset is None:\n            raise ValueError(\"You must provide a valid asset pair\")\n        # for crypto, market is 24/7\n        self.set_market(\"24/7\")\n        self.sleeptime = \"1D\"\n        self.asset = asset\n        self.base, self.quote = asset",
        "detail": "pages2.lumibot.example_strategies.ccxt_backtesting_example",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.crypto_important_functions",
        "description": "pages2.lumibot.example_strategies.crypto_important_functions",
        "peekOfCode": "class ImportantFunctions(Strategy):\n    def initialize(self):\n        # Set the time between trading iterations\n        self.sleeptime = \"30S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n    def on_trading_iteration(self):\n        ###########################\n        # Placing an Order\n        ###########################",
        "detail": "pages2.lumibot.example_strategies.crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "DriftRebalancer",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.drift_rebalancer",
        "description": "pages2.lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class DriftRebalancer(Strategy):\n    \"\"\"The DriftRebalancer strategy rebalances a portfolio based on drift from target weights.\n    The strategy calculates the drift of each asset in the portfolio and triggers a rebalance if the drift exceeds\n    the drift_threshold. The strategy will sell assets that have drifted above the threshold and\n    buy assets that have drifted below the threshold.\n    The current version of the DriftRebalancer strategy only supports limit orders and whole share quantities.\n    Submit an issue if you need market orders or fractional shares. It should be pretty easy to add.\n    Example parameters:\n    parameters = {\n        ### Standard lumibot strategy parameters",
        "detail": "pages2.lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "DriftCalculationLogic",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.drift_rebalancer",
        "description": "pages2.lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class DriftCalculationLogic:\n    def __init__(self, target_weights: Dict[str, Decimal]) -> None:\n        self.df = pd.DataFrame({\n            \"symbol\": target_weights.keys(),\n            \"is_quote_asset\": False,\n            \"current_quantity\": Decimal(0),\n            \"current_value\": Decimal(0),\n            \"current_weight\": Decimal(0),\n            \"target_weight\": [Decimal(weight) for weight in target_weights.values()],\n            \"target_value\": Decimal(0),",
        "detail": "pages2.lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LimitOrderRebalanceLogic",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.drift_rebalancer",
        "description": "pages2.lumibot.example_strategies.drift_rebalancer",
        "peekOfCode": "class LimitOrderRebalanceLogic:\n    def __init__(\n            self,\n            *,\n            strategy: Strategy,\n            df: pd.DataFrame,\n            fill_sleeptime: int = 15,\n            acceptable_slippage: Decimal = Decimal(\"0.005\"),\n            shorting: bool = False\n    ) -> None:",
        "detail": "pages2.lumibot.example_strategies.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LifecycleLogger",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.lifecycle_logger",
        "description": "pages2.lumibot.example_strategies.lifecycle_logger",
        "peekOfCode": "class LifecycleLogger(Strategy):\n    parameters = {\n        \"sleeptime\": \"10s\",\n        \"market\": \"24/7\",\n    }\n    def initialize(self, symbol=\"\"):\n        self.sleeptime = self.parameters[\"sleeptime\"]\n        self.set_market(self.parameters[\"market\"])\n    def before_market_opens(self):\n        dt = self.get_datetime()",
        "detail": "pages2.lumibot.example_strategies.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.lifecycle_logger",
        "description": "pages2.lumibot.example_strategies.lifecycle_logger",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LifecycleLogger(Strategy):\n    parameters = {\n        \"sleeptime\": \"10s\",\n        \"market\": \"24/7\",\n    }\n    def initialize(self, symbol=\"\"):\n        self.sleeptime = self.parameters[\"sleeptime\"]\n        self.set_market(self.parameters[\"market\"])\n    def before_market_opens(self):",
        "detail": "pages2.lumibot.example_strategies.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "OptionsHoldToExpiry",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.options_hold_to_expiry",
        "description": "pages2.lumibot.example_strategies.options_hold_to_expiry",
        "peekOfCode": "class OptionsHoldToExpiry(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"expiry\": datetime(2023, 10, 20),\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants\n        # Built in Variables\n        self.sleeptime = \"1D\"",
        "detail": "pages2.lumibot.example_strategies.options_hold_to_expiry",
        "documentation": {}
    },
    {
        "label": "MyStrategy",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.simple_start_single_file",
        "description": "pages2.lumibot.example_strategies.simple_start_single_file",
        "peekOfCode": "class MyStrategy(Strategy):\n    def initialize(self, symbol=\"\"):\n        # Will make on_trading_iteration() run every 180 minutes\n        self.sleeptime = 180\n        # Custom parameters\n        self.symbol = symbol\n        self.quantity = 1\n        self.side = \"buy\"\n    def on_trading_iteration(self):\n        self.order = self.create_order(self.symbol, self.quantity, self.side)",
        "detail": "pages2.lumibot.example_strategies.simple_start_single_file",
        "documentation": {}
    },
    {
        "label": "StockBracket",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_bracket",
        "description": "pages2.lumibot.example_strategies.stock_bracket",
        "peekOfCode": "class StockBracket(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "pages2.lumibot.example_strategies.stock_bracket",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_buy_and_hold",
        "description": "pages2.lumibot.example_strategies.stock_buy_and_hold",
        "peekOfCode": "class BuyAndHold(Strategy):\n    parameters = {\n        \"buy_symbol\": \"QQQ\",\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the sleep time to one day (the strategy will run once per day)\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        \"\"\"Buys the self.buy_symbol once, then never again\"\"\"",
        "detail": "pages2.lumibot.example_strategies.stock_buy_and_hold",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_diversified_leverage",
        "description": "pages2.lumibot.example_strategies.stock_diversified_leverage",
        "peekOfCode": "class DiversifiedLeverage(Strategy):\n    # =====Overloading lifecycle methods=============\n    parameters = {\n        \"portfolio\": [\n            {\n                \"symbol\": \"TQQQ\",  # 3x Leveraged Nasdaq\n                \"weight\": 0.20,\n            },\n            {\n                \"symbol\": \"UPRO\",  # 3x Leveraged S&P 500",
        "detail": "pages2.lumibot.example_strategies.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "LimitAndTrailingStop",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_limit_and_trailing_stops",
        "description": "pages2.lumibot.example_strategies.stock_limit_and_trailing_stops",
        "peekOfCode": "class LimitAndTrailingStop(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"limit_buy_price\": 403,\n        \"limit_sell_price\": 407,\n        \"trail_percent\": 0.02,\n        \"trail_price\": 7,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):",
        "detail": "pages2.lumibot.example_strategies.stock_limit_and_trailing_stops",
        "documentation": {}
    },
    {
        "label": "Momentum",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_momentum",
        "description": "pages2.lumibot.example_strategies.stock_momentum",
        "peekOfCode": "class Momentum(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self, symbols=None):\n        # Setting the waiting period (in days)\n        self.period = 2\n        # The counter for the number of days we have been holding the current asset\n        self.counter = 0\n        # There is only one trading operation per day\n        # No need to sleep between iterations\n        self.sleeptime = 0",
        "detail": "pages2.lumibot.example_strategies.stock_momentum",
        "documentation": {}
    },
    {
        "label": "StockOco",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_oco",
        "description": "pages2.lumibot.example_strategies.stock_oco",
        "peekOfCode": "class StockOco(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405,\n        \"stop_loss_price\": 395,\n        \"quantity\": 10,\n    }\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the initial variables or constants",
        "detail": "pages2.lumibot.example_strategies.stock_oco",
        "documentation": {}
    },
    {
        "label": "StockSentiment",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.stock_sentiment",
        "description": "pages2.lumibot.example_strategies.stock_sentiment",
        "peekOfCode": "class StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],\n            base_url=BASE_URL",
        "detail": "pages2.lumibot.example_strategies.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "pages2.lumibot.example_strategies.stock_sentiment",
        "description": "pages2.lumibot.example_strategies.stock_sentiment",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nclass StockSentiment(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(\n            key_id=ALPACA_CREDS[\"API_KEY\"],\n            secret_key=ALPACA_CREDS[\"API_SECRET\"],",
        "detail": "pages2.lumibot.example_strategies.stock_sentiment",
        "documentation": {}
    },
    {
        "label": "Strangle",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.strangle",
        "description": "pages2.lumibot.example_strategies.strangle",
        "peekOfCode": "class Strangle(Strategy):\n    \"\"\"Strategy Description: Strangle\n    In a long stranglethe more common strategythe investor simultaneously buys an\n    out-of-the-money call and an out-of-the-money put option. The call option's strike\n    price is higher than the underlying asset's current market price, while the put has a\n    strike price that is lower than the asset's market price. This strategy has large profit\n    potential since the call option has theoretically unlimited upside if the underlying\n    asset rises in price, while the put option can profit if the underlying asset falls.\n    The risk on the trade is limited to the premium paid for the two options.\n    Place the strangle two weeks before earnings announcement.",
        "detail": "pages2.lumibot.example_strategies.strangle",
        "documentation": {}
    },
    {
        "label": "BrokerTest",
        "kind": 6,
        "importPath": "pages2.lumibot.example_strategies.test_broker_functions",
        "description": "pages2.lumibot.example_strategies.test_broker_functions",
        "peekOfCode": "class BrokerTest(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the time between trading iterations\n        # strategy runs every 20 seconds.\n        self.sleeptime = \"20S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n        # Record the last trade time\n        self.last_trade_time = None",
        "detail": "pages2.lumibot.example_strategies.test_broker_functions",
        "documentation": {}
    },
    {
        "label": "CustomLoggerAdapter",
        "kind": 6,
        "importPath": "pages2.lumibot.strategies._strategy",
        "description": "pages2.lumibot.strategies._strategy",
        "peekOfCode": "class CustomLoggerAdapter(logging.LoggerAdapter):\n    def __init__(self, logger, extra):\n        super().__init__(logger, extra)\n        self.prefix = f'[{self.extra[\"strategy_name\"]}] '\n    def process(self, msg, kwargs):\n        try:\n            return self.prefix + msg, kwargs\n        except Exception as e:\n            return msg, kwargs\nclass Vars:",
        "detail": "pages2.lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "Vars",
        "kind": 6,
        "importPath": "pages2.lumibot.strategies._strategy",
        "description": "pages2.lumibot.strategies._strategy",
        "peekOfCode": "class Vars:\n    def __init__(self):\n        super().__setattr__('_vars_dict', {})\n    def __getattr__(self, name):\n        try:\n            return self._vars_dict[name]\n        except KeyError:\n            raise AttributeError(f\"'Vars' object has no attribute '{name}'\")\n    def __setattr__(self, name, value):\n        self._vars_dict[name] = value",
        "detail": "pages2.lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "_Strategy",
        "kind": 6,
        "importPath": "pages2.lumibot.strategies._strategy",
        "description": "pages2.lumibot.strategies._strategy",
        "peekOfCode": "class _Strategy:\n    IS_BACKTESTABLE = True\n    _trader = None\n    def __init__(\n        self,\n        broker=None,\n        minutes_before_closing=1,\n        minutes_before_opening=60,\n        minutes_after_closing=0,\n        sleeptime=\"1M\",",
        "detail": "pages2.lumibot.strategies._strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "pages2.lumibot.strategies.strategy",
        "description": "pages2.lumibot.strategies.strategy",
        "peekOfCode": "class Strategy(_Strategy):\n    @property\n    def name(self):\n        \"\"\"Returns the name of the strategy.\n        Returns:\n            str: The name of the strategy.\n        Example\n        -------\n        >>> self.log_message(f'Strategy name: {self.name}')\n        \"\"\"",
        "detail": "pages2.lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "STATS_TABLE_NAME",
        "kind": 5,
        "importPath": "pages2.lumibot.strategies.strategy",
        "description": "pages2.lumibot.strategies.strategy",
        "peekOfCode": "STATS_TABLE_NAME = \"strategy_tracker\"\nclass Strategy(_Strategy):\n    @property\n    def name(self):\n        \"\"\"Returns the name of the strategy.\n        Returns:\n            str: The name of the strategy.\n        Example\n        -------\n        >>> self.log_message(f'Strategy name: {self.name}')",
        "detail": "pages2.lumibot.strategies.strategy",
        "documentation": {}
    },
    {
        "label": "StrategyExecutor",
        "kind": 6,
        "importPath": "pages2.lumibot.strategies.strategy_executor",
        "description": "pages2.lumibot.strategies.strategy_executor",
        "peekOfCode": "class StrategyExecutor(Thread):\n    # Trading events flags\n    NEW_ORDER = \"new\"\n    CANCELED_ORDER = \"canceled\"\n    FILLED_ORDER = \"fill\"\n    PARTIALLY_FILLED_ORDER = \"partial_fill\"\n    def __init__(self, strategy):\n        super(StrategyExecutor, self).__init__()\n        self.daemon = True\n        self.stop_event = Event()",
        "detail": "pages2.lumibot.strategies.strategy_executor",
        "documentation": {}
    },
    {
        "label": "GK",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "class GK:\n    \"\"\"Garman-Kohlhagen\n\tUsed for pricing European options on currencies\n\tGK([underlyingPrice, strikePrice, domesticRate, foreignRate, \\\n\t\t\tdaysToExpiration], volatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "BS",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "class BS:\n    \"\"\"Black-Scholes\n\tUsed for pricing European options on stocks without dividends\n\tBS([underlyingPrice, strikePrice, interestRate, daysToExpiration], \\\n\t\t\tvolatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "Me",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "class Me:\n    \"\"\"Merton\n\tUsed for pricing European options on stocks with dividends\n\tMe([underlyingPrice, strikePrice, interestRate, annualDividends, \\\n\t\t\tdaysToExpiration], volatility=x, callPrice=y, putPrice=z)\n\teg: \n\t\tc = mibian.Me([52, 50, 1, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "impliedVolatility",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "def impliedVolatility(className, args, callPrice=None, putPrice=None, high=500.0, low=0.0):\n    \"\"\"Returns the estimated implied volatility\"\"\"\n    if callPrice:\n        target = callPrice\n        restimate = eval(className)(args, volatility=high, performance=True).callPrice\n        if restimate < target:\n            return high\n        if args[0] > args[1] + callPrice:\n            return 0.001\n    if putPrice:",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRhoD\t\t\t\t# Returns the call domestic rho",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], putPrice=0.03)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], putPrice=0.03)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.domesticRate = float(args[2]) / 100\n        self.foreignRate = float(args[3]) / 100",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.GK([1.4565, 1.45, 1, 2, 30], callPrice=0.0359, putPrice=0.03)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.domesticRate = float(args[2]) / 100\n        self.foreignRate = float(args[3]) / 100\n        self.daysToExpiration = float(args[4]) / 365\n        for i in [",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRho\t\t\t\t# Returns the call rho",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.daysToExpiration = float(args[3]) / 365",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.BS([1.4565, 1.45, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.daysToExpiration = float(args[3]) / 365\n        for i in [\n            \"callPrice\",",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], volatility=20)\n\t\tc.callPrice\t\t\t\t# Returns the call price\n\t\tc.putPrice\t\t\t\t# Returns the put price\n\t\tc.callDelta\t\t\t\t# Returns the call delta\n\t\tc.putDelta\t\t\t\t# Returns the put delta\n\t\tc.callDelta2\t\t\t# Returns the call dual delta\n\t\tc.putDelta2\t\t\t\t# Returns the put dual delta\n\t\tc.callTheta\t\t\t\t# Returns the call theta\n\t\tc.putTheta\t\t\t\t# Returns the put theta\n\t\tc.callRho\t\t\t\t# Returns the call rho",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the call price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], putPrice=0.0306)\n\t\tc.impliedVolatility\t\t# Returns the implied volatility from the put price\n\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.dividend = float(args[3])",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "\t\tc",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.black_scholes",
        "description": "pages2.lumibot.tools.black_scholes",
        "peekOfCode": "\t\tc = mibian.Me([52, 50, 1, 1, 30], callPrice=0.0359, putPrice=0.0306)\n\t\tc.putCallParity\t\t\t# Returns the put-call parity\n\t\"\"\"\n    def __init__(self, args, volatility=None, callPrice=None, putPrice=None, performance=None):\n        self.underlyingPrice = float(args[0])\n        self.strikePrice = float(args[1])\n        self.interestRate = float(args[2]) / 100\n        self.dividend = float(args[3])\n        self.dividendYield = self.dividend / self.underlyingPrice\n        self.daysToExpiration = float(args[4]) / 365",
        "detail": "pages2.lumibot.tools.black_scholes",
        "documentation": {}
    },
    {
        "label": "CcxtCacheDB",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.ccxt_data_store",
        "description": "pages2.lumibot.tools.ccxt_data_store",
        "peekOfCode": "class CcxtCacheDB:\n    \"\"\"A ccxt data cache class using duckdb.\n    The data being cached is OHLCV data and is stored in UTC.\n    After importing the data, you'll need to change the timezone if necessary.\n    Create an exchange_id folder in the cache folder, and create a symbol_timeframe.duckdb file under it.\n    ex) Create a BTC_USDT_1m.duckdb file in the binance folder.\n    If there is an existing cache file, it will use it to fetch the data, otherwise it will use ccxt to fetch the data.\n    If a cache file exists, but the requested data range is not in the cache file, the data will be fetched using ccxt.\n    For example, if the cache file contains data from 2023-01-01 to 2023-01-10, and you request data from 2023-01-05 to 2023-01-15,\n    the data from 2023-01-05 to 2023-01-10 will be fetched from the cache file, and the data from 2023-01-11 to 2023-01-15 will be fetched using ccxt.",
        "detail": "pages2.lumibot.tools.ccxt_data_store",
        "documentation": {}
    },
    {
        "label": "PerfCounters",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.debugers",
        "description": "pages2.lumibot.tools.debugers",
        "peekOfCode": "class PerfCounters:\n    def __init__(self):\n        self.counters = {}\n    def add_counter(self, name):\n        self.counters[name] = [0, 0]\n    def tic_counter(self, name):\n        self.counters[name][1] = perf_counter()\n    def toc_counter(self, name):\n        toc = perf_counter()\n        counter = self.counters[name]",
        "detail": "pages2.lumibot.tools.debugers",
        "documentation": {}
    },
    {
        "label": "perf_counters",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.debugers",
        "description": "pages2.lumibot.tools.debugers",
        "peekOfCode": "perf_counters = PerfCounters()",
        "detail": "pages2.lumibot.tools.debugers",
        "documentation": {}
    },
    {
        "label": "staticdecorator",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.decorators",
        "description": "pages2.lumibot.tools.decorators",
        "peekOfCode": "def staticdecorator(func):\n    \"\"\"Makes a function decorated with staticmethod executable\"\"\"\n    return func.__get__(\"\")\ndef call_function_get_frame(func, *args, **kwargs):\n    \"\"\"\n    Calls the function *func* with the specified arguments and keyword\n    arguments and snatches its local frame before it actually executes.\n    \"\"\"\n    frame = None\n    trace = sys.gettrace()",
        "detail": "pages2.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "call_function_get_frame",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.decorators",
        "description": "pages2.lumibot.tools.decorators",
        "peekOfCode": "def call_function_get_frame(func, *args, **kwargs):\n    \"\"\"\n    Calls the function *func* with the specified arguments and keyword\n    arguments and snatches its local frame before it actually executes.\n    \"\"\"\n    frame = None\n    trace = sys.gettrace()\n    def snatch_locals(_frame, name, arg):\n        nonlocal frame\n        if frame is None and name == \"call\":",
        "detail": "pages2.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "snatch_locals",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.decorators",
        "description": "pages2.lumibot.tools.decorators",
        "peekOfCode": "def snatch_locals(store):\n    \"\"\"Snatch a function local variables\n    and store them in store variable\"\"\"\n    def wrapper(func_input):\n        @wraps(func_input)\n        def func_output(*args, **kwargs):\n            global store\n            frame, result = call_function_get_frame(func_input, *args, **kwargs)\n            store = frame.f_locals\n            return result",
        "detail": "pages2.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "append_locals",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.decorators",
        "description": "pages2.lumibot.tools.decorators",
        "peekOfCode": "def append_locals(func_input):\n    \"\"\"Snatch a function local variables\n    and store them in store variable\"\"\"\n    @wraps(func_input)\n    def func_output(*args, **kwargs):\n        frame, result = call_function_get_frame(func_input, *args, **kwargs)\n        if frame is not None:\n            func_output.locals = frame.f_locals\n        else:\n            func_output.locals = None",
        "detail": "pages2.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "execute_after",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.decorators",
        "description": "pages2.lumibot.tools.decorators",
        "peekOfCode": "def execute_after(actions):\n    def decorator_func(input_func):\n        @wraps(input_func)\n        def output_func(*args, **kwargs):\n            input_func(*args, **kwargs)\n            for action in actions:\n                action()\n        return output_func\n    return decorator_func",
        "detail": "pages2.lumibot.tools.decorators",
        "documentation": {}
    },
    {
        "label": "ComparaisonMixin",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "class ComparaisonMixin:\n    COMPARAISON_PROP = \"timestamp\"\n    def __eq__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) == getattr(other, self.COMPARAISON_PROP)\n    def __ne__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) != getattr(other, self.COMPARAISON_PROP)\n    def __gt__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) > getattr(other, self.COMPARAISON_PROP)\n    def __ge__(self, other):\n        return getattr(self, self.COMPARAISON_PROP) >= getattr(other, self.COMPARAISON_PROP)",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_chunks",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def get_chunks(l, chunk_size):\n    chunks = []\n    for i in range(0, len(l), chunk_size):\n        chunks.append(l[i: i + chunk_size])\n    return chunks\ndef deduplicate_sequence(seq, key=\"\"):\n    seen = set()\n    pos = 0\n    if key:\n        get_ref = lambda item: getattr(item, key)",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "deduplicate_sequence",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def deduplicate_sequence(seq, key=\"\"):\n    seen = set()\n    pos = 0\n    if key:\n        get_ref = lambda item: getattr(item, key)\n    else:\n        get_ref = lambda item: item\n    for item in seq:\n        ref = get_ref(item)\n        if ref not in seen:",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def get_trading_days(market=\"NYSE\", start_date=\"1950-01-01\", end_date=None):\n    format_datetime = lambda dt: dt.to_pydatetime().astimezone(LUMIBOT_DEFAULT_PYTZ)\n    start_date = to_datetime_aware(pd.to_datetime(start_date))\n    today = get_lumibot_datetime()\n    # macl's \"24/7\" calendar doesn't return consecutive days, so need to be generated manually.\n    if market == \"24/7\":\n        market_open = pd.date_range(\n            start=start_date, end=end_date or today).to_frame(index=False,name=\"market_open\")\n        market_close = pd.date_range(\n            start=start_date.replace(hour=23,minute=59,second=59,microsecond=999999), ",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "print_progress_bar",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def print_progress_bar(\n    value,\n    start_value,\n    end_value,\n    backtesting_started,\n    file=sys.stdout,\n    length=None,\n    prefix=\"Progress\",\n    suffix=\"\",\n    decimals=2,",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "get_lumibot_datetime",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def get_lumibot_datetime():\n    return dt.datetime.now().astimezone(LUMIBOT_DEFAULT_PYTZ)\ndef to_datetime_aware(dt_in):\n    \"\"\"Convert naive time to datetime aware on default timezone.\"\"\"\n    if not dt_in:\n        return dt_in\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo is None):\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo.utcoffset(dt_in) is None):\n        # TODO: This will fail because an exception is thrown if tzinfo is not None.",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "to_datetime_aware",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def to_datetime_aware(dt_in):\n    \"\"\"Convert naive time to datetime aware on default timezone.\"\"\"\n    if not dt_in:\n        return dt_in\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo is None):\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    elif isinstance(dt_in, dt.datetime) and (dt_in.tzinfo.utcoffset(dt_in) is None):\n        # TODO: This will fail because an exception is thrown if tzinfo is not None.\n        return LUMIBOT_DEFAULT_PYTZ.localize(dt_in)\n    else:",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_symbol",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def parse_symbol(symbol):\n    \"\"\"\n    Parse the given symbol and determine if it's an option or a stock.\n    For options, extract and return the stock symbol, expiration date (as a datetime.date object),\n    type (call or put), and strike price.\n    For stocks, simply return the stock symbol.\n    TODO: Crypto and Forex support\n    \"\"\"\n    # Check that the symbol is a string\n    if not isinstance(symbol, str):",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "create_options_symbol",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def create_options_symbol(stock_symbol, expiration_date, option_type, strike_price):\n    \"\"\"\n    Create an option symbol string from its components.\n    Parameters\n    ----------\n    stock_symbol : str\n        The stock symbol, e.g., 'AAPL'.\n    expiration_date : dt.date or dt.datetime\n        The expiration date of the option.\n    option_type : str",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "parse_timestep_qty_and_unit",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.helpers",
        "description": "pages2.lumibot.tools.helpers",
        "peekOfCode": "def parse_timestep_qty_and_unit(timestep):\n    \"\"\"\n    Parse the timestep string and return the quantity and unit.\n    Parameters\n    ----------\n    timestep : str\n        The timestep string to parse.\n    Returns\n    -------\n    tuple",
        "detail": "pages2.lumibot.tools.helpers",
        "documentation": {}
    },
    {
        "label": "total_return",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def total_return(_df):\n    \"\"\"Calculate the cumulative return in a dataframe\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    df = df.sort_index(ascending=True)\n    df[\"cum_return\"] = (1 + df[\"return\"]).cumprod()\n    total_ret = df[\"cum_return\"].iloc[-1] - 1\n    return total_ret",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "cagr",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def cagr(_df):\n    \"\"\"Calculate the Compound Annual Growth Rate\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    Example:\n    >>> df = pd.DataFrame({\"return\": [0.1, 0.2, 0.3, 0.4, 0.5]})\n    >>> cagr(df)\n    0.3125\n    \"\"\"\n    df = _df.copy()",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "volatility",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def volatility(_df):\n    \"\"\"Calculate the volatility (standard deviation)\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    start = datetime.fromtimestamp(df.index.values[0].astype(\"O\") / 1e9, pytz.UTC)\n    end = datetime.fromtimestamp(df.index.values[-1].astype(\"O\") / 1e9, pytz.UTC)\n    period_years = (end - start).days / 365.25\n    if period_years == 0:",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "sharpe",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def sharpe(_df, risk_free_rate):\n    \"\"\"Calculate the Sharpe Rate, or (CAGR - risk_free_rate) / volatility\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily).\n    risk_free_rate should be either LIBOR, or the shortest possible US Treasury Rate\n    \"\"\"\n    ret = cagr(_df)\n    vol = volatility(_df)\n    if vol == 0:\n        return 0",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "max_drawdown",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def max_drawdown(_df):\n    \"\"\"Calculate the Max Drawdown, or the biggest percentage drop\n    from peak to trough.\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    if _df.shape[0] == 1:\n        return {\"drawdown\": 0, \"date\": _df.index[0]}\n    df = _df.copy()\n    df = df.sort_index(ascending=True)",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "romad",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def romad(_df):\n    \"\"\"Calculate the Return Over Maximum Drawdown (RoMaD)\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    ret = cagr(_df)\n    mdd = max_drawdown(_df)\n    if mdd[\"drawdown\"] == 0:\n        return 0\n    romad = ret / mdd[\"drawdown\"]",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "stats_summary",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def stats_summary(_df, risk_free_rate):\n    return {\n        \"cagr\": cagr(_df),\n        \"volatility\": volatility(_df),\n        \"sharpe\": sharpe(_df, risk_free_rate),\n        \"max_drawdown\": max_drawdown(_df),\n        \"romad\": romad(_df),\n        \"total_return\": total_return(_df),\n    }\ndef performance(_df, risk_free, prefix=\"\"):",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "performance",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def performance(_df, risk_free, prefix=\"\"):\n    \"\"\"Calculate and print out all of our performance indicators\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    cagr_adj = cagr(_df)\n    vol_adj = volatility(_df)\n    sharpe_adj = sharpe(_df, risk_free)\n    maxdown_adj = max_drawdown(_df)\n    romad_adj = romad(_df)",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "get_symbol_returns",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def get_symbol_returns(symbol, start=datetime(1900, 1, 1), end=datetime.now()):\n    \"\"\"Get the returns for a symbol between two dates\n    Parameters\n    ----------\n    symbol : str\n        The symbol to get the returns for\n    start : datetime, optional\n        The start date, by default datetime(1900, 1, 1)\n    end : datetime, optional\n        The end date, by default datetime.now()",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "calculate_returns",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def calculate_returns(symbol, start=datetime(1900, 1, 1), end=datetime.now()):\n    start = to_datetime_aware(start)\n    end = to_datetime_aware(end)\n    benchmark_df = get_symbol_returns(symbol, start, end)\n    risk_free_rate = get_risk_free_rate()\n    performance(benchmark_df, risk_free_rate, symbol)\ndef plot_indicators(\n    plot_file_html=\"indicators.html\",\n    chart_markers_df=None,\n    chart_lines_df=None,",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "plot_indicators",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def plot_indicators(\n    plot_file_html=\"indicators.html\",\n    chart_markers_df=None,\n    chart_lines_df=None,\n    strategy_name=None,\n    show_indicators=True,\n):\n    # If show plot is False, then we don't want to open the plot in the browser\n    if not show_indicators:\n        logger.debug(\"show_indicators is False, not creating the plot file.\")",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "plot_returns",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def plot_returns(\n    strategy_df,\n    strategy_name,\n    benchmark_df,\n    benchmark_name,\n    plot_file_html=\"backtest_result.html\",\n    trades_df=None,\n    show_plot=True,\n    initial_budget=1,\n    # chart_markers_df=None,",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "create_tearsheet",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def create_tearsheet(\n    # =========BY DOV========\n    strategy_df: pd.DataFrame.to_numpy,\n    strat_name: str,\n    tearsheet_file: str,\n    benchmark_df: pd.DataFrame.to_numpy,\n    benchmark_asset,  # This is causing a circular import: Asset,\n    show_tearsheet: bool,\n    save_tearsheet: bool,\n    risk_free_rate: float,",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "get_risk_free_rate",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "def get_risk_free_rate(dt: datetime = None):\n    try:\n        result = yh.get_risk_free_rate(dt=dt)\n    except Exception as e:\n        logging.error(f\"Error getting the risk free rate: {e}\")\n        result = 0\n    return result",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.indicators",
        "description": "pages2.lumibot.tools.indicators",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef total_return(_df):\n    \"\"\"Calculate the cumulative return in a dataframe\n    The dataframe _df must include a column \"return\" that\n    has the return for that time period (eg. daily)\n    \"\"\"\n    df = _df.copy()\n    df = df.sort_index(ascending=True)\n    df[\"cum_return\"] = (1 + df[\"return\"]).cumprod()\n    total_ret = df[\"cum_return\"].iloc[-1] - 1",
        "detail": "pages2.lumibot.tools.indicators",
        "documentation": {}
    },
    {
        "label": "warning_time_sleep",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.lumibot_time",
        "description": "pages2.lumibot.tools.lumibot_time",
        "peekOfCode": "def warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):\n            warned_against_calling_time_sleep = True\n            # TODO: Look into this warning being handled more gracefully. Right now it",
        "detail": "pages2.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "default_time_sleep",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.lumibot_time",
        "description": "pages2.lumibot.tools.lumibot_time",
        "peekOfCode": "default_time_sleep = time.sleep\nwarned_against_calling_time_sleep = False\ndef warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):",
        "detail": "pages2.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "warned_against_calling_time_sleep",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.lumibot_time",
        "description": "pages2.lumibot.tools.lumibot_time",
        "peekOfCode": "warned_against_calling_time_sleep = False\ndef warning_time_sleep(sleeptime):\n    global warned_against_calling_time_sleep\n    if warned_against_calling_time_sleep is False:\n        thread_name = currentThread().getName()\n        authorized_threads_with_sleep = [r\"^.*_requesting_data_.*$\"]\n        if not any(\n            [re.match(expr, thread_name) for expr in authorized_threads_with_sleep]\n        ):\n            warned_against_calling_time_sleep = True",
        "detail": "pages2.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "time.sleep",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.lumibot_time",
        "description": "pages2.lumibot.tools.lumibot_time",
        "peekOfCode": "time.sleep = warning_time_sleep",
        "detail": "pages2.lumibot.tools.lumibot_time",
        "documentation": {}
    },
    {
        "label": "day_deduplicate",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.pandas",
        "description": "pages2.lumibot.tools.pandas",
        "peekOfCode": "def day_deduplicate(df_):\n    df_copy = df_.copy()\n    df_copy = df_copy.groupby(level=0).head(1)\n    return df_copy\ndef is_daily_data(df_):\n    times = pd.Series(df_.index).apply(lambda x: x.time()).unique()\n    if len(times) == 1 and times[0] == time(0, 0):\n        return True\n    return False\ndef fill_void(df_, interval, end):",
        "detail": "pages2.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "is_daily_data",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.pandas",
        "description": "pages2.lumibot.tools.pandas",
        "peekOfCode": "def is_daily_data(df_):\n    times = pd.Series(df_.index).apply(lambda x: x.time()).unique()\n    if len(times) == 1 and times[0] == time(0, 0):\n        return True\n    return False\ndef fill_void(df_, interval, end):\n    n_rows = len(df_.index)\n    missing_lines = pd.DataFrame()\n    for index, row in df_.iterrows():\n        position = df_.index.get_loc(index)",
        "detail": "pages2.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "fill_void",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.pandas",
        "description": "pages2.lumibot.tools.pandas",
        "peekOfCode": "def fill_void(df_, interval, end):\n    n_rows = len(df_.index)\n    missing_lines = pd.DataFrame()\n    for index, row in df_.iterrows():\n        position = df_.index.get_loc(index)\n        if position + 1 == n_rows:\n            if index < end:\n                n_missing = (end - index) // interval\n                missing_days = [index + (i + 1) * interval for i in range(n_missing)]\n                missing_lines = pd.concat(",
        "detail": "pages2.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "print_full_pandas_dataframes",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.pandas",
        "description": "pages2.lumibot.tools.pandas",
        "peekOfCode": "def print_full_pandas_dataframes():\n    \"\"\"\n    Show the whole dataframe when printing pandas dataframes\n    \"\"\"\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_colwidth', None)\n    pd.set_option('display.max_rows', None)\n    pd.set_option('display.width', 1000)\ndef set_pandas_float_precision(precision: int = 5):\n    format_str = '{:.' + str(precision) + 'f}'",
        "detail": "pages2.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "set_pandas_float_precision",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.pandas",
        "description": "pages2.lumibot.tools.pandas",
        "peekOfCode": "def set_pandas_float_precision(precision: int = 5):\n    format_str = '{:.' + str(precision) + 'f}'\n    pd.set_option('display.float_format', format_str.format)\ndef prettify_dataframe_with_decimals(df: pd.DataFrame, decimal_places: int = 5) -> str:\n    def decimal_formatter(x):\n        if isinstance(x, Decimal):\n            return f\"{x:.{decimal_places}f}\"\n        return x\n    return df.to_string(formatters={col: decimal_formatter for col in df.columns})",
        "detail": "pages2.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "prettify_dataframe_with_decimals",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.pandas",
        "description": "pages2.lumibot.tools.pandas",
        "peekOfCode": "def prettify_dataframe_with_decimals(df: pd.DataFrame, decimal_places: int = 5) -> str:\n    def decimal_formatter(x):\n        if isinstance(x, Decimal):\n            return f\"{x:.{decimal_places}f}\"\n        return x\n    return df.to_string(formatters={col: decimal_formatter for col in df.columns})",
        "detail": "pages2.lumibot.tools.pandas",
        "documentation": {}
    },
    {
        "label": "PolygonClient",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "class PolygonClient(RESTClient):\n    ''' Rate Limited RESTClient with factory method '''\n    WAIT_SECONDS_RETRY = 60\n    @classmethod\n    def create(cls, *args, **kwargs) -> RESTClient:\n        \"\"\"\n        Factory method to create a RESTClient or PolygonClient instance.\n        The method uses environment variables to determine default values for the API key \n        and subscription type. If the `api_key` is not provided in `kwargs`, it defaults \n        to the value of the `POLYGON_API_KEY` environment variable.",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_cached_schedule",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache\n    if cache_key in schedule_cache:\n        return schedule_cache[cache_key]",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_price_data_from_polygon",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_price_data_from_polygon(\n    api_key: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    force_cache_update: bool = False,\n):\n    \"\"\"",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "validate_cache",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def validate_cache(force_cache_update: bool, asset: Asset, cache_file: Path, api_key: str):\n    \"\"\"\n    If the list of splits for a stock have changed then we need to invalidate its cache\n    because all of the prices will have changed (because we're using split adjusted prices).\n    Get the splits data from Polygon only once per day per stock.\n    Use the timestamp on the splits feather file to determine if we need to get the splits again.\n    When invalidating we delete the cache file and return force_cache_update=True too.\n    \"\"\"\n    if asset.asset_type not in [Asset.AssetType.STOCK, Asset.AssetType.OPTION]:\n        return force_cache_update",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_trading_dates",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_trading_dates(asset: Asset, start: datetime, end: datetime):\n    \"\"\"\n    Get a list of trading days for the asset between the start and end dates\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    start : datetime\n        Start date for the data requested\n    end : datetime",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_polygon_symbol",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_polygon_symbol(asset, polygon_client, quote_asset=None):\n    \"\"\"\n    Get the symbol for the asset in a format that Polygon will understand\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    polygon_client : RESTClient\n        The RESTClient connection for Polygon Stock-Equity API\n    quote_asset : Asset",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "build_cache_filename",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def build_cache_filename(asset: Asset, timespan: str):\n    \"\"\"Helper function to create the cache filename for a given asset and timespan\"\"\"\n    lumibot_polygon_cache_folder = Path(LUMIBOT_CACHE_FOLDER) / \"polygon\"\n    # If It's an option then also add the expiration date, strike price and right to the filename\n    if asset.asset_type == \"option\":\n        if asset.expiration is None:\n            raise ValueError(f\"Expiration date is required for option {asset} but it is None\")\n        # Make asset.expiration datetime into a string like \"YYMMDD\"\n        expiry_string = asset.expiration.strftime(\"%y%m%d\")\n        uniq_str = f\"{asset.symbol}_{expiry_string}_{asset.strike}_{asset.right}\"",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_missing_dates",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def get_missing_dates(df_all, asset, start, end):\n    \"\"\"\n    Check if we have data for the full range\n    Later Query to Polygon will pad an extra full day to start/end dates so that there should never\n    be any gap with intraday data missing.\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        Data loaded from the cache file\n    asset : Asset",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def load_cache(cache_file):\n    \"\"\"Load the data from the cache file and return a DataFrame with a DateTimeIndex\"\"\"\n    df_feather = pd.read_feather(cache_file)\n    # Set the 'datetime' column as the index of the DataFrame\n    df_feather.set_index(\"datetime\", inplace=True)\n    df_feather.index = pd.to_datetime(\n        df_feather.index\n    )  # TODO: Is there some way to speed this up? It takes several times longer than just reading the feather file\n    df_feather = df_feather.sort_index()\n    # Check if the index is already timezone aware",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "update_cache",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def update_cache(cache_file, df_all, missing_dates=None):\n    \"\"\"Update the cache file with the new data.  Missing dates are added as empty (all NaN) \n    rows before it is saved to the cache file.\n    Parameters\n    ----------\n    cache_file : Path\n        The path to the cache file\n    df_all : pd.DataFrame\n        The DataFrame with the data we want to cache\n    missing_dates : list[datetime.date]",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "update_polygon_data",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "def update_polygon_data(df_all, result):\n    \"\"\"\n    Update the DataFrame with the new data from Polygon\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        A DataFrame with the data we already have\n    result : list\n        A List of dictionaries with the new data from Polygon\n        Format: [{'o': 1.0, 'h': 2.0, 'l': 3.0, 'c': 4.0, 'v': 5.0, 't': 116120000000}]",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "MAX_POLYGON_DAYS",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "MAX_POLYGON_DAYS = 30\n# Define a cache dictionary to store schedules and a global dictionary for buffered schedules\nschedule_cache = {}\nbuffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "schedule_cache",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "schedule_cache = {}\nbuffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "buffered_schedules",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.polygon_helper",
        "description": "pages2.lumibot.tools.polygon_helper",
        "peekOfCode": "buffered_schedules = {}\ndef get_cached_schedule(cal, start_date, end_date, buffer_days=30):\n    \"\"\"\n    Fetch schedule with a buffer at the end. This is done to reduce the number of calls to the calendar API (which is slow).\n    \"\"\"\n    global buffered_schedules\n    buffer_end = end_date + timedelta(days=buffer_days)\n    cache_key = (cal.name, start_date, end_date)\n    # Check if the required range is in the schedule cache\n    if cache_key in schedule_cache:",
        "detail": "pages2.lumibot.tools.polygon_helper",
        "documentation": {}
    },
    {
        "label": "get_price_data",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    dt=None,\n    datastyle: str = \"ohlc\"",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_trading_dates",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_trading_dates(asset: Asset, start: datetime, end: datetime):\n    \"\"\"\n    Get a list of trading days for the asset between the start and end dates\n    Parameters\n    ----------\n    asset : Asset\n        Asset we are getting data for\n    start : datetime\n        Start date for the data requested\n    end : datetime",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "build_cache_filename",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def build_cache_filename(asset: Asset, timespan: str, datastyle: str = \"ohlc\"):\n    \"\"\"Helper function to create the cache filename for a given asset and timespan\"\"\"\n    lumibot_cache_folder = Path(LUMIBOT_CACHE_FOLDER) / CACHE_SUBFOLDER\n    # If It's an option then also add the expiration date, strike price and right to the filename\n    if asset.asset_type == \"option\":\n        if asset.expiration is None:\n            raise ValueError(f\"Expiration date is required for option {asset} but it is None\")\n        # Make asset.expiration datetime into a string like \"YYMMDD\"\n        expiry_string = asset.expiration.strftime(\"%y%m%d\")\n        uniq_str = f\"{asset.symbol}_{expiry_string}_{asset.strike}_{asset.right}\"",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_missing_dates",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_missing_dates(df_all, asset, start, end):\n    \"\"\"\n    Check if we have data for the full range\n    Later Query to Polygon will pad an extra full day to start/end dates so that there should never\n    be any gap with intraday data missing.\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        Data loaded from the cache file\n    asset : Asset",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def load_cache(cache_file):\n    \"\"\"Load the data from the cache file and return a DataFrame with a DateTimeIndex\"\"\"\n    df_feather = pd.read_feather(cache_file)\n    # Set the 'datetime' column as the index of the DataFrame\n    df_feather.set_index(\"datetime\", inplace=True)\n    df_feather.index = pd.to_datetime(\n        df_feather.index\n    )  # TODO: Is there some way to speed this up? It takes several times longer than just reading the feather file\n    df_feather = df_feather.sort_index()\n    # Check if the index is already timezone aware",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "update_cache",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def update_cache(cache_file, df_all, df_feather):\n    \"\"\"Update the cache file with the new data\"\"\"\n    # Check if df_all is different from df_feather (if df_feather exists)\n    if df_all is not None and len(df_all) > 0:\n        # Check if the dataframes are the same\n        if df_all.equals(df_feather):\n            return\n        # Create the directory if it doesn't exist\n        cache_file.parent.mkdir(parents=True, exist_ok=True)\n        # Reset the index to convert DatetimeIndex to a regular column",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "update_df",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def update_df(df_all, result):\n    \"\"\"\n    Update the DataFrame with the new data from ThetaData\n    Parameters\n    ----------\n    df_all : pd.DataFrame\n        A DataFrame with the data we already have\n    result : pandas DataFrame\n        A List of dictionaries with the new data from Polygon\n        Format:",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "start_theta_data_client",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def start_theta_data_client(username: str, password: str):\n    # First try shutting down any existing connection\n    try:\n        requests.get(f\"{BASE_URL}/v2/system/terminal/shutdown\")\n    except Exception:\n        pass\n    client = ThetaClient(username=username, passwd=password)\n    time.sleep(1)\n    return client\ndef check_connection(username: str, password: str):",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "check_connection",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def check_connection(username: str, password: str):\n    # Do endless while loop and check if connected every 100 milliseconds\n    MAX_RETRIES = 15\n    counter = 0\n    client = None\n    connected = False\n    while True:\n        try:\n            time.sleep(0.5)\n            res = requests.get(f\"{BASE_URL}/v2/system/mdds/status\", timeout=1)",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_request",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_request(url: str, headers: dict, querystring: dict, username: str, password: str):\n    counter = 0\n    while True:\n        try:\n            response = requests.get(url, headers=headers, params=querystring)\n            # If status code is not 200, then we are not connected\n            if response.status_code != 200:\n                check_connection(username=username, password=password)\n            else:\n                json_resp = response.json()",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_historical_data",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_historical_data(asset: Asset, start_dt: datetime, end_dt: datetime, ivl: int, username: str, password: str, datastyle:str = \"ohlc\"):\n    \"\"\"\n    Get data from ThetaData\n    Parameters\n    ----------\n    asset : Asset\n        The asset we are getting data for\n    start_dt : datetime\n        The start date/time for the data we want\n    end_dt : datetime",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_expirations",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_expirations(username: str, password: str, ticker: str, after_date: date):\n    \"\"\"\n    Get a list of expiration dates for the given ticker\n    Parameters\n    ----------\n    username : str\n        Your ThetaData username\n    password : str\n        Your ThetaData password\n    ticker : str",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "get_strikes",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "def get_strikes(username: str, password: str, ticker: str, expiration: datetime):\n    \"\"\"\n    Get a list of strike prices for the given ticker and expiration date\n    Parameters\n    ----------\n    username : str\n        Your ThetaData username\n    password : str\n        Your ThetaData password\n    ticker : str",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "WAIT_TIME",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "WAIT_TIME = 60\nMAX_DAYS = 30\nCACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "MAX_DAYS",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "MAX_DAYS = 30\nCACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "CACHE_SUBFOLDER",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "CACHE_SUBFOLDER = \"thetadata\"\nBASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.thetadata_helper",
        "description": "pages2.lumibot.tools.thetadata_helper",
        "peekOfCode": "BASE_URL = \"http://127.0.0.1:25510\"\ndef get_price_data(\n    username: str,\n    password: str,\n    asset: Asset,\n    start: datetime,\n    end: datetime,\n    timespan: str = \"minute\",\n    quote_asset: Asset = None,\n    dt=None,",
        "detail": "pages2.lumibot.tools.thetadata_helper",
        "documentation": {}
    },
    {
        "label": "check_numeric",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.types",
        "description": "pages2.lumibot.tools.types",
        "peekOfCode": "def check_numeric(\n    input, type, error_message, positive=True, strict=False, nullable=False, ratio=False, allow_negative=True\n):\n    if nullable and input is None:\n        return None\n    error = ValueError(error_message)\n    if isinstance(input, str) or (type == Decimal and not isinstance(input, Decimal)):\n        try:\n            input = type(input)\n        except:",
        "detail": "pages2.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_positive",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.types",
        "description": "pages2.lumibot.tools.types",
        "peekOfCode": "def check_positive(input, type, custom_message=\"\", strict=False):\n    if strict:\n        error_message = \"%r is not a strictly positive value.\" % input\n    else:\n        error_message = \"%r is not a positive value.\" % input\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    result = check_numeric(\n        input,\n        type,",
        "detail": "pages2.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_quantity",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.types",
        "description": "pages2.lumibot.tools.types",
        "peekOfCode": "def check_quantity(quantity, custom_message=\"\"):\n    error_message = \"%r is not a positive Decimal.\" % quantity\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    quantity = Decimal(quantity)\n    result = check_numeric(\n        quantity,\n        Decimal,\n        error_message,\n        strict=True,",
        "detail": "pages2.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "check_price",
        "kind": 2,
        "importPath": "pages2.lumibot.tools.types",
        "description": "pages2.lumibot.tools.types",
        "peekOfCode": "def check_price(price, custom_message=\"\", nullable=True, allow_negative=True):\n    error_message = \"%r is not a valid price.\" % price\n    if custom_message:\n        error_message = f\"{error_message} {custom_message}\"\n    result = check_numeric(price, float, error_message, strict=True, nullable=nullable, allow_negative=allow_negative)\n    return result",
        "detail": "pages2.lumibot.tools.types",
        "documentation": {}
    },
    {
        "label": "_YahooData",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.yahoo_helper",
        "description": "pages2.lumibot.tools.yahoo_helper",
        "peekOfCode": "class _YahooData:\n    def __init__(self, symbol, type, data):\n        self.symbol = symbol\n        self.type = type.lower()\n        self.data = data\n        self.file_name = f\"{symbol}_{type.lower()}.pickle\"\n    def is_up_to_date(self, last_needed_datetime=None):\n        if last_needed_datetime is None:\n            last_needed_datetime = get_lumibot_datetime()\n        if self.type == '1d':",
        "detail": "pages2.lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "YahooHelper",
        "kind": 6,
        "importPath": "pages2.lumibot.tools.yahoo_helper",
        "description": "pages2.lumibot.tools.yahoo_helper",
        "peekOfCode": "class YahooHelper:\n    # =========Internal initialization parameters and methods============\n    CACHING_ENABLED = False\n    LUMIBOT_YAHOO_CACHE_FOLDER = os.path.join(LUMIBOT_CACHE_FOLDER, \"yahoo\")\n    if not os.path.exists(LUMIBOT_YAHOO_CACHE_FOLDER):\n        try:\n            os.makedirs(LUMIBOT_YAHOO_CACHE_FOLDER)\n            CACHING_ENABLED = True\n        except Exception as e:\n            pass",
        "detail": "pages2.lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "INFO_DATA",
        "kind": 5,
        "importPath": "pages2.lumibot.tools.yahoo_helper",
        "description": "pages2.lumibot.tools.yahoo_helper",
        "peekOfCode": "INFO_DATA = \"info\"\nclass _YahooData:\n    def __init__(self, symbol, type, data):\n        self.symbol = symbol\n        self.type = type.lower()\n        self.data = data\n        self.file_name = f\"{symbol}_{type.lower()}.pickle\"\n    def is_up_to_date(self, last_needed_datetime=None):\n        if last_needed_datetime is None:\n            last_needed_datetime = get_lumibot_datetime()",
        "detail": "pages2.lumibot.tools.yahoo_helper",
        "documentation": {}
    },
    {
        "label": "DebugLogTrader",
        "kind": 6,
        "importPath": "pages2.lumibot.traders.debug_log_trader",
        "description": "pages2.lumibot.traders.debug_log_trader",
        "peekOfCode": "class DebugLogTrader(Trader):\n    \"\"\"I'm just a trader instance with debug turned on by default\"\"\"\n    def __init__(self, logfile=\"\", backtest=False, debug=True, strategies=None, quiet_logs=False):\n        super().__init__(logfile=logfile, backtest=backtest, debug=debug, strategies=strategies, quiet_logs=quiet_logs)",
        "detail": "pages2.lumibot.traders.debug_log_trader",
        "documentation": {}
    },
    {
        "label": "Trader",
        "kind": 6,
        "importPath": "pages2.lumibot.traders.trader",
        "description": "pages2.lumibot.traders.trader",
        "peekOfCode": "class Trader:\n    def __init__(self, logfile=\"\", backtest=False, debug=False, strategies=None, quiet_logs=False):\n        \"\"\"\n        Parameters\n        ----------\n        logfile: str\n            The path to the logfile. If not specified, the logfile will be saved in the user's log directory.\n        backtest: bool\n            Whether to run the strategies in backtest mode or not. This is used as a safety check to make sure you\n            don't mix backtesting and live strategies.",
        "detail": "pages2.lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.traders.trader",
        "description": "pages2.lumibot.traders.trader",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# import streamlit as st\nclass Trader:\n    def __init__(self, logfile=\"\", backtest=False, debug=False, strategies=None, quiet_logs=False):\n        \"\"\"\n        Parameters\n        ----------\n        logfile: str\n            The path to the logfile. If not specified, the logfile will be saved in the user's log directory.\n        backtest: bool",
        "detail": "pages2.lumibot.traders.trader",
        "documentation": {}
    },
    {
        "label": "CustomStream",
        "kind": 6,
        "importPath": "pages2.lumibot.trading_builtins.custom_stream",
        "description": "pages2.lumibot.trading_builtins.custom_stream",
        "peekOfCode": "class CustomStream:\n    def __init__(self):\n        self._queue = Queue(100)\n        self._actions_mapping = {}\n    def dispatch(self, event, wait_until_complete=False, **payload):\n        self._queue.put((event, payload), block=False)\n        # Primarily used for backtesting. If wait_until_complete is True, the function will block until the queue is\n        # empty. This is useful for ensuring that all events have been processed before moving on to the next step.\n        if wait_until_complete:\n            self._queue.join()",
        "detail": "pages2.lumibot.trading_builtins.custom_stream",
        "documentation": {}
    },
    {
        "label": "PollingStream",
        "kind": 6,
        "importPath": "pages2.lumibot.trading_builtins.custom_stream",
        "description": "pages2.lumibot.trading_builtins.custom_stream",
        "peekOfCode": "class PollingStream(CustomStream):\n    \"\"\"\n    A stream that polls an API endpoint at a regular interval and dispatches events based on the response. It is\n    required that a polling action is registered with the stream using add_action(). The polling action should make a\n    request to the API and dispatch events based on the response. A user can also dispatch events to the stream manually\n    using dispatch(), including the poll event to force an off-cycle poll action to occur.\n    \"\"\"\n    POLL_EVENT = \"poll\"\n    def __init__(self, polling_interval=5.0):\n        \"\"\"",
        "detail": "pages2.lumibot.trading_builtins.custom_stream",
        "documentation": {}
    },
    {
        "label": "SafeList",
        "kind": 6,
        "importPath": "pages2.lumibot.trading_builtins.safe_list",
        "description": "pages2.lumibot.trading_builtins.safe_list",
        "peekOfCode": "class SafeList:\n    def __init__(self, lock, initial=None):\n        if not isinstance(lock, rlock_type):\n            raise ValueError(\"lock must be a threading.RLock\")\n        if initial is None:\n            initial = []\n        self.__lock = lock\n        self.__items = initial\n    def __repr__(self):\n        return repr(self.__items)",
        "detail": "pages2.lumibot.trading_builtins.safe_list",
        "documentation": {}
    },
    {
        "label": "find_and_load_dotenv",
        "kind": 2,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "def find_and_load_dotenv(base_dir) -> bool:\n    for root, dirs, files in os.walk(base_dir):\n        logger.debug(f\"Checking {root} for .env file\")\n        if '.env' in files:\n            dotenv_path = os.path.join(root, '.env')\n            load_dotenv(dotenv_path)\n            # Create a colored message for the log using termcolor\n            colored_message = termcolor.colored(f\".env file loaded from: {dotenv_path}\", \"green\")\n            logger.info(colored_message)\n            return True",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef find_and_load_dotenv(base_dir) -> bool:\n    for root, dirs, files in os.walk(base_dir):\n        logger.debug(f\"Checking {root} for .env file\")\n        if '.env' in files:\n            dotenv_path = os.path.join(root, '.env')\n            load_dotenv(dotenv_path)\n            # Create a colored message for the log using termcolor\n            colored_message = termcolor.colored(f\".env file loaded from: {dotenv_path}\", \"green\")\n            logger.info(colored_message)",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "script_dir",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\nlogger.debug(f\"script_dir: {script_dir}\")\nfound_dotenv = find_and_load_dotenv(script_dir)\nif not found_dotenv:\n    # Get the root directory of the project\n    cwd_dir = os.getcwd()\n    logger.debug(f\"cwd_dir: {cwd_dir}\")\n    found_dotenv = find_and_load_dotenv(cwd_dir)\n# If no .env file was found, print a warning message\nif not found_dotenv:",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "found_dotenv",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "found_dotenv = find_and_load_dotenv(script_dir)\nif not found_dotenv:\n    # Get the root directory of the project\n    cwd_dir = os.getcwd()\n    logger.debug(f\"cwd_dir: {cwd_dir}\")\n    found_dotenv = find_and_load_dotenv(cwd_dir)\n# If no .env file was found, print a warning message\nif not found_dotenv:\n    # Create a colored message for the log using termcolor\n    colored_message = termcolor.colored(\"No .env file found. This is ok if you are using environment variables or secrets (like on Replit, AWS, etc), but if you are not, please create a .env file in the root directory of the project.\", \"yellow\")",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "is_backtesting",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "is_backtesting = os.environ.get(\"IS_BACKTESTING\")\nif not is_backtesting or is_backtesting.lower() == \"false\":\n    IS_BACKTESTING = False\nelif is_backtesting.lower() == \"true\":\n    IS_BACKTESTING = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"IS_BACKTESTING must be set to 'true' or 'false'. Got '{is_backtesting}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    IS_BACKTESTING = False",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "hide_trades",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "hide_trades = os.environ.get(\"HIDE_TRADES\")\nif not hide_trades or hide_trades.lower() == \"false\":\n    HIDE_TRADES = False\nelif hide_trades.lower() == \"true\":\n    HIDE_TRADES = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"HIDE_TRADES must be set to 'true' or 'false'. Got '{hide_trades}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    HIDE_TRADES = False",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "hide_positions",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "hide_positions = os.environ.get(\"HIDE_POSITIONS\")\nif not hide_positions or hide_positions.lower() == \"false\":\n    HIDE_POSITIONS = False\nelif hide_positions.lower() == \"true\":\n    HIDE_POSITIONS = True\nelse:\n    # Log a warning if the value is not a boolean\n    colored_message = termcolor.colored(f\"HIDE_POSITIONS must be set to 'true' or 'false'. Got '{hide_positions}'. Defaulting to False.\", \"yellow\")\n    logger.warning(colored_message)\n    HIDE_POSITIONS = False",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "STRATEGY_NAME",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "STRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")\n# Market to be traded\nMARKET = os.environ.get(\"MARKET\")\n# Live trading configuration (if applicable)\nLIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "MARKET",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "MARKET = os.environ.get(\"MARKET\")\n# Live trading configuration (if applicable)\nLIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "LIVE_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "LIVE_CONFIG = os.environ.get(\"LIVE_CONFIG\")\n# Discord credentials\nDISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DISCORD_WEBHOOK_URL",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "DISCORD_WEBHOOK_URL = os.environ.get(\"DISCORD_WEBHOOK_URL\")\n# Get SHOW_PLOT and SHOW_INDICATORS from the environment variables, default to True\nSHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_PLOT",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "SHOW_PLOT = os.environ.get(\"SHOW_PLOT\", \"True\") == \"True\"\nSHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_INDICATORS",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "SHOW_INDICATORS = os.environ.get(\"SHOW_INDICATORS\", \"True\") == \"True\"\nSHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "SHOW_TEARSHEET",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "SHOW_TEARSHEET = os.environ.get(\"SHOW_TEARSHEET\", \"True\") == \"True\"\n# Set DB_CONNECTION_STR to None by default\nDB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):\n    DB_CONNECTION_STR = os.environ.get(\"DB_CONNECTION_STR\")",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "DB_CONNECTION_STR",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "DB_CONNECTION_STR = None\n# Add a warning if ACCOUNT_HISTORY_DB_CONNECTION_STR is set because it is now replaced by DB_CONNECTION_STR\nif os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\"):\n    print(\"ACCOUNT_HISTORY_DB_CONNECTION_STR is deprecated and will be removed in a future version. Please use DB_CONNECTION_STR instead.\")\n    DB_CONNECTION_STR = os.environ.get(\"ACCOUNT_HISTORY_DB_CONNECTION_STR\")\n# Database connection string\nif os.environ.get(\"DB_CONNECTION_STR\"):\n    DB_CONNECTION_STR = os.environ.get(\"DB_CONNECTION_STR\")\n# Name for the strategy to be used in the database\nSTRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "STRATEGY_NAME",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "STRATEGY_NAME = os.environ.get(\"STRATEGY_NAME\")\n# Set a hard limit on the memory polygon uses\nPOLYGON_MAX_MEMORY_BYTES = os.environ.get(\"POLYGON_MAX_MEMORY_BYTES\")\nPOLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_MAX_MEMORY_BYTES",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "POLYGON_MAX_MEMORY_BYTES = os.environ.get(\"POLYGON_MAX_MEMORY_BYTES\")\nPOLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,\n}\n# Polygon API Key",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "POLYGON_CONFIG = {\n    # Add POLYGON_API_KEY and POLYGON_IS_PAID_SUBSCRIPTION to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"POLYGON_API_KEY\"),\n    \"IS_PAID_SUBSCRIPTION\": os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\").lower()\n    == \"true\"\n    if os.environ.get(\"POLYGON_IS_PAID_SUBSCRIPTION\")\n    else False,\n}\n# Polygon API Key\nPOLYGON_API_KEY = POLYGON_CONFIG['API_KEY']",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "POLYGON_API_KEY",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "POLYGON_API_KEY = POLYGON_CONFIG['API_KEY']\n# Thetadata Configuration\nTHETADATA_CONFIG = {\n    # Get the ThetaData API key from the .env file or secrets\n    \"THETADATA_USERNAME\": os.environ.get(\"THETADATA_USERNAME\"),\n    \"THETADATA_PASSWORD\": os.environ.get(\"THETADATA_PASSWORD\")\n}\n# Alpaca Configuration\nALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "THETADATA_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "THETADATA_CONFIG = {\n    # Get the ThetaData API key from the .env file or secrets\n    \"THETADATA_USERNAME\": os.environ.get(\"THETADATA_USERNAME\"),\n    \"THETADATA_PASSWORD\": os.environ.get(\"THETADATA_PASSWORD\")\n}\n# Alpaca Configuration\nALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"ALPACA_API_KEY\"),\n    \"API_SECRET\": os.environ.get(\"ALPACA_API_SECRET\"),",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "ALPACA_CONFIG = {  # Paper trading!\n    # Add ALPACA_API_KEY, ALPACA_API_SECRET, and ALPACA_IS_PAPER to your .env file or set them as secrets\n    \"API_KEY\": os.environ.get(\"ALPACA_API_KEY\"),\n    \"API_SECRET\": os.environ.get(\"ALPACA_API_SECRET\"),\n    \"PAPER\": os.environ.get(\"ALPACA_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"ALPACA_IS_PAPER\")\n    else True,\n}\nALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", ",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": \"PKXQGLU5DJJ30MUWS2G6\", \n    \"API_SECRET\": \"vPSm9TeqjD7WhYYcuhhvdyXZiFjJQDSlO5ic5s1d\", \n    \"PAPER\": True\n}\nBASE_URL = \"https://paper-api.alpaca.markets\"\n# Tradier Configuration\nTRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\n# Tradier Configuration\nTRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),\n    \"ACCOUNT_NUMBER\": os.environ.get(\"TRADIER_ACCOUNT_NUMBER\"),\n    \"PAPER\": os.environ.get(\"TRADIER_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"TRADIER_IS_PAPER\")\n    else True,\n}",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "TRADIER_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "TRADIER_CONFIG = {\n    # Add TRADIER_ACCESS_TOKEN, TRADIER_ACCOUNT_NUMBER, and TRADIER_IS_PAPER to your .env file or set them as secrets\n    \"ACCESS_TOKEN\": os.environ.get(\"TRADIER_ACCESS_TOKEN\"),\n    \"ACCOUNT_NUMBER\": os.environ.get(\"TRADIER_ACCOUNT_NUMBER\"),\n    \"PAPER\": os.environ.get(\"TRADIER_IS_PAPER\").lower() == \"true\"\n    if os.environ.get(\"TRADIER_IS_PAPER\")\n    else True,\n}\nKRAKEN_CONFIG = {\n    # Add KRAKEN_API_KEY and KRAKEN_API_SECRET to your .env file or set them as secrets",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "KRAKEN_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "KRAKEN_CONFIG = {\n    # Add KRAKEN_API_KEY and KRAKEN_API_SECRET to your .env file or set them as secrets\n    \"exchange_id\": \"kraken\",\n    \"apiKey\": os.environ.get(\"KRAKEN_API_KEY\"),\n    \"secret\": os.environ.get(\"KRAKEN_API_SECRET\"),\n    \"margin\": True,\n    \"sandbox\": False,\n}\nCOINBASE_CONFIG = {\n    # Add COINBASE_API_KEY and COINBASE_API_SECRET to your .env file or set them as secrets",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "COINBASE_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "COINBASE_CONFIG = {\n    # Add COINBASE_API_KEY and COINBASE_API_SECRET to your .env file or set them as secrets\n    \"exchange_id\": \"coinbase\",\n    \"apiKey\": os.environ.get(\"COINBASE_API_KEY\"),\n    \"secret\": os.environ.get(\"COINBASE_API_SECRET\"),\n    \"margin\": False,\n    \"sandbox\": False,\n}\nINTERACTIVE_BROKERS_CONFIG = {\n    \"SOCKET_PORT\": int(os.environ.get(\"INTERACTIVE_BROKERS_PORT\")) if os.environ.get(\"INTERACTIVE_BROKERS_PORT\") else None,",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "INTERACTIVE_BROKERS_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "INTERACTIVE_BROKERS_CONFIG = {\n    \"SOCKET_PORT\": int(os.environ.get(\"INTERACTIVE_BROKERS_PORT\")) if os.environ.get(\"INTERACTIVE_BROKERS_PORT\") else None,\n    \"CLIENT_ID\": int(os.environ.get(\"INTERACTIVE_BROKERS_CLIENT_ID\")) if os.environ.get(\"INTERACTIVE_BROKERS_CLIENT_ID\") else None,\n    \"IP\": os.environ.get(\"INTERACTIVE_BROKERS_IP\", \"127.0.0.1\"),\n    \"IB_SUBACCOUNT\": os.environ.get(\"IB_SUBACCOUNT\", None)\n}\nINTERACTIVE_BROKERS_REST_CONFIG = {\n    \"IB_USERNAME\": os.environ.get(\"IB_USERNAME\"),\n    \"IB_PASSWORD\": os.environ.get(\"IB_PASSWORD\"),\n    \"ACCOUNT_ID\": os.environ.get(\"ACCOUNT_ID\"),",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "INTERACTIVE_BROKERS_REST_CONFIG",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "INTERACTIVE_BROKERS_REST_CONFIG = {\n    \"IB_USERNAME\": os.environ.get(\"IB_USERNAME\"),\n    \"IB_PASSWORD\": os.environ.get(\"IB_PASSWORD\"),\n    \"ACCOUNT_ID\": os.environ.get(\"ACCOUNT_ID\"),\n    \"API_URL\": os.environ.get(\"IB_API_URL\"),\n    \"RUNNING_ON_SERVER\": os.environ.get(\"RUNNING_ON_SERVER\")\n}\nLUMIWEALTH_API_KEY = os.environ.get(\"LUMIWEALTH_API_KEY\")\nif IS_BACKTESTING:\n    broker = None",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "LUMIWEALTH_API_KEY",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "LUMIWEALTH_API_KEY = os.environ.get(\"LUMIWEALTH_API_KEY\")\nif IS_BACKTESTING:\n    broker = None\nelse:\n    # If using Alpaca as a broker, set that as the broker\n    if ALPACA_CONFIG[\"API_KEY\"]:\n        broker = Alpaca(ALPACA_CONFIG)\n    # If using Tradier as a broker, set that as the broker\n    elif TRADIER_CONFIG[\"ACCESS_TOKEN\"]:\n        broker = Tradier(TRADIER_CONFIG)",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "BROKER",
        "kind": 5,
        "importPath": "pages2.lumibot.credentials",
        "description": "pages2.lumibot.credentials",
        "peekOfCode": "BROKER = broker",
        "detail": "pages2.lumibot.credentials",
        "documentation": {}
    },
    {
        "label": "get_sentiment_score",
        "kind": 2,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "def get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n    result = sentiment_analyzer(text)\n    sentiment = result[0]['label']\n    score = result[0]['score']\n    return sentiment, score\n# Step 2: Data Collection",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "collect_data",
        "kind": 2,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "def collect_data():\n    import pandas as pd\n    # Example dataset\n    data = {\n        'date': ['2023-10-01', '2023-10-02', '2023-10-03'],\n        'text': ['Great earnings report!', 'Market crash expected.', 'Stable growth predicted.']\n    }\n    df = pd.DataFrame(data)\n    # Apply sentiment analysis\n    df['sentiment'], df['score'] = zip(*df['text'].apply(get_sentiment_score))",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "estimate_sentiment",
        "kind": 2,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "def estimate_sentiment(news):\n    if news:\n        tokens = tokenizer(news, return_tensors=\"pt\", padding=True).to(device)\n        result = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[\n            \"logits\"\n        ]\n        result = torch.nn.functional.softmax(torch.sum(result, 0), dim=-1)\n        probability = result[torch.argmax(result)]\n        sentiment = labels[torch.argmax(result)]\n        return probability, sentiment",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\nlabels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pages2.lumibot.finbert_utils",
        "description": "pages2.lumibot.finbert_utils",
        "peekOfCode": "labels = [\"positive\", \"negative\", \"neutral\"]\n# added by dov to prevent TOKENIZERS_PARALLELISM the warning:\n# TOKENIZERS_PARALLELISM=False\n# Step 1: Sentiment Analysis with BERT\n# We will use the transformers library from Hugging Face to load a pre-trained BERT model for sentiment analysis. This model will classify financial news or tweets as positive, neutral, or negative.\ndef get_sentiment_score(text):\n    # DOV\n    from transformers import pipeline\n    # Load pre-trained BERT model for sentiment analysis\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")",
        "detail": "pages2.lumibot.finbert_utils",
        "documentation": {}
    },
    {
        "label": "generate_response",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.1.simple_chatbot.1.simple_chatbot",
        "description": "pages2.ollama-chatbot.1.simple_chatbot.1.simple_chatbot",
        "peekOfCode": "def generate_response(input_text):\n    model = ChatOllama(model=\"llama3.2:1b\", base_url=\"http://localhost:11434/\")\n    response = model.invoke(input_text)\n    return response.content\nif \"chat_history\" not in st.session_state:\n    st.session_state['chat_history'] = []\nif submit and text:\n    with st.spinner(\"Generating response...\"):\n        response = generate_response(text)\n        st.session_state['chat_history'].append({\"user\": text, \"ollama\": response})",
        "detail": "pages2.ollama-chatbot.1.simple_chatbot.1.simple_chatbot",
        "documentation": {}
    },
    {
        "label": "generate_response",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "description": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "peekOfCode": "def generate_response(chat_histroy):\n    chat_template = ChatPromptTemplate.from_messages(chat_histroy)\n    chain = chat_template|model|StrOutputParser()\n    response = chain.invoke({})\n    return response\n# user message in 'user' key\n# ai message in 'assistant' key\ndef get_history():\n    chat_history = [system_message]\n    for chat in st.session_state['chat_history']:",
        "detail": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "documentation": {}
    },
    {
        "label": "get_history",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "description": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "peekOfCode": "def get_history():\n    chat_history = [system_message]\n    for chat in st.session_state['chat_history']:\n        prompt = HumanMessagePromptTemplate.from_template(chat['user'])\n        chat_history.append(prompt)\n        ai_message = AIMessagePromptTemplate.from_template(chat['assistant'])\n        chat_history.append(ai_message)\n    return chat_history\nif submit and text:\n    with st.spinner(\"Generating response...\"):",
        "detail": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "description": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "peekOfCode": "model = ChatOllama(model=\"llama3.2:1b\", base_url=\"http://localhost:11434/\")\nsystem_message = SystemMessagePromptTemplate.from_template(\"You are a helpful AI Assistant. You work as teacher for 5th grade students. You explain things in short and brief.\")\nif \"chat_history\" not in st.session_state:\n    st.session_state['chat_history'] = []\nwith st.form(\"llm-form\"):\n    text = st.text_area(\"Enter your question here.\")\n    submit = st.form_submit_button(\"Submit\")\ndef generate_response(chat_histroy):\n    chat_template = ChatPromptTemplate.from_messages(chat_histroy)\n    chain = chat_template|model|StrOutputParser()",
        "detail": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "documentation": {}
    },
    {
        "label": "system_message",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "description": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "peekOfCode": "system_message = SystemMessagePromptTemplate.from_template(\"You are a helpful AI Assistant. You work as teacher for 5th grade students. You explain things in short and brief.\")\nif \"chat_history\" not in st.session_state:\n    st.session_state['chat_history'] = []\nwith st.form(\"llm-form\"):\n    text = st.text_area(\"Enter your question here.\")\n    submit = st.form_submit_button(\"Submit\")\ndef generate_response(chat_histroy):\n    chat_template = ChatPromptTemplate.from_messages(chat_histroy)\n    chain = chat_template|model|StrOutputParser()\n    response = chain.invoke({})",
        "detail": "pages2.ollama-chatbot.2.chatbot_with_history.2.chatbot_with_history",
        "documentation": {}
    },
    {
        "label": "generate_response",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "description": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "peekOfCode": "def generate_response(chat_histroy):\n    chat_template = ChatPromptTemplate.from_messages(chat_histroy)\n    chain = chat_template|model|StrOutputParser()\n    response = chain.invoke({})\n    return response\n# user message in 'user' key\n# ai message in 'assistant' key\ndef get_history():\n    chat_history = [system_message]\n    for chat in st.session_state['chat_history']:",
        "detail": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "documentation": {}
    },
    {
        "label": "get_history",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "description": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "peekOfCode": "def get_history():\n    chat_history = [system_message]\n    for chat in st.session_state['chat_history']:\n        prompt = HumanMessagePromptTemplate.from_template(chat['user'])\n        chat_history.append(prompt)\n        ai_message = AIMessagePromptTemplate.from_template(chat['assistant'])\n        chat_history.append(ai_message)\n    return chat_history\nif submit and text:\n    with st.spinner(\"Generating response...\"):",
        "detail": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "description": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "peekOfCode": "model_name = \"deepseek-r1:1.5b\"\n# model_name = \"deepseek-r1:1.5b\"\nmodel = ChatOllama(model=model_name, base_url=\"http://localhost:11434\")\nst.write(\"DeepSeek is a powerful language model that can generate human-like text. It is trained on a diverse range of text data and can generate text in multiple languages. It is a large model with 1.5 billion parameters.\")\nsystem_message = SystemMessagePromptTemplate.from_template(\"You are helpful AI assistant. You work as a software progremmer who like to write code in short and correct. You also like to use a lot of print for debugging.\")\nif \"chat_history\" not in st.session_state:\n    st.session_state['chat_history'] = []\nwith st.form(\"llm-form\"):\n    text = st.text_area(\"Enter your question here.\")\n    submit = st.form_submit_button(\"Submit\")",
        "detail": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "description": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "peekOfCode": "model = ChatOllama(model=model_name, base_url=\"http://localhost:11434\")\nst.write(\"DeepSeek is a powerful language model that can generate human-like text. It is trained on a diverse range of text data and can generate text in multiple languages. It is a large model with 1.5 billion parameters.\")\nsystem_message = SystemMessagePromptTemplate.from_template(\"You are helpful AI assistant. You work as a software progremmer who like to write code in short and correct. You also like to use a lot of print for debugging.\")\nif \"chat_history\" not in st.session_state:\n    st.session_state['chat_history'] = []\nwith st.form(\"llm-form\"):\n    text = st.text_area(\"Enter your question here.\")\n    submit = st.form_submit_button(\"Submit\")\ndef generate_response(chat_histroy):\n    chat_template = ChatPromptTemplate.from_messages(chat_histroy)",
        "detail": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "documentation": {}
    },
    {
        "label": "system_message",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "description": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "peekOfCode": "system_message = SystemMessagePromptTemplate.from_template(\"You are helpful AI assistant. You work as a software progremmer who like to write code in short and correct. You also like to use a lot of print for debugging.\")\nif \"chat_history\" not in st.session_state:\n    st.session_state['chat_history'] = []\nwith st.form(\"llm-form\"):\n    text = st.text_area(\"Enter your question here.\")\n    submit = st.form_submit_button(\"Submit\")\ndef generate_response(chat_histroy):\n    chat_template = ChatPromptTemplate.from_messages(chat_histroy)\n    chain = chat_template|model|StrOutputParser()\n    response = chain.invoke({})",
        "detail": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.chat_deepseek",
        "documentation": {}
    },
    {
        "label": "generate_fibonacci",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.code",
        "description": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.code",
        "peekOfCode": "def generate_fibonacci(n):\n    fib_sequence = []\n    if n < 0:\n        return []\n    a, b = 0, 1\n    for _ in range(2, n + 1):  # Start from 2 to reach up to the nth number (inclusive)\n        fib_sequence.append(a)\n        a, b = a + b, a\n    if len(fib_sequence) > 0 and fib_sequence[-1] < n:\n        fib_sequence.pop()",
        "detail": "pages2.ollama-chatbot.4. deepseek_r1_chatbot.code",
        "documentation": {}
    },
    {
        "label": "load_and_convert_document",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "description": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "peekOfCode": "def load_and_convert_document(file_path):\n    converter = DocumentConverter()\n    result = converter.convert(file_path)\n    return result.document.export_to_markdown()\n# Splitting markdown content into chunks\ndef get_markdown_splits(markdown_content):\n    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n    return markdown_splitter.split_text(markdown_content)\n# Embedding and vector store setup",
        "detail": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "documentation": {}
    },
    {
        "label": "get_markdown_splits",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "description": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "peekOfCode": "def get_markdown_splits(markdown_content):\n    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n    return markdown_splitter.split_text(markdown_content)\n# Embedding and vector store setup\ndef setup_vector_store(chunks):\n    embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url=\"http://localhost:11434\")\n    single_vector = embeddings.embed_query(\"this is some text data\")\n    index = faiss.IndexFlatL2(len(single_vector))\n    vector_store = FAISS(",
        "detail": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "documentation": {}
    },
    {
        "label": "setup_vector_store",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "description": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "peekOfCode": "def setup_vector_store(chunks):\n    embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url=\"http://localhost:11434\")\n    single_vector = embeddings.embed_query(\"this is some text data\")\n    index = faiss.IndexFlatL2(len(single_vector))\n    vector_store = FAISS(\n        embedding_function=embeddings,\n        index=index,\n        docstore=InMemoryDocstore(),\n        index_to_docstore_id={}\n    )",
        "detail": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "documentation": {}
    },
    {
        "label": "format_docs",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "description": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "peekOfCode": "def format_docs(docs):\n    return \"\\n\\n\".join([doc.page_content for doc in docs])\n# Setting up the RAG chain\ndef create_rag_chain(retriever):\n    prompt = \"\"\"\n        You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n        If you don't know the answer, just say that you don't know.\n        Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\n        Question: {question} \n        Context: {context} ",
        "detail": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "documentation": {}
    },
    {
        "label": "create_rag_chain",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "description": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "peekOfCode": "def create_rag_chain(retriever):\n    prompt = \"\"\"\n        You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n        If you don't know the answer, just say that you don't know.\n        Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\n        Question: {question} \n        Context: {context} \n        Answer:\n    \"\"\"\n    model = ChatOllama(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")",
        "detail": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "documentation": {}
    },
    {
        "label": "os.environ['KMP_DUPLICATE_LIB_OK']",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "description": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "peekOfCode": "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\nwarnings.filterwarnings(\"ignore\")\nload_dotenv()\n# Document conversion\ndef load_and_convert_document(file_path):\n    converter = DocumentConverter()\n    result = converter.convert(file_path)\n    return result.document.export_to_markdown()\n# Splitting markdown content into chunks\ndef get_markdown_splits(markdown_content):",
        "detail": "pages2.ollama-chatbot.5. Build RAG Locally with DeepSeek.finance_rag",
        "documentation": {}
    },
    {
        "label": "display_pdf_in_sidebar",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "peekOfCode": "def display_pdf_in_sidebar(pdf_path, file_name):\n    try:\n        images_folder = Path(VECTOR_DB_FOLDER) / file_name / \"images\"\n        os.makedirs(images_folder, exist_ok=True)\n        # Check if images already exist\n        image_paths = list(images_folder.glob(\"*.png\"))\n        if image_paths:\n            # If images exist, display them\n            for img_path in image_paths:\n                image = Image.open(img_path)",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "documentation": {}
    },
    {
        "label": "VECTOR_DB_FOLDER",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "peekOfCode": "VECTOR_DB_FOLDER = \"vector_db\"\nos.makedirs(VECTOR_DB_FOLDER, exist_ok=True)\n# Function to display PDF content as images in the sidebar\ndef display_pdf_in_sidebar(pdf_path, file_name):\n    try:\n        images_folder = Path(VECTOR_DB_FOLDER) / file_name / \"images\"\n        os.makedirs(images_folder, exist_ok=True)\n        # Check if images already exist\n        image_paths = list(images_folder.glob(\"*.png\"))\n        if image_paths:",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "documentation": {}
    },
    {
        "label": "vector_db_options",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "peekOfCode": "vector_db_options = [f.stem for f in Path(VECTOR_DB_FOLDER).glob(\"*.faiss\")]\nvector_db_options.append(\"Upload New Document\")  # Add option to upload a new document\nselected_vector_db = st.selectbox(\"Select Vector DB or Upload New Document\", vector_db_options, index=0)\n# If 'Upload New Document' is selected, show the file uploader\nif selected_vector_db == \"Upload New Document\":\n    uploaded_file = st.file_uploader(\"Upload a PDF file for analysis\", type=[\"pdf\"])\n    # Process the uploaded PDF\n    if uploaded_file:\n        st.sidebar.subheader(\"Uploaded PDF\")\n        st.sidebar.write(uploaded_file.name)",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "documentation": {}
    },
    {
        "label": "selected_vector_db",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "peekOfCode": "selected_vector_db = st.selectbox(\"Select Vector DB or Upload New Document\", vector_db_options, index=0)\n# If 'Upload New Document' is selected, show the file uploader\nif selected_vector_db == \"Upload New Document\":\n    uploaded_file = st.file_uploader(\"Upload a PDF file for analysis\", type=[\"pdf\"])\n    # Process the uploaded PDF\n    if uploaded_file:\n        st.sidebar.subheader(\"Uploaded PDF\")\n        st.sidebar.write(uploaded_file.name)\n        # Save the PDF file temporarily and display it\n        temp_path = f\"temp_{uploaded_file.name}\"",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "documentation": {}
    },
    {
        "label": "question",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "peekOfCode": "question = st.text_input(\"Enter your question:\", placeholder=\"e.g., What is the company's revenue for the quarter?\")\n# Button to process and generate answers\nif st.button(\"Submit Question\") and question and selected_vector_db != \"Upload New Document\":\n    with st.spinner(\"Answering your question...\"):\n        # Build retriever from the selected vector store\n        retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 5})\n        # Build and run the RAG chain\n        rag_chain = build_rag_chain(retriever)\n        # Create a placeholder for streaming response\n        response_placeholder = st.empty()  # Create an empty placeholder for the answer",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.app",
        "documentation": {}
    },
    {
        "label": "load_and_convert_document",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "peekOfCode": "def load_and_convert_document(file_path):\n    converter = DocumentConverter()\n    result = converter.convert(file_path)\n    return result.document.export_to_markdown()\n# Split markdown into chunks\ndef get_markdown_splits(markdown_content):\n    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n    splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n    return splitter.split_text(markdown_content)\n# Create or load the vector store",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "documentation": {}
    },
    {
        "label": "get_markdown_splits",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "peekOfCode": "def get_markdown_splits(markdown_content):\n    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n    splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n    return splitter.split_text(markdown_content)\n# Create or load the vector store\ndef create_or_load_vector_store(filename, chunks, embeddings):\n    vector_db_path = Path(VECTOR_DB_FOLDER) / f\"{filename}.faiss\"\n    if vector_db_path.exists():\n        vector_store = FAISS.load_local(str(vector_db_path), embeddings=embeddings, allow_dangerous_deserialization=True)\n    else:",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "documentation": {}
    },
    {
        "label": "create_or_load_vector_store",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "peekOfCode": "def create_or_load_vector_store(filename, chunks, embeddings):\n    vector_db_path = Path(VECTOR_DB_FOLDER) / f\"{filename}.faiss\"\n    if vector_db_path.exists():\n        vector_store = FAISS.load_local(str(vector_db_path), embeddings=embeddings, allow_dangerous_deserialization=True)\n    else:\n        single_vector = embeddings.embed_query(\"initialize\")\n        index = faiss.IndexFlatL2(len(single_vector))\n        vector_store = FAISS(\n            embedding_function=embeddings,\n            index=index,",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "documentation": {}
    },
    {
        "label": "build_rag_chain",
        "kind": 2,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "peekOfCode": "def build_rag_chain(retriever):\n    prompt = \"\"\"\n        You are an assistant for financial data analysis. Use the retrieved context to answer questions. \n        If you don't know the answer, say so. \n        Question: {question}\n        Context: {context}\n        Answer:\n    \"\"\"\n    prompt_template = ChatPromptTemplate.from_template(prompt)\n    model = ChatOllama(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "documentation": {}
    },
    {
        "label": "VECTOR_DB_FOLDER",
        "kind": 5,
        "importPath": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "description": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "peekOfCode": "VECTOR_DB_FOLDER = \"vector_db\"\nos.makedirs(VECTOR_DB_FOLDER, exist_ok=True)\n# Load and convert PDF to markdown content\ndef load_and_convert_document(file_path):\n    converter = DocumentConverter()\n    result = converter.convert(file_path)\n    return result.document.export_to_markdown()\n# Split markdown into chunks\ndef get_markdown_splits(markdown_content):\n    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]",
        "detail": "pages2.ollama-chatbot.6. Build Financial Document Analyst with DeepSeek.rag",
        "documentation": {}
    },
    {
        "label": "AlphaVantageData",
        "kind": 6,
        "importPath": "pages2.util.alpha_vantage_data",
        "description": "pages2.util.alpha_vantage_data",
        "peekOfCode": "class AlphaVantageData(DataSource):\n    SOURCE = \"ALPHA_VANTAGE\"\n    MIN_TIMESTEP = \"minute\"\n    DATA_STALE_AFTER = timedelta(days=1)\n    def __init__(self, config=None, auto_adjust=True, **kwargs):\n        self.name = \"alpha vantage\"\n        self.auto_adjust = auto_adjust\n        self._data_store = {}\n        self.config = config\n    def _append_data(self, asset, data):",
        "detail": "pages2.util.alpha_vantage_data",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "ALPACA_API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom lib.rl.config import (\n    OrderType,\n    OrderSide,\n    TimeInForce,\n)\n# from alpaca.trading.enums import OrderSide, TimeInForce, OrderType\nfrom lib.rl.config_tickers import DOW_30_TICKER\nfrom lib.rl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom lib.rl.meta.preprocessor.preprocessors import FeatureEngineer, data_split",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "TRAIN_START_DATE = '2009-04-01'\nTRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "TRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "TEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())\nst.write(df.tail())",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "TEST_END_DATE = '2022-06-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())\nst.write(df.tail())\nst.write(df.shape)",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\ndf.sort_values(['date','tic']).head()\nst.write(len(df.tic.unique()))\nst.write(df.tic.value_counts())\nst.write(df.head())\nst.write(df.tail())\nst.write(df.shape)\nINDICATORS = ['macd',",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, ",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, ",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, ",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, ",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, ",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension, \n    \"reward_scaling\": 1e-4,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "SAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}\nTD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "TD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "timesteps_dict = {\n    'a2c': 1,  # Example value, adjust as needed\n    'ppo': 1,\n    'ddpg': 1,\n    'sac' : 1,\n    'td3' : 1\n}\ndf_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,\n    DDPG_model_kwargs,\n    SAC_model_kwargs,\n    TD3_model_kwargs,\n    timesteps_dict\n)\nst.write(df_summary)\nunique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value = pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value = pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\ndf_account_value.account_value.plot()",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "df_account_value",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "df_account_value = pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\ndf_account_value.account_value.plot()\nst.line_chart(df_account_value['account_value'])",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "baseline_df",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "baseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "stats = backtest_stats(baseline_df, value_col_name = 'close')\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX\nbacktest_plot(df_account_value, \n              baseline_ticker = '^DJI', \n              baseline_start = df_account_value.loc[0,'date'],\n              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "pages2.util.rl_Stock_Trading",
        "description": "pages2.util.rl_Stock_Trading",
        "peekOfCode": "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')\ntry:\n    account = api.get_account()\n    st.write(f\"Account status: {account.status}\")\n    symbol = 'CAT'\n    qty = 1  # Quantity to buy\n    if (sharpe > - 94):\n        buy_order = api.submit_order(\n            symbol=symbol,\n            qty=qty,",
        "detail": "pages2.util.rl_Stock_Trading",
        "documentation": {}
    },
    {
        "label": "stock_trading_rolling_window",
        "kind": 2,
        "importPath": "pages2.util.rl_stock_trading_rolling_window",
        "description": "pages2.util.rl_stock_trading_rolling_window",
        "peekOfCode": "def stock_trading_rolling_window(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    rolling_window_length: int,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,",
        "detail": "pages2.util.rl_stock_trading_rolling_window",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "class MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(base_url=API_BASE_URL, key_id=ALPACA_API_KEY, secret_key=ALPACA_API_SECRET)\n    def position_sizing(self): \n        cash = self.get_cash() \n        last_price = self.get_last_price(self.symbol)",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\nALPACA_CREDS = {\n    \"API_KEY\": ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}   \nfrom lumibot.brokers.alpaca import Alpaca    \nfrom lumibot.backtesting import YahooDataBacktesting, PandasDataBacktesting,  PolygonDataBacktesting, AlpacaBacktesting\nfrom lib.rl.config_tickers import index_dict\nfrom lumibot.strategies import Strategy",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}   \nfrom lumibot.brokers.alpaca import Alpaca    \nfrom lumibot.backtesting import YahooDataBacktesting, PandasDataBacktesting,  PolygonDataBacktesting, AlpacaBacktesting\nfrom lib.rl.config_tickers import index_dict\nfrom lumibot.strategies import Strategy\nimport os",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nfrom lumibot.finbert_utils import estimate_sentiment\nfrom lumibot.traders import Trader\nst.set_page_config(page_title=\"Stock Sentiment & Trading\", layout=\"wide\", page_icon=\"\")\n#  Title & One-Line Description\nst.markdown(\"##  Stock Sentiment & Trading Strategy\")\nst.markdown(\"Analyze stock trends using real-time market data, historical price movements, and AI-powered sentiment analysis.\")\n#  Expandable Detailed Description\nwith st.expander(\" About...\"):\n    st.markdown(\"\"\"",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "stock_data",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "stock_data = fetch_stock_data(ticker, start_date, end_date)\nt1 = start_date\nt2 = end_date\n# t1 = datetime.datetime(start_date)\n# t2 = datetime.datetime(end_date  )\n# t1 = datetime(2020,1,1)\n# t2 = datetime(2023,12,31) \nif stock_data is not None:\n    df_stock = plot_stock_data(stock_data, ticker)\n    #  News Section",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "t1",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "t1 = start_date\nt2 = end_date\n# t1 = datetime.datetime(start_date)\n# t2 = datetime.datetime(end_date  )\n# t1 = datetime(2020,1,1)\n# t2 = datetime(2023,12,31) \nif stock_data is not None:\n    df_stock = plot_stock_data(stock_data, ticker)\n    #  News Section\n    news_data = fetch_news_data(ticker)",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "t2",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "t2 = end_date\n# t1 = datetime.datetime(start_date)\n# t2 = datetime.datetime(end_date  )\n# t1 = datetime(2020,1,1)\n# t2 = datetime(2023,12,31) \nif stock_data is not None:\n    df_stock = plot_stock_data(stock_data, ticker)\n    #  News Section\n    news_data = fetch_news_data(ticker)\n    if news_data:",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "broker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":ticker, \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    t1, \n    t2, \n    parameters={\"symbol\":ticker, \"cash_at_risk\":.5}\n)",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "strategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":ticker, \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    t1, \n    t2, \n    parameters={\"symbol\":ticker, \"cash_at_risk\":.5}\n)\ntrader = Trader()",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "trader",
        "kind": 5,
        "importPath": "pages2.0_ml_Stock2_Sentiment",
        "description": "pages2.0_ml_Stock2_Sentiment",
        "peekOfCode": "trader = Trader()\ntrader.add_strategy(strategy)\ntrader.run_all()",
        "detail": "pages2.0_ml_Stock2_Sentiment",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n        action_avg = self.net(state)\n        action_std = self.action_std_log.exp()",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {'env_name': None, 'state_dim': None, 'action_dim': None, 'if_discrete': None}\n        self.env_name = env_args['env_name']  # the name of environment. Be used to set 'cwd'.\n        self.state_dim = env_args['state_dim']  # vector dimension (feature number) of state\n        self.action_dim = env_args['action_dim']  # vector dimension (feature number) of action\n        self.if_discrete = env_args['if_discrete']  # discrete or continuous action space",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class AgentBase:\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.gamma = args.gamma\n        self.batch_size = args.batch_size\n        self.repeat_times = args.repeat_times\n        self.reward_scale = args.reward_scale\n        self.soft_update_tau = args.soft_update_tau\n        self.states = None  # assert self.states == (1, state_dim)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n        self.if_off_policy = False\n        self.act_class = getattr(self, \"act_class\", ActorPPO)\n        self.cri_class = getattr(self, \"cri_class\", CriticPPO)\n        AgentBase.__init__(self, net_dims, state_dim, action_dim, gpu_id, args)\n        self.ratio_clip = getattr(args, \"ratio_clip\", 0.25)  # `ratio.clamp(1 - clip, 1 + clip)`\n        self.lambda_gae_adv = getattr(args, \"lambda_gae_adv\", 0.95)  # could be 0.80~0.99\n        self.lambda_entropy = getattr(args, \"lambda_entropy\", 0.01)  # could be 0.00~0.10\n        self.lambda_entropy = torch.tensor(self.lambda_entropy, dtype=torch.float32, device=self.device)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < '0.18.0' else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        '''the necessary env information when you design a custom env'''\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class Evaluator:\n    def __init__(self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = '.'):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = eval_times  # number of times that get episodic cumulative return\n        self.eval_per_step = eval_per_step  # evaluate the agent per training steps\n        self.recorder = []",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class AlpacaPaperTrading():\n    def __init__(self,ticker_list, time_interval, drl_lib, agent, cwd, net_dim, \n                 state_dim, action_dim, API_KEY, API_SECRET, \n                 API_BASE_URL, tech_indicator_list, turbulence_thresh=30, \n                 max_stock=1e2, latency = None):\n        #load agent\n        self.drl_lib = drl_lib\n        if agent =='ppo':\n            if drl_lib == 'elegantrl':              \n                agent_class = AgentPPO",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    #Empty Env used for loading rllib agent\n    def __init__(self,config):\n      state_dim = config['state_dim']\n      action_dim = config['action_dim']\n      self.env_num = 1\n      self.max_step = 10000\n      self.env_name = 'StockEnvEmpty'\n      self.state_dim = state_dim  \n      self.action_dim = action_dim",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {'unwrapped', 'observation_space', 'action_space', 'spec'}.issubset(dir(env)):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = state_shape[0] if len(state_shape) == 1 else state_shape  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)\n        if if_discrete:  # make sure it is discrete action space\n            action_dim = env.action_space.n\n        elif isinstance(env.action_space, gym.spaces.Box):  # make sure it is continuous action space\n            action_dim = env.action_space.shape[0]",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == 'gym.envs.registration':  # special rule\n        env = env_class(id=env_args['env_name'])\n    else:",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == 'gym.envs.registration':  # special rule\n        env = env_class(id=env_args['env_name'])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in ('env_name', 'state_dim', 'action_dim', 'if_discrete'):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args)\n    new_env, _ = env.reset()\n    agent.states = new_env[np.newaxis, :]\n    evaluator = Evaluator(eval_env=build_env(args.env_class, args.env_args),\n                          eval_per_step=args.eval_per_step,\n                          eval_times=args.eval_times,\n                          cwd=args.cwd)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def render_agent(env_class, env_args: dict, net_dims: [int], agent_class, actor_path: str, render_times: int = 8):\n    env = build_env(env_class, env_args)\n    state_dim = env_args['state_dim']\n    action_dim = env_args['action_dim']\n    agent = agent_class(net_dims, state_dim, action_dim, gpu_id=-1)\n    actor = agent.act\n    print(f\"| render and load actor from: {actor_path}\")\n    actor.load_state_dict(torch.load(actor_path, map_location=lambda storage, loc: storage))\n    for i in range(render_times):\n        cumulative_reward, episode_step = get_rewards_and_steps(env, actor, if_render=True)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def get_rewards_and_steps(env, actor, if_render: bool = False) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state, _ = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        tensor_action = actor(tensor_state)\n        action = tensor_action.detach().cpu().numpy()[0]  # not need detach(), because using torch.no_grad() outside\n        state, reward, done, _, _ = env.step(action)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\nclass ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "data_url = 'wss://data.alpaca.markets'\nclass ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n        action_avg = self.net(state)",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "ticker_list = DOW_30_TICKER\naction_dim = len(DOW_30_TICKER)\nprint(ticker_list)\nprint(INDICATORS)\n## Calculate the DRL state dimension manually for paper trading\nstate_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nprint(f\"The DRL state dimension = {state_dim}\")\nenv = StockTradingEnv\n## Show the data\n### Step 1. Pick a data source",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "action_dim",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "action_dim = len(DOW_30_TICKER)\nprint(ticker_list)\nprint(INDICATORS)\n## Calculate the DRL state dimension manually for paper trading\nstate_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nprint(f\"The DRL state dimension = {state_dim}\")\nenv = StockTradingEnv\n## Show the data\n### Step 1. Pick a data source\nDP = DataProcessor(data_source = 'alpaca',",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "state_dim",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nprint(f\"The DRL state dimension = {state_dim}\")\nenv = StockTradingEnv\n## Show the data\n### Step 1. Pick a data source\nDP = DataProcessor(data_source = 'alpaca',\n                 API_KEY = API_KEY, \n                 API_SECRET = API_SECRET, \n                 API_BASE_URL = API_BASE_URL\n                 )",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "env = StockTradingEnv\n## Show the data\n### Step 1. Pick a data source\nDP = DataProcessor(data_source = 'alpaca',\n                 API_KEY = API_KEY, \n                 API_SECRET = API_SECRET, \n                 API_BASE_URL = API_BASE_URL\n                 )\n### Step 2. Get ticker list, Set start date and end date, specify the data frequency\ndata = DP.download_data(start_date = '2021-10-04', ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "DP",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "DP = DataProcessor(data_source = 'alpaca',\n                 API_KEY = API_KEY, \n                 API_SECRET = API_SECRET, \n                 API_BASE_URL = API_BASE_URL\n                 )\n### Step 2. Get ticker list, Set start date and end date, specify the data frequency\ndata = DP.download_data(start_date = '2021-10-04', \n                       end_date = '2021-10-08',\n                       ticker_list = ticker_list, \n                        time_interval= '1Min')         ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "data = DP.download_data(start_date = '2021-10-04', \n                       end_date = '2021-10-08',\n                       ticker_list = ticker_list, \n                        time_interval= '1Min')         \ndata['timestamp'].nunique()    \n### Step 3. Data Cleaning & Feature Engineering   \ndata = DP.clean_data(data)\ndata = DP.add_technical_indicator(data, INDICATORS)\ndata = DP.add_vix(data)     \ndata.shape   ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "data = DP.clean_data(data)\ndata = DP.add_technical_indicator(data, INDICATORS)\ndata = DP.add_vix(data)     \ndata.shape   \n### Step 4. Transform to numpy array\nprice_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\nprint(price_array.shape)\n# Part 2: Train the agent\n## Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "data = DP.add_technical_indicator(data, INDICATORS)\ndata = DP.add_vix(data)     \ndata.shape   \n### Step 4. Transform to numpy array\nprice_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\nprint(price_array.shape)\n# Part 2: Train the agent\n## Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "data = DP.add_vix(data)     \ndata.shape   \n### Step 4. Transform to numpy array\nprice_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\nprint(price_array.shape)\n# Part 2: Train the agent\n## Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n        \"eval_times\":1} ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n        \"eval_times\":1} \nenv = StockTradingEnv\n#if you want to use larger datasets (change to longer period), and it raises error, \n#please try to increase \"target_step\". It should be larger than the episode steps. \ntrain(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "env = StockTradingEnv\n#if you want to use larger datasets (change to longer period), and it raises error, \n#please try to increase \"target_step\". It should be larger than the episode steps. \ntrain(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "train(start_date",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "train(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', \n      env=env,\n      model_name='ppo',\n      if_vix=True, ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "ccount_value_erl=test(start_date",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "ccount_value_erl=test(start_date = '2022-09-01', \n                      end_date = '2022-09-02',\n                      ticker_list = ticker_list, \n                      data_source = 'alpaca',\n                      time_interval= '1Min', \n                      technical_indicator_list= INDICATORS,\n                      drl_lib='elegantrl', \n                      env=env, \n                      model_name='ppo',\n                      if_vix=True, ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "train(start_date",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "train(start_date = '2022-08-25', \n      end_date = '2022-09-02',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', \n      env=env, \n      model_name='ppo',\n      if_vix=True, ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "paper_trading_erl",
        "kind": 5,
        "importPath": "pages2.10_rl_PaperTrading_Demo",
        "description": "pages2.10_rl_PaperTrading_Demo",
        "peekOfCode": "paper_trading_erl = AlpacaPaperTrading(ticker_list = DOW_30_TICKER, \n                                       time_interval = '1Min', \n                                       drl_lib = 'elegantrl', \n                                       agent = 'ppo', \n                                       cwd = './papertrading_erl_retrain', \n                                       net_dim = ERL_PARAMS['net_dimension'], \n                                       state_dim = state_dim, \n                                       action_dim= action_dim, \n                                       API_KEY = API_KEY, \n                                       API_SECRET = API_SECRET, ",
        "detail": "pages2.10_rl_PaperTrading_Demo",
        "documentation": {}
    },
    {
        "label": "configparser.SafeConfigParser",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "configparser.SafeConfigParser = configparser.RawConfigParser\nst.button(\"Re-run\")\n# st.markdown(\"# Stock Training\")\n# st.sidebar.header(\"Stock Testing\")\nst.write(\n    \"\"\"This app shows how you can use Streamlit to build cool animations.\nIt displays an animated fractal based on the the Julia Set. Use the slider\nto tune different parameters.\"\"\"\n)\ncheck_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "TRAIN_START_DATE = '2009-04-01'\nTRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "TRAIN_END_DATE = '2021-01-01'\nTEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "TEST_START_DATE = '2021-01-01'\nTEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "TEST_END_DATE = '2022-06-01'\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\ntic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :\ndf = YahooDownloader(start_date = TRAIN_START_DATE,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "tic",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "tic = DOW_30_TICKER\ntic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = tic).fetch_data()",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "tic",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "tic = [DOW_30_TICKER[0]]\nst.write(\"jojo\".join(str(ticker) for ticker in tic))\n# if tic = [\"AXP\"] has 1 row it work , but if tic = [\n#     \"AXP\",\n#     \"AMGN\"\n#     ] or greater than 1 I get the message below :\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = tic).fetch_data()\ndf.sort_values(['date','tic']).head()",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = tic).fetch_data()\ndf.sort_values(['date','tic']).head()\nprint(len(df.tic.unique()))\nprint(df.tic.value_counts())\nprint(df.head())\nprint(df.tail())\nprint(df.shape)\nst.write(len(df.tic.unique()))",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, ",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nprint(processed.sample(5))\nst.write(processed.sample(5))\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, ",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, ",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nst.write(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, ",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100, \n    \"initial_amount\": 1000000, \n    \"buy_cost_pct\": 0.001, \n    \"sell_cost_pct\": 0.001, \n    \"state_space\": state_space, \n    \"stock_dim\": stock_dimension, \n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension, \n    \"reward_scaling\": 1e-4,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window, \n                 validation_window=validation_window, \n                 **env_kwargs)\nA2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2, #2048\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "SAC_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64}\nTD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "TD3_model_kwargs = {\n                      \"buffer_size\": 1, #10_000\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64,\n}\ntimesteps_dict = {\n    'a2c': 10,  # Example value, adjust as needed\n    'ppo': 10,\n    'ddpg': 10,\n    'sac' : 10,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "timesteps_dict = {\n    'a2c': 10,  # Example value, adjust as needed\n    'ppo': 10,\n    'ddpg': 10,\n    'sac' : 10,\n    'td3' : 10\n}\ndf_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(\n    A2C_model_kwargs,\n    PPO_model_kwargs,\n    DDPG_model_kwargs,\n    SAC_model_kwargs,\n    TD3_model_kwargs,\n    timesteps_dict\n)\nprint(df_summary)\nst.write(df_summary)",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv(RESULTS_DIR + '/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    # temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\nst.write('Sharpe Ratio: ',sharpe)",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv(RESULTS_DIR + '/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    # temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\nst.write('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\nst.write(\"==============Get Baseline Stats===========\")\nbaseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "baseline_df",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "baseline_df = get_baseline(\n        ticker=\"^DJI\", \n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "stats = backtest_stats(baseline_df, value_col_name = 'close')\nprint(\"==============Compare to DJIA===========\")\nst.write(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# S&P 500: ^GSPC\n# Dow Jones Index: ^DJI\n# NASDAQ 100: ^NDX\nbacktest_plot(df_account_value, \n              baseline_ticker = '^DJI', \n              baseline_start = df_account_value.loc[0,'date'],",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "pages2.12_rl_Stock_Training",
        "description": "pages2.12_rl_Stock_Training",
        "peekOfCode": "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET , ALPACA_API_BASE_URL, api_version='v2')\ntry:\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    st.write(f\"Account status: {account.status}\")\n    symbol = 'CAT'\n    qty = 1  # Quantity to buy\n    if (sharpe > - 94):\n        buy_order = api.submit_order(\n            symbol=symbol,",
        "detail": "pages2.12_rl_Stock_Training",
        "documentation": {}
    },
    {
        "label": "SentimentTradingBot",
        "kind": 6,
        "importPath": "pages2.1_ml_chat",
        "description": "pages2.1_ml_chat",
        "peekOfCode": "class SentimentTradingBot(Strategy):\n    def initialize(self, params):\n        self.params = params\n        self.sleeptime = \"1D\"\n        self.set_asset(self.params['symbol'])\n    def on_trading_iteration(self):\n        try:\n            # Get sentiment from chat history\n            latest_news = self.params['news'][-1] if self.params['news'] else \"\"\n            sentiment = sentiment_analyzer(latest_news)[0]",
        "detail": "pages2.1_ml_chat",
        "documentation": {}
    },
    {
        "label": "load_sentiment_model",
        "kind": 2,
        "importPath": "pages2.1_ml_chat",
        "description": "pages2.1_ml_chat",
        "peekOfCode": "def load_sentiment_model():\n    return pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\nsentiment_analyzer = load_sentiment_model()\n# Custom Lumibot Strategy\nclass SentimentTradingBot(Strategy):\n    def initialize(self, params):\n        self.params = params\n        self.sleeptime = \"1D\"\n        self.set_asset(self.params['symbol'])\n    def on_trading_iteration(self):",
        "detail": "pages2.1_ml_chat",
        "documentation": {}
    },
    {
        "label": "sentiment_analyzer",
        "kind": 5,
        "importPath": "pages2.1_ml_chat",
        "description": "pages2.1_ml_chat",
        "peekOfCode": "sentiment_analyzer = load_sentiment_model()\n# Custom Lumibot Strategy\nclass SentimentTradingBot(Strategy):\n    def initialize(self, params):\n        self.params = params\n        self.sleeptime = \"1D\"\n        self.set_asset(self.params['symbol'])\n    def on_trading_iteration(self):\n        try:\n            # Get sentiment from chat history",
        "detail": "pages2.1_ml_chat",
        "documentation": {}
    },
    {
        "label": "CcxtBacktestingExampleStrategy",
        "kind": 6,
        "importPath": "pages2.20_ccxt_backtesting_example",
        "description": "pages2.20_ccxt_backtesting_example",
        "peekOfCode": "class CcxtBacktestingExampleStrategy(Strategy):\n    def initialize(self, asset: tuple[Asset, Asset] = None,\n                   cash_at_risk: float = .25, window: int = 21):\n        if asset is None:\n            raise ValueError(\"You must provide a valid asset pair\")\n        self.set_market(\"24/7\")\n        self.sleeptime = \"1D\"\n        self.asset = asset\n        self.base, self.quote = asset\n        self.window = window",
        "detail": "pages2.20_ccxt_backtesting_example",
        "documentation": {}
    },
    {
        "label": "OptionsHoldToExpiry",
        "kind": 6,
        "importPath": "pages2.22_ccxt_hold_to_expiry",
        "description": "pages2.22_ccxt_hold_to_expiry",
        "peekOfCode": "class OptionsHoldToExpiry(Strategy):\n    \"\"\"\n    A trading strategy that buys an option (call/put) and holds it until expiry.\n    - Customizable option type, strike price, expiration date, and position size.\n    - Supports stop loss & take profit levels.\n    - Monitors option Greeks (Delta, Theta, Vega).\n    - Supports backtesting with Polygon.io and live trading with Interactive Brokers.\n    \"\"\"\n    parameters = {\n        \"buy_symbol\": \"SPY\",",
        "detail": "pages2.22_ccxt_hold_to_expiry",
        "documentation": {}
    },
    {
        "label": "ImportantFunctions",
        "kind": 6,
        "importPath": "pages2.24_crypto_important_functions",
        "description": "pages2.24_crypto_important_functions",
        "peekOfCode": "class ImportantFunctions(Strategy):\n    \"\"\"\n    A cryptocurrency trading strategy that:\n    - Places market and limit orders for BTC\n    - Fetches and analyzes historical price data\n    - Uses technical indicators like RSI, MACD, and EMA\n    - Monitors positions, orders, and portfolio value\n    \"\"\"\n    def initialize(self):\n        self.sleeptime = \"30S\"",
        "detail": "pages2.24_crypto_important_functions",
        "documentation": {}
    },
    {
        "label": "header",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "header = \" Analyze stock trends using real-time market data, historical price movements, and AI-powered sentiment analysis.\"\ncontent =  \"\"\"   This app combines **machine learning** and **sentiment analysis** to forecast stock market trends using news and price data.\n    It integrates:\n    -  Stock price data (via Alpaca)\n    -  News sentiment analysis\n    -  LSTM model predictions\n    -  Technical indicators (SMA, EMA)\n    GitHub source references:\n    - [Stock Market Trend Prediction project](https://github.com/sardarosama/Stock-Market-Trend-Prediction-Using-Sentiment-Analysis)\n    - [Web App with Tweet Sentiment](https://github.com/kaushikjadhav01/Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis)",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "content",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "content =  \"\"\"   This app combines **machine learning** and **sentiment analysis** to forecast stock market trends using news and price data.\n    It integrates:\n    -  Stock price data (via Alpaca)\n    -  News sentiment analysis\n    -  LSTM model predictions\n    -  Technical indicators (SMA, EMA)\n    GitHub source references:\n    - [Stock Market Trend Prediction project](https://github.com/sardarosama/Stock-Market-Trend-Prediction-Using-Sentiment-Analysis)\n    - [Web App with Tweet Sentiment](https://github.com/kaushikjadhav01/Stock-Market-Prediction-Web-App-using-Machine-Learning-And-Sentiment-Analysis)\n    - [Financial News Sentiment Tool](https://github.com/IshanDissanayake/Financial-News-Sentiment-Analysis-Tool)",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "start = \"2011-02-01\"\nend = \"2019-12-31\"\nuser_input = st.text_input(\"Enter Stock Ticker\", \"AAPL\")\n# df = yf.download(user_input, start=start, end=end)\ndf = fetch_stock_data(ticker, start_date, end_date)\nbarset = fetch_stock_data(ticker, start_date, end_date)\ndf, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\nif df is None or df.empty:\n    st.error(\" No stock data to display.\")\n    st.stop()",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "end",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "end = \"2019-12-31\"\nuser_input = st.text_input(\"Enter Stock Ticker\", \"AAPL\")\n# df = yf.download(user_input, start=start, end=end)\ndf = fetch_stock_data(ticker, start_date, end_date)\nbarset = fetch_stock_data(ticker, start_date, end_date)\ndf, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\nif df is None or df.empty:\n    st.error(\" No stock data to display.\")\n    st.stop()\n#  Now it's safe to reset the index if needed",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "user_input",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "user_input = st.text_input(\"Enter Stock Ticker\", \"AAPL\")\n# df = yf.download(user_input, start=start, end=end)\ndf = fetch_stock_data(ticker, start_date, end_date)\nbarset = fetch_stock_data(ticker, start_date, end_date)\ndf, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\nif df is None or df.empty:\n    st.error(\" No stock data to display.\")\n    st.stop()\n#  Now it's safe to reset the index if needed\n# df = df.reset_index()",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "df = fetch_stock_data(ticker, start_date, end_date)\nbarset = fetch_stock_data(ticker, start_date, end_date)\ndf, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\nif df is None or df.empty:\n    st.error(\" No stock data to display.\")\n    st.stop()\n#  Now it's safe to reset the index if needed\n# df = df.reset_index()\ndf = df.reset_index()\ndf = df.dropna()",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "barset",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "barset = fetch_stock_data(ticker, start_date, end_date)\ndf, close_col = convert_barSet_to_DataFrame(barset, None, ticker)\nif df is None or df.empty:\n    st.error(\" No stock data to display.\")\n    st.stop()\n#  Now it's safe to reset the index if needed\n# df = df.reset_index()\ndf = df.reset_index()\ndf = df.dropna()\n# Describing data",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "df = df.reset_index()\ndf = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization\nst.subheader(\"Closing Price vs Time Chart\")\nfig = plt.figure(figsize=(12, 6))\n# plt.plot(df.Close)",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "df = df.dropna()\n# Describing data\nst.subheader('Data from 2011-2019')\nst.write(\"Description\")\nst.write(df.describe())\n# Visualization\nst.subheader(\"Closing Price vs Time Chart\")\nfig = plt.figure(figsize=(12, 6))\n# plt.plot(df.Close)\nplt.plot(df[close_col])",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "fig = plt.figure(figsize=(12, 6))\n# plt.plot(df.Close)\nplt.plot(df[close_col])\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA\")\n# ma100 = df.Close.rolling(100).mean()\nma100 = df[close_col].rolling(100).mean()\nif close_col not in df.columns:\n    st.error(f\" Column '{close_col}' not found in data.\")\n    st.stop()",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "ma100",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "ma100 = df[close_col].rolling(100).mean()\nif close_col not in df.columns:\n    st.error(f\" Column '{close_col}' not found in data.\")\n    st.stop()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100)\n# plt.plot(df.Close)\nplt.plot(df[close_col])\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA and 200MA\")",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "fig = plt.figure(figsize=(12, 6))\nplt.plot(ma100)\n# plt.plot(df.Close)\nplt.plot(df[close_col])\nst.pyplot(fig)\nst.subheader(\"Closing Price vs Time Chart with 100MA and 200MA\")\nma100 = df[close_col].rolling(100).mean()\nma200 = df[close_col].rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "ma100",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "ma100 = df[close_col].rolling(100).mean()\nma200 = df[close_col].rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")\nplt.plot(df[close_col])\nst.pyplot(fig)\nsplit = int(len(df) * 0.70)\ndata_training = pd.DataFrame(df[close_col][:split])\ndata_testing = pd.DataFrame(df[close_col][split:])",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "ma200",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "ma200 = df[close_col].rolling(200).mean()\nfig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")\nplt.plot(df[close_col])\nst.pyplot(fig)\nsplit = int(len(df) * 0.70)\ndata_training = pd.DataFrame(df[close_col][:split])\ndata_testing = pd.DataFrame(df[close_col][split:])\nif len(data_testing) > 0:",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "fig = plt.figure(figsize=(12, 6))\nplt.plot(ma100, \"b\")\nplt.plot(ma200, \"g\")\nplt.plot(df[close_col])\nst.pyplot(fig)\nsplit = int(len(df) * 0.70)\ndata_training = pd.DataFrame(df[close_col][:split])\ndata_testing = pd.DataFrame(df[close_col][split:])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "split",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "split = int(len(df) * 0.70)\ndata_training = pd.DataFrame(df[close_col][:split])\ndata_testing = pd.DataFrame(df[close_col][split:])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_training_array = scaler.fit_transform(data_training)\n    # // jojostock1/pages/Stock-Prediction/models/model0.h5\n    # jojostock1/pages/Stock-Prediction/models/model0.h5\n    model_path = \"pages/Stock-Prediction/models/model0.h5\"\n    if not os.path.exists(model_path):",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "data_training",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "data_training = pd.DataFrame(df[close_col][:split])\ndata_testing = pd.DataFrame(df[close_col][split:])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_training_array = scaler.fit_transform(data_training)\n    # // jojostock1/pages/Stock-Prediction/models/model0.h5\n    # jojostock1/pages/Stock-Prediction/models/model0.h5\n    model_path = \"pages/Stock-Prediction/models/model0.h5\"\n    if not os.path.exists(model_path):\n        st.error(f\" Model file not found: {model_path}\")",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "data_testing",
        "kind": 5,
        "importPath": "pages2.2_ml_train_sentiment_analysys",
        "description": "pages2.2_ml_train_sentiment_analysys",
        "peekOfCode": "data_testing = pd.DataFrame(df[close_col][split:])\nif len(data_testing) > 0:\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data_training_array = scaler.fit_transform(data_training)\n    # // jojostock1/pages/Stock-Prediction/models/model0.h5\n    # jojostock1/pages/Stock-Prediction/models/model0.h5\n    model_path = \"pages/Stock-Prediction/models/model0.h5\"\n    if not os.path.exists(model_path):\n        st.error(f\" Model file not found: {model_path}\")\n        st.stop()",
        "detail": "pages2.2_ml_train_sentiment_analysys",
        "documentation": {}
    },
    {
        "label": "FinRAGClient",
        "kind": 6,
        "importPath": "pages2.31_rag_client",
        "description": "pages2.31_rag_client",
        "peekOfCode": "class FinRAGClient:\n    BASE_URL = \"http://localhost:8000\"\n    def query(self, user_query):\n        payload = {\n            \"chatId\": \"12345\",\n            \"ownerId\": \"user\",\n            \"chatName\": \"Finance Assistant\",\n            \"initInputs\": {\"categoryIds\": []},\n            \"initOpening\": \"\",\n            \"chatMessages\": [{\"role\": \"user\", \"rawContent\": user_query}]",
        "detail": "pages2.31_rag_client",
        "documentation": {}
    },
    {
        "label": "start_fastapi",
        "kind": 2,
        "importPath": "pages2.31_rag_client",
        "description": "pages2.31_rag_client",
        "peekOfCode": "def start_fastapi():\n    try:\n        response = requests.get(\"http://localhost:8000/docs\")\n        if response.status_code == 200:\n            st.success(\" FastAPI server is already running.\")\n            return\n    except requests.exceptions.RequestException:\n        pass  # If request fails, start the server\n    st.info(\" Starting FastAPI server...\")\n    subprocess.Popen([\"python3\", \"pages/FinRag/main.py\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)",
        "detail": "pages2.31_rag_client",
        "documentation": {}
    },
    {
        "label": "finrag",
        "kind": 5,
        "importPath": "pages2.31_rag_client",
        "description": "pages2.31_rag_client",
        "peekOfCode": "finrag = FinRAGClient()\n# Streamlit UI\nst.title(\" FinRAG Financial Assistant\")\nst.write(\"Ask any finance-related question, and I'll fetch the best answer for you!\")\n# User input\nquery = st.text_input(\" Enter your financial query:\")\nresponse = {}  # Ensure response is always defined\nif st.button(\"Get Answer\"):\n    if query:\n        with st.spinner(\" Searching...\"):",
        "detail": "pages2.31_rag_client",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "pages2.31_rag_client",
        "description": "pages2.31_rag_client",
        "peekOfCode": "query = st.text_input(\" Enter your financial query:\")\nresponse = {}  # Ensure response is always defined\nif st.button(\"Get Answer\"):\n    if query:\n        with st.spinner(\" Searching...\"):\n            response = finrag.query(query)  # This now always returns a dictionary\n        # Display answer\n        st.subheader(\" Answer:\")\n        st.write(response.get(\"answer\", \"No response received.\"))\n        # Display retrieved documents (if available)",
        "detail": "pages2.31_rag_client",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "pages2.31_rag_client",
        "description": "pages2.31_rag_client",
        "peekOfCode": "response = {}  # Ensure response is always defined\nif st.button(\"Get Answer\"):\n    if query:\n        with st.spinner(\" Searching...\"):\n            response = finrag.query(query)  # This now always returns a dictionary\n        # Display answer\n        st.subheader(\" Answer:\")\n        st.write(response.get(\"answer\", \"No response received.\"))\n        # Display retrieved documents (if available)\n        retrieved_docs = response.get(\"chunks\", [])  # Use 'chunks' instead of 'retrieved_docs'",
        "detail": "pages2.31_rag_client",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "API_KEY = \"your_api_key\"\nAPI_SECRET = \"your_api_secret\"\nBASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "API_SECRET = \"your_api_secret\"\nBASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "alpaca",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "alpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "analyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "symbol",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "symbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "start_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "end_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "sentiment_threshold",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "sentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")\n    data = {",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "API_KEY = \"your_api_key_here\"\nAPI_SECRET = \"your_api_secret_here\"\nclient = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "API_SECRET = \"your_api_secret_here\"\nclient = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "client = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:\n    dates.append(bar.timestamp)",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "request",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "request = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:\n    dates.append(bar.timestamp)\n    opens.append(bar.open)",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "bars",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "bars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:\n    dates.append(bar.timestamp)\n    opens.append(bar.open)\n    closes.append(bar.close)\n    highs.append(bar.high)\n    lows.append(bar.low)\n    volumes.append(bar.volume)\n#  Align all arrays\nmin_len = min(len(dates), len(opens), len(closes), len(highs), len(lows), len(volumes))",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "min_len",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "min_len = min(len(dates), len(opens), len(closes), len(highs), len(lows), len(volumes))\ndata = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "data = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "df = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(df)\nst.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "df[\"sentiment\"]",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final",
        "description": "pages2.3_ml_sent_final",
        "peekOfCode": "df[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(df)\nst.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")\n            alpaca.submit_order(symbol, qty=1, side=\"buy\", type=\"market\", time_in_force=\"gtc\")",
        "detail": "pages2.3_ml_sent_final",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "API_KEY = \"your_api_key\"\nAPI_SECRET = \"your_api_secret\"\nBASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "API_SECRET = \"your_api_secret\"\nBASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "alpaca",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "alpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "analyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "symbol",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "symbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "start_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "end_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "sentiment_threshold",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "sentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")\n    data = {",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "API_KEY = \"your_api_key_here\"\nAPI_SECRET = \"your_api_secret_here\"\nclient = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "API_SECRET = \"your_api_secret_here\"\nclient = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "client = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:\n    dates.append(bar.timestamp)",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "request",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "request = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\nbars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:\n    dates.append(bar.timestamp)\n    opens.append(bar.open)",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "bars",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "bars = client.get_stock_bars(request).data[symbol]\nfor bar in bars:\n    dates.append(bar.timestamp)\n    opens.append(bar.open)\n    closes.append(bar.close)\n    highs.append(bar.high)\n    lows.append(bar.low)\n    volumes.append(bar.volume)\n#  Align all arrays\nmin_len = min(len(dates), len(opens), len(closes), len(highs), len(lows), len(volumes))",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "min_len",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "min_len = min(len(dates), len(opens), len(closes), len(highs), len(lows), len(volumes))\ndata = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "data = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)\n    df[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned",
        "description": "pages2.3_ml_sent_final_cleaned",
        "peekOfCode": "df = pd.DataFrame(data)\n    df[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\n    st.write(df)\n    st.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")",
        "detail": "pages2.3_ml_sent_final_cleaned",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "API_SECRET = \"your_api_secret\"\nBASE_URL   = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "alpaca",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "alpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "analyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "symbol",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "symbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "start_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "end_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "sentiment_threshold",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "sentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")\n    data = {",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "API_KEY = \"your_api_key_here\"\nAPI_SECRET = \"your_api_secret_here\"\nclient = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\n# bars = client.get_stock_bars(request).data[symbol]",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "API_SECRET = \"your_api_secret_here\"\nclient = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\n# bars = client.get_stock_bars(request).data[symbol]\ntry:",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "client = StockHistoricalDataClient(API_KEY, API_SECRET)\nrequest = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\n# bars = client.get_stock_bars(request).data[symbol]\ntry:\n    bars = client.get_stock_bars(request).data[symbol]",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "request",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "request = StockBarsRequest(\n    symbol_or_symbols=symbol,\n    timeframe=TimeFrame.Day,\n    start=start_date,\n    end=end_date\n)\n# bars = client.get_stock_bars(request).data[symbol]\ntry:\n    bars = client.get_stock_bars(request).data[symbol]\nexcept Exception as e:",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "min_len",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "min_len = min(len(dates), len(opens), len(closes), len(highs), len(lows), len(volumes))\ndata = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "data = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "df = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(df)\nst.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "df[\"sentiment\"]",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_final_cleaned_v2",
        "description": "pages2.3_ml_sent_final_cleaned_v2",
        "peekOfCode": "df[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(df)\nst.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")\n            alpaca.submit_order(symbol, qty=1, side=\"buy\", type=\"market\", time_in_force=\"gtc\")",
        "detail": "pages2.3_ml_sent_final_cleaned_v2",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "API_KEY = \"your_api_key\"\nAPI_SECRET = \"your_api_secret\"\nBASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "API_SECRET = \"your_api_secret\"\nBASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"  # Use for paper trading\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET\n# Initialize Alpaca client\nalpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "alpaca",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "alpaca = REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url=BASE_URL)\n# Sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "analyzer = SentimentIntensityAnalyzer()\n# Streamlit app setup\nst.title(\"Sentiment-Based Trading Bot\")\nst.write(\"Analyze sentiment and trade stocks using Alpaca API.\")\n# User inputs\nsymbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "symbol",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "symbol = st.text_input(\"Stock Symbol\", value=\"AAPL\")\nstart_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "start_date = st.date_input(\"Start Date\", value=datetime.now() - timedelta(days=30))\nend_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "end_date = st.date_input(\"End Date\", value=datetime.now())\nsentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "sentiment_threshold",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "sentiment_threshold = st.slider(\"Sentiment Threshold\", -1.0, 1.0, 0.0)\n# Fetch historical price data\nif st.button(\"Fetch Data\"):\n    st.write(f\"Fetching historical data for {symbol}...\")\n    bars = alpaca.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n    st.write(bars.tail())\n# Sentiment analysis\nif st.button(\"Analyze Sentiment\"):\n    st.write(\"Performing sentiment analysis...\")\n    data = {",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "min_len",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "min_len = min(len(dates), len(opens), len(closes), len(highs), len(lows), len(volumes))\ndata = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "data = {\n    'Date': dates[:min_len],\n    'Open': opens[:min_len],\n    'Close': closes[:min_len],\n    'High': highs[:min_len],\n    'Low': lows[:min_len],\n    'Volume': volumes[:min_len],\n}\ndf = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "df = pd.DataFrame(data)\ndf[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(df)\nst.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "df[\"sentiment\"]",
        "kind": 5,
        "importPath": "pages2.3_ml_sent_fixed_indented",
        "description": "pages2.3_ml_sent_fixed_indented",
        "peekOfCode": "df[\"sentiment\"] = df[\"news\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\nst.write(df)\nst.line_chart(df[\"sentiment\"])\n# Trading logic\nif st.button(\"Execute Trades\"):\n    st.write(\"Executing trades...\")\n    for index, row in df.iterrows():\n        if row[\"sentiment\"] > sentiment_threshold:\n            st.write(f\"BUY: {symbol} on {row['date']} (Sentiment: {row['sentiment']})\")\n            alpaca.submit_order(symbol, qty=1, side=\"buy\", type=\"market\", time_in_force=\"gtc\")",
        "detail": "pages2.3_ml_sent_fixed_indented",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pages2.5_rl_ensemble_stock_trading",
        "description": "pages2.5_rl_ensemble_stock_trading",
        "peekOfCode": "def main():\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    # import datetime\n    from datetime import datetime",
        "detail": "pages2.5_rl_ensemble_stock_trading",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "pages2.6_rl_quickstart",
        "description": "pages2.6_rl_quickstart",
        "peekOfCode": "def build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        dest=\"mode\",\n        help=\"start mode, train, download_data\" \" backtest\",\n        metavar=\"MODE\",\n        default=\"train\",\n    )\n    return parser",
        "detail": "pages2.6_rl_quickstart",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "kind": 2,
        "importPath": "pages2.6_rl_quickstart",
        "description": "pages2.6_rl_quickstart",
        "peekOfCode": "def check_and_make_directories(directories: List[str]):\n    for directory in directories:\n        if not os.path.exists(\"./\" + directory):\n            os.makedirs(\"./\" + directory)\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n    if options.mode == \"train\":\n        from lib.rl.train import train",
        "detail": "pages2.6_rl_quickstart",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pages2.6_rl_quickstart",
        "description": "pages2.6_rl_quickstart",
        "peekOfCode": "def main():\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n    if options.mode == \"train\":\n        from lib.rl.train import train\n        env = StockTradingEnv\n        # demo for elegantrl\n        kwargs = {}  # in current meta, with respect yahoofinance, kwargs is {}. For other data sources, such as joinquant, kwargs is not empty\n        train(",
        "detail": "pages2.6_rl_quickstart",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "pages2.6_rl_quickstart",
        "description": "pages2.6_rl_quickstart",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom lib.rl.config import (\n    DATA_SAVE_DIR,\n    TRAINED_MODEL_DIR,\n    TENSORBOARD_LOG_DIR,\n    RESULTS_DIR,\n    INDICATORS,\n    TRAIN_START_DATE,\n    TRAIN_END_DATE,\n    TEST_START_DATE,",
        "detail": "pages2.6_rl_quickstart",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pages2.8_rl_Stock_NeurIPS2018_SB3",
        "description": "pages2.8_rl_Stock_NeurIPS2018_SB3",
        "peekOfCode": "def main():\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    from lib.rl.meta.preprocessor.yahoodownloader import YahooDownloader\n    from lib.rl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n    from lib.rl.meta.env_stock_trading.env_stocktrading import StockTradingEnv",
        "detail": "pages2.8_rl_Stock_NeurIPS2018_SB3",
        "documentation": {}
    },
    {
        "label": "latest_price",
        "kind": 5,
        "importPath": "pages2.Stock_Sentiment_Dashboard",
        "description": "pages2.Stock_Sentiment_Dashboard",
        "peekOfCode": "latest_price = get_real_time_price(ticker)\nif latest_price:\n    st.metric(label=f\"{ticker} Price\", value=f\"${latest_price:.2f}\")\nelse:\n    st.warning(\"No real-time price available.\")\n# --- Fetch Stock Data ---\nstock_data = fetch_stock_data(ticker, start_date, end_date)\nif not stock_data or not stock_data.__dict__:\n    st.warning(\" No stock data found.\")\n    st.stop()",
        "detail": "pages2.Stock_Sentiment_Dashboard",
        "documentation": {}
    },
    {
        "label": "stock_data",
        "kind": 5,
        "importPath": "pages2.Stock_Sentiment_Dashboard",
        "description": "pages2.Stock_Sentiment_Dashboard",
        "peekOfCode": "stock_data = fetch_stock_data(ticker, start_date, end_date)\nif not stock_data or not stock_data.__dict__:\n    st.warning(\" No stock data found.\")\n    st.stop()\ndf_stock, close_col = convert_barSet_to_DataFrame(stock_data, None, ticker)\nif df_stock is None or close_col is None or close_col not in df_stock.columns:\n    st.error(f\" No closing price data available for {close_col}.\")\n    st.info(f\"Try a more liquid ticker  {ticker} returned no usable closing data.\")\n    st.stop()\nst.write(\" Raw stock_data:\", stock_data)",
        "detail": "pages2.Stock_Sentiment_Dashboard",
        "documentation": {}
    },
    {
        "label": "news_data",
        "kind": 5,
        "importPath": "pages2.Stock_Sentiment_Dashboard",
        "description": "pages2.Stock_Sentiment_Dashboard",
        "peekOfCode": "news_data = fetch_news_data(ticker)\ndf_news = analyze_sentiment(news_data) if news_data else pd.DataFrame()\nif not df_news.empty:\n    st.dataframe(df_news)\n    display_sentiment_summary(df_news)\nelse:\n    st.warning(\" No sentiment data available.\")\n# --- Technicals ---\nst.subheader(\" Technical Analysis\")\ndf_stock = compute_moving_averages(df_stock, close_col, df_news)",
        "detail": "pages2.Stock_Sentiment_Dashboard",
        "documentation": {}
    },
    {
        "label": "df_news",
        "kind": 5,
        "importPath": "pages2.Stock_Sentiment_Dashboard",
        "description": "pages2.Stock_Sentiment_Dashboard",
        "peekOfCode": "df_news = analyze_sentiment(news_data) if news_data else pd.DataFrame()\nif not df_news.empty:\n    st.dataframe(df_news)\n    display_sentiment_summary(df_news)\nelse:\n    st.warning(\" No sentiment data available.\")\n# --- Technicals ---\nst.subheader(\" Technical Analysis\")\ndf_stock = compute_moving_averages(df_stock, close_col, df_news)\ndf_signals = generate_trade_signals(df_stock, df_news, close_col)",
        "detail": "pages2.Stock_Sentiment_Dashboard",
        "documentation": {}
    },
    {
        "label": "df_stock",
        "kind": 5,
        "importPath": "pages2.Stock_Sentiment_Dashboard",
        "description": "pages2.Stock_Sentiment_Dashboard",
        "peekOfCode": "df_stock = compute_moving_averages(df_stock, close_col, df_news)\ndf_signals = generate_trade_signals(df_stock, df_news, close_col)\nif not df_signals.empty:\n    st.line_chart(df_signals[[close_col, \"SMA_50\", \"EMA_20\", \"Buy_Signal\", \"Sell_Signal\"]])\n# --- Alternative Sentiment Sources ---\nst.subheader(\" Alternative Data Sources\")\nalt_col1, alt_col2, alt_col3 = st.columns(3)\nwith alt_col1:\n    if st.checkbox(\" Twitter\"):\n        st.write(fetch_twitter_sentiment(ticker))",
        "detail": "pages2.Stock_Sentiment_Dashboard",
        "documentation": {}
    },
    {
        "label": "df_signals",
        "kind": 5,
        "importPath": "pages2.Stock_Sentiment_Dashboard",
        "description": "pages2.Stock_Sentiment_Dashboard",
        "peekOfCode": "df_signals = generate_trade_signals(df_stock, df_news, close_col)\nif not df_signals.empty:\n    st.line_chart(df_signals[[close_col, \"SMA_50\", \"EMA_20\", \"Buy_Signal\", \"Sell_Signal\"]])\n# --- Alternative Sentiment Sources ---\nst.subheader(\" Alternative Data Sources\")\nalt_col1, alt_col2, alt_col3 = st.columns(3)\nwith alt_col1:\n    if st.checkbox(\" Twitter\"):\n        st.write(fetch_twitter_sentiment(ticker))\nwith alt_col2:",
        "detail": "pages2.Stock_Sentiment_Dashboard",
        "documentation": {}
    },
    {
        "label": "Classic60_40Strategy",
        "kind": 6,
        "importPath": "pages2.classic_60_40",
        "description": "pages2.classic_60_40",
        "peekOfCode": "class Classic60_40Strategy(Strategy):\n    def initialize(self, cash_at_risk: float = 0.25, drift_threshold: float = 0.05, stock_symbol: str = \"SPY\", bond_symbol: str = \"TLT\", stock_allocation: float = 0.60):\n        self.set_market(\"NYSE\")\n        self.sleeptime = \"1D\"\n        self.cash_at_risk = cash_at_risk\n        self.drift_threshold = drift_threshold\n        self.stock_symbol = stock_symbol\n        self.bond_symbol = bond_symbol\n        self.target_weights = {stock_symbol: stock_allocation, bond_symbol: 1 - stock_allocation}\n        self.last_trade = None",
        "detail": "pages2.classic_60_40",
        "documentation": {}
    },
    {
        "label": "DriftRebalancerStrategy",
        "kind": 6,
        "importPath": "pages2.drift_rebalancer",
        "description": "pages2.drift_rebalancer",
        "peekOfCode": "class DriftRebalancerStrategy(Strategy):\n    def initialize(self, cash_at_risk: float = 0.25, drift_threshold: float = 0.05, stock_symbol: str = \"SPY\", bond_symbol: str = \"TLT\", stock_allocation: float = 0.60):\n        self.set_market(\"NYSE\")\n        self.sleeptime = \"1D\"\n        self.cash_at_risk = cash_at_risk\n        self.drift_threshold = drift_threshold\n        self.stock_symbol = stock_symbol\n        self.bond_symbol = bond_symbol\n        self.target_weights = {stock_symbol: stock_allocation, bond_symbol: 1 - stock_allocation}\n        self.last_trade = None",
        "detail": "pages2.drift_rebalancer",
        "documentation": {}
    },
    {
        "label": "LifecycleLogger",
        "kind": 6,
        "importPath": "pages2.lifecycle_logger",
        "description": "pages2.lifecycle_logger",
        "peekOfCode": "class LifecycleLogger(Strategy):\n    \"\"\"\n    A strategy that logs key lifecycle events during a trading session.\n    It does not execute trades but provides valuable insights into:\n    - Market opening and closing times\n    - Trading session start and end\n    - Iterative trading loops\n    Useful for debugging and understanding the trading lifecycle.\n    \"\"\"\n    parameters = {",
        "detail": "pages2.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "pages2.lifecycle_logger",
        "description": "pages2.lifecycle_logger",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LifecycleLogger(Strategy):\n    \"\"\"\n    A strategy that logs key lifecycle events during a trading session.\n    It does not execute trades but provides valuable insights into:\n    - Market opening and closing times\n    - Trading session start and end\n    - Iterative trading loops\n    Useful for debugging and understanding the trading lifecycle.\n    \"\"\"",
        "detail": "pages2.lifecycle_logger",
        "documentation": {}
    },
    {
        "label": "MachineLearningCrypto",
        "kind": 6,
        "importPath": "pages2.ml_strategy_crypto",
        "description": "pages2.ml_strategy_crypto",
        "peekOfCode": "class MachineLearningCrypto(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "pages2.ml_strategy_crypto",
        "documentation": {}
    },
    {
        "label": "MachineLearningStocks",
        "kind": 6,
        "importPath": "pages2.ml_strategy_stocks",
        "description": "pages2.ml_strategy_stocks",
        "peekOfCode": "class MachineLearningStocks(Strategy):\n    \"\"\"Parameters:\n    symbol (str, optional): The symbol that we want to trade. Defaults to \"SRNE\".\n    compute_frequency (int, optional): The time (in minutes) that we should retrain our model.\n    lookback_period (int, optional): The amount of data (in minutes) that we get from our data source to use in the model.\n    pct_portfolio_per_trade (float, optional): The size that each trade will be (in percent of the total portfolio).\n    price_change_threshold_up (float, optional): The difference between predicted price and the current price that will trigger a buy order (in percentage change).\n    price_change_threshold_down (float, optional): The difference between predicted price and the current price that will trigger a sell order (in percentage change).\n    max_pct_portfolio (float, optional): The maximum that the strategy will buy or sell as a percentage of the portfolio (eg. if this is 0.8 - or 80% - and our portfolio is worth $100k, then we will stop buying when we own $80k worth of the symbol)\n    take_profit_factor: Where you place your limit order based on the prediction",
        "detail": "pages2.ml_strategy_stocks",
        "documentation": {}
    },
    {
        "label": "MyStrategy",
        "kind": 6,
        "importPath": "pages2.simple_start_single_file",
        "description": "pages2.simple_start_single_file",
        "peekOfCode": "class MyStrategy(Strategy):\n    def initialize(self, symbol=\"\", quantity=1, sleeptime=180):\n        self.sleeptime = sleeptime\n        self.symbol = symbol\n        self.quantity = quantity\n        self.side = \"buy\"\n    def on_trading_iteration(self):\n        if self.get_position(self.symbol) is None:\n            order = self.create_order(self.symbol, self.quantity, self.side)\n            self.submit_order(order)",
        "detail": "pages2.simple_start_single_file",
        "documentation": {}
    },
    {
        "label": "StockBracket",
        "kind": 6,
        "importPath": "pages2.stock_bracket",
        "description": "pages2.stock_bracket",
        "peekOfCode": "class StockBracket(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405.0,\n        \"stop_loss_price\": 395.0,\n        \"quantity\": 10,\n    }\n    def initialize(self):\n        self.sleeptime = \"1D\"\n        self.counter = 0",
        "detail": "pages2.stock_bracket",
        "documentation": {}
    },
    {
        "label": "StockBracket.parameters",
        "kind": 5,
        "importPath": "pages2.stock_bracket",
        "description": "pages2.stock_bracket",
        "peekOfCode": "StockBracket.parameters = {\n    \"buy_symbol\": buy_symbol,\n    \"take_profit_price\": take_profit,\n    \"stop_loss_price\": stop_loss,\n    \"quantity\": quantity,\n}\n# Execution Mode Selection\nst.divider()\nlive_mode = st.checkbox(\"Enable Live Trading\", value=False)\nif not live_mode:",
        "detail": "pages2.stock_bracket",
        "documentation": {}
    },
    {
        "label": "live_mode",
        "kind": 5,
        "importPath": "pages2.stock_bracket",
        "description": "pages2.stock_bracket",
        "peekOfCode": "live_mode = st.checkbox(\"Enable Live Trading\", value=False)\nif not live_mode:\n    # Backtest Configuration\n    st.subheader(\" Backtest Period\")\n    col1, col2 = st.columns(2)\n    with col1:\n        start_date = (st.date_input(\"Start Date\", datetime(2023, 3, 3)))\n    with col2:\n        end_date = st.date_input(\"End Date\", datetime(2023, 3, 10))\n    if st.button(\" Run Backtest\"):",
        "detail": "pages2.stock_bracket",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "pages2.stock_buy_and_hold",
        "description": "pages2.stock_buy_and_hold",
        "peekOfCode": "class BuyAndHold(Strategy):\n    parameters = {\n        \"buy_symbol\": \"QQQ\",\n    }\n    def initialize(self):\n        self.sleeptime = \"1D\"\n        st.session_state.portfolio_history = []\n        st.session_state.last_trade = \"No trades yet\"\n    def on_trading_iteration(self):\n        buy_symbol = self.parameters[\"buy_symbol\"]",
        "detail": "pages2.stock_buy_and_hold",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage",
        "kind": 6,
        "importPath": "pages2.stock_diversified_leverage",
        "description": "pages2.stock_diversified_leverage",
        "peekOfCode": "class DiversifiedLeverage(Strategy):\n    parameters = {\n        \"portfolio\": [\n            {\"symbol\": \"TQQQ\", \"weight\": 0.20},  # 3x Leveraged Nasdaq\n            {\"symbol\": \"UPRO\", \"weight\": 0.20},  # 3x Leveraged S&P 500\n            {\"symbol\": \"UDOW\", \"weight\": 0.10},  # 3x Leveraged Dow Jones\n            {\"symbol\": \"TMF\", \"weight\": 0.25},   # 3x Leveraged Treasury Bonds\n            {\"symbol\": \"UGL\", \"weight\": 0.10},   # 3x Leveraged Gold\n            {\"symbol\": \"DIG\", \"weight\": 0.15},  # 2x Leveraged Oil and Gas\n        ],",
        "detail": "pages2.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "DiversifiedLeverage.parameters[\"rebalance_period\"]",
        "kind": 5,
        "importPath": "pages2.stock_diversified_leverage",
        "description": "pages2.stock_diversified_leverage",
        "peekOfCode": "DiversifiedLeverage.parameters[\"rebalance_period\"] = rebalance_period\n# Backtest Configuration\nif not live_mode:\n    st.subheader(\" Backtest Period\")\n    col1, col2 = st.columns(2)\n    with col1:\n        start_date = st.date_input(\"Start Date\", datetime(2010, 6, 1))\n    with col2:\n        end_date = st.date_input(\"End Date\", datetime(2023, 7, 31))\n# Live Trading Setup",
        "detail": "pages2.stock_diversified_leverage",
        "documentation": {}
    },
    {
        "label": "LimitAndTrailingStop",
        "kind": 6,
        "importPath": "pages2.stock_limit_and_trailing_stops",
        "description": "pages2.stock_limit_and_trailing_stops",
        "peekOfCode": "class LimitAndTrailingStop(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"limit_buy_price\": 403.0,\n        \"limit_sell_price\": 407.0,\n        \"trail_percent\": 0.02,\n        \"trail_price\": 7.0,\n    }\n    def initialize(self):\n        self.sleeptime = \"1D\"",
        "detail": "pages2.stock_limit_and_trailing_stops",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pages2.stock_limit_and_trailing_stops",
        "description": "pages2.stock_limit_and_trailing_stops",
        "peekOfCode": "def main():\n    # Page Header\n    st.markdown('<div class=\"main-header\"> Limit Orders & Trailing Stops Strategy</div>', unsafe_allow_html=True)\n    # Strategy Description\n    st.markdown(\"\"\"\n        **Strategy Overview**  \n        This strategy demonstrates how to use limit orders and trailing stops to manage trades:\n        - **Limit Orders**: Buy or sell at specific price levels\n        - **Trailing Stops**: Automatically adjust stop-loss levels based on price movements\n        - **Risk Management**: Protects profits and limits losses",
        "detail": "pages2.stock_limit_and_trailing_stops",
        "documentation": {}
    },
    {
        "label": "Momentum",
        "kind": 6,
        "importPath": "pages2.stock_momentum",
        "description": "pages2.stock_momentum",
        "peekOfCode": "class Momentum(Strategy):\n    def initialize(self, symbols=None):\n        self.period = 2\n        self.counter = 0\n        self.sleeptime = 0\n        self.symbols = symbols if symbols else [\"SPY\", \"VEU\", \"AGG\"]\n        self.asset = \"\"\n        self.quantity = 0\n        st.session_state.trade_history = []\n        st.session_state.last_trade = \"No trades yet\"",
        "detail": "pages2.stock_momentum",
        "documentation": {}
    },
    {
        "label": "StockOco",
        "kind": 6,
        "importPath": "pages2.stock_oco",
        "description": "pages2.stock_oco",
        "peekOfCode": "class StockOco(Strategy):\n    parameters = {\n        \"buy_symbol\": \"SPY\",\n        \"take_profit_price\": 405.0,\n        \"stop_loss_price\": 395.0,\n        \"quantity\": 10,\n    }\n    def initialize(self):\n        self.sleeptime = \"1D\"\n        self.counter = 0",
        "detail": "pages2.stock_oco",
        "documentation": {}
    },
    {
        "label": "StockOco.parameters",
        "kind": 5,
        "importPath": "pages2.stock_oco",
        "description": "pages2.stock_oco",
        "peekOfCode": "StockOco.parameters = {\n    \"buy_symbol\": buy_symbol,\n    \"take_profit_price\": take_profit_price,\n    \"stop_loss_price\": stop_loss_price,\n    \"quantity\": quantity,\n}\n# Backtest Configuration\nif not live_mode:\n    st.subheader(\" Backtest Period\")\n    col1, col2 = st.columns(2)",
        "detail": "pages2.stock_oco",
        "documentation": {}
    },
    {
        "label": "Strangle",
        "kind": 6,
        "importPath": "pages2.strangle",
        "description": "pages2.strangle",
        "peekOfCode": "class Strangle(Strategy):\n    \"\"\"Strategy Description: Strangle\n    In a long stranglethe more common strategythe investor simultaneously buys an\n    out-of-the-money call and an out-of-the-money put option. The call option's strike\n    price is higher than the underlying asset's current market price, while the put has a\n    strike price that is lower than the asset's market price. This strategy has large profit\n    potential since the call option has theoretically unlimited upside if the underlying\n    asset rises in price, while the put option can profit if the underlying asset falls.\n    The risk on the trade is limited to the premium paid for the two options.\n    Place the strangle two weeks before earnings announcement.",
        "detail": "pages2.strangle",
        "documentation": {}
    },
    {
        "label": "Strangle.take_profit_threshold",
        "kind": 5,
        "importPath": "pages2.strangle",
        "description": "pages2.strangle",
        "peekOfCode": "Strangle.take_profit_threshold = take_profit_threshold / 100\nStrangle.max_trades = max_trades\nStrangle.max_days_expiry = max_days_expiry\nStrangle.days_to_earnings_min = days_to_earnings_min\n# Execution Control\nif st.button(\" Start Analysis\" if live_mode else \" Run Backtest\"):\n    if live_mode:\n        st.error(\"Live trading is not implemented in this example.\")\n    else:\n        with st.spinner(\" Running backtest...\"):",
        "detail": "pages2.strangle",
        "documentation": {}
    },
    {
        "label": "Strangle.max_trades",
        "kind": 5,
        "importPath": "pages2.strangle",
        "description": "pages2.strangle",
        "peekOfCode": "Strangle.max_trades = max_trades\nStrangle.max_days_expiry = max_days_expiry\nStrangle.days_to_earnings_min = days_to_earnings_min\n# Execution Control\nif st.button(\" Start Analysis\" if live_mode else \" Run Backtest\"):\n    if live_mode:\n        st.error(\"Live trading is not implemented in this example.\")\n    else:\n        with st.spinner(\" Running backtest...\"):\n            results = Strangle.backtest(",
        "detail": "pages2.strangle",
        "documentation": {}
    },
    {
        "label": "Strangle.max_days_expiry",
        "kind": 5,
        "importPath": "pages2.strangle",
        "description": "pages2.strangle",
        "peekOfCode": "Strangle.max_days_expiry = max_days_expiry\nStrangle.days_to_earnings_min = days_to_earnings_min\n# Execution Control\nif st.button(\" Start Analysis\" if live_mode else \" Run Backtest\"):\n    if live_mode:\n        st.error(\"Live trading is not implemented in this example.\")\n    else:\n        with st.spinner(\" Running backtest...\"):\n            results = Strangle.backtest(\n                YahooDataBacktesting,",
        "detail": "pages2.strangle",
        "documentation": {}
    },
    {
        "label": "Strangle.days_to_earnings_min",
        "kind": 5,
        "importPath": "pages2.strangle",
        "description": "pages2.strangle",
        "peekOfCode": "Strangle.days_to_earnings_min = days_to_earnings_min\n# Execution Control\nif st.button(\" Start Analysis\" if live_mode else \" Run Backtest\"):\n    if live_mode:\n        st.error(\"Live trading is not implemented in this example.\")\n    else:\n        with st.spinner(\" Running backtest...\"):\n            results = Strangle.backtest(\n                YahooDataBacktesting,\n                datetime(start_date.year, start_date.month, start_date.day),",
        "detail": "pages2.strangle",
        "documentation": {}
    },
    {
        "label": "legacy_model_path",
        "kind": 5,
        "importPath": "pages2.t1",
        "description": "pages2.t1",
        "peekOfCode": "legacy_model_path = \"Stock-Prediction/models/model0.h5\"\nconverted_model_path = \"Stock-Prediction/models/model0.keras\"\n# Load legacy model\nlegacy_model = load_model(legacy_model_path, compile=False)\n# Save in new format\nlegacy_model.save(converted_model_path)\nprint(f\" Model converted and saved as {converted_model_path}\")",
        "detail": "pages2.t1",
        "documentation": {}
    },
    {
        "label": "converted_model_path",
        "kind": 5,
        "importPath": "pages2.t1",
        "description": "pages2.t1",
        "peekOfCode": "converted_model_path = \"Stock-Prediction/models/model0.keras\"\n# Load legacy model\nlegacy_model = load_model(legacy_model_path, compile=False)\n# Save in new format\nlegacy_model.save(converted_model_path)\nprint(f\" Model converted and saved as {converted_model_path}\")",
        "detail": "pages2.t1",
        "documentation": {}
    },
    {
        "label": "legacy_model",
        "kind": 5,
        "importPath": "pages2.t1",
        "description": "pages2.t1",
        "peekOfCode": "legacy_model = load_model(legacy_model_path, compile=False)\n# Save in new format\nlegacy_model.save(converted_model_path)\nprint(f\" Model converted and saved as {converted_model_path}\")",
        "detail": "pages2.t1",
        "documentation": {}
    },
    {
        "label": "BrokerTest",
        "kind": 6,
        "importPath": "pages2.test_broker_functions",
        "description": "pages2.test_broker_functions",
        "peekOfCode": "class BrokerTest(Strategy):\n    # =====Overloading lifecycle methods=============\n    def initialize(self):\n        # Set the time between trading iterations\n        # strategy runs every 20 seconds.\n        self.sleeptime = \"20S\"\n        # Set the market to 24/7 since those are the hours for the crypto market\n        self.set_market(\"24/7\")\n        # Record the last trade time\n        self.last_trade_time = None",
        "detail": "pages2.test_broker_functions",
        "documentation": {}
    },
    {
        "label": "compute_price_features",
        "kind": 2,
        "importPath": "pages2.util_refactored_step1_2_randomkey",
        "description": "pages2.util_refactored_step1_2_randomkey",
        "peekOfCode": "def compute_price_features(df, close_col, short_window=50, long_window=100):\n    if close_col not in df.columns:\n        st.error(f\" '{close_col}' not found in data.\")\n        return df\n    df[\"SMA_50\"] = df[close_col].rolling(window=short_window, min_periods=1).mean()\n    df[\"EMA_20\"] = df[close_col].ewm(span=20, adjust=False).mean()\n    df[\"SMA_100\"] = df[close_col].rolling(window=long_window, min_periods=1).mean()\n    df[\"% Change\"] = df[close_col].pct_change()\n    df.dropna(inplace=True)\n    return df",
        "detail": "pages2.util_refactored_step1_2_randomkey",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "class BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "UnknownField",
        "kind": 6,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "class UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}\nDATABASE_MAP = dict((value, key)",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "make_introspector",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def make_introspector(database_type, database_name, **kwargs):\n    if database_type not in DATABASE_MAP:\n        err('Unrecognized database, must be one of: %s' %\n            ', '.join(DATABASE_MAP.keys()))\n        sys.exit(1)\n    schema = kwargs.pop('schema', None)\n    DatabaseClass = DATABASE_MAP[database_type]\n    db = DatabaseClass(database_name, **kwargs)\n    return Introspector.from_database(db, schema=schema)\ndef print_models(introspector, tables=None, preserve_order=False,",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "print_models",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def print_models(introspector, tables=None, preserve_order=False,\n                 include_views=False, ignore_unknown=False, snake_case=True):\n    database = introspector.introspect(table_names=tables,\n                                       include_views=include_views,\n                                       snake_case=snake_case)\n    db_kwargs = introspector.get_database_kwargs()\n    header = HEADER % (\n        introspector.get_additional_imports(),\n        introspector.get_database_class().__name__,\n        introspector.get_database_name(),",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "print_header",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def print_header(cmd_line, introspector):\n    timestamp = datetime.datetime.now()\n    print_('# Code generated by:')\n    print_('# python -m pwiz %s' % cmd_line)\n    print_('# Date: %s' % timestamp.strftime('%B %d, %Y %I:%M%p'))\n    print_('# Database: %s' % introspector.get_database_name())\n    print_('# Peewee version: %s' % peewee_version)\n    print_('')\ndef err(msg):\n    sys.stderr.write('\\033[91m%s\\033[0m\\n' % msg)",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "err",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def err(msg):\n    sys.stderr.write('\\033[91m%s\\033[0m\\n' % msg)\n    sys.stderr.flush()\ndef get_option_parser():\n    parser = OptionParser(usage='usage: %prog [options] database_name')\n    ao = parser.add_option\n    ao('-H', '--host', dest='host')\n    ao('-p', '--port', dest='port', type='int')\n    ao('-u', '--user', dest='user')\n    ao('-P', '--password', dest='password', action='store_true')",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "get_option_parser",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def get_option_parser():\n    parser = OptionParser(usage='usage: %prog [options] database_name')\n    ao = parser.add_option\n    ao('-H', '--host', dest='host')\n    ao('-p', '--port', dest='port', type='int')\n    ao('-u', '--user', dest='user')\n    ao('-P', '--password', dest='password', action='store_true')\n    engines = sorted(DATABASE_MAP)\n    ao('-e', '--engine', dest='engine', choices=engines,\n       help=('Database type, e.g. sqlite, mysql, postgresql or cockroachdb. '",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "get_connect_kwargs",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def get_connect_kwargs(options):\n    ops = ('host', 'port', 'user', 'schema')\n    kwargs = dict((o, getattr(options, o)) for o in ops if getattr(options, o))\n    if options.password:\n        kwargs['password'] = getpass()\n    return kwargs\nif __name__ == '__main__':\n    raw_argv = sys.argv\n    parser = get_option_parser()\n    options, args = parser.parse_args()",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "HEADER = \"\"\"from peewee import *%s\ndatabase = %s('%s'%s)\n\"\"\"\nBASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "database",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "database = %s('%s'%s)\n\"\"\"\nBASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "BASE_MODEL",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "BASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "UNKNOWN_FIELD",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "UNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "DATABASE_ALIASES",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "DATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}\nDATABASE_MAP = dict((value, key)\n                    for key in DATABASE_ALIASES\n                    for value in DATABASE_ALIASES[key])\ndef make_introspector(database_type, database_name, **kwargs):",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "DATABASE_MAP",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "DATABASE_MAP = dict((value, key)\n                    for key in DATABASE_ALIASES\n                    for value in DATABASE_ALIASES[key])\ndef make_introspector(database_type, database_name, **kwargs):\n    if database_type not in DATABASE_MAP:\n        err('Unrecognized database, must be one of: %s' %\n            ', '.join(DATABASE_MAP.keys()))\n        sys.exit(1)\n    schema = kwargs.pop('schema', None)\n    DatabaseClass = DATABASE_MAP[database_type]",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "class MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(base_url=BASE_URL, key_id=API_KEY, secret_key=API_SECRET)\n    def position_sizing(self): \n        cash = self.get_cash() \n        last_price = self.get_last_price(self.symbol)",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "API_KEY = \"PKEJH4W0URAU56SHKQW3\" \nAPI_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nBASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "API_SECRET = \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\"\nBASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": API_KEY, \n    \"API_SECRET\": API_SECRET, \n    \"PAPER\": True\n}\nALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "ALPACA_CONFIG",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "ALPACA_CONFIG = {\n    \"API_KEY\":  \"PKEJH4W0URAU56SHKQW3\" ,\n    \"API_SECRET\": \"9g6xpk2x2RiBeV5Cy48WdpxCU51chZx91Lj8x6Ow\",\n    \"PAPER\": True\n}\nclass MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None ",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "start_date = datetime(2020,1,1)\nend_date = datetime(2023,12,31) \nbroker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, ",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "end_date = datetime(2023,12,31) \nbroker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, \n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":.5}",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "broker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, \n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":.5}\n)",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "strategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters={\"symbol\":\"SPY\", \n                                \"cash_at_risk\":.5})\nstrategy.backtest(\n    YahooDataBacktesting, \n    start_date, \n    end_date, \n    parameters={\"symbol\":\"SPY\", \"cash_at_risk\":.5}\n)\ntrader = Trader()",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "trader",
        "kind": 5,
        "importPath": "5_sent_bot",
        "description": "5_sent_bot",
        "peekOfCode": "trader = Trader()\ntrader.add_strategy(strategy)\ntrader.run_all()",
        "detail": "5_sent_bot",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "get_OHLCV_alpaca2",
        "description": "get_OHLCV_alpaca2",
        "peekOfCode": "def alpaca_history(alpaca_API_KEY, alpaca_API_SECRET):\n  from alpaca.data.historical import StockHistoricalDataClient\n  from alpaca.data.requests import StockBarsRequest\n  from alpaca.data.timeframe import TimeFrame\n  client = StockHistoricalDataClient(alpaca_API_KEY, alpaca_API_SECRET)\n  request_params = StockBarsRequest(\n    symbol_or_symbols=[\"AAPL\", \"AXP\"],  # Stock symbol(s) to fetch\n    timeframe=TimeFrame.Day,            # Timeframe: Daily data\n    start=datetime(2025, 1, 1),         # Start date\n    end  =datetime(2025, 3, 16)         # End date",
        "detail": "get_OHLCV_alpaca2",
        "documentation": {}
    },
    {
        "label": "btc_bars",
        "kind": 5,
        "importPath": "get_OHLCV_alpaca2",
        "description": "get_OHLCV_alpaca2",
        "peekOfCode": "btc_bars = alpaca_history(ALPACA_API_KEY, ALPACA_API_SECRET)\nif btc_bars:\n    st.write(btc_bars.df)\nelse:\n    st.write(\" No data retrieved!\")",
        "detail": "get_OHLCV_alpaca2",
        "documentation": {}
    },
    {
        "label": "current_date",
        "kind": 5,
        "importPath": "get_OHLCV_yfinance1",
        "description": "get_OHLCV_yfinance1",
        "peekOfCode": "current_date = datetime.now().strftime(\"%Y-%m-%d\")\nfrom lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL\nimport yfinance as yf\nimport streamlit as st\nfrom datetime import datetime\n# Define the ticker and date range\ntickers = [\"AAPL\"]\nstart_date = \"2022-09-01\"\nend_date = \"2022-09-07\"\n# Fetch data from Yahoo Finance",
        "detail": "get_OHLCV_yfinance1",
        "documentation": {}
    },
    {
        "label": "tickers",
        "kind": 5,
        "importPath": "get_OHLCV_yfinance1",
        "description": "get_OHLCV_yfinance1",
        "peekOfCode": "tickers = [\"AAPL\"]\nstart_date = \"2022-09-01\"\nend_date = \"2022-09-07\"\n# Fetch data from Yahoo Finance\ndata = {ticker: yf.download(ticker, start=start_date, end=end_date) for ticker in tickers}\n# Filter out tickers that failed to download\nvalid_data = {ticker: df for ticker, df in data.items() if not df.empty}\nif valid_data:\n    # Combine the data into a single DataFrame\n    combined_data = pd.concat(valid_data.values(), axis=1, keys=valid_data.keys())",
        "detail": "get_OHLCV_yfinance1",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "get_OHLCV_yfinance1",
        "description": "get_OHLCV_yfinance1",
        "peekOfCode": "start_date = \"2022-09-01\"\nend_date = \"2022-09-07\"\n# Fetch data from Yahoo Finance\ndata = {ticker: yf.download(ticker, start=start_date, end=end_date) for ticker in tickers}\n# Filter out tickers that failed to download\nvalid_data = {ticker: df for ticker, df in data.items() if not df.empty}\nif valid_data:\n    # Combine the data into a single DataFrame\n    combined_data = pd.concat(valid_data.values(), axis=1, keys=valid_data.keys())\n    st.write(combined_data)  # Display the DataFrame in Streamlit",
        "detail": "get_OHLCV_yfinance1",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "get_OHLCV_yfinance1",
        "description": "get_OHLCV_yfinance1",
        "peekOfCode": "end_date = \"2022-09-07\"\n# Fetch data from Yahoo Finance\ndata = {ticker: yf.download(ticker, start=start_date, end=end_date) for ticker in tickers}\n# Filter out tickers that failed to download\nvalid_data = {ticker: df for ticker, df in data.items() if not df.empty}\nif valid_data:\n    # Combine the data into a single DataFrame\n    combined_data = pd.concat(valid_data.values(), axis=1, keys=valid_data.keys())\n    st.write(combined_data)  # Display the DataFrame in Streamlit\nelse:",
        "detail": "get_OHLCV_yfinance1",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "get_OHLCV_yfinance1",
        "description": "get_OHLCV_yfinance1",
        "peekOfCode": "data = {ticker: yf.download(ticker, start=start_date, end=end_date) for ticker in tickers}\n# Filter out tickers that failed to download\nvalid_data = {ticker: df for ticker, df in data.items() if not df.empty}\nif valid_data:\n    # Combine the data into a single DataFrame\n    combined_data = pd.concat(valid_data.values(), axis=1, keys=valid_data.keys())\n    st.write(combined_data)  # Display the DataFrame in Streamlit\nelse:\n    st.write(\" No valid data retrieved! Check ticker names or API availability.\")",
        "detail": "get_OHLCV_yfinance1",
        "documentation": {}
    },
    {
        "label": "valid_data",
        "kind": 5,
        "importPath": "get_OHLCV_yfinance1",
        "description": "get_OHLCV_yfinance1",
        "peekOfCode": "valid_data = {ticker: df for ticker, df in data.items() if not df.empty}\nif valid_data:\n    # Combine the data into a single DataFrame\n    combined_data = pd.concat(valid_data.values(), axis=1, keys=valid_data.keys())\n    st.write(combined_data)  # Display the DataFrame in Streamlit\nelse:\n    st.write(\" No valid data retrieved! Check ticker names or API availability.\")",
        "detail": "get_OHLCV_yfinance1",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        dest=\"mode\",\n        help=\"start mode, train, download_data\" \" backtest\",\n        metavar=\"MODE\",\n        default=\"train\",\n    )\n    return parser",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def check_and_make_directories(directories: List[str]):\n    for directory in directories:\n        if not os.path.exists(\"./\" + directory):\n            os.makedirs(\"./\" + directory)\nos.environ[\"APCA_API_KEY_ID\"] = ALPACA_API_KEY\nos.environ[\"APCA_API_SECRET_KEY\"] = ALPACA_API_SECRET\nos.environ[\"APCA_API_BASE_URL\"] = ALPACA_API_BASE_URL\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n    if options.mode == \"train\":\n        from lib.rl.train import train\n        env = StockTradingEnv\n        kwargs = {\n        }\n        train(",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "streamlit.runtime.scriptrunner_utils._is_running_with_streamlit",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "streamlit.runtime.scriptrunner_utils._is_running_with_streamlit = lambda: True\nfrom typing import List\nfrom argparse import ArgumentParser\nfrom lib.rl import config\nfrom lib.rl.config_tickers import DOW_30_TICKER\nfrom lib.rl.config import (\n    DATA_SAVE_DIR,\n    TRAINED_MODEL_DIR,\n    TENSORBOARD_LOG_DIR,\n    RESULTS_DIR,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "os.environ[\"APCA_API_KEY_ID\"]",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "os.environ[\"APCA_API_KEY_ID\"] = ALPACA_API_KEY\nos.environ[\"APCA_API_SECRET_KEY\"] = ALPACA_API_SECRET\nos.environ[\"APCA_API_BASE_URL\"] = ALPACA_API_BASE_URL\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n    if options.mode == \"train\":\n        from lib.rl.train import train\n        env = StockTradingEnv",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "os.environ[\"APCA_API_SECRET_KEY\"]",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "os.environ[\"APCA_API_SECRET_KEY\"] = ALPACA_API_SECRET\nos.environ[\"APCA_API_BASE_URL\"] = ALPACA_API_BASE_URL\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n    if options.mode == \"train\":\n        from lib.rl.train import train\n        env = StockTradingEnv\n        kwargs = {",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "os.environ[\"APCA_API_BASE_URL\"]",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "os.environ[\"APCA_API_BASE_URL\"] = ALPACA_API_BASE_URL\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n    if options.mode == \"train\":\n        from lib.rl.train import train\n        env = StockTradingEnv\n        kwargs = {\n        }",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "run_backtest",
        "kind": 2,
        "importPath": "ml_stock_chat_sentiment",
        "description": "ml_stock_chat_sentiment",
        "peekOfCode": "def run_backtest():\n    \"\"\"Long-running backtest & live trading in a background thread.\"\"\"\n    try:\n        st.session_state[\"backtest_running\"] = True\n        # Define the backtest period\n        start_date = datetime(2020,1,1)\n        end_date   = datetime(2020,11,12)\n        print(f\"[Thread] Starting backtest from {start_date} to {end_date}...\")\n        # Set up broker and strategy\n        broker = Alpaca(ALPACA_CREDS)",
        "detail": "ml_stock_chat_sentiment",
        "documentation": {}
    },
    {
        "label": "start_background_backtest",
        "kind": 2,
        "importPath": "ml_stock_chat_sentiment",
        "description": "ml_stock_chat_sentiment",
        "peekOfCode": "def start_background_backtest():\n    # Reset old results\n    st.session_state[\"backtest_results\"] = None\n    st.session_state[\"tear_sheet_figure\"] = None\n    # Start a thread to run the backtest\n    worker_thread = threading.Thread(target=run_backtest, args=())\n    worker_thread.start()\n# Button to trigger backtest\n# if st.button(\"Start Backtest\"):\n#     # Prevent multiple backtest runs",
        "detail": "ml_stock_chat_sentiment",
        "documentation": {}
    },
    {
        "label": "ProgressState",
        "kind": 6,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "class ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)\n        self.trading_days = len(dates)\n    def update(self, current_date):",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "DailyProgressStrategy",
        "kind": 6,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "class DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())\n        time.sleep(0.01)  # Allow UI updates",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "backtest_worker",
        "kind": 2,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "def backtest_worker():\n    try:\n        from lumibot.credentials import ALPACA_CREDS\n        broker = Alpaca(\n            ALPACA_CREDS, \n            connect_stream=False\n        )\n        start_date = datetime(2023, 1, 1)\n        end_date = datetime(2023, 12, 31)\n        progress.start_date = start_date",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE']",
        "kind": 5,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE'] = '1'\n# Global progress state\nclass ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "progress",
        "kind": 5,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "progress = ProgressState()\nclass DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "placeholder",
        "kind": 5,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "placeholder = st.empty()\nprogress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "kind": 5,
        "importPath": "progress_test",
        "description": "progress_test",
        "peekOfCode": "progress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition\n        if current_value >= 0.999:",
        "detail": "progress_test",
        "documentation": {}
    },
    {
        "label": "AlpacaBacktesting",
        "kind": 6,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "class AlpacaBacktesting(AlpacaData):\n    \"\"\"Custom Alpaca Backtesting Data Source\"\"\"\n    IS_BACKTESTING_DATA_SOURCE = True  # Correct flag for backtesting\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        config = {\n            'API_KEY': ALPACA_API_KEY,\n            'API_SECRET': ALPACA_API_SECRET,\n            'PAPER': True,\n            'is_backtesting': True  # Explicitly mark as backtesting\n        }",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "MLTrader",
        "kind": 6,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "class MLTrader(Strategy): \n    def initialize(self, symbol:str=\"SPY\", cash_at_risk:float=.5): \n        self.symbol = symbol\n        self.sleeptime = \"24H\" \n        self.last_trade = None \n        self.cash_at_risk = cash_at_risk\n        self.api = REST(base_url=BASE_URL, key_id=API_KEY, secret_key=API_SECRET)\n    def position_sizing(self): \n        cash = self.get_cash() \n        last_price = self.get_last_price(self.symbol)",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "BASE_URL = \"https://paper-api.alpaca.markets\"\nALPACA_CREDS = {\n    \"API_KEY\": ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nclass AlpacaBacktesting(AlpacaData):\n    \"\"\"Custom Alpaca Backtesting Data Source\"\"\"\n    IS_BACKTESTING_DATA_SOURCE = True  # Correct flag for backtesting\n    def __init__(self, datetime_start, datetime_end, **kwargs):",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "ALPACA_CREDS",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "ALPACA_CREDS = {\n    \"API_KEY\": ALPACA_API_KEY, \n    \"API_SECRET\": ALPACA_API_SECRET, \n    \"PAPER\": True\n}\nclass AlpacaBacktesting(AlpacaData):\n    \"\"\"Custom Alpaca Backtesting Data Source\"\"\"\n    IS_BACKTESTING_DATA_SOURCE = True  # Correct flag for backtesting\n    def __init__(self, datetime_start, datetime_end, **kwargs):\n        config = {",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "start_date = datetime(2020, 1, 1)\nend_date = datetime(2023, 12, 31)\nbroker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters = {\"symbol\":\"SPY\", \n                                 \"cash_at_risk\":.5})\n# Run backtest with custom data source\nresults = strategy.backtest(\n    AlpacaBacktesting,\n    start_date,",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "end_date = datetime(2023, 12, 31)\nbroker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters = {\"symbol\":\"SPY\", \n                                 \"cash_at_risk\":.5})\n# Run backtest with custom data source\nresults = strategy.backtest(\n    AlpacaBacktesting,\n    start_date,\n    end_date,",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "broker",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "broker = Alpaca(ALPACA_CREDS) \nstrategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters = {\"symbol\":\"SPY\", \n                                 \"cash_at_risk\":.5})\n# Run backtest with custom data source\nresults = strategy.backtest(\n    AlpacaBacktesting,\n    start_date,\n    end_date,\n    parameters={\"symbol\": \"SPY\", \"cash_at_risk\": 0.5}",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "strategy",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "strategy = MLTrader(name='mlstrat', broker=broker, \n                    parameters = {\"symbol\":\"SPY\", \n                                 \"cash_at_risk\":.5})\n# Run backtest with custom data source\nresults = strategy.backtest(\n    AlpacaBacktesting,\n    start_date,\n    end_date,\n    parameters={\"symbol\": \"SPY\", \"cash_at_risk\": 0.5}\n)",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "t1",
        "description": "t1",
        "peekOfCode": "results = strategy.backtest(\n    AlpacaBacktesting,\n    start_date,\n    end_date,\n    parameters={\"symbol\": \"SPY\", \"cash_at_risk\": 0.5}\n)\nprint(f\"Backtest Results:\\n{results}\")",
        "detail": "t1",
        "documentation": {}
    },
    {
        "label": "ProgressState",
        "kind": 6,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "class ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)\n        self.trading_days = len(dates)\n    def update(self, current_date):",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "DailyProgressStrategy",
        "kind": 6,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "class DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())\n        time.sleep(0.01)  # Allow UI updates",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "backtest_worker",
        "kind": 2,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "def backtest_worker():\n    try:\n        from lumibot.credentials import ALPACA_CREDS\n        broker = Alpaca(\n            ALPACA_CREDS, \n            connect_stream=False\n        )\n        start_date = datetime(2023, 1, 1)\n        end_date = datetime(2023, 12, 31)\n        progress.start_date = start_date",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE']",
        "kind": 5,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE'] = '1'\n# Global progress state\nclass ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "progress",
        "kind": 5,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "progress = ProgressState()\nclass DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "placeholder",
        "kind": 5,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "placeholder = st.empty()\nprogress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "kind": 5,
        "importPath": "t10",
        "description": "t10",
        "peekOfCode": "progress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition\n        if current_value >= 0.999:",
        "detail": "t10",
        "documentation": {}
    },
    {
        "label": "start_fastapi",
        "kind": 2,
        "importPath": "t11",
        "description": "t11",
        "peekOfCode": "def start_fastapi():\n    try:\n        # Check if the FastAPI server is already running\n        import requests\n        response = requests.get(\"http://localhost:8000\")\n        if response.status_code == 200:\n            st.success(\"FastAPI server is already running.\")\n            return\n    except:\n        pass  # If request fails, start the server",
        "detail": "t11",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "t2",
        "description": "t2",
        "peekOfCode": "class BuyAndHold(Strategy):\n    def initialize(self):\n        # Set the symbol to trade (e.g., SPY for S&P 500 ETF)\n        self.symbol = \"SPY\"\n        # Set how often to run the trading logic (daily)\n        self.sleeptime = \"1D\"\n    def on_trading_iteration(self):\n        # Only buy on the first iteration\n        if self.first_iteration:\n            # Get the current price of the asset",
        "detail": "t2",
        "documentation": {}
    },
    {
        "label": "BuyAndHold",
        "kind": 6,
        "importPath": "t3",
        "description": "t3",
        "peekOfCode": "class BuyAndHold(Strategy):\n    parameters = {\n        \"symbol\": \"SPY\",  # Asset to trade\n    }\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Run strategy once per day\n    def on_trading_iteration(self):\n        if self.first_iteration:\n            symbol = self.parameters[\"symbol\"]\n            price = self.get_last_price(symbol)",
        "detail": "t3",
        "documentation": {}
    },
    {
        "label": "SentimentTradingBot",
        "kind": 6,
        "importPath": "t8",
        "description": "t8",
        "peekOfCode": "class SentimentTradingBot(Strategy):\n    def initialize(self, params):\n        self.params = params\n        self.sleeptime = \"1D\"\n        self.set_asset(self.params['symbol'])\n    def on_trading_iteration(self):\n        try:\n            # Get sentiment from chat history\n            latest_news = self.params['news'][-1] if self.params['news'] else \"\"\n            sentiment = sentiment_analyzer(latest_news)[0]",
        "detail": "t8",
        "documentation": {}
    },
    {
        "label": "load_sentiment_model",
        "kind": 2,
        "importPath": "t8",
        "description": "t8",
        "peekOfCode": "def load_sentiment_model():\n    return pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\nsentiment_analyzer = load_sentiment_model()\n# Custom Lumibot Strategy\nclass SentimentTradingBot(Strategy):\n    def initialize(self, params):\n        self.params = params\n        self.sleeptime = \"1D\"\n        self.set_asset(self.params['symbol'])\n    def on_trading_iteration(self):",
        "detail": "t8",
        "documentation": {}
    },
    {
        "label": "sentiment_analyzer",
        "kind": 5,
        "importPath": "t8",
        "description": "t8",
        "peekOfCode": "sentiment_analyzer = load_sentiment_model()\n# Custom Lumibot Strategy\nclass SentimentTradingBot(Strategy):\n    def initialize(self, params):\n        self.params = params\n        self.sleeptime = \"1D\"\n        self.set_asset(self.params['symbol'])\n    def on_trading_iteration(self):\n        try:\n            # Get sentiment from chat history",
        "detail": "t8",
        "documentation": {}
    },
    {
        "label": "ProgressState",
        "kind": 6,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "class ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)\n        self.trading_days = len(dates)\n    def update(self, current_date):",
        "detail": "x",
        "documentation": {}
    },
    {
        "label": "DailyProgressStrategy",
        "kind": 6,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "class DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())\n        time.sleep(0.01)  # Allow UI updates",
        "detail": "x",
        "documentation": {}
    },
    {
        "label": "backtest_worker",
        "kind": 2,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "def backtest_worker():\n    try:\n        from lumibot.credentials import ALPACA_CREDS\n        broker = Alpaca(\n            ALPACA_CREDS, \n            connect_stream=False\n        )\n        start_date = datetime(2023, 1, 1)\n        end_date = datetime(2023, 12, 31)\n        progress.start_date = start_date",
        "detail": "x",
        "documentation": {}
    },
    {
        "label": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE']",
        "kind": 5,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "os.environ['STREAMLIT_RUNNING_IN_BARE_MODE'] = '1'\n# Global progress state\nclass ProgressState:\n    def __init__(self):\n        self.value = 0.0\n        self.lock = threading.Lock()\n        self.trading_days = None\n    def initialize(self, start, end):\n        \"\"\"Calculate actual trading days\"\"\"\n        dates = pd.bdate_range(start=start, end=end)",
        "detail": "x",
        "documentation": {}
    },
    {
        "label": "progress",
        "kind": 5,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "progress = ProgressState()\nclass DailyProgressStrategy(Strategy):\n    def initialize(self):\n        self.sleeptime = \"1D\"  # Match Yahoo's daily data\n        progress.initialize(\n            self.parameters[\"start_date\"],\n            self.parameters[\"end_date\"]\n        )\n    def on_trading_iteration(self):\n        progress.update(self.get_datetime())",
        "detail": "x",
        "documentation": {}
    },
    {
        "label": "placeholder",
        "kind": 5,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "placeholder = st.empty()\nprogress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition",
        "detail": "x",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "kind": 5,
        "importPath": "x",
        "description": "x",
        "peekOfCode": "progress_bar = st.progress(0.0)\n# UI update loop\nwhile True:\n    try:\n        current_value = progress.value\n        progress_bar.progress(current_value)\n        # Update every 100ms\n        time.sleep(0.1)\n        # Exit condition\n        if current_value >= 0.999:",
        "detail": "x",
        "documentation": {}
    }
]