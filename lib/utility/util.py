import pandas as pd
import streamlit as st
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
from alpaca.data.historical import StockHistoricalDataClient
from alpaca.data.requests import StockBarsRequest
from alpaca.data.timeframe import TimeFrame
from alpaca.data.models.bars import BarSet
from alpaca_trade_api import REST
from lib.rl.config_private import ALPACA_API_KEY, ALPACA_API_SECRET
import datetime
import random

import plotly.express as px

FINVIZ_URL = "https://finviz.com/quote.ashx?t="

# üî• Download NLTK dependencies
nltk.download("vader_lexicon")

# üì° Fetch Real-Time Stock Price
import alpaca_trade_api as tradeapi

def get_ticker_start_end_date(index_dict):
    # Select Index Category
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
    with col1:
        selected_index = st.selectbox("üìà Select Index Category:", list(index_dict.keys()))
        TICKERS = index_dict[selected_index]  # Update TICKERS based on selection

    with col2:
        ticker = st.selectbox("üìä Select a Stock Ticker:", TICKERS)

    with col3:
        start_date = st.date_input("üìÖ Start Date", datetime.date(2025, 1, 1))

    with col4:    
        end_date = st.date_input("üìÖ End Date", datetime.date.today())

    col1, col2 = st.columns([2, 1])

    st.subheader("üì° Live Stock Price")
    latest_price = get_real_time_price(ticker)

    if latest_price is None:
        st.warning(f"‚ö†Ô∏è No trade data found for {ticker}. Please select another stock.")
    else:
        st.metric(label=f"{ticker} Price", value=f"${latest_price:.2f}")
    return ticker, start_date, end_date
        
def get_real_time_price(ticker):
    try:
        api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url="https://paper-api.alpaca.markets")
        trade = api.get_latest_trade(ticker)
        return trade.price  # ‚úÖ Return price if trade exists
    except tradeapi.rest.APIError as e:
        print(f"‚ö†Ô∏è Alpaca API Error: {e}")  # ‚úÖ Log the error
        return None  # ‚úÖ Return None if no trade is found

# üîÑ Cached API Client
@st.cache_resource
def get_stock_client():
    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)

# üîÑ Cached API Client
@st.cache_resource
def get_stock_client():
    return StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)

# üìä Fetch Stock Data from Alpaca
@st.cache_data
def fetch_stock_data(ticker, start_date, end_date):
    """Fetch historical stock data from Alpaca."""
    try:
        # client = get_stock_client()
        # request_params = StockBarsRequest(symbol_or_symbols=[ticker], timeframe=TimeFrame.Day, start=start_date, end=end_date)
        # return client.get_stock_bars(request_params)
    
        if not ticker:
            raise ValueError("Ticker is empty or None.")
        
        client = get_stock_client()
        request_params = StockBarsRequest(
            symbol_or_symbols=[ticker.upper()],
            timeframe=TimeFrame.Day,
            start=start_date,
            end=end_date
        )
        return client.get_stock_bars(request_params)    
    except Exception as e:
        st.error(f"‚ö†Ô∏è Error fetching stock data: {e}")
        return None

# üìä Convert Alpaca Data to DataFrame
def convert_alpaca_data_to_df(stock_data):
    """Converts Alpaca BarSet to a Pandas DataFrame for visualization."""
    if isinstance(stock_data, BarSet):
        data_list = []
        for symbol, bars in stock_data.data.items():
            for bar in bars:
                data_list.append({
                    "timestamp": bar.timestamp,
                    "open": bar.open,
                    "high": bar.high,
                    "low": bar.low,
                    "close": bar.close,
                    "volume": bar.volume
                })

        df = pd.DataFrame(data_list)
        df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True)
        df.set_index("timestamp", inplace=True)
        return df
    else:
        return pd.DataFrame()  # Return empty DataFrame to avoid errors

# üì∞ Fetch News Data from Finviz
@st.cache_data
def fetch_news_data(ticker):
    """Retrieve news headlines from Finviz and ensure date values exist."""
    try:
        req = Request(url=FINVIZ_URL + ticker, headers={"user-agent": "Mozilla/5.0"})
        html = BeautifulSoup(urlopen(req), "html.parser")
        news_table = html.find(id="news-table")

        if not news_table:
            st.warning(f"‚ö†Ô∏è No news data found for {ticker}.")
            return None

        news_list = []
        for row in news_table.findAll("tr"):
            if row.a:
                title = row.a.text.strip()
                date_time_text = row.td.text.strip().split()

                # ‚úÖ Ensure we always have a date
                date = date_time_text[1] if len(date_time_text) > 1 else date_time_text[0] if date_time_text else "Unknown"

                news_list.append({"title": title, "date": date})

        return news_list if news_list else None  # Return None if no valid news found

    except Exception as e:
        st.error(f"‚ö†Ô∏è Error fetching news: {e}")
        return None

# üß† Analyze Sentiment from News
@st.cache_data
def analyze_sentiment(news_list):
    if not news_list:
        return None

    df_sentiment = pd.DataFrame(news_list)
    df_sentiment["Date"] = pd.to_datetime(df_sentiment["date"], errors="coerce").dt.date
    df_sentiment["Compound Score"] = df_sentiment["title"].apply(lambda title: SentimentIntensityAnalyzer().polarity_scores(title)["compound"])
    return df_sentiment

# üìä Display Sentiment Summary
def display_sentiment_summary(df_sentiment):
    st.subheader("üìä Sentiment Summary")
    avg_score = df_sentiment["Compound Score"].mean() * 100
    sentiment_icon = "üòä" if avg_score > 10 else "üò¢" if avg_score < -10 else "üòê"
    st.metric(label=f"üí° Average Sentiment Score {sentiment_icon}", value=f"{avg_score:.2f}%")

    summary = {
        "üìà Positive": f"{(df_sentiment['Compound Score'] > 0).sum() / len(df_sentiment) * 100:.2f}%",
        "üìâ Negative": f"{(df_sentiment['Compound Score'] < 0).sum() / len(df_sentiment) * 100:.2f}%",
        "‚öñÔ∏è Neutral": f"{(df_sentiment['Compound Score'] == 0).sum() / len(df_sentiment) * 100:.2f}%"
    }
    st.json(summary)

# üìà Plot Stock Data
def plot_stock_data(stock_data, ticker):
    """Processes stock data and plots it."""
    df_stock = convert_alpaca_data_to_df(stock_data)

    if not df_stock.empty:
        st.subheader(f"üìà {ticker} Stock Price Movements")
        st.line_chart(df_stock[["close"]])
    else:
        st.warning("‚ö†Ô∏è No valid stock data available.")
        
# üìà Compute Moving Averages
def compute_moving_averages(df_stock, close_col):
    """Computes SMA & EMA indicators."""
    df_stock["SMA_50"] = df_stock[close_col].rolling(window=50, min_periods=1).mean()
    df_stock["EMA_20"] = df_stock[close_col].ewm(span=20, adjust=False).mean()
    return df_stock

# üìä Generate Buy/Sell Signals
def generate_trade_signals(df_stock, df_news, close_col):
    if df_stock is None or df_news is None or close_col not in df_stock.columns:
        st.warning("‚ö†Ô∏è Cannot generate trade signals due to missing price or sentiment data.")
        return pd.DataFrame()

    df_news = df_news.copy()
    if "Date" not in df_news.columns and df_news.index.name == "Date":
        df_news = df_news.reset_index()

    df_news["Date"] = pd.to_datetime(df_news["Date"], errors="coerce", utc=True)
    df_news.set_index("Date", inplace=True)

    df_merged = df_stock.merge(
        df_news[["Compound Score"]],
        left_index=True,
        right_index=True,
        how="left"
    )
    df_merged["Buy_Signal"] = ((df_merged[close_col] > df_merged["SMA_50"]) & (df_merged["Compound Score"] > 0)).astype(int)
    df_merged["Sell_Signal"] = ((df_merged[close_col] < df_merged["SMA_50"]) & (df_merged["Compound Score"] < 0)).astype(int)
    return df_merged

# convert_barSet_to_DataFrame
def convert_barSet_to_DataFrame(stock_data, _, ticker):
    if isinstance(stock_data, BarSet):
        data_list = []
        for symbol, bars in stock_data.data.items():
            for bar in bars:
                data_list.append({
                    "timestamp": bar.timestamp,
                    "open": bar.open,
                    "high": bar.high,
                    "low": bar.low,
                    "close": bar.close,
                    "volume": bar.volume
                })

        df = pd.DataFrame(data_list)
        df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True)
        df.set_index("timestamp", inplace=True)

        col_map = {
            "open": f"{ticker}_open",
            "high": f"{ticker}_high",
            "low": f"{ticker}_low",
            "close": f"{ticker}_close",
            "volume": f"{ticker}_volume"
        }

        df.rename(columns=col_map, inplace=True)

        close_col = col_map["close"]
        return df, close_col

    return None, None

def compute_moving_averages(df_stock_, ticker, df_news):
        close_col = f"{ticker}_close" if f"{ticker}_close" in df_stock_.columns else None
        if close_col:
            # ‚úÖ Compute Moving Averages
            df_stock_["SMA_50"] = df_stock_[close_col].rolling(window=50, min_periods=1).mean()
            df_stock_["EMA_20"] = df_stock_[close_col].ewm(span=20, adjust=False).mean()

            # ‚úÖ Convert df_news["Date"] to datetime & set as index
            df_news["Date"] = pd.to_datetime(df_news["Date"], errors="coerce", utc=True)
            df_news.set_index("Date", inplace=True)

            # ‚úÖ Merge Sentiment and Stock Data (Fixed: Ensure both indices are datetime64[ns, UTC])
            df_merged = df_stock_.merge(df_news[["Compound Score"]], left_index=True, right_index=True, how="left")

            # ‚úÖ Generate Buy/Sell Signals
            df_merged["Buy_Signal"] = ((df_merged[close_col] > df_merged["SMA_50"]) & (df_merged["Compound Score"] > 0)).astype(int)
            df_merged["Sell_Signal"] = ((df_merged[close_col] < df_merged["SMA_50"]) & (df_merged["Compound Score"] < 0)).astype(int)

            # ‚úÖ Debugging: Print Buy/Sell Signals to Check if they are valid
            st.write("üîç Buy/Sell Signal Data Preview:", df_merged[["Buy_Signal", "Sell_Signal"]].tail())

            # ‚úÖ Plot Data (Fixed: Use `df_merged` for plotting)
            st.subheader("üìä Buy/Sell Signals & Moving Averages")
            st.line_chart(df_merged[[close_col, "SMA_50", "EMA_20", "Buy_Signal", "Sell_Signal"]])
        else:
            st.warning(f"‚ö†Ô∏è No closing price data available for {ticker}.")
            
def collapsible_detailed_description(s1,s2):          
  with st.expander(s1):
    st.markdown(s2)  
    
@st.cache_data
def fetch_twitter_sentiment(ticker):
    # Placeholder/mock: In real app, integrate Twitter API or snscrape
    mock_data = [
        {"text": f"{ticker} is going to the moon! üöÄ", "sentiment": 0.8},
        {"text": f"I'm not sure about {ticker}, looks weak.", "sentiment": -0.3},
    ]
    df = pd.DataFrame(mock_data)
    df["source"] = "Twitter"
    return df    

@st.cache_data
def fetch_reddit_sentiment(ticker):
    mock_data = [
        {"text": f"{ticker} YOLO play on r/wallstreetbets", "sentiment": 0.7},
        {"text": f"{ticker} is overhyped.", "sentiment": -0.2},
    ]
    df = pd.DataFrame(mock_data)
    df["source"] = "Reddit"
    return df

@st.cache_data
def fetch_google_trends(ticker):
    from pytrends.request import TrendReq
    pytrends = TrendReq()
    kw_list = [ticker]
    pytrends.build_payload(kw_list, timeframe="now 7-d")
    interest = pytrends.interest_over_time()
    if not interest.empty:
        df = interest.reset_index()[["date", ticker]]
        df.rename(columns={ticker: "interest"}, inplace=True)
        return df
    return pd.DataFrame()

# üåç 4. Alternative Data Sources
# üõ†Ô∏è Features Added:
# Integrates Google Trends, Twitter, and Reddit sentiment.
def alternative_data_source():
    from pytrends.request import TrendReq

    pytrends = TrendReq()
    pytrends.build_payload([ticker], timeframe="now 7-d", geo="US")
    trends_data = pytrends.interest_over_time()
    st.subheader("üìä Google Trends Interest")
    st.line_chart(trends_data)

# üí∞ 5. Portfolio Analysis
# üõ†Ô∏è Features Added:
# Tracks multiple stocks.
# Shows portfolio value & profit/loss.
def calculate_portfolio_value(portfolio):
    portfolio = {
    "AAPL": {"quantity": 5, "buy_price": 150},
    "TSLA": {"quantity": 3, "buy_price": 700}
    }

    total_value = 0
    for stock, details in portfolio.items():
        current_price = get_real_time_price(stock)
        total_value += details["quantity"] * current_price
    return total_value

    st.metric("üí∞ Portfolio Value", f"${calculate_portfolio_value(portfolio)}")    
        
# ü§ñ 6. Auto-Trading with Alpaca
# üõ†Ô∏è Features Added:

# Allows placing trades from Streamlit.
# Uses Alpaca‚Äôs paper trading API.
def place_trade(order_type, ticker, qty):
    import alpaca_trade_api as tradeapi

    api = tradeapi.REST(ALPACA_API_KEY, ALPACA_API_SECRET, base_url="https://paper-api.alpaca.markets")
 
    api.submit_order(
        symbol=ticker,
        qty=qty,
        side=order_type,
        type="market",
        time_in_force="gtc"
    )
    st.button("üíµ Buy Stock", on_click=lambda: place_trade("buy", ticker, 1))
    st.button("üìâ Sell Stock", on_click=lambda: place_trade("sell", ticker, 1))
    


# 7. Stock Prediction (üîÆ)
# Use LSTM (Long Short-Term Memory) models to forecast future stock prices.
# Display predictions in a line chart.
def stock_prediction():
    import tensorflow as tf
    from keras.models import Sequential
    from keras.layers import LSTM, Dense

    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
        LSTM(50, return_sequences=False),
        Dense(25),
        Dense(1)
    ])

    model.compile(optimizer="adam", loss="mean_squared_error")
    model.fit(X_train, y_train, epochs=10, batch_size=32)
    
# 8. Daily Market Summary (üì∞)
# Provide a daily summary of market trends.
# Include top gainers, losers, and news highlights.    
def daily_market_summary():
    st.subheader("üìä Market Summary")
    market_summary = {
        "üìà Top Gainer": "NVDA (+12.5%)",
        "üìâ Top Loser": "TSLA (-8.2%)",
        "üîé Market Trend": "Bullish üìà"
    }
    st.json(market_summary)
    
# 3. AI-Based Sentiment Classification (GPT-4)
# üõ†Ô∏è Features Added:

# Uses GPT-4 for advanced sentiment analysis.
# Classifies sentiment beyond just "Positive/Neutral/Negative".   

def get_sentiment_gpt4(news_headline):
    import openai
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": f"Analyze the sentiment of this stock-related news: {news_headline}"}]
    )
    return response["choices"][0]["message"]["content"]

# (function) def load_and_plot_stock_data(
#     ticker: Any,
#     start_date: Any,
#     end_date: Any,
#     plot: bool = True
# ) -> (tuple[None, None] | tuple[DataFrame, str | None])

def load_and_plot_stock_data(ticker, start_date, end_date, plot=True):
    barset = fetch_stock_data(ticker, start_date, end_date)

    if barset is None:
        st.error("‚ö†Ô∏è Failed to fetch stock data.")
        return None, None

    df, close_col = convert_barSet_to_DataFrame(barset, None, ticker)

    if df is None or df.empty or close_col not in df.columns:
        st.warning(f"‚ö†Ô∏è No valid data for {ticker}.")
        return None, None

    if plot:
        chart_key = f"stock_price_chart_{random.randint(1000, 9999)}"
        fig = px.line(df, x=df.index, y=close_col, title=f"{ticker} Stock Price")
        st.plotly_chart(fig, use_container_width=True, key=chart_key)

    return df, close_col


def compute_price_features(df, close_col, short_window=50, long_window=100):
    """
    Compute SMA, EMA, and percentage change on the closing price column.

    Args:
        df (pd.DataFrame): Stock price data.
        close_col (str): Column name for close prices (e.g. 'AAPL_close').
        short_window (int): Window for short-term SMA.
        long_window (int): Window for long-term SMA.

    Returns:
        pd.DataFrame: DataFrame with new SMA, EMA, and % Change columns added.
    """
    if close_col not in df.columns:
        st.error(f"‚ö†Ô∏è '{close_col}' not found in data.")
        return df

    df["SMA_50"] = df[close_col].rolling(window=short_window, min_periods=1).mean()
    df["EMA_20"] = df[close_col].ewm(span=20, adjust=False).mean()
    df["SMA_100"] = df[close_col].rolling(window=long_window, min_periods=1).mean()
    df["% Change"] = df[close_col].pct_change()

    df.dropna(inplace=True)
    return df



 


    